nathanielclizbe@MacBookAir citation-analysis % python3 ref_analysis.py
Loaded 118 paper titles from google sheets.
Found 936 PDFs in Zotero storage
114 PDFs match titles in papers_list.txt
2. Applebaum, B., Beimel, A., Nir, O., Peter, N.: Better secret sharing via robust conditional disclosure of secrets. In: Makarychev, K., Makarychev, Y., Tulsiani, M., Kamath, G., Chuzhoy, J. (eds.), 52nd ACM STOC,  ACM Press, June 2020
5. Asmuth, C., Bloom, J.: A modular approach to key safeguarding. IEEE Trans. Inf. Theory 29(2), 208–210 (1983)
10. Beimel, A., Weinreb, E.: Monotone circuits for monotone weighted threshold func- tions. Inf. Process. Lett. 97(1), 12–18 (2006)
12. Benhamouda, F., Halevi, S., Stambler, L.: Weighted secret sharing from wiretap channels. In: ITC (2023)
14. Breidenbach, L., et al.: Chainlink 2.0: next steps in the evolution of decentralized oracle networks. Chainlink Labs (2021)
21. Ellis, S., Juels, A., Nazarov, S.: Chainlink: a decentralized oracle network. Retrieved March 11(2018), 1 (2017)
23. Franklin, M.K., Yung, M.: Communication complexity of secure computation (extended abstract). In: 24th ACM STOC,  ACM Press, May 1992
26. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or a com- pleteness theorem for protocols with honest majority. In: Aho, A. (ed.), 19th ACM STOC,  ACM Press, May 1987
27. Goldreich, O., Ron, D., Sudan, M.: Chinese remaindering with errors. In: 31st ACM STOC,  ACM Press, May 1999
29. Harn, L., Miao, F.: Weighted secret sharing based on the Chinese remainder the- orem. Int. J. Netw. Secur. 16(6), 420–425 (2014)
30. H˚astad, J., Impagliazzo, R., Levin, L.A., Luby, M.: A pseudorandom generator from any one-way function. SIAM J. Comput. 28(4), 1364–1396 (1999)
31. Iftene, S., Boureanu, I.: Weighted threshold secret sharing based on the Chinese remainder theorem. Sci. Ann. Cuza Univ. 15, 161–172 (2005)
34. Liu, T., Vaikuntanathan, V.: Breaking the circuit-size barrier in secret sharing. In: Diakonikolas, I., Kempe, D., Henzinger, M. (eds.), 50th ACM STOC, ACM Press, June 2018
36. Morillo, P., Padr´o, C., S´aez, G., Villar, J.L.: Weighted threshold secret sharing schemes. Inf. Process. Lett. 70(5), 211–216 (1999)
38. Shamir, A.: How to share a secret. Commun. Assoc. Comput. Mach. 22(11), 612– 613 (1979)
40. Stathakopoulous, C., Cachin, C.: Threshold signatures for blockchain systems. Swiss Federal Institute of Technology, vol. 30 (2017)
43. Yao, A.C.C.: How to generate and exchange secrets (extended abstract). In: 27th FOCS,  IEEE Computer Society Press, October 1986
44. Zou, X., Maino, F., Bertino, E., Sui, Y., Wang, K., Li, F.: A new approach to weighted multi-secret sharing. In: Wang, H., Li, J., Rouskas, G.N., Zhou, X. (eds.), Proceedings of 20th International Conference on Computer Communications and Networks, ICCCN 2011, Maui, Hawaii, USA, July 31–August 4, 2011, IEEE (2011)
7. Albrecht, M.: Sis with hints Zoo (2023). https://malb.io/sis-with-hints.html
16. Brakerski, Z., Vaikuntanathan, V.: Lattice-based FHE as secure as PKE. In: Naor, M. (ed.) ITCS 2014,  ACM (2014)
19. Brakerski, Z., Vaikuntanathan, V.: Lattice-inspired broadcast encryption and suc- cinct ciphertext-policy ABE. In: ITCS, pp. 28:1–28:20 (2022)
20. Canetti, R., et al.: Fiat-Shamir: from practice to theory. In: Charikar, M., Cohen, E. (eds.) 51st ACM STOC,  ACM Press (2019)
25. Cini, V., Wee, H.: Abe for circuits with poly(λ)-sized keys from LWE. In: FOCS (2023)
26. Dong, F., Hao, Z., Mook, E., Wichs, D.: Laconic function evaluation, functional encryption and obfuscation for RAMs with sublinear computation. In: EURO- CRYPT (2024)
31. Goldwasser, S., Kalai, Y.T., Popa, R.A., Vaikuntanathan, V., Zeldovich, N.: Reusable garbled circuits and succinct functional encryption. In: Boneh, D., Rough- garden, T., Feigenbaum, J. (eds.) 45th ACM STOC,  ACM Press (2013)
32. Gorbunov, S., Vaikuntanathan, V., Wee, H.: Attribute-based encryption for cir- cuits. In: Boneh, D., Roughgarden, T., Feigenbaum, J. (eds.) 45th ACM STOC, ACM Press (2013)
34. Gorbunov, S., Vaikuntanathan, V., Wichs, D.: Leveled fully homomorphic signa- tures from standard lattices. In: Servedio, R.A., Rubinfeld, R. (eds.) 47th ACM STOC,  ACM Press (2015)
37. Hsieh, Y.-C., Lin, H., Luo, J.: Attribute-based encryption for circuits of unbounded depth from lattices: garbled circuits of optimal size, laconic functional evaluation, and more. In: FOCS (2023)
42. Quach, W., Wee, H., Wichs, D.: Laconic function evaluation and applications. In: Thorup, M. (ed.) 59th FOCS,  IEEE Computer Society Press (2018)
1. Aggarwal, D., D¨ottling, N., Dujmovic, J., Hajiabadi, M., Malavolta, G., Obremski, M.: Algebraic restriction codes and their applications. In: Braverman, M (ed.) 13th Innovations in Theoretical Computer Science Conference, ITCS 2022, LIPIcs, Berkeley, CA, USA, 31 January–3 February 2022, vol. 215, pp. 2:1–2:15. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2022)
3. Alekhnovich, M.: More on average case versus approximation complexity. In: Pro- ceedings of 44th Symposium on Foundations of Computer Science (FOCS 2003), Cambridge, MA, USA, 11–14 October 2003,  IEEE Computer Society (2003)
9. Banaszczyk, W.: New bounds in some transference theorems in the geometry of numbers. Mathematische Annalen 296(4), 625–636 (1993)
13. Bitansky, N., Khurana, D., Paneth, O.: Weak zero-knowledge beyond the black-box barrier. In: Charikar, M., Cohen, E. (eds.) Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix, AZ, USA, 23–26 June 2019,  ACM (2019)
17. Blum, A., Kalai, A., Wasserman, H.: Noise-tolerant learning, the parity problem, and the statistical query model. J. ACM 50(4), 506–519 (2003)
20. Brakerski, Z., Langlois, A., Peikert, C., Regev, O., Stehl´e, D.: Classical hardness of learning with errors. In: Boneh, D., Roughgarden, T., Feigenbaum, J. (eds.) Symposium on Theory of Computing Conference, STOC 2013, Palo Alto, CA, USA, 1–4 June 2013,  ACM (2013) 652 N. Bitansky and S. Freizeit
23. Brakerski, Z., Vaikuntanathan, V.: Eﬃcient fully homomorphic encryption from (standard) LWE. In: Ostrovsky, R. (ed.) IEEE 52nd Annual Symposium on Foun- dations of Computer Science, FOCS 2011, Palm Springs, CA, USA, 22–25 October 2011,  IEEE Computer Society (2011)
26. Dwork, C., Naor, M.: Zaps and their applications. In: 41st Annual Symposium on Foundations of Computer Science, FOCS 2000, Redondo Beach, California, USA, 12–14 November 2000,  IEEE Computer Society (2000)
27. Even, S., Goldreich, O., Lempel, A.: A randomized protocol for signing contracts. Commun. ACM 28(6), 637–647 (1985)
28. Gentry, C.: Fully homomorphic encryption using ideal lattices. In: Mitzenmacher, M. (ed.) Proceedings of the 41st Annual ACM Symposium on Theory of Comput- ing, STOC 2009, Bethesda, MD, USA, 31 May–2 June 2009,  ACM (2009)
29. Gutfreund, D., Shaltiel, R., Ta-Shma, A.: Uniform hardness versus randomness tradeoﬀs for arthur-merlin games. In: 18th Annual IEEE Conference on Compu- tational Complexity (Complexity 2003), Aarhus, Denmark, 7–10 July 2003,  IEEE Computer Society (2003)
31. Hub´acek, P., Naor, M., Yogev, E.: The journey from NP to TFNP hardness. In: Papadimitriou, C.H. (ed.) 8th Innovations in Theoretical Computer Science Con- ference, ITCS 2017. LIPIcs, Berkeley, CA, USA, vol. 67, pp. 60:1–60:21. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2017)
36. Khurana, D., Sahai, A.: How to achieve non-malleability in one or two rounds. In: Umans, C. (ed.) 58th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2017, Berkeley, CA, USA, 15–17 October 2017,  IEEE Computer Society (2017)
38. Lautemann, C.: BPP and the polynomial hierarchy. Inf. Process. Lett. 17(4), 215– 217 (1983)
40. Miltersen, P.B., Vinodchandran, N.V.: Derandomizing Arthur-Merlin games using hitting sets. In: 40th Annual Symposium on Foundations of Computer Science, FOCS 1999, New York, NY, USA, 17–18 October 1999,  IEEE Computer Society (1999)
41. Naor, M., Pinkas, B.: Eﬃcient oblivious transfer protocols. In: Rao Kosaraju, S. (ed.) Proceedings of the Twelfth Annual Symposium on Discrete Algorithms, Washington, DC, USA, 7–9 January 2001,  ACM/SIAM (2001)
1. Hermez. https://hermez.io
2. Miden. https://github.com/0xPolygonMiden
3. Netpture. https://neptune.cash/
4. Ola. https://ola.ﬁnance
5. Polygon. https://polygon.technology
6. Risc0. https://risc0.com
7. Sandstorm. https://github.com/andrewmilson/sandstorm
8. StarkEx. https://starkware.co/starkex/
10. zkSync. https://zksync.io
11. arkworks: An ecosystem for developing and programming with zkSNARKs . ark- works.rs
13. Arnon, G., Chiesa, A., Yogev, E.: IOPs with inverse polynomial soundness error. In: 64th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2023, Santa Cruz, CA, USA, 6–9 November 2023,  IEEE (2023)
14. Arora, S., Lund, C., Motwani, R., Sudan, M., Szegedy, M.: Proof veriﬁcation and the hardness of approximation problems. J. ACM 45(3), 501–555 (1998). Prelimi- nary version in FOCS ’92
15. Arora, S., Safra, S.: Probabilistic checking of proofs: a new characterization of NP. J. ACM 45(1), 70–122 (1998). Preliminary version in FOCS ’92
16. Babai, L.: Trading group theory for randomness. In: Proceedings of the 17th Annual ACM Symposium on Theory of Computing, STOC 1985, (1985)
17. Babai, L., Fortnow, L., Levin, L.A., Szegedy, M.: Checking computations in poly- logarithmic time. In: Proceedings of the 23rd Annual ACM Symposium on Theory of Computing, STOC 1991,  (1991)
19. Ben-Sasson, E., Carmon, D., Ishai, Y., Kopparty, S., Saraf, S.: Proximity gaps for Reed–Solomon codes. In: Proceedings of the 61st Annual IEEE Symposium on Foundations of Computer Science, FOCS 2020,  (2020) STIR: Reed-Solomon Proximity Testing with Fewer Queries 413
22. Ben-Sasson, E., Goldberg, L., Kopparty, S., Saraf, S.: DEEP-FRI: sampling outside the box improves soundness. In: Proceedings of the 11th Innovations in Theoretical Computer Science Conference, ITCS 2020, pp. 5:1–5:32 (2020)
23. Ben-Sasson, E., Sudan, M.: Short PCPs with polylog query complexity. SIAM J. Comput. 38(2), 551–607 (2008). Preliminary version appeared in STOC ’05
25. Dinur, I.: The PCP theorem by gap ampliﬁcation. J. ACM 54(3), 12 (2007)
26. Feige, U., Goldwasser, S., Lov´asz, L., Safra, S., Szegedy, M.: Interactive proofs and the hardness of approximating cliques. J. ACM 43(2), 268–292 (1996). Preliminary version in FOCS ’91
27. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interac- tive proof systems. SIAM J. Comput. 18(1), 186–208 (1989). Preliminary version appeared in STOC ’85
30. Mie, T.: Short PCPPs veriﬁable in polylogarithmic time with o(1) queries. Ann. Math. Artif. Intell. 56, 313–338 (2009)
31. Reed, I.S., Solomon, G.: Polynomial codes over certain ﬁnite ﬁelds. J. Soc. Ind. Appl. Math. 8(2), 300–304 (1960)
32. Reingold, O., Rothblum, R., Rothblum, G.: Constant-round interactive proofs for delegating computation. In: Proceedings of the 48th ACM Symposium on the The- ory of Computing, STOC 2016,  (2016)
33. Ron-Zewi, N., Rothblum, R.: Local proofs approaching the witness length. In: Proceedings of the 61st Annual IEEE Symposium on Foundations of Computer Science, FOCS 2020,  (2020)
34. Ron-Zewi, N., Rothblum, R.D.: Proving as fast as computing: Succinct arguments with constant prover overhead. In: Proceedings of the 54th ACM Symposium on the Theory of Computing, STOC 2022,  (2022)
[63] to perform abuse reporting or Status
[57] and Slyo
[45] (which isn’t concerned with asynchrony). This state of aﬀairs seems to call for a security analysis within a framework that allows for modular analysis and composable security guarantees. First steps in this direction were taken by 4 the work of Jost, Maurer, and Mularczyk
[1] guarantee secrecy only against a selective adversary that determines ahead of time who and when it will corrupt. There are two prior works that perform composable analyses of Signal. In concurrent work to our own, Bienstock et al.
[12] provide an alternative modeling of an ideal secure messaging within the UC framework and demonstrate how the Signal protocol can be modeled in a way that is shown to realize their formulation of ideal secure messaging. Like this work, they demonstrate several shortcomings of previous formulations, such as overlooking the eﬀect of choosing keys too early or keeping them around for too long. Additionally, Jost, Maurer, and Mularczyk
[12] and
[41] diﬀer from our FSM in several ways. • Diﬀerences between our work and both of [12,41]: Their modeling does not account for the session initiation process, nor the PKI and long-term key modules that are an integral part of any secure messaging application. Additionally, they include the communication medium as part of the protocol, which (a) makes it harder to argue about immediate decryption and (b) means that an instantiation of Signal would have to include an entire TCP/IP stack, which weakens modularity and inhibits the use of Signal as a sub-routine within larger functionali- ties. • Additional diﬀerences with Bienstock et al. [12]: While the modeling of the Signal protocol in
[12] follows the traditional partitioning into continuous key exchange, epoch key derivation and authenticated encryption modules, it does not formalize this partitioning within the UC 14 framework as done in this work; commensurately, they model all key derivation modules as random oracles. Also, their modeling forces the “calling protocol” to keep track of the message IDs for the Secure Messaging functionality/protocol, and assumes uniqueness of the IDs which might create a security risk. On the other hand,
[12] accounts for adversarial choice of randomness, which our modeling does not account for. They also propose and analyze an enhancement of the double ratchet structure, which they call the Triple Ratchet protocol, that helps parties regain security faster following a compromise event. • Additional diﬀerences with Jost, Maurer, and Mularczyk [41]: To model ratcheting compo- nents in a modular fashion,
[41] introduces a global event history deﬁned for the entire real (or ideal) world, where a history is a list of events having happened at a module (e.g. a message being input by Alice or one having leaked to the adversary). The event history is visible to the environment, the resources, and the simulator. The security of a resource is then allowed to depend on the global event history. They make composable statements about continuous key agreement protocols in their model (a notion introduced by Alwen et al. [1]) by restricting the adversaries capabilities in the real world as a function of the global event history. Alternatively, for the case of unrestricted adversaries
1. If no such (τ, α, linking) was recorded, output ⊥.
2. If linking == true then: • Go through program α and link the program by doing the following for all calls to dependencies (τ ′, I): (a) Find the latest (τ ′, α′, linking′) that has been recorded. (b) If no such record exists for a dependency, output ⊥. (c) If linking′ == true then run this compilation on α′ starting at step 2. (d) Inline the code for the calls to α′. (e) If this is the last dependency, record (τ, α, linking = false).
1. Set ikpk pid and rkpk pid as the identity and rotating keys corresponding to pid, respectively, and
2. Output (RecordKeys, pid, Success) to the caller. ReplaceRotatingKey: On input (ReplaceRotatingKey, pid, rkpk pid) from (FLTM, pid), replace the rotating key corre- sponding to pid with rkpk pid and Output (ReplaceRotatingKey, pid, Success). StoreOnetimeKeys: On input (StoreOnetimeKeys, pid, ls) from from (FLTM, pid), do:
1. If the list onetime keyspid corresponding to pid doesn’t exist, then create it.
2. Append ls to onetime keyspid and Output (StoreOnetimeKeys, pid, Success) to the caller. GetInitKeys: On input (GetInitKeys, pidj, pidi): //pidj is the responder and pidi is the initiator.
1. If there is no entry for pidj then output (GetInitKeys, Fail) to the caller.
2. Choose the ﬁrst key okpk pidj from the list onetime keyspidj (If the list is empty then let okpk pid =⊥.)
3. Remove okpk pid from the list onetime keyspid.
4. Output (GetInitKeys, pid, ikpk pid, rkpk pid, okpk pid) to the caller. GetResponseKeys: On input (GetResponseKeys, pidi) from a machine with party id pidj: //pidj is the responder.
1. Send (GetResponseKeys, pidi, ikpk pidi) to the caller. GetRotatingKey: On input (GetRotatingKey, pid), do: If there is no entry for pid then output (GetRotatingKey, Fail) to the caller. Else (GetRotatingKey, pid, rkpk pid) to the caller. Figure 3: The Public-Key Directory Functionality, FDIR FpRO On input (HashQuery, m, ℓ):
1. If there is a record (m, h) • If |h| ≥ℓ: let h′ be the ﬁrst ℓbits of h. //FpRO returns preﬁxes of already-computed entries. • If |h| < ℓ: choose hend $←{0, 1}ℓ−|h|, let h′ = h||hend, and replace the record (m, h) with (m, h′). Else choose h′ $←{0, 1}ℓand record (m, h′).
2. Output (HashQuery, h′) to the caller. On message (Program, m, h) from the adversary:
1. If there is no record (m, h′), then record (m, h). Send (Program) to the adversary. //If m has already been queried then programming fails silently. Figure 4: The Programamble Random Oracle Functionality, FpRO 20 FLTM FLTM is parameterized by a speciﬁc activator program Root, a key derivation function HKDF and key generation function keyGen(), and an algebraic group G. All algebraic operations are done in G. The local session ID is of the form (FLTM, pid). Inputs from senders whose party ID is diﬀerent than pid are ignored. Initialize: On input (Initialize) from (pid, Root) do: If this is not the ﬁrst activation then end the activation. Else:
1. Create an empty list onetime keyspid = [ ]. Also, choose and record the key pairs (iksk pid, ikpk pid), (rksk pid, rkpk pid) $← keyGen(), which will be called the party’s identity key-pair and rotating key-pair, respectively.
2. Provide input (RecordKeys, pid, ikpk pid, rkpk pid) to FDIR. UpdateRotatingKey: On input (UpdateRotatingKey) from (pid, Root), do:
1. Replace the rotating key pair with a new key pair (rksk pid, rkpk pid) $←keyGen().
2. Provide input (ReplaceRotatingKey, pid, rkpk pid) to FDIR. GenOnetimeKeys: On input (GenOnetimeKeys, pid, j) from (pid, Root), do:
1. Choose j new key pairs (oksk 1 , okpk 1 ), . . . , (oksk j , okpk j ) $←keyGen() and append them to onetime keyspid.
2. Provide input (StoreOnetimeKeys, pid, okpk 1 , . . . , okpk j ) to FDIR. ConﬁrmRegistration: On input (ConfirmRegistration) from (FSM, pid) or (ΠSGNL, pid), do:
1. If pid has already called (Initialize), output (ConfirmRegistration, Success).
2. Otherwise output (ConfirmRegistration, Fail). ComputeSendingRootKey: On input (ComputeSendingRootKey, ikpk partner, rkpk partner, okpk partner) from a machine with PID pid and code ΠeKE:
1. Choose an ephemeral key pair (eksk, ekpk) $←keyGen() and compute the following: • DH1 = (rkpk partner)iksk pid //Here (a)b denotes the exponentiation operation in the respective algebraic group. • DH2 = (ikpk partner)eksk • DH3 = (rkpk partner)eksk • DH4 = (okpk partner)eksk
2. Output (ComputeSendingRootKey, HKDF(DH1||DH2||DH3||DH4), ekpk). ComputeReceivingRootKey: On input (ComputeReceivingRootKey, ikpk partner, ekpk partner, okpk) from (ΠeKE, pid) do:
1. If list onetime keyspid does not contain an entry (oksk, okpk) for the given okpk, then output an error message to (ΠeKE, pid).
2. Else, delete the one-time key pair (oksk, okpk) from the list and compute: • DH1 = (ikpk partner)rksk pid • DH2 = (ekpk partner)iksk pid • DH3 = (ekpk partner)rksk pid • DH4 = (ekpk partner)oksk
3. Output (ComputeReceivingRootKey, HKDF(DH1||DH2||DH3||DH4)). Figure 5: The Long-Term Keys Module Functionality, FLTM 21 FSM (Part 1) This functionality has a session id sid = (sid′, pid0, pid1). Inputs arriving from machines whose identity is neither pid0 nor pid1 are ignored. //For notational simplicity we assume some ﬁxed interpretation of pid0 and pid1 as complete identities of the two calling machines. SendMessage: On input (SendMessage, m) from pid: //pid is the extended identity of a party’s machine.
1. Let i be such that pid = pidi.
2. If initialized not set do: //initialization • If pid ̸= pid0, end the activation. Else, send (ConfirmRegistration) to (FLTM, pid). • Upon output (ConfirmRegistration, t) from FLTM: If t = Success, send (GetInitKeys) to FDIR. Else, end the activation. • Upon receiving a response (GetInitKeys, pid1, ikpk 1 , rkpk 1 , okpk 1 ) from FDIR: If okpk 1 ̸= ⊥, continue. Else, end the activation. • Initialize boolean variables initialized = true, diverge parties = false, integer vari- ables (set to 0) epoch num0, sent msgnum0, rcv msgnum0, N self0 = 0 and empty dictionaries advControl, id dict, N dict = {}. //advControl will record which parties are adversarially controlled in each epoch, id dict maps epoch id’s to epoch numbers, and N dict will hold the number of messages sent in each epoch. • For all e ≥0, set N dict[e] = ∞. Set advControl[epoch num0] = ⊥. • Initialize stateI = ⊥and call Flib to obtain the internal code I.
3. Increment sent msgnumi by 1.
4. If leak ∈advControl[epoch numi] ∨diverge parties = true, send backdoor message (stateI, SendMessage, pid, m) to A. Else, run I(stateI, SendMessage, pid, |m|).
5. Upon obtaining (state′ I, SendMessage, pid, epoch id, c) from A or I, continue.
6. Update stateI ←state′ I.
7. If sent msgnumi == 1: //If this is the start of a new sending epoch store the returned epoch id. • If epoch id /∈keys(id dict), record id dict[epoch id] = epoch numi. Else, end the activation.
8. Set h = (epoch id, sent msgnumi, N selfi). //N selfi is the number of messages sent by pidi in its previous sending epoch.
9. If diverge parties = false, record (pid, h, c, m). Else, continue. //If the parties’ states have diverged, then encrypted messages are no longer recorded.
10. Output (SendMessage, sid, pid, h, c) to pid. Corrupt: On input (Corrupt, pid) from Env:
1. If pid /∈{pid0, pid1}, end the activation. Else, continue.
2. Initialize the list corruptionsi if it does not exist.
3. Append (epoch numi, sent msg numi, received msg numi) to the list corruptionsi.
4. For all epochs e ≤epoch numi, set advControl[e] = {leak, Inject} to allow the adversary to inﬂuence messages still in transit.
5. Set advControl[epoch numi+1], advControl[epoch numi+2] = {leak, Inject}. Set advControl[epoch numi+3] = {leak}.
6. Initialize a list pending msgs = []. For each record (pid1−i, h, c, m) do the following: //Make a list of all the messages still in transit to party pid1. (a) If there already was a successful ReceiveMessage for h (i.e there is a record (Authenticate, h, c′, 1) for some c′), continue to the next record. Else, append (pid1−i, h, c, m) to pending msgs.
7. Send a request (stateI, ReportState, i, pending msgs) to A.
8. On receiving (ReportState, i, S) from A, output (Corrupt, S) to Env. (The rest of this functionality is in Fig. 7 on Page 23) Figure 6: The Secure Messaging Functionality FSM 22 FSM (Part 2) (This functionality begins in Fig. 7 on Page 23) ReceiveMessage: On receiving (ReceiveMessage, h = (epoch id, msg num, N), c) from pid, do:
1. Let i be such that pid = pidi.
2. If this is the ﬁrst ReceiveMessage request: //initialize the responder • If i = 1, continue. Else, end the activation. • Send (ConfirmRegistration) to (FLTM, pid). • Upon receiving the output (ConfirmRegistration, t) from FLTM: If t = Success, continue. Else, end activation. • Send (GetResponseKeys, pid0, pid1) to FDIR. • Upon receiving output (GetResponseKeys, pid0, ikpk 0 ) from FDIR, continue. • Initialize the variables sent msgnum1, rcv msgnum1 = 0 and epoch num1 = 1.
3. If there already was a successful ReceiveMessage for h (i.e there is a record (Authenticate, h, c′, 1) for some c′), or this ciphertext previously failed to authenticate (i.e. a record (Authenticate, h, c, 0) exits), output (ReceiveMessage, h, c, Fail) to pid.
4. If epoch id ∈keys(id dict), set temporary variable epoch num = id dict[epoch id]. Else: (a) If sent msgnumi = 0, output (ReceiveMessage, h, c, Fail) to pid. Else, continue. //If pid is in a receiving state and hasn’t sent any messages in its current sending epoch, it will not accept messages with a new epoch id. (b) Set temporary variable epoch num = epoch numi + 1. (c) If leak ∈advControl[epoch num]:a • For epochs e ∈{epoch num, epoch num + 1}: Set advControl[e] = {leak, Inject}. • Add leak to advControl[epoch num + 2]
5. If msg num > N dict[epoch num], output (ReceiveMessage, h, c, Fail) to pid //For epoch num’s that are not ﬁnished yet, the N dict returns a default value of ∞, so this check passes automatically.
6. If diverge parties = false ∧Inject /∈advControl[epoch num], run I(stateI, Inject, pid, h, c). //honest case
7. Else, send backdoor message (stateI, Inject, pid, h, c) to A.
8. On receiving (state′ I, Inject, h, c, v) from A or I: • Update stateI ←state′ I. • If v = ⊥, record (Authenticate, pid, h, c, 0) and output (ReceiveMessage, h, c, Fail). Else, continue. • If diverge parties = false and Inject /∈advControl[epoch num]: //honest case – If there is a record (sender, h, c∗, m) for header h, record (Authenticate, h, c, 1) and set m∗= m. Else, output (ReceiveMessage, h, c, Fail). //allow authentication of a message with a diﬀerent mac in the honest case. • Else: //compromised case – Record (Authenticate, h, c, 1), and set m∗= v. – If epoch id does not appear as a key in id dict then set diverge parties = true. //diverge parties is being set here.
9. If epoch numi < epoch num: //we only get to this step if decryption is successful • Set N dict[epoch num −2] = N, epoch numi += 2, N selfi = sent msgnumi, and sent msgnumi = 0.
10. Output (ReceiveMessage, h, m∗) to pid. aThis provision (which was missing in the
1. Verifying the existence of the instance of FLTM corresponding to the initiator pid0.
2. Checking if the desired peer (pid1) has an available one-time key okpk registered with the directory FDIR.
3. Initiating variables that will record subsequent epoch identiﬁers, message numerals within each epoch, compromised epochs, etc.
4. Initializing internal adversarial state stateI and calling Flib to obtain internal adversarial code I.5 If the local state of FSM indicates that this SendMessage activation is the ﬁrst one in a new epoch, then FSM will have already allowed the ideal-model adversary (namely, the simulator) to choose a new epoch identiﬁer for this epoch within the ReceiveMessage interface. When the epoch is uncompromised, I will have been run internally by FSM to allow the simulator to choose the new epoch identiﬁer. Otherwise the epoch is compromised and FSM will have asked the simulator for a new epoch identiﬁer and waited to receive a response. In both cases FSM will have veriﬁed that the newly chosen identiﬁer is diﬀerent than all previously used ones before continuing. After initialization during the ﬁrst activation and at the start of all subsequent activations, FSM lets the ideal-model adversary choose the ciphertext c that will correspond to m. There are two cases (Case 1: Uncompromised sending epoch.) The functionality allows the simulator to make the choice of ciphertext by running the code I internally with only the length of m as input. (Case 2: Compromised sending epoch.) The message m is leaked in full to the simulator by FSM who then waits for the simulator to send back its chosen ciphertext c. Finally, FSM records (m, c, h) where h is the “header information” that includes the epoch identiﬁer epoch id of the message and the message number msg num in the epoch. The output (c, h) is sent to pid0. As long as the epoch ids are unique, no two records of encrypted messages have the same header information. Indeed, uniqueness is the only property that the epoch ids need to satisfy. 5When no party is compromised, the functionality never hands over control to the simulator. Instead, it allows adversarial choices by internally running the adversarially provided code I. This enables the functionality to achieve immediate decryption. 24 ReceiveMessage. This input allows the receiving party to perform an “idealized authenticated decryption” operation, even though the ciphertext was generated without knowledge of the message and FSM itself has no keying material. Upon the ﬁrst (ReceiveMessage, c, h) input, FSM perform initialization by (1) Verifying that this request is coming from pid1 (2) Verifying that the instance of FLTM that corresponds to pid1 exists, and (3) Verifying that pid0 is registered with FDIR. After initialization during the ﬁrst activation and on all subsequent activations, decryption proceeds with respect to the following cases:
1. if there is an encryption record (m, c, h) for the header h with the exact ciphertext c, then FSM returns the corresponding message m to pid regardless of whether the epoch is compromised.
2. Otherwise, if there is some encryption record (m, c′, h) for the header h with a diﬀerent cipher- text c′ (presumably, c is a “mauled ciphertext”) then FSM gives the adversary the latitude to decide whether decryption should succeed. This behavior combines the standard EU-CMA guarantee for the underlying authentication scheme, combined with one-time decryption. There are two sub-cases 1) Uncompromised receiving epoch. The functionality allows the simulator to decide if the ciphertext c successfully decrypts by running the code I inter- nally and providing it h and c as inputs. If the output of I isn’t ⊥then decryption succeeds and the message m is output. Hence immediate decryption is preserved. 2) Compromised receiving epoch. The ideal-model adversary can cause the receiving party to accept any plaintext of its choosing. To this end, the functionality provides h and c as inputs to the adversary and waits for the adversary to return a plaintext m′ to decrypt to. As long as m′ ̸=⊥, decryption succeeds.
2. This outcome corre- sponds to a weakness in the standalone security of ΠeKE, as it does not include any authen- tication of keys. 6 • If decryption succeeds, the functionality behaves as if both parties are compro- mised for the rest of the session. The success of decryption corresponds to the party starting to receive messages in a new epoch where its peer can never send a message, causing the parties’ states and keys to diverge from each other. In this scenario, FSM notes that the session is forked—or in other words, that the parties’ states have diverged, and the func- tionality then behaves as if both parties are compromised for the rest of the session. This divergence (i.e., fork) event represents a complete break of security for the session. 4 Overview of our Modular Decomposition This work provides a modular analysis of Signal’s protocol. In this section provide more details about our modular, iterative process for decomposing the Signal architecture into a collection of 6This provision was missing in the
1. full state compromise (the party’s entire state is known during epochs e, e+1.) If a party is corrupted during sending epoch e then they will be a receiver in epoch e +
1. Since the party does not add any secret randomness to its state in epoch e + 1, the adversary still knows the party’s entire state at this point.
2. sender’s randomness is updated (epoch e + 2) In epoch e + 2, the corrupted party will update its randomness and send a value epoch ide+2 to their peer. Once their peer conﬁrms the new epoch id, the adversary will be unable to tamper with the communication in a signiﬁcant way; however, full deniability has not been restored.
3. both parties’ randomness is updated (epoch e + 3) In epoch e + 3 the peer will update its randomness and send a value epoch ide+3 to the corrupted party. Once the corrupted party conﬁrms the new epoch id, full deniability will be restored. However, since such a conﬁrmation is evidenced by the start of epoch e + 4, this is the ﬁrst uncompromised epoch after the corruption. The compromise period may be extended further if a party receives a packet with a bogus epoch id that corresponds to some compromised epoch e∗. In this case, one of two things can happen: • If the party does not conﬁrm the bogus epoch id, the compromise extends until epoch e∗+
2. This outcome corresponds to a weakness in the standalone security of ΠeKE, as it does not include any authentication of keys.10 • If the party does conﬁrm the bogus epoch id, the functionality behaves as if both parties are compromised for the rest of the session. The conﬁrmation of a bogus epoch id corresponds to the divergence of the parties’ states and keys. In this scenario, FeKE notes that the parties have diverged, and the functionality then behaves as if both parties are compromised for the rest of the session. 10This provision was missing in the
3. This modiﬁcation is discussed in the remark on Page 51 5.2 The Forward Secure Encryption Functionality Ffs aead The forward secure authenticated encryption functionality (see Figure 15 on page 41) processes encryptions and decryptions for a single epoch (speciﬁed in sid.fs) for the protocol ΠSGNL. As the name suggests, Ffs aead enforces the forward security property for messages encrypted within an epoch. That is, on a state compromise of the receiver for the epoch, the adversary only gets (c, m) pairs for messages that are in transit from the sender to receiver, and it gets the power to replace ciphertexts in transit with authentic-looking ones. Note that once an epoch has been compromised, there is no recovery within the epoch; that is, the adversary retains the power to tamper with in- transit ciphertexts from the epoch until all have arrived at the receiver. Any ciphertexts that the receiver decrypted prior to state compromise are not available to A; this models the forward security property of Signal’s symmetric chain. Encryption On receiving an encryption request for a message m, it sends N (the number of messages sent in the previous sending epoch) and leaks either |m| or m to A (depending on whether the epoch is compromised) and gets a ciphertext c in return, which it records along with m, msg num, N, and the leakage. Note that in the real protocol, the msg num, epoch id, as well as N are authenticated but sent in the clear with each ciphertext. Ffs aead then sends the ciphertext up to the protocol ΠSGNL. Decryption When receiving a decrypt request for ciphertext c and message number msg num, Ffs aead checks whether the receiver has already successfully decrypted this msg num; if so, the msg num was set to inaccessible and Ffs aead will return a failure message to ΠSGNL. Next, Ffs aead checks whether the ciphertext c previously failed authentication for msg num; in this case, the functionality also outputs a failure message to ΠSGNL. If the decryption has not failed from the previous two cases, the functionality sends an Inject message to A. If the state of Ffs aead is not compromised, then A should only be able to Inject the true message m that was encrypted for msg num. In the honest setting (no state corruption), if the adversary returns ⊥or there is no record of an encryption for msg num, Ffs aead returns a failure; otherwise, regardless of which message v the adversary returns, Ffs aead sends m to ΠSGNL. This models the fact that without compromising a party, the real world adversary should not be able to produce ciphertexts that authenticate. In the case that a state compromise has occurred, if A returns some v ̸= ⊥, Ffs aead marks msg num as unavailable and sends v up to ΠSGNL. This models the power that the adversary has after a state compromise (of either party) to tamper with the sender’s ciphertexts to produce authentic-looking ciphertexts. Note that Ffs aead never recovers from a state compromise; thus, the adversary maintains the power to tamper with the ciphertexts for the epoch as long as there are messages from the epoch in transit. 37 FeKE This functionality has a session id sid.eKE that takes the following format: sid.eKE = (“eKE”, sid). Inputs arriving from machines whose identity is neither pid0 nor pid1 are ignored. //For notational simplicity we assume some ﬁxed interpertation of pid0 and pid1 as complete identities of the two calling machines. //The following method is also used by the sender of epoch 0 to start the conversation. ConﬁrmReceivingEpoch: On input (ConfirmReceivingEpoch, epoch id∗) from (ΠSGNL, sid, pidi):
1. If this is the ﬁrst activation, initialize conversation using FDIR, FLTM and get internal code from Flib: (a) Parse sid to retrieve two party ids (pid0, pid1) for the initiator and responder parties and store them. If pid0 ̸= pidi end the activation. (b) Provide input (GetInitKeys, pid1, pid0) to (FDIR). (c) Upon receiving output (GetInitKeys, ikpk 1 , rkpk 1 , okpk 1 ) from (FDIR): i. If okpk pid1 = ⊥then output (ConfirmReceivingEpoch, Fail). //Don’t start the conversation if the one time keys belonging to the other party have run out. ii. Initialize empty lists corruptions0, corruptions1, compromised epochs. iii. Set epoch id partner0 = epoch id self1 = okpk pid1, epoch num0 = −2, and epoch num1 = −1. iv. Send (ComputeSendingRootKey, ikpk 1 , rkpk 1 , okpk 1 ) to FLTM. (d) On receiving (ComputeSendingRootKey, k, ekpk) from FLTM, continue. (e) Initialize stateI = ⊥, call Flib to obtain internal adversarial code IeKE.
2. Else (this is not ﬁrst activation): (a) Set epoch id partneri = epoch id∗. (b) If epoch id∗̸= epoch id self1−i: Set diverge parties = true, run step 3 of Corrupt to set recv chain key∗ and leakage, and send (ReportState, stateI, i, recv chain key∗, leakage) to the adversary. On receiving a response, continue. //diverge parties is set here //If this may be the ﬁrst divergence, make sure the simulator has control.
3. If epoch numi + 2 ∈compromised epochs or diverge parties: Send backdoor message (GenEpochId, i, epoch id∗) to the adversary. Else run I(stateI, GenEpochId, i, epoch id∗). //If the parties are diverged or compromised send a backdoor message to the adversary, otherwise run the internal adversarial code.
4. Upon receiving (GenEpochId, state′ I, i, epoch id) from A or from I, update stateI ←state′ I and do the following: (a) If epoch id is the same as any previous invocation of GenEpochId, end the activation. (b) Set epoch id selfi = epoch id, epoch num dict[epoch id] = epoch numi, got sending keyi = false, and epoch numi +=
2. //save the next sending epoch id. (c) Output (ConfirmReceivingEpoch, epoch id selfi) to (ΠSGNL, sid, pidi). GetSendingKey: On receiving input (GetSendingKey) from (ΠmKE, sid.mKE, pid):
1. Parse sid.mKE = (“mKE”, “fs aead”, sid, epoch id). If epoch id ̸= epoch id selfi end the activation; else set i such that pid = pidi.
2. If got sending keyi = true or ConfirmReceivingEpoch has never been run successfully then end the activation. //the functionality isn’t initialized or the sending key for the current epoch has already been retrieved
3. Sample sending chain keyi $←Kep from the key distribution. //In the honest case, the key is not known to the adversary. Otherwise the key will get overwritten in the following step.
4. If diverge parties = true, or epoch numi ∈compromised epochs send backdoor message (GetSendingKey, i) to the adversary; on receiving backdoor message (GetSendingKey, i, Ksend) from A set sending chain keyi = Ksend. //If the parties are diverged or compromised let the adversary choose sending chain keyi.
5. Set got sending keyi = true and output (GetSendingKey, sending chain keyi). (The rest of this functionality is in Fig. 14 on Page 39) Figure 13: The Epoch Key Exchange Functionality, FeKE 38 FeKE continued... (This functionality begins in Fig. 13 on Page 38) GetReceivingKey: On receiving input (GetReceivingKey, epoch id) from (ΠmKE, sid.mKE, pid):
1. If pid /∈{pid0, pid1} then end this activation. Else, set i such that pid = pidi.
2. If sending chain key1−i has been deleted or ConfirmReceivingEpoch has never been run successfully end the activation.
3. Parse epoch id = (epoch id′, ekpk j , okpk i←j) and sid.mKE = (“mKE”, “fs aead”, sid, epoch id”). If epoch id′ ̸= epoch id” end the activation.
4. If this is the ﬁrst call to GetReceivingKey: (a) If pid1 ̸= pidi, then end the activation. (b) Send (GetResponseKeys, pid1−i) to FDIR. (c) Upon receiving (GetResponseKeys, ikpk j ), send input (ComputeReceivingRootKey, ikpk j , ekpk j , okpk i←j) to FLTM.
5. If diverge parties = true or epoch numi + 1 ∈compromised epochs: //Let A choose key (a) If epoch id ̸= epoch id self1−i add epoch numi + 2, epoch numi + 3 to compromised epochs.a (b) Send (GetReceivingKey, i, epoch id) to the adversary. (c) Upon receiving (GetReceivingKey, i, epoch id, recv chain key∗) from A, output (GetReceivingKey, recv chain key∗).
6. Else, if epoch id ̸= epoch id self1−i: //No corruptions or divergence but epoch id doesn’t match epoch id1−i. (a) Sample recv chain keyi $←Kep. (b) Add (epoch id, recv chain key) to receive attempts[epoch num]. (c) Output (GetReceivingKey, recv chain key).
7. Else, output (GetReceivingKey, sending chain key1−i). //Expected case. Corrupt: On receiving a (Corrupt) request from (ΠSGNL, sid, pidi) for i ∈{0, 1} do:
1. Add epoch id selfi to the list corruptionsi.
2. Add epoch numi, epoch numi + 1, . . . , epoch numi + 3 to the list compromised epochs. //Compromise goes through the following stages: fully compromised for 2-3 epochs, sender randomness up- dated, both parties’ randomness updated. //epoch numi + 5 is protected by forward secrecy even in the case of re-corruption.
3. Let j be such that epoch numj > epoch num1−j and: (a) If got sending keyj = false set recv chain key∗= ⊥. Else set recv chain key∗= sending chain keyj. (b) If epoch numj ∈receive attempts.keys then set leakage = receive attempts[epoch numj]. Else set leakage = [].
4. Send (ReportState, stateI, i, recv chain key∗, leakage) to the adversary.
5. Upon receiving (ReportState, i, S) from A, output (Corrupt, S) to (ΠSGNL, sid, pidi). aThis provision (which was missing in the
1. If this is the ﬁrst activation then: • Let i be such that pid = pidi. Initialize msg num = 0 and sender sender = i. • Initialize stateI = ⊥, call Flib to obtain the internal adversarial code I.
2. Verify that sid matches the one in the local state and pid = pidb, otherwise end the activation.
3. If the sender has deleted the ability to encrypt messages, then end the activation.
4. Increment msg num = msg num + 1.
5. If IsCorrupt? = false: Run I(stateI, Encrypt, pid, N, |m|).
6. If IsCorrupt? = true: Send a backdoor message (stateI, Encrypt, pid, msg num, N, m) to A.
7. On obtaining the output (stateI, Encrypt, pid, c, msg num, N) from I or A, update stateI and record (m, c, msg num, N).
8. Output (Encrypt, c) to (ΠSGNL, sid, pid). Decrypt: On receiving (Decrypt, c, msg num, N) from (ΠSGNL, sid, pid) do:
1. Verify that sid matches the one in the local state and pid = pid1−sender, otherwise end the activation. //end the activation if the decrypt request is not from the receiving party
2. If msg num is set as inaccessible, or there is a record (Authenticate, c, msg num, N, 0), then output (Decrypt, c, msg num, N, Fail) to (ΠSGNL, sid, pid).
3. If IsCorrupt? = false: • Run I(stateI, Authenticate, pid, c, msg num, N) and obtain updated state stateI and output (Authenticate, pid, c, msg num, N, v). • If v = ⊥, then record (Authenticate, c, msg num, N, 0) and output (Decrypt, c, msg num, N, Fail) to (ΠSGNL, sid, pid). • Otherwise, mark msg num as inaccessible and output (Decrypt, c, msg num, N, m) to (ΠSGNL, sid, pid).
4. Else (IsCorrupt? = true): • Send (stateI, Inject, pid, c, msg num, N) to A. • On receiving (stateI, Inject, pid, c, msg num, N, v) from A, update stateI and do: – If v = ⊥, record (Authenticate, c, msg num, N, 0) and output (Decrypt, c, msg num, N, Fail). – Else, then mark msg num as inaccessible and output (Decrypt, c, msg num, N, v) to (ΠSGNL, sid, pid). StopEncrypting: On receiving (StopEncrypting) from (ΠSGNL, sid, pid) do:
1. If sid doesn’t match the one in the local state, if pid ̸= pidsender, or if this is the ﬁrst activation: end the activation.
2. Otherwise, note that pidi has deleted the ability to encrypt future messages. Output (StopEncrypting, Success). StopDecrypting: On receiving (StopDecrypting, msg num∗) from (ΠSGNL, sid, pid) do:
1. If sid doesn’t match the one in the local state, pid ̸= pid1−sender, or no messages have been successfully decrypted by pidi: end the activation.
2. Mark all msg num > msg num∗as inaccessible, and output (StopDecrypting, Success) to (ΠSGNL, sid, pid). Corrupt: On receiving (Corrupt, pid) from (ΠSGNL, sid, pid):
1. Record (Corrupt, pid) and set IsCorrupt? = true.
2. If pid = pid1−sender (pid is the receiver), let leakage = {(pidsender, h = (epoch id, msg num, N), c, m)} be the set of all messages sent by pidsender which are not marked as inaccessible.
3. Otherwise (pid is the sender), set leakage = ∅
4. Send (ReportState, stateI, pid, leakage) to A.
5. Upon receiving a response (ReportState, stateI, pid, S) from A, send S to (ΠSGNL, sid, pid). Figure 15: The Forward-Secure Encryption Functionality Ffs aead 41 receiver’s state if necessary. It then sends a Decrypt request for ciphertext c to the Ffs aead in- stance corresponding to the value epoch id in header h. On receiving a response from Ffs aead, if decryption failed, ΠSGNL outputs a failure message. Otherwise, it updates the list of msg num’s that were skipped in the epoch corresponding to the value epoch id. If the value epoch id is new (i.e. no messages have been received by this party under this value before) then ΠSGNL closes its last sending and receiving epochs (by sending a StopDecrypting request to the Ffs aead in- stance corresponding to epoch idpartner, and a StopEncrypting request to the Ffs aead instance corresponding to epoch idself.) The protocol ΠSGNL then updates epoch idpartner = epoch id and sends (ConfirmReceivingEpoch, epoch id) to FeKE to ratchet forward and receive a new epoch id∗ for its next sending epoch. Finally, ΠSGNL deletes the decrypted message v returned by Ffs aead and outputs the ciphertext c, message v, and header h to pid. Corruption The protocol ΠSGNL has one additional interface, a Corrupt interface that is accessi- ble only to Env. This interface is not part of the real protocol, but is included only for UC-modelling purposes. On a corruption from the environment, ΠSGNL sends Corrupt notiﬁcations to FeKE and to every Ffs aead instance that has messages in transit. These sub-functionalities report their internal states to ΠSGNL who forwards the union of their states up to Env. 5.4 Security Analysis of ΠSGNL In this section we prove Theorem 2 which says that ΠSGNL, FeKE, and Ffs aead together UC-realize FSM in the presence of global functionalities Flib, FLTM, and FDIR. As a reminder, the claim that “A UC-realizes B in the presence of C” means that the envi- ronment’s views are indistinguishable when interacting with A or B, together with their respective adversaries and a global subroutine C. We refer readers to Section 2 for a more detailed primer on the universally composable security framework. Theorem 2 Protocol ΠSGNL (perfectly) UC-realizes the ideal functionality FSM in the presence of Flib, FDIR and FLTM. Proof:To prove Theorem 2, we ﬁrst construct the simulator SSM and the internal code ISM. Then, we argue that the environment Env has an identically distributed view in its interaction with ΠSGNL + Ffs aead + FeKE as it does in its interaction with FSM + SSM + ISM. In an interaction between Env and FSM, the simulator SSM and internal adversarial code ISM are provided with only the information that FSM gives to its ideal process adversary and internal adversarial code. When the session is not compromised, the functionality never calls the simulator SSM. Instead, the only adversarial choices are made when the functionality runs the internal code ISM. The objective of SSM and ISM is to respond in such a way that simulates the artifacts that would be generated if Env were interacting with ΠSGNL. The detailed versions of ISM and SSM can be found in Figure 19 (Page 46) and Figure 17 (Page 44) respectively. Before arguing that the adversary’s view is identical in the two scenarios, we describe where SSM and ISM are called by FSM within each of its methods: • Within SendMessage, as long as initialization has been properly performed then FSM will generate tuple (SendMessage, pid, ℓ) and either run the code ISM on it or send it to SSM based on whether the parties are compromised, diverged, or neither. When the parties are neither compromised nor diverged, ℓ= |m| and the code ISM is run on (SendMessage, pid, ℓ). Otherwise, ℓ= m and the tuple is sent to SSM. 42 ΠSGNL SendMessage: Upon receiving input (SendMessage, m) from pid, do:
1. If this is the ﬁrst activation do: //initialization for the initiator of the session • Parse the local session id sid to retrieve the party identiﬁers (pid0, pid1) for the initiator and responder. If pid0 is diﬀerent from either the local party identiﬁer pid, or the party identiﬁer of pid, end the activation. • Initialize epoch idself = ⊥, epoch idpartner = ⊥, sent msg num = 0, Nlast = 0. • Provide input (ConfirmReceivingEpoch, ⊥) to (FeKE, sid.eKE). • On receiving (ConfirmReceivingEpoch, epoch id) from (FeKE, sid.eKE), set epoch idself = epoch id. • Initialize a list receiving epochs = [].
2. Provide input (Encrypt, m, Nlast) to (Ffs aead, sid.fs), where sid.fs = (sid, epoch idself). //Ffs aead already knows epoch id and msg num
3. On receiving (Encrypt, c, Nlast) from (Ffs aead, sid.fs), delete m, increment sent msg num += 1, output (SendMessage, sid, h, c) to pid, where h = (epoch idself, sent msg num, Nlast). ReceiveMessage: Upon receiving (ReceiveMessage, h = (epoch id, msg num, N), c) from pid:
1. If this is the ﬁrst activation then do: //initialization for the responder of the session • Parse the local session identiﬁer sid to retrieve the party identiﬁers (pid0, pid1) for the initiator and responder. If pid1 is diﬀerent from either the local party identiﬁer, or the party identiﬁer for pid, then end the activation. • Initialize epoch idself = ⊥, epoch idpartner = ⊥, sent msg num = 0 and Nlast = 0, received msg num = 0. • Initialize a dictionary missed msgs = {} and a list receiving epochs = [].
2. Provide input (Decrypt, c, msg num, N) to (Ffs aead, sid.fs = (sid, epoch id)).
3. Upon receiving (Decrypt, c, msg num, N, v) from (Ffs aead, sid.fs): if v = Fail then send (ReceiveMessage, h, ad, Fail) to pid. //Otherwise, v is the decrypted message
4. While msg num > received msg num: //note down any expected messages • Append received msg num to the entry missed msgs[epoch id]. • Increment received msg num+ = 1.
5. If msg num is in the entry missed msgs[epoch id]: • remove it from the list. • If the entry missed msgs[epoch id] is now an empty list then remove epoch id from missed msgs.keys.
6. Else (msg num /∈missed msgs[epoch id]): • If epoch id = epoch idpartner or sent msg num = 0, output (ReceiveMessage, h, c, ⊥). Otherwise continue. //Starting new epoch–ratchet forward • Append the numbers received msg num, . . . , N to the entry missed msgs[epoch id]. • Send (StopDecrypting, N) to (Ffs aead, (sid, epoch idpartner)). //‘Closing’ the Ffs aead for the last epoch. • On receiving (StopDecrypting, Success), update epoch idpartner = epoch id, and send (StopEncrypting) to (Ffs aead, (sid, epoch idself)). • On receiving (StopEncrypting, Success), send (ConfirmReceivingEpoch, epoch id) to (FeKE, sid.eKE). • On receiving (ConfirmReceivingEpoch, epoch id∗), update epoch idself = epoch id∗, Nlast = sent msg num, and sent msg num = 0.
7. Output (ReceiveMessage, h, c, v) to pid while deleting the decrypted message v. Corruption: Upon receiving (Corrupt, pid) from Env: //Note that the Corrupt interface is not part of the “real” protocol; it is only included for modelling purposes.
1. Initialize a list S and send (Corrupt) as input to (FeKE, sid.eKE = “eKE”, sid).
2. On receiving (Corrupt, SeKE) from (FeKE, sid.eKE = “eKE”, sid), add it to S and continue. //now corrupt individual Ffs aead instances.
3. For epoch id ∈missed msgs.keys do: • Send (Corrupt) as input to (Ffs aead, sid.fs = (“fs aead′′, sid, epoch id)). • On receiving Sepoch id, add it to S.
4. Output (Corrupt, pidi, S) to Env. 43 SSM At ﬁrst activation: Send (FSM, I) to Flib. SendMessage: On receiving (stateI, SendMessage, pid, m) from (FSM, sid) do:
1. Set i such that pid = pidi. //this is the identity of the sender
2. If this is the ﬁrst invocation of SendMessage do: • Initialize diverge parties = false, injectable = false, corrupted party = ⊥, sent msg num0 = 0, and sent msg num1 = 0. • Create empty stacks sent ids0 = [] and sent ids1 = []. • Create empty sets injectable ids0 = ∅and injectable ids1 = ∅. • Parse state.eKE from stateI • Send (state.eKE, GenEpochId, i, ⊥) to Env (in the name of (FeKE, sid.eKE)). • Upon receiving (state, GenEpochId, i, epoch id) from Env, update state.eKE ←state and push epoch id onto the stack sent ids0.
3. Set epoch id equal to the top of the stack sent idsi, and increment sent msg numi += 1.
4. Parse state.fs.epoch id from stateI.
5. Send (state.fs.epoch id, Encrypt, pid, sent msg numi, m) to Env (in the name of (Ffs aead, sid.fs), where sid.fs = (“fs aead”, sid, epoch id))
6. On receiving (state, Encrypt, pid, sent msg num, c) from Env: • Update state.fs.epoch id ←state • Add (h, c) ∈sentheaders. • Update sentheaders and sent ids0, sent ids1 in stateI • Send (stateI, SendMessage, pid, epoch id, c) to (FSM, sid) Inject: On receiving (stateI, Inject, pid, h, c) from (FSM, sid) do:
1. Set i such that pid = pidi. //this is the identity of the attempted sender, and pid1−i is the receiver
2. Parse h = (epoch id, msg num, N).
3. Parse state.fs.epoch id from stateI.
4. Send (state.fs.epoch id, Inject, pid, msg num, c) to Env (in the name of (Ffs aead, sid.fs) where sid.fs = (“fs aead”, sid, epoch id)).
5. On receiving (state, Inject, v) from Env, update state.fs.epoch id ←state.
6. If (h, c) /∈sentheaders ∧v = ⊥: output (Inject, h, c, ⊥) to (FSM, sid). //in this case FSM should output Fail, otherwise decryption succeeds
7. If epoch id ̸= sent idsi then set diverge parties = true. //this epoch id was generated by the adversary rather than the sender, and it caused a divergence
8. If this is the ﬁrst successfully received message with this epoch id do: //received ﬁrst message from the sender’s newest epoch • Parse state.eKE from stateI • Send a message (state.eKE, GenEpochId, i, epoch id) to Env (in the name of (FeKE, sid.eKE)) • On receiving (state, GenEpochId, i, epoch id∗), update state.eKE ←state and add epoch id∗to the stack sent ids1−i and add epoch id∗to stateI. //this will be party i’s next epoch id when it next sends a message • If epoch id = sent idsi.top and injectable = true and diverge parties = false and corrupted party = i then: set injectable = false and corrupted party = ⊥. //if party i succeeds in establishing a new sending epoch, the adversary can no longer inject
9. Output (stateI, Inject, h, c, v) to (FSM, sid). (The rest of this simulator is in Fig. 18 on Page 45) Figure 17: Secure Messaging Simulator, SSM 44 SSM continued... (This simulator begins in Fig. 17 on Page 44) ReportState: On receiving (ReportState, pid, pending msgs) from (FSM, sid) do:
1. Set i such that pid = pidi. //this is the identity of the corrupted party
2. Set corrupted party = i, injectable ids0 = sent ids0, injectable ids1 = sent ids1, and initialize an empty list Si.
3. Set recv chain key $←Kep from the key distribution.
4. Send (state.eKE, ReportState, i, recv chain key) to Env (in the name of (FeKE, sid.eKE)).
5. Upon receiving (ReportState, i, S∗) from Env, add S∗to Si.
6. For all epoch id∗such that there exists a header h ∈pending msgs containing epoch id∗: • Send (state.fs.epoch id∗, Corrupt, pid, leakage) to Env (in the name of (Ffs aead, sid.fs) where sid.fs = (“fs aead”, sid, epoch id∗). • Upon receiving a response (Corrupt, pid, S∗) from Env, add S∗to the set Si.
7. Output (stateI, ReportState, pidi, Si) to (FSM, sid). Figure 18: Secure Messaging Simulator SSM continued... • Within ReceiveMessage, after performing several input validation checks (e.g., that the epoch/message header hasn’t been used before) FSM will generate a tuple (state.fs.epoch id, Inject, pid, msg n When the parties are not compromised or diverged, FSM runs the code ISM on the tuple to decide whether the message is authentic. Otherwise, it sends the tuple to SSM to allow it to decide whether the message is authentic or even run a rushing attack to change the mes- sage contents. If this is the ﬁrst successfully received message of a new epoch then ISM/SSM additionally generates a new epoch id for the recipient party to use when it sends its next message. • If the corruption of a party is requested by environment, then FSM calls the simulator’s ReportState method to generate a simulated state for the party which it sends to the envi- ronment in response. In the remainder of this proof, we describe why the actions of SSM and ISM ensure that Env’s view in its interaction with FSM is identically distributed (when treated as a random variable) to its view when interacting with the real protocol ΠSGNL. This argument is divided into two cases based on whether the session is compromised or not. When the session is not compromised, the proof proceeds via induction over the steps of the internal code ISM where we argue that each individual action taken within the internal code maintains the indistinguishability property between the environment’s view in the real and ideal worlds. Likewise, when the session is compromised, the proof proceeds by induction over the steps of the simulator. Observing that corruption, uncorruption, and divergence occur at the same times in FSM and ΠSGNL, on can see that checking the above cases suﬃces to complete the argument that the environment’s view is identical in the real and ideal cases. Note that the simulator SSM may assume that the ﬁrst call made by the environment is to SendMessage and that all subsequent calls to ReceiveMessage use (epoch id, msg num) headers that haven’t been used before and that have valid epoch id. If these constraints do not hold, then we observe by inspection that both FSM and ΠSGNL terminate before ever invoking the ideal-world 45 ISM This internal adversary is only called when no parties are compromised. SendMessage: On receiving (stateI, SendMessage, pid, |m|) from (FSM, sid) do:
1. Set i such that pid = pidi. //this is the identity of the sender
2. If this is the ﬁrst invocation of SendMessage do: • Initialize sent msg num0 = 0, and sent msg num1 = 0. • Create empty stacks sent ids0 = [] and sent ids1 = []. • Create empty sets injectable ids0 = ∅and injectable ids1 = ∅. • Parse state.eKE from stateI • Run IeKE(state.eKE, GenEpochId, i, ⊥) • Upon receiving (state′, GenEpochId, i, epoch id) from Env, update state.eKE ←state′ and push epoch id onto the stack sent ids0.
3. Set epoch id equal to the top of the stack sent idsi, and increment sent msg numi += 1.
4. Parse state.fs.epoch id from stateI.
5. Run Ifsaead(state.fs.epoch id, Encrypt, pid, sent msg numi, |m|) for speciﬁcally (Ifsaead, sid.fs), where sid.fs = (“fs aead”, sid, epoch id)).
6. On receiving (state, Encrypt, pid, sent msg num, c) from Ifsaead: • Update state.fs.epoch id ←state • Add (h, c) ∈sentheaders • Update sentheaders and sent ids0, sent ids1 in stateI • Send (stateI, SendMessage, pid, epoch id, c) to (FSM, sid) Inject: On receiving (stateI, Inject, pid, h, c) from (FSM, sid) do:
1. Set i such that pid = pidi. //this is the identity of the attempted sender, and pid1−i is the receiver
2. Parse h = (epoch id, msg num, N), read in sentheaders and sent ids0, sent ids1 from stateI, and read in state.fs.epoch id from stateI
3. Run Ifsaead(state.fs.epoch id, Inject, pid, msg num, c) speciﬁcally for (Ffs aead, sid.fs) where sid.fs = (“fs aead”, sid, epoch id)).
4. On receiving (state, Inject, v) from I, update state.fs.epoch id ←state.
5. If (h, c) /∈sentheaders ∧(v = ⊥∨(∄c∗s.t. (h, c∗) ∈sentheaders)): output (stateI, Inject, h, c, ⊥) to (FSM, sid). //in this case FSM should output Fail, otherwise decryption succeeds
6. If epoch id ̸= sent idsi then set diverge parties = true. //this epoch id was generated by the adversary rather than the sender, and it caused a divergence
7. If this is the ﬁrst successfully received message with this epoch id do: //received ﬁrst message from the sender’s newest epoch • Parse state.eKE from stateI • Run IeKE(state.eKE, GenEpochId, i, epoch id) • On receiving (state′, GenEpochId, i, epoch id∗), update state.eKE ←state′, add epoch id∗to the stack sent ids1−i and add epoch id∗to stateI. //this will be party i’s next epoch id when it next sends a message
1. If pid′ ̸= pid, then end the activation. Let i be such that pid = pidi.
2. Set temp epoch id partneri = epoch id∗.
3. If this is the ﬁrst activation: • Initialize state variables (root keya, root keyc), epoch id, epoch key, sending chain key = ⊥. • Send (GetInitKeys, pid1−i, pidi) to FDIR. • Upon receiving (GetInitKeys, ikpk j , rkpk j , okpk j←i), if okpk j←i = ⊥ then output (ConfirmReceivingEpoch, Fail). Otherwise, send input (ComputeSendingRootKey, ikpk j , rkpk j , okpk j←i) to FLTM. • Upon receiving (ComputeSendingRootKey, s = (sa, sc), ekpk i ), set (root keya, root keyc) = (sa, sc). • Run the subroutine Compute Sending Chain Key. • Erase ekpk i and output (ConfirmReceivingEpoch, epoch idself||ekpk i ||okpk j←i) to (ΠSGNL, sid, pidi)
4. Else (this is not the ﬁrst activation): • Run the steps in Compute Sending Chain Key. • Output (ConfirmReceivingEpoch, epoch idself) to (ΠSGNL, sid, pidi). GetSendingKey: On receiving input (GetSendingKey) from (ΠmKE, sid.mKE, pid′):
1. If pid′ ̸= pid, or if sending chain key has already been erased, end the activation.
2. Output (GetSendingKey, sending chain key) and erase sending chain key. GetReceivingKey: On receiving input (GetReceivingKey, epoch id) from (ΠmKE, sid, pid′):
1. If pid′ ̸= pid, then end the activation. Otherwise, let i be such that pid = pidi.
2. Set temp epoch id partner = epoch id.
3. If this is the ﬁrst activation: • Initialize state variables (root keya, root keyc), epoch id, epoch key, sending chain key = ⊥. • Parse epoch id = (epoch id′, ekpk j , okpk i←j) and set temp epoch id partner = epoch id′ • Send (GetResponseKeys, pid1−i) to FDIR. • Upon receiving (GetResponseKeys, ikpk j ), send input (ComputeReceivingRootKey, ikpk j , ekpk j , okpk i←j) to FLTM. • Upon receiving (ComputeReceivingRootKey, s = (sa, sc)), set (root keya, root keyc) = (sa, sc).
4. Run the subroutine Compute Receiving Chain Key.
5. Output (GetReceivingKey, temp recv chain key) and erase temp recv chain key. (The rest of this protocol is in Fig. 21 on Page 52) Figure 20: The Epoch Key Exchange Protocol ΠeKE 50 party retrieves it using the GetSendingKey method. (This second update also entails overwriting of old value. This time, the party’s old Diﬃe-Hellman pair is overwritten along with the old root key.) GetSendingKey This method simply outputs the stored sending chain key value and then deletes it. If the value has already been deleted then it does nothing. Now we brieﬂy discuss the initialization of the protocol for each party and the corrupt method that exists only for record keeping purposes. Initiator Initialization The ﬁrst time the initiator runs the ConfirmReceivingEpoch method of ΠeKE, the method must initialize the KDF-chain and the Diﬃe-Hellman ratchet. It then updates both using a randomly chosen Diﬃe-Hellman pair (epoch id′, epoch key′), and temporarily store the produced sending chain key value till the party retrieves it using the GetSendingKey method. To initialize the Diﬃe-Hellman Ratchet, the party retrieves the responder’s keys from directory functionality FDIR using the GetInitKeys method. It can then use the ComputeSendingRootKey method of its long-term memory functionality FLTM to run a triple Diﬃe-Hellman on both parties’ keys. This initializes the Diﬃe-Hellman ratchet and KDF-chain, it also binds the conversation to the longterm identity keys of the two parties. Responder Initialization The ﬁrst time the responder runs the GetReceivingKey method of ΠeKE, the method must initialize the KDF-chain and Diﬃe-Hellman ratchet of the responder in much the same way as the initialization of the Initiator that happens on the its ﬁrst call to ConfirmReceivingEpoch. After this, the steps of the GetReceivingKey method are run like they will be for the rest of the conversation. Corrupt The corrupt method in Figure 20 deﬁnes the model of corruption we are considering. On corruption, ΠeKE returns its internal state containing: (epoch key, epoch idself, epoch idpartner, root key). Note that, as with the other protocols, the Corrupt method is not a “real” interface, but is only record keeping for the purposes of the model. Remark We remark that a simple modiﬁcation to ΠeKE, also mentioned in [1], allows for the protocol to heal even faster with a small increase in communication. This modiﬁed protocol can realize a functionality FeKE that heals in 2 rounds instead of
3. Such a protocol can easily be substituted in place of the current ΠeKE to show that the resulting ΠSGNL + Πaead + Π′ eKE system will realise functionality FSM that heals from corruption in ≥2 rounds. This modiﬁcation has each party use two Diﬃe-Hellman pairs when an epoch turns over, one for the party’s new sending epoch, and one for the other party’s next sending epoch when it responds. This allows both parties to delete the Diﬃe-Hellman exponents corresponding to their sending epochs as soon as they begin. Bienstock et al.
1. If this is the ﬁrst activation start at step 5.
2. Compute a root input root input = Exp(temp epoch idpartner, epoch keyself).
3. Compute the new root key KDF.Advance(root keya, root input) = (root key′ a, root key′ c) and update the value (root keya, root keyc) = (root key′ a, root key′ c).
4. Generate a key pair (epoch keyself, epoch idself) ←keyGen().
5. Compute a new root input root input = Exp(temp epoch idpartner, epoch keyself).
6. Compute the sending chain key KDF.Compute(root keyc, root input) = (root key′ c, sending chain key) and update root keyc = root key′ c.
7. Erase root input. //The old root key is overwritten and therefore erased. The old sending chain key was already erased. Compute Receiving Chain Key:
1. Compute root input = Exp(temp epoch idpartner, epoch keyself).
2. Compute KDF.Compute(root keyc, root input) = (root key′ c, temp recv chain key) and update the value root keyc = root key′ c.
[44] used in the Signal application also meets this deﬁnition of a CPRFG, albeit in the random oracle model.) 6.2.1 Deﬁning the CPRFG The deﬁnition of a Cascaded PRF-PRG (CPRFG) extends the PRF-PRNG model from Alwen et al.
[1] to capture the requirements from a KDF-chain under adaptive corruptions. The beneﬁt of the CPRFG deﬁnition is that it directly requires the exact adaptive properties needed from a KDF-chain as speciﬁed in the Signal architecture
1. If the state is compromised it outputs S(Compute, r) = k and adds the tuple (r, k) to the list computed values.
2. Else (the state is not compromised), it outputs F(r) = k and adds the tuple (r, k) to the list computed values. • On input (Advance, r):
1. The oracle OCPRFG resets computed values = {}.
2. If the state isn’t compromised, OCPRFG updates its state to a new function F $←{f : Rλ →{0, 1}m(λ)} sampled uniformly at random.
1. Parse sc = (s1, s2), and further parse s1 = (bs1, (a1, b1), ..., (ak, bk))
2. If r = ai for some i: set bfs1(root input) = bi and s′ c = sc.
3. Else: (a) bs′ 1 ←Puncture(bs1, r) (b) Update s′ 1 = (bs′ 1, (a1, b1), ..., (ak, bk), (r, fbs1(r)) (c) Compute bfs1(r) ←fbs1(r)
4. Output (s′ c, bfs1(r) ⊕s2) KDF.Advance(sa, r):
1. Output (sa, sc) ←h(gsa(r)) Figure 23: CPRFG Construction Theorem 12 Assume that {f} is a puncturable PRF, {g} is a PRP, and h is a PRG. Then the KDF construction in Figure 23 is a cascaded PRF-PRG. Cascaded PRF-PRG Simulator On input (Compute, r) run the honest KDF.Compute(sc, r) from Figure 23 and update sc accordingly. On input (Advance, r) run the honest KDF.Advance(sa, r) from Figure 23 and update s = (sa, sc) accordingly. On input (computed values, (r, k)) or (computed values, ⊥): • Sample s1, sa $←{0, 1}λ independently and uniformly at random. • Parse computed values = ((a1, b1), . . . , (ak, bk)). • Let b s1 be the result of puncturing s1 at points a1, . . . , ak. • Set s′ 1 = (bs1, (a1, b1), . . . , (ak, bk)). • If (r, k) ̸= ⊥, set s2 = k ⊕ˆfs′ 1(r). • Finally, set sc = (s′ 1, s2) and output s = (sa, sc). On input (Recover): delete state s. Figure 24: Cascaded PRF-PRG Simulator Proof:Consider the simulator SKDF in Figure 24 (on Page 56). We argue that an adversary A that distinguishes between the real and ideal games can be used to break either the fact that {f} is a puncturable PRF (as in [15]), or the fact that {g} is a PRF, or the PRG property of h. The proof uses the following hybrid argument. Let the hybrid experiment H1 i consist of the ideal CPRFG game up to and including the i-th instance of (Advance, ·) or (Recover) in the CPRFG 56 game; all following calls to the game are real. Next, let H2 i consist of the ideal CPRFG game up to the i-th instance of (Advance, ·) or (Recover) and the subsequent calls to the CPRFG game before the next advance; only then do all subsequent calls act as in the real game. Speciﬁcally, if epoch i was not corrupted, the (i + 1)-th (Advance, ·) will use a random root key3 to key g. We will begin with the ﬁrst case. Suppose there is some A that can distinguish H1 i from H2 i (which diﬀer only in whether the operations computed during the i-th epoch are real or ideal). Then, clearly epoch i is not compromised because the simulator ensures that the two hybrids are identical (the simulation is perfect). Then, construct the following adversary APPRF against the puncturable PRF property of f:
1. Emulate the ideal CPRFG game to A up to and including the i-th Advance.
2. Until the next Advance or Compromise: (a) Initialize a list of computed values computed values (b) Let K be the set of possible values for r. (c) For inputs of the form (Compute, r), for some r from A: Query k ←PPRF.Challenge(r) and return k; Also, set K = K \ {r} to puncture this input.
3. If we exited Step 2 with a (Compromise, r∗) for some r∗, query s1 ←PPRF.Constrain(K∪{r∗}), sample s′ 2 and sa uniformly and set s2 = PPRF.Challenge(r∗)⊕ s′
2. Output s = ((s1, s2), sa).
4. If we exited Step 2 with a (Advance, r) for some r, sample (sa, sc) $←{0, 1}λ uniformly.
5. Emulate the real CPRFG game with the state initialized to s for the remaining calls from A.
6. If A outputs “H1 i ”, then output “pseudorandom function”. Otherwise (A outputs H2 i ), output “random function”. Notice that if the function in the PPRF game is pseudorandom, then hybrid H1 i is exactly emulated to A, because the PPRF key is truly random; otherwise, H2 i is perfectly emulated to A. Thus, A’s distinguishing probability is identical to APRF PRG’s. Now, consider the case that A can distinguish between hybrids H2 i−1 and H1 i (which diﬀer only on whether the i-th Advance is real or ideal). Clearly then epoch i is not corrupt because the simulator ensures that the two hybrids are identical (the simulation is perfect) Then, we will construct the following PRF-PRG adversary APRF PRG:
1. Emulate the ideal CPRFG game to A up to the i-th Advance.
2. On the i-th (Advance, ·) or Recover: (a) If (Advance, r) for some r: (sa, sc) ←h(PRF.Challenge(r)). (b) Else (Recover): the PRF key k is known to A, but the r is uniformly random. Set k ←PRG.Challenge().
3. For the remaining calls from A, emulate the real CPRFG game with state initialized to s = (sa, sc). 57
1. If this is the ﬁrst activation: • Set epoch num0 = 0, epoch num1 = −1 in stateI.
2. Else (this is not the ﬁrst activation): • Parse stateI to recover the pair (epoch keyi, epoch idi). • Store old epoch idi = epoch idi and old epoch keyi = epoch keyi in stateI.
3. Sample a new pair (epoch keyi, epoch idi) $←keyGen() and record this pair in stateI.
4. Output (stateI, GenEpochId, i, epoch idi) to (FeKE, sid.eKE). Figure 25: Internal adversarial code IeKE how an honest corruption would go. To ﬂesh out this intuition, let’s start by discussing how the simulator will handle a ReportState request from ΠeKE. ReportState: When the functionality FeKE receives a corruption notiﬁcation from its calling protocol, it will send a request of the form (ReportState, i, recv chain key) to the simulator. The simulator must return ‘the state of pidi’; this state will be returned to the calling protocol and in turn to the adversary. The only variables stored in a party’s state in ΠeKE are epoch keyi, epoch idi, epoch id1−i, s = sa||sc. Note that epoch keyi, epoch idi, and epoch id1−i were chosen by the adversarial code IeKE just like they would be in the real protocol and can be provided as-is. So, the only remaining question is what value s = sa||sc) should the simulator provide. Remember that any sending or receiv- ing chain key not yet provided by FeKE will be chosen by the simulator in the future using these dummy parties who simply run the honest protocol on this provided state. So, the sa||sc pro- duced here only needs to take account past chain keys. Fortunately, because KDF is a cascaded PRF-PRG, the current sa||sc in the state of a party will be unrelated to all previous keys pro- vided by FeKE in most cases and can simply be chosen at random. The only case where s is related to a previous output of FeKE is when the instance of protocol ΠSGNL for pid1−i has already started a sending epoch whose chain key recv chain key has not yet been retrieved from FeKE by the receiving party’s instance (ΠSGNL, sid, pidi). In this case, the provided (sa||sc) must satisfy KDF.Compute(sc, epoch idepoch keyi 1−i ) = −, recv chain key. In these cases only, the functionality will provide recv chain key to the simulator at the time of making the request. On receiving a request containing recv chain key, the simulator will invoke the KDF simulator SKDF that proves the security of KDF; since the KDF protocol is a secure CPRFG, such a simulator SKDF must exist. After pidi is corrupted, the simulator will be able to provide all the keys for the parties by running the instructions for ΠeKE within the dummy parties and using the epoch id∗provided in the GenEpochId requests to know how to ratchet forward to the receiving epochs for each party. Once the functionality ‘heals’ from the corruption, it will stop asking the simulator for keys unless the parties have diverged. If divergence doesn’t occur, the simulator will end the execution of the 59 Simulator SeKE for realizing FeKE SeKE runs only if the parties are diverged, or if the current epoch is compromised (i.e. we’re within the quarantine period for a corruption.) The keyGen(·) and KDF components are the same ones from ΠeKE: (1) keyGen chooses a random Diﬃe-Hellman pair (epoch key, epoch id). (2) The protocol KDF is a CPRFG (Cascaded PRF-PRG). At ﬁrst activation: Send (FeKE, IeKE) to Flib. //GetSendingKey and GetReceivingKey are used as subroutines to answer ReportState and GenEpochId requests. GetSendingKey: On receiving (GetSendingKey, i) from (FeKE, sid.eKE) do:
1. If Viewi.sending chain key exists: • Output (GetSendingKey, i, Viewi.sending chain key) and delete Viewi.sending chain key.
2. Otherwise end the activation. GetReceivingKey: On receiving (GetReceivingKey, i, epoch id) from (FeKE, sid.eKE) do:
1. Set Viewi.temp epoch idpartner = epoch id
2. Compute Viewi.root input = Exp(Viewi.temp epoch idpartner, Viewi.epoch keyself).
3. If diverge parties = false: • If epoch id ̸= View1−i.epoch idself: Add epoch num1−i + 1, epoch num1−i + 2 to compromised epochs. • Run the KDF simulator SKDF(Compute, Viewi.root input) and set the output as Viewi.temp recv chain key.
4. Else (diverge parties = true): • Set Viewi.temp recv chain key = KDF.Compute(Viewi.root key, Viewi.root input).
5. Erase Viewi.root input and Viewi.temp epoch idpartner.
6. Output (GetReceivingKey, i, epoch id, Viewi.temp recv chain key) to (FeKE, sid.eKE) and delete Viewi.temp recv chain key. ReportState: On receiving (ReportState, stateI, pidi, recv chain key∗, leakage) from (FeKE, sid.eKE) do: //This method is run every time FeKE is informed that a party has been corrupted. //recv chain key∗= ⊥if and only if epoch num1−i < epoch numi.
1. Add epoch numi, epoch numi + 1, epoch numi + 2, epoch numi + 3 to the list compromised epochs in stateI.
2. If View0, View1 already exist, output (ReportState, pidi, Viewi) to (FeKE, sid.eKE). Otherwise, continue to create them.
3. Create two dictionaries View0, View1. //This and following steps will run only if the parties weren’t compromised when ReportState was called.
4. From stateI get the variables epoch id0, epoch id1, epoch key0, epoch key1, old epoch id0, old epoch id1.
5. Set the following values in the view objects View0, View1: (a) Set View0.epoch idself = epoch id0, View0.epoch keyself = epoch key0. (b) Set View1.epoch idself = epoch id1, View1.epoch keyself = epoch key1. (c) Let j ∈{0, 1} be such that pidj started the latest sending epoch. (i.e epoch numj > epoch num1−j.) i. Set Viewj.epoch idpartner = epoch id1−j. ii. Set View1−j.epoch idpartner = old epoch idj. iii. Let root input∗= Exp(epoch idj, epoch key1−j). iv. Run SKDF(Compromise, leakage, (root input∗, recv chain key∗)) to get an output root key. v. Set View1−j.root key = root key. vi. If recv chain key∗̸= ⊥, set Viewj.sending chain key = recv chain key∗. vii. Set Viewj.root key = KDF.Advance(root key, root input∗). //Only the receiver tells SKDF to advance. Compute sender’s root key locally.
6. Output (ReportState, pidi, Viewi = {epoch keyself, epoch idself, epoch idpartner, root key}) to (FeKE, sid.eKE). (The rest of this simulator is in Fig. 27 on Page 61) Figure 26: Simulator SeKE for realizing FeKE 60 Simulator SeKE continued... (This simulator begins in Fig. 26 on Page 60) GenEpochId: On receiving (GenEpochId, i, epoch id∗) from (FeKE, sid.eKE) do:
1. Set epoch numi += 2.
2. Set Viewi.epoch idpartner = epoch id∗.
3. Compute root input = Exp(epoch id∗, Viewi.epoch keyself).
4. If diverge parties = false: (a) Run SKDF(Advance, root input). //The receiver will tell SKDF to advance its epoch. //Next, we check if the states have diverged. (b) Compute s = KDF.Advance(Viewi.root key, root input) and set Viewi.root key = s. (c) If Viewi.root key ̸= View1−i.root key then set diverge parties = true. //divergence occurs here
5. Else (diverge parties = true): • Set Viewi.root key = KDF.Advance(Viewi.root key, root input).
6. If epoch numi /∈compromised epochs and diverge parties ̸= true): //If the views are in sync and epoch numi + 1 is the ﬁrst uncompromised epoch after corruption. //Delete the view objects and generate a new epoch id. (a) Sample (Viewi.epoch keyself, Viewi.epoch idself) $←keyGen(). (b) Let j ∈{0, 1} be such that pidj started the latest sending epoch. (i.e epoch numj > epoch num1−j.) (c) Set the following values in stateI: i. epoch idj = Viewj.epoch idself and epoch keyj = Viewj.epoch keyself. ii. epoch id1−j = View1−j.epoch idself and epoch key1−j = View1−j.epoch keyself. iii. old epoch idj = View1−j.epoch idpartner and old epoch id1−j = ⊥. (d) Delete View0, View1 and output (GenEpochId, stateI, i, epoch idi) to (FeKE, sid.eKE).
3. If epoch numi + 2 ∈compromised epochs or diverge parties: Run SeKE(GenEpochId, i, epoch id∗). Send backdoor message (GenEpochId, i, epoch id∗) to the adversary. Else run I(stateI, GenEpochId, i, epoch id∗). GetSendingKey:
4. If diverge parties = true, or epoch numi ∈compromised epochs run SeKE(GetSendingKey, i), on producing output (GetSendingKey, i, Ksend), set sending chain keyi = Ksend. send backdoor message (GetSendingKey, i) to the adversary; on receiving backdoor message (GetSendingKey, i, Ksend) from A set sending chain keyi = Ksend. GetReceivingKey: 5. (a) If epoch id ̸= epoch id self1−i, add epoch numi + 2 to compromised epochs. (b) Run SeKE(GetReceivingKey, i, epoch id). On producing output (GetReceivingKey, i, epoch id, recv chain key∗), output (GetReceivingKey, recv chain key∗). Send (GetReceivingKey, i, epoch id) to the adversary. (c) Upon receiving (GetReceivingKey, i, epoch id, recv chain key∗) from A, output (GetReceivingKey, recv chain key∗). Corrupt:
4. Run SeKE(ReportState, stateI, i, recv chain key∗, leakage). On producing the output (ReportState, i, Viewi) output (Corrupt, Viewi). Send (ReportState, stateI, i, recv chain key∗, leakage) to the adversary.
5. Upon receiving (ReportState, i, Viewi) from A, output (Corrupt, Viewi) to (ΠSGNL, sid, pidi). 63 6.3.2 Hybrid H1 The changes made in this step are very important for setting up the next few hybrids. The two main changes between this hybrid and the previous one are:
1. This hybrid chooses the initial root key completely at random in Step 1d of FeKE, ignoring the output of FLTM.
2. When parties are uncompromised, this hybrid chooses root inputs randomly from G and runs those though a function F : G →Kep (chosen uniformly at random for the corresponding epoch.) Note the exception in the choice of root input that happens for the very ﬁrst sending chain key chosen after the end of a compromise. The random choice of root input in this case corresponds to the Recover interface in the ‘real execution’ of the CPRFG security game. The properties provided to the root input via the DDH assumption on group G are only required for secure recovery. In a later hybrid, this random choice of root input in the case of recovery is replaced with the computation of a Diﬃe-Hellman key as in ΠeKE via a reduction to the DDH assumption on group G. Note that the view of the environment in this hybrid is identically distributed to its view in the previous hybrid: The ﬁrst change doesn’t impact the view of the adversary at all in this hybrid since the initial root key isn’t used anywhere in the rest of this hybrid. Moreover, from the security of the X3DH protocol, the initial root key computed by FLTM is indistinguishable from a randomly chosen initial root key. This will be important in hybrid H3 where a CPRFG protocol KDF is used to choose the chainkeys. The edits to the code of SeKE + IeKE + FeKE are presented in detail below. In particular, the only edits in this hybrid are to the code of FeKE. Recall that this functionality can now access the internal states of IeKE and SeKE; the values epoch idi, epoch keyi referred to below belong to IeKE’s state. These values are used to compute root input for every epoch except when recovering from compromise. 64 FeKE (Hybrid 1) ConﬁrmReceivingEpoch: 1. (d) On receiving (ComputeSendingRootKey, k, ekpk) from FLTM, sample a value sa||sc $←{0, 1}n. continue. 4. (c) Choose a new random function F : G →Kep. (d) Output (ConfirmReceivingEpoch, epoch id selfi) to (ΠSGNL, sid, pidi). GetSendingKey:
3. If there is a tuple (epoch idi, epoch idi−1, chain key) in the list computed values, set sending chain keyi = chain key. Else : Sample sending chain keyi $←Kep from the key distribution. (a) If epoch numi −1 /∈compromised epochs compute root input = Exp(epoch id1−i, epoch keyi). Else choose a random value root input $←G and store the tuple (epoch numi, root input). (b) Compute sending chain keyi = F(root input) and store the tuple (epoch idi, epoch idi−1, sending chain keyi) in the list computed values. GetReceivingKey: 65 6. (a) If there is a tuple (epoch id, epoch idi, chain key) in the list computed values, set recv chain keyi = chain key. Sample recv chain keyi $←Kep. (b) Else: i. Compute root input = Exp(epoch id, epoch keyi). ii. Compute recv chain keyi = F(root input) and store the tuple (epoch id, epoch idi, recv chain keyi) in the list computed values. Note that the changes here closely map to the ideal interface in the CPRFG security game when b =
1. (In the next hybrid, a secure CPRFG KDF will be used instead.) Lemma 13 The view of the environment in H0 is identically distributed to that in hybrid H1. Proof:As mentioned earlier, the ﬁrst change doesn’t impact the view of the adversary at all in this hybrid since the initial root key isn’t used anywhere in the rest of this hybrid. Additionally, the outputs of a function F : G →Kep chosen uniformly at random are identically distribution to chain key $←Kep chosen uniformly at random, this remains true both when root input is sampled randomly and when root input is known. 2 6.3.3 Hybrid H2 (This hybrid uses a CPRFG protocol KDF to choose the output keys.) This hybrid transitions from using a version of the ideal CPRFG game + SKDF to using the actual protocol. In particular, the KDF.Compute and KDF.Advance methods of the KDF are now used to compute the chain keys and update the value s = sa||sc for each party instead functions chosen uniformly at random for each epoch. The detailed edits to the version of SeKE + IeKE + FeKE from the previous hybrid are presented below. The edits in the ﬁrst box pertain to the same lines of code in FeKE as were edited in the previous hybrid. Following that are the edits to SeKE which replace the use of SKDF with the use of the protocol KDF. As before, the values epoch idi, epoch keyi for i ∈{0, 1} belong to IeKE’s state. These values are used to compute root input for every epoch except for during recovery from compromise. FeKE (Hybrid 2) ConﬁrmReceivingEpoch: 1. (d) On receiving (ComputeSendingRootKey, k, ekpk) from FLTM, sample a value sa||sc $←{0, 1}n. 4. (c) If epoch numi −2 /∈compromised epochs, compute root input = Exp(epoch id1−i, epoch keyi). Else, get root input from the tuple (epoch numi, root input). Choose a new random function F : G →Kep. (d) Run KDF.Advance(sa, root input) = s′, and change state s = s′. GetSendingKey:
3. If there is a tuple (epoch idi, epoch idi−1, chain key) in the list computed values, set sending chain keyi = chain key. Else: (a) If epoch numi −1 /∈compromised epochs compute root input = Exp(epoch id1−i, epoch keyi). Else choose a random value root input $←G and store the tuple (epoch numi, root input). (b) Compute sending chain keyi = F(root input) and s Run KDF.Compute(sc, root input) = (s′ c, sending chain keyi) and change state sc = s′ c. Store the tuple (epoch idi, epoch idi−1, sending chain keyi) in the list computed values. 66 GetReceivingKey: 6. (a) If there is a tuple (epoch id, epoch idi, chain key) in the list computed values, set recv chain keyi = chain key. (b) Else: i. Compute root input = Exp(epoch id, epoch keyi). ii. Compute recv chain keyi = F(root input) and s Run KDF.Compute(sc, root input) = (s′ c, recv chain keyi) and update the value sc = s′ c. Store the tuple (epoch id, epoch idi, recv chain keyi) in the list computed values. SeKE (Hybrid 2) GetReceivingKey:
3. If diverge parties = false: • Run the KDF simulator SKDF(Compute, Viewi.root input). Set the output as Viewi.temp recv chain key.
4. Else (diverge parties = true): • Set Viewi.temp recv chain key = KDF.Compute(Viewi.root key, Viewi.root input). ReportState: 5. (c) iv. Run SKDF(Compromise, leakage, (root input∗, recv chain key∗)) to get an output root key. v. Set View1−j.root key = sa||scroot key. GenEpochId: 4. (a) Run SKDF(Advance, root input). 6. (c) Set sa||sc = View1−j.root key. (d) Delete the objects View0, View1 and output (GenEpochId, stateI, i, epoch idi) to (FeKE, sid.eKE). 7. (c) Let sa||sc = Viewi.root key and compute KDF.Compute(sc, Viewi.root input) = s′ c, k. If diverge parties = false, run SKDF(Compute, root input) and set Viewi.sending chain key to be its output. (d) Update Viewi.sending chain key = k and Viewi.root key = sa||s′ c. Else (diverge parties = true), set Viewi.sending chain key = KDF.Compute(Viewi.root key, root input). This hybrid is indistinguishable from the previous one because our KDF is a secure CPRFG. This is proved via a reduction to the security of the KDF protocol. An environment that can distinguish this hybrid from the previous one can be used to build an adversary that wins the CPRFG security game from Figure 22. Lemma 14 Assume that KDF is a CPRFG. Then the view of the environment in hybrid H1 is computationally indistinguishable from that in hybrid H2. A: FeKE (proof of Lemma 14) ConﬁrmReceivingEpoch: 1. (d) On receiving (ComputeSendingRootKey, k, ekpk) from FLTM, initialise OCPRFG. sample a value sa||sc $←{0, 1}n. 4. (c) If epoch numi −2 /∈compromised epochs, compute root input = Exp(epoch id1−i, epoch keyi). Else, get root input from the tuple (epoch numi, root input). (d) Send (Advance, root input) to OCPRFG. 67 Run KDF.Advance(sa, root input) = s′, and change state s = s′. //If epoch numi ∈compromised epochs, recovery just occurred so the epoch was advanced by the other party calling the GetSendingKey method. GetSendingKey:
3. If there is a tuple (epoch idi, epoch idi−1, chain key) in the list computed values, set sending chain keyi = chain key. Else: (a) If epoch numi −1 /∈compromised epochs compute root input = Exp(epoch id1−i, epoch keyi). and send (Compute, root input) to the oracle OCPRFG. Else send (Recover) to the oracle OCPRFG. choose a random value root input $←G and store the tuple (epoch numi, root input). (b) Run KDF.Compute(sc, root input) = (s′ c, sending chain keyi) and change state sc = s′ c. S On getting a response sending chain keyi, store the tuple (epoch idi, epoch idi−1, sending chain keyi) in the list computed values. GetReceivingKey: 6. (a) If there is a tuple (epoch id, epoch idi, chain key) in the list computed values, set recv chain keyi = chain key. (b) Else: i. Compute root input = Exp(epoch id, epoch keyi). ii. If epoch idi /∈compromised epochs, then send (Compute, root input) to the oracle OCPRFG for the CPRFG security game and get an output chain key. Else, run KDF.Compute(sc, root input) = (s′ c, recv chain keyi) and update the value sc = s′ c. Store the tuple (epoch id, epoch idi, recv chain keyi) in the list computed values. A: SeKE (proof of Lemma 14) GetReceivingKey:
3. If diverge parties = false: • Send (Compute, Viewi.root input) to OCPRFG Run the KDF simulator SKDF(Compute, Viewi.root input) and set the output as Viewi.temp recv chain key.
1. Because the DDH assumption holds for group G, no PPT adversary A can distinguish whether b = 0 or b = 1 with advantage greater than negligible in the security parameter λ. 69 Say that there exists a distinguishing environment D that can distinguish between H2 and H3 with non-negligible probability. Then D can be used by an adversary A to win the DDH distin- guishing game with non-negligible advantage. The adversary A is constructed diﬀerently on a case by case basis but in both cases the adversary A will respond to requests from D by running the instructions for FeKE + SeKE + IeKE from H3 up to epoch k −1 and from H2 starting epoch k + 1 for some value k. Also in both cases A will choose the root input for epoch k to be gz from the challenge triple (gx, gy, gz), and the epoch ids for epochs k −1 and k to be gx and gy respectively. (Since A not doesn’t have the secret exponent for the epoch gx, it chooses the root input for epoch k −1 to be (gx)a where a is the known secret exponent for epoch k −2.) Instructions for A in both cases:
1. If there is some environment D that successfully distinguishes between hybrids H2 and H3 with non-negligible probability in the parameter λ, then it can also distinguish neighboring hybrids Hk−1 3 and Hk 3 for at least one k. First, ﬁnd such a k.
2. When the parties are compromised, simply follow the code of hybrid H2 (which is the same as hybrid HM 3 .)
3. When the parties are not compromised follow the instructions below to choose root inputs for all epochs and to choose epoch ids for epochs k −1 and k. All the rest of the code of hybrids H2 and HM 3 is the same, so follow it exactly. • Up to epoch k, choose root inputs to be real Diﬃe-Hellman keys. • During epoch k, choose root input gz from the challenge triple (gx, gy, gz). Correspond- ingly, choose epoch ids gx, gy for epochs k −1 and k respectively. (choose the root input for epoch k −1 to be (gx)a where a is the known secret exponent for epoch k −2) • For each epoch starting k + 1, randomly sample a fresh root input h $←G. Case 1: The probability that epoch k is compromised by D is higher in one of the two hybrids Hk−1 3 and Hk 3 by an amount that is non-negligible in λ. If epoch k is compromised by D signiﬁcantly more often in one of the two hybrids, then the adversary can win the DDH distinguishing game by choosing its outputs as below: 3 If D takes any actions that cause epoch k to be compromised, stop and output 1, other- wise output a randomly chosen bit at the end of the execution. (The actions that could cause epoch k to be compromised include: 1) corrupting the party in epochs epoch num∗+ 1, epoch num∗, epoch num∗−1, epoch num∗−2, epoch num∗−3, 2) diverging the parties 3) sending bogus epoch ids to the receiver of epoch k−2 or k−1 while the epoch is compromised.) Pr[A(gx, gy, gxy) = 1] −Pr[A(gx, gy, gz) = 1] = Pr[epoch k compromised in Hk−1 3 ] −Pr[epoch k compromised in Hk 3 ] Case 2: Now, if the probability that epoch k is compromised D in hybrid Hk−1 3 is within a negligible distance of the probability that epoch k is compromised in hybrid Hk 3 , then this can be used by A to win the DDH distinguishing game by choosing its outputs as follows: 70 3 If D takes any actions that cause epoch k to be compromised, then stop and output a randomly chosen bit, otherwise wait till D stops, and then produce the same output that D produces. Let the event that epoch k is compromised be cprm and let the event that epoch k is not compromised be ¬ cprm. Note that when epoch k is compromised then the hybrids Hk−1 3 and Hk 3 are identical. So, an environment D that corrupts epoch k roughly the same amount in hybrids Hk 3 and Hk+1 3 must have that Pr[D(Hk+1 3 ) = 1 | cprm] −Pr  D(Hk 3 ) = 1 | cprm  = negl(λ) for some negligible function negl(·). Therefore, Pr[A(gx, gy, gxy) = 1] −Pr[A(gx, gy, gz) = 1] = Pr[D(Hk+1 3 ) = 1 | ¬ cprm] −Pr[D(Hk 3 ) = 1 | ¬ cprm] = Pr[D(Hk+1 3 ) = 1] −Pr[D(Hk 3 ) = 1] −negl(λ) Given that epoch k is not compromised, the environment’s view is exactly as in Hk−1 3 when b = 0 and Hk 3 when b =
1. If this is the ﬁrst activation, • Parse sid to recover the two party ids (pid0, pid1). • Initialize dictionary key dict and variables IsCorrupt? = false, msg num0, msg num1 = 0. //If this epoch is corrupted then this isn’t the ﬁrst activation because there was already a (Corrupt) request. //msg numi is the largest message number whose key has abeen successfully retrieved by pidi.
2. If there is record (Retrieved, i, msg num) or a record (StopKeys, i, N) for N < msg num, end the activation.
3. If IsCorrupt? = false: • If msg num ∈key dict.keys, set k = key dict[msg num]. • Else (msg num /∈key dict.keys), set k $←{0, 1}λ.
4. Else (IsCorrupt? = true): • Send (RetrieveKey, pid, msg num) to the the adversary. • Upon receiving (RetrieveKey, pid, k) from the adversary, continue.
5. Store key dict[msg num] = k.
6. If msg num > msg numi, set msg numi = msg num. //msg numi is the largest message number whose key has abeen successfully retrieved by pidi.
7. Record (Retrieved, i, msg num) and output (RetrieveKey, pid, k) to (Πaead, sid.aead). StopKeys: On receiving (StopKeys, N) from (Πfs aead, sid.fs = (“fs aead”, sid, epoch id, b), pid), • Run steps 2-6 of RetrieveKey for all msg num such that msg numi < msg num ≤N. • Record (StopKeys, i, N) and output (StopKeys, Success). Corruption: On receiving (Corrupt) from (Πfs aead, sid.fs = (“fs aead”, sid, epoch id, b), pid):
1. Let i be such that pid = pidi.
2. Set IsCorrupt? = true, create empty lists keys in transit, pending msgs.
3. For all msg num ∈ key dict.keys, if there is no record (Retrieved, i, msg num) then append (msg num, key dict[msg num]) to keys in transit and append msg num to pending msgs.
4. If there is a record (StopKeys, i, N) set stop request = (StopKeys, i, N), Else set stop request = ⊥.
5. Send (ReportState, i, keys in transit, msg num0, msg num1, stop request) to A.
6. On receiving a response (ReportState, i, S) from A, output (Corrupt, S) to (Πfs aead, sid.fs, pidi). Figure 28: The Message Key Exchange Functionality FmKE 73 Faead This functionality has a session id sid.aead = (“aead′′, sid.fs, msg num) where sid.fs = (“fs aead”, sid = (sid′, pid0, pid1), epoch id). Inputs arriving from machines whose identity is neither pid0 nor pid1 are ignored. //For notational simplicity we assume some ﬁxed interpretation of pid0 and pid1 as complete identities of the two calling machines. Encryption: On receiving (Encrypt, m, N) from (Πfs aead, sid.fs, pid):
1. Let i be such that pid = pidi.
2. If this is not the ﬁrst encryption request end the activation.
3. If IsCorrupt? = true, Send a backdoor message (stateI, Encrypt, pid, m, N) to A.
4. Else (IsCorrupt? = false): • Provide input (RetrieveKey, pid) to (FmKE, sid.mKE, pid). • Upon receiving output (RetrieveKey, pid, k) from (FmKE, sid.mKE, pid), if k =⊥then end the activation. //The key is not available. • Initialize stateI = ⊥, call Flib to obtain the internal code I, and run I(stateI, Encrypt, pid, |m|, N).
5. Upon obtaining (stateI, Encrypt, pid, c) from A or I, record the tuple (c, m, N, 1), record the sender S = i, and set ready2decrypt = true.
6. Output (Encrypt, c) to (Πfs aead, sid.fs, pid). Decryption: On receiving (Decrypt, c, N) from (Πfs aead, sid.fs, pid):
1. If IsCorrupt? = false: • If there isn’t a stored key k, provide input (RetrieveKey, pid) to (FmKE, sid.mKE, pid). Upon obtaining a response (RetrieveKey, pid, k) from FmKE: Store k. • If there hasn’t been a successful encryption request or pid ̸= pidS−i, output (Decrypt, Fail) to (Πfs aead, sid.fs, pid).
2. If k = ⊥, if ready2decrypt = false, or if there is a record (c, N, 0), output (Decrypt, Fail) to (Πfs aead, sid.fs, pid). //Failure of decryption can occur for an honest receiver so we need an explicit failure notiﬁcation.
3. If there is a record (c, m, N, 1), note ready2decrypt = false and output (Decrypt, m).
4. If IsCorrupt? = false: • Run I(stateI, Authenticate, pid, c, N) to obtain the output (stateI, v). • If v = ⊥then record (c, N, 0), and output (Decrypt, Fail). Else, note ready2decrypt = false, and output (Decrypt, m).
5. Else (IsCorrupt? = true): • Send backdoor message (stateI, Inject, pid, c, N) to A. • Upon receiving response (stateI, Inject, pid, c, N, v) from A: If v = ⊥then record (c, N, 0), and output (Decrypt, Fail). Else output (Decrypt, v) to (Πfs aead, sid.fs, pid). Corruption: On receiving (Corrupt) from (Πfs aead, sid.fs, pid):
1. Provide input (RetrieveKey, pid) to (FmKE, sid.mKE, pid).
2. Upon obtaining a response (RetrieveKey, pid, k) from FmKE, store k.
3. If a message m was successfully decrypted then set m∗= m, otherwise, set m∗= ⊥.
4. Set IsCorrupt? to true, and send (ReportState, stateI, pid, k, m∗) to A.
1. Check that sid matches the one in the local session ID, and that pid matches the local party id, else abort.
2. If this is the ﬁrst activation then initialize curr msg num = 0.
3. Increment curr msg num+ = 1.
4. Send (Encrypt, m, N) to (Faead, sid.aead = (“aead”, sid.fs, msg num)) and delete m.
5. Upon receiving (Encrypt, c), output (Encrypt, c) to (ΠSGNL, sid, pid). Decrypt: On receiving (Decrypt, c, msg num, N) from (ΠSGNL, sid, pid) do:
1. Check that sid matches the one in the local session ID, and that pid matches the local party id, else abort.
2. If this is the ﬁrst activation then initialize curr msg num = 0, pending msgs = [].
3. Send (Decrypt, c, N) to (Faead, sid.aead = (“aead”, sid.fs, msg num)).
4. Upon receiving (Decrypt, v), if v = Fail then output (Decrypt, Fail) to (ΠSGNL, sid, pid).
5. Otherwise (v ̸= Fail): • While curr msg num < msg num: – Increment curr msg num+ = 1. – Add curr msg num to pending msgs. • Remove msg num from pending msgs and output (Decrypt, v) to (ΠSGNL, sid, pid). StopEncrypting: On receiving (StopEncrypting) from (ΠSGNL, sid, pid) do:
1. Check that sid matches the one in the local session ID, and that pid matches the local party id, else abort.
2. Send (StopKeys, msg num) to (FmKE, sid.mKE).
3. On receiving (StopKeys, Success), output (StopEncrypting, Success) to (ΠSGNL, sid, pid). StopDecrypting: On receiving (StopDecrypting, msg num∗) from (ΠSGNL, sid, pid) do:
1. Check that sid matches the one in the local session ID, and that pid matches the local party id, else abort.
2. Send (StopKeys, msg num∗) to (FmKE, sid.mKE).
3. On receiving (StopKeys, Success): • While curr msg num < msg num∗: – Increment curr msg num+ = 1. – Add curr msg num to pending msgs. • Output (StopDecrypting, Success) to (ΠSGNL, sid, pid). Corruption: On receiving (Corrupt) from (ΠSGNL, sid, pid): //Note that the Corrupt interface is not part of the “real” protocol; it is only included for UC-modelling purposes.
1. Check that sid matches the one in the local session ID, and that pid matches the local party id, else abort.
2. Initialize a state object S and add curr msg num, pending msgs to it.
3. Send (Corrupt) to (FmKE, sid.mKE = (“mKE′′, sid.fs)).
4. On receiving (Corrupt, SmKE), add it to S and do the following.
5. For each record msg num ∈pending msgs: • Send (Corrupt, pidi) to (Faead, sid.aead = (“aead′′, sid.fs, msg num)) • On receiving a response (Corrupt, pidi, Smsg num), add Smsg num to S.
6. Output (Corrupt, S) to (ΠSGNL, sid, pid). Figure 30: The Forward-Secure Encryption Πfs aead 75 Ifsaead Encrypt: On receiving (stateI, Encrypt, pid, N, |m|) from (Ffs aead, sid.fs) do:
1. Let i be such that pid = pidi.
2. If stateI = ⊥: (a) Initialize objects View0, View1, and dictionary records. (b) Set View0.curr msg num = View1.curr msg num = 0. (c) Set View0.pending msgs = View1.pending msgs = []
3. Else, parse the objects View0, View1, and the dictionary records from stateI.
4. Set msg num = Viewi.curr msg num + 1 and update Viewi.curr msg num + = 1.
5. If msg num stateaead exists in stateI then parse it otherwise initialize msg num stateaead = ⊥.
6. Run Iaead(msg num stateaead, Encrypt, pid, |m|, N).
7. Upon receiving output (msg num stateaead, Encrypt, pid, c), store (ℓ= |m|, pid, ready2decrypt = true), (c, N, 1) in records[msg num].
8. Update or store for the ﬁrst time the values View0, View1, records, msg num stateaead, in stateI
9. Output (stateI, Encrypt, pid, msg num, N, c) to (Ffs aead, sid.fs). Authenticate: On receiving (stateI, Authenticate, pid, c, msg num, N) from (Ffs aead, sid.fs) do:
1. Let i be such that pid = pidi.
2. Parse the dictionary records from stateI: (a) If records[msg num] = ⊥then output (stateI, Authenticate, pid, c, msg num, N, ⊥) to (Ffs aead, sid.fs). (b) Else get (ℓ, pid, ready2decrypt) and any record of the form (c, N, v) from records[msg num].
3. If ready2decrypt = false in the retrieved record, output (stateI, Authenticate, pid, c, msg num, N, ⊥) to (Ffs aead, sid.fs).
4. If there is no record (c, n, v): • Run Iaead(msg num stateaead, Authenticate, pid, c, N). On obtaining the output (msg num stateaead, Authenticate, pid, c, N, v), append (c, N, v) to records[msg num] and update records in stateI.
5. If v = 0 then output (stateI, Authenticate, pid, c, msg num, N, ⊥) to (Ffs aead, sid.fs). Else continue.
6. While Viewi.curr msg num ≤msg num do: //we only get to this step if decryption succeeds. • Increment Viewi.curr msg num+ = 1. • Append Viewi.curr msg num to Viewi.pending msgs.
7. Output (stateI, Authenticate, pid, c, msg num, N, 1) to (Ffs aead, sid.fs). Figure 31: Internal Adversary, Ifsaead Decryption: Once a successful decryption occurs, an instance of the functionality Faead will never try to decrypt a ciphertext again. While not corrupted, the encryption functionality Faead will only ever output the originally encrypted message m or a failure notiﬁcation. On receiving a decryption request, if the instance is not corrupted, then the functionality ﬁrst consults with the message key exchange functionality FmKE to decide whether decryption of this message is possible for the party pid at all, if not then it outputs a failure notiﬁcation. (If the instance has been corrupted already then this key has already been retrieved and sent to A by the functionality.) Otherwise, if the ciphertext provided matches the ciphertext c chosen at the time of corruption then 76 Faead always outputs m in both the honest and corrupted case. In general Faead keeps consistency with its prior outputs, always outputting a failure notiﬁcation for ciphertexts it previously refused to decrypt. If the ciphertext does not match the one produced at the time of encryption, and if decryption of this ciphertext has never been attempted before, then based on whether corruption has occurred, the functionality will either run the adversarial code to decide if the ciphertext authenticates or it will allow the adversary to decrypt the ciphertext to any value of its choosing (up to consistency of outputs.). 7.3 Protocol Πfs aead As outlined in Section 4, protocol Πfs aead makes straightforward use of multiple instances of Faead, along with FmKE. It is presented in Figure 30 on page
1. Initialize keys in transit = [ ] and a simulated state object statepid.
2. If IsCorrupt? = true, skip to step
4. Else, set IsCorrupt? = true and continue.
3. If stateI = ⊥: (a) Initialize objects View0, View1, and dictionary records. (b) Set View0.curr msg num = View1.curr msg num = 0. (c) Set View0.pending msgs = View1.pending msgs = [ ]
4. Else, parse the objects View0, View1, and the dictionary records from stateI and store them. Also parse and store any records msg num stateaead.
5. Add Viewi.curr msg num and Viewi.pending msgs to statepid.
6. For each h = (epoch id, msg num, N), c, m ∈leakage: (a) Pick a new key kmsg num $←{0, 1}λ (where λ is the key length that parametrizes FmKE). (b) Append the tuple (msg num, kmsg num) to keys in transit. (c) If msg num stateaead doesn’t exist, initialize msg num stateaead = ⊥. (d) Send (msg num stateaead, ReportState, pid, kmsg num, m) to A on behalf of (Faead, sid.aead = (“aead”, sid.fs, msg num)). (e) On receiving a response (ReportState, pid, S), add S to statepid.
7. If there is a record (StopKeys, i, N) set stop request = (StopKeys, i, N), Else set stop request = ⊥.
8. Send (ReportState, i, keys in transit, View0.curr msg num, View1.curr msg num, stop request). to A on behalf of (FmKE, sid.mKE = (“mKE”, sid.fs))
9. On receiving a response (ReportState, i, statemKE) from A, add it to the state statepid.
10. Output (stateI, ReportState, statepid) to (Ffs aead, sid.fs). Encrypt: On receiving (stateI, Encrypt, pid, N, m) from (Ffs aead, sid.fs) do:
1. Let i be such that pid = pidi.
2. Set msg num = Viewi.curr msg num + 1 and update Viewi.curr msg num + = 1.
3. If msg num stateaead exists in stateI then parse it otherwise initialize msg num stateaead = ⊥.
4. Send a backdoor message (RetrieveKey, pid, msg num) to A on behalf of (FmKE, sid.mKE = (“mKE”, sid.fs)) and await a response (RetrieveKey, pid, k). On receiving the response, continue.
5. Send a backdoor message (msg num stateaead, ReportState, pid, k) to A on behalf of Faead with sid.aead = (“aead”, sid.fs, msg num) and await a response.
6. Send a backdoor message (msg num stateaead, Encrypt, pid, m, N) to A on behalf of Faead with sid.aead = (“aead”, sid.fs, msg num).
7. On receiving a response (msg num stateaead, Encrypt, pid, c) from A, store (ℓ= |m|, pid, ready2decrypt = true), (c, N, 1) in records[msg num].
8. Update or store for the ﬁrst time the values View0, View1, records, msg num stateaead, in stateI
9. Output (stateI, Encrypt, pid, msg num, N, c) to (Ffs aead, sid.fs). (The rest of this simulator is in Fig. 33 on Page 79.) Figure 32: Forward Secure Authenticated Encryption Simulator, Sfsaead 78 Sfsaead Continued... (This simulator begins in Fig. 33 on Page 79.) Authenticate: On receiving (stateI, Authenticate, pid, c, msg num, N) from (Ffs aead, sid.fs) do:
1. Let i be such that pid = pidi.
2. Provide input ()
3. Parse the dictionary records from stateI: (a) If records[msg num] = ⊥then output (stateI, Authenticate, pid, c, msg num, N, ⊥) to (Ffs aead, sid.fs). (b) Else get (ℓ, pid, ready2decrypt) and any record of the form (c, N, v) from records[msg num].
4. If ready2decrypt = false in the retrieved record, output (stateI, Authenticate, pid, c, msg num, N, ⊥) to (Ffs aead, sid.fs).
5. If there is no record (c, n, v): • Send a backdoor message (RetrieveKey, pid, msg num) to A on behalf of (FmKE, sid.mKE = (“mKE”, sid.fs)) and await a response (RetrieveKey, pid, k). • If k = ⊥then output (stateI, Authenticate, pid, c, msg num, N, ⊥) to (Ffs aead, sid.fs). • Else a backdoor message (msg num stateaead, ReportState, pid, k) to A on behalf of Faead with sid.aead = (“aead”, sid.fs, msg num) and await a response. • Senda backdoor message (msg num stateaead, Inject, pid, c, N) to A on behalf of Faead with sid.aead = (“aead”, sid.fs, msg num). • On obtaining the output (msg num stateaead, Inject, pid, c, N, v), append (c, N, v) to records[msg num] and update records in stateI.
1. if pid /∈{pid0, pid1} then end the activation.
2. If this is the ﬁrst activation, set curr msg num = 0 and provide input (GetSendingKey) to (FΠeKE eKE , sid.eKE) //FΠeKE eKE = (SeKE, IeKE, FeKE).
3. Upon receiving (GetSendingKey, sending chain key) from FΠeKE eKE set curr chain key = sending chain key.
4. While curr msg num ≤msg num do: • Increment curr msg num. • (curr chain key, k) = PRG(curr chain key). • Store missed msgs[curr msg num] = k.
5. Output (RetrieveKey, pid, missed msgs[msg num]) to (Πaead, sid.aead, pid) while erasing the entry missed msgs[msg num]. StopKeys: On receiving (StopKeys, msg num∗) from (Πfs aead, sid.fs, pid) do:
1. If StopKeys has already been called, return (StopKeys, Success).
2. While curr msg num ≤msg num∗do: • Increment curr msg num. • (curr chain key, k) = PRG(curr chain key). • Store missed msgs[curr msg num] = k.
3. Set curr chain key = ⊥.
4. Return (StopKeys, Success). Corruption: On receiving (Corrupt) from (Πfs aead, sid.fs, pid): //Note that the Corrupt interface is not part of the “real” protocol; it is only included for UC-modelling purposes.
1. Let S = (curr chain key, curr msg num, missed msgs).
2. Output (Corrupt, S) to (Πfs aead, sid.fs, pid). Figure 34: The Message Key Exchange Protocol ΠmKE Theorem 5 Assume that PRG is a secure length-doubling pseudorandom generator. Then protocol ΠmKE UC-realizes FmKE in the presence of global functionalities Flib, FDIR, FLTM, as well as FΠeKE eKE , where FΠeKE eKE = (IeKE, SeKE, FeKE). Proof:We construct an ideal-process adversary SmKE in the ﬁgure on Fig. 35 that interacts with functionality FmKE. The objective of SmKE is to simulate the interactions that would take place between the environment and the protocol ΠmKE (in the presence of FeKE+SeKE+IeKE), so that the views of the environment Env are computationally indistinguishable in the real and ideal scenarios. 82 SmKE The global session id sid encodes a ciphersuite, including the PRG (used by ΠmKE), and the length λ of key seeds. ReportState: On receiving (ReportState, i, keys in transit, msg numi, stop request) from (FmKE, sid.mKE) do:
1. If msg numi ̸= 0 or stop request ̸= ⊥output (ReportState, S = ⊥) to (FmKE, sid.mKE). //Note that FmKE only gets corrupted if the sender has already initialized it. This means that the sender’s msg num will never be 0.
2. Else If msg numi ̸= 0 (i.e. stop request = ⊥), initialize chain key $←{0, 1}λ. //The chain key is selected at random unless the receiver is corrupted before retrieving any keys for the epoch, this is because later chain keys should be unrelated to the initial one due to the PRG property.
3. Else (msg numi = 0 and stop request ̸= ⊥), send (GetReceivingKey, epoch id) to FΠeKE eKE . On receiving a response (GetReceivingKey, recv chain key) set chain key = recv chain key. //  FΠeKE eKE = (SeKE, IeKE, FeKE), Flib, FDIR, FLTM  //If the receiver has not retrieved any keys, we get the chain key from FΠeKE eKE so that it matches the key the sender used in the real world.
4. Initialize a dictionary seeds = {}.
5. For (msg num, k) ∈keys in transit such that msg num < msg numi: • Store seeds[msg num] = k
6. Let curr msg num = msg numi, and let the curr chain key = chain key.
7. While there is some (msg num, k) ∈keys in transit such that msg num > msg numi: • curr msg num+ = 1 • Let (curr chain key, key seed) = PRG(curr chain key). • Store seeds[curr msg num] = key seed. • Set latest seed num = curr msg num. • Delete (msg num, k) from keys in transit.
8. Delete local variable curr msg num.
9. Output (ReportState, S = {chain key, seeds}). RetrieveKey: On receiving (RetrieveKey, pid, msg num) from (FmKE, sid.mKE) do: //This happens only if IsCorrupt? = true. In particular, SmKE has already gotten a ReportState directive.
1. If msg num ≤latest seed num then output (RetrieveKey, pid, k = seeds[msg num]) to (FmKE, sid.mKE). //The only keys not in this dictionary are keys that were already retrieved by both parties at the time of corruption.
2. If msg num > latest seed num, initialize j = latest seed num + 1.
3. While j < msg num: • (curr chain key, key seed) ←PRG(curr chain key). • Store seeds[j] = key seed, j+ = 1.
4. Output (RetrieveKey, pid, k = seeds[msg num]) to (FmKE, sid.mKE). Figure 35: Message Key Exchange Simulator, SmKE 83 When the simulator SmKE receives messages from FmKE in the ideal world, it takes the actions speciﬁed in the pseudocode on Fig. 35. Note that the real world adversary sees no keys before a compromise. If the epoch has been compromised, the real world adversary gets all key seeds for messages that are in transit. The real world adversary also gains the ability to compute all future key seeds available to the party (if StopKeys has not been called). At such a compromise, the ideal world functionality FmKE provides the simulator SmKE with all the message numbers for which pending keys should be stored in the party’s state, the party’s current message number, as well as a chain key. The provided chain key is chosen at random in most cases, except for the case in which the party has not retrieved a single key in the epoch. In this case, the functionality provides SmKE with the initial chain key that a party would retrieve from the combined FeKE + SeKE + IeKE for this epoch to provide indistinguishability from the real world. The simulator SmKE then produces the keyseeds that are “in transit” by sampling them uniformly at random; it computes the future key seeds honestly using the chain key provided to it during compromise. Since SmKE generates future keys just like ΠmKE would and otherwise uses the keys produced at compromise, if the state produced by the simulator at compromise is indistinguishable from the real world, then this proof is complete. Note that if a uniformly random input is run through a PRG and then the output of the PRG run through the PRG again – and chained like this polynomially many times, the tuple containing all the outputs is still pseudorandom and therefore indistinguishable from outputs chosen independently at random. Therefore, the state produced at compromise is indistinguishable from the real world. 2 9 Authenticated Encryption for Single Messages: Realising Faead As outlined in Section 4, the ideal authenticated encryption functionality Faead is realized by way of a speciﬁc symmetric authenticated encryption scheme, which obtains its secret key from FmKE, and provides security against adaptive curruptions in the programmable random oracle model (which is captured by way of FpRO). If corruptions were not adaptive, any authenticated encryption scheme would suﬃce here; in particular, there would have been no no need to resort to the random oracle model. In fact, this would have remained true even if the overall corruption structure was adaptive, as long as the adversary does not learn the keys that correspond to messages that were sent to the corrupted party but not yet received. However, assert full-ﬂedged security in our model requires coming up with a simulation process that ﬁrst generates a ciphertext c, and is then given an arbitrary message m and asked to generate a key k such that Dec(k, c) = m. While such schemes exist, they require having a key that is longer than the total length of the messages encrypted with that key. Furthermore, impossibility holds even when authentication is not required: There do not exist adaptively secure encryption schemes in the plain model where the key is shorter t han the message [50]. We circumvent this impossibility by resorting to the random oracle model (again, using ideas from [50]). Speciﬁcally, we employ a simple Encrypt-then-MAC scheme
[43] where the encryption is simply a one-time-pad, and the random oracle is used to expand the key to the length needed for the MAC algorithm, plus the length of the message. We note that when the message is shorter than the overall keylength minus the length of the MAC key, the above scheme is adaptively secure even in the plain model. Consequently, in situations where there is a known bound on the total length of messages sent in each epoch, our solution is 84 fully secure in the plain model. Protocol Πaead is presented in Figure 36 on page 85. Πaead This protocol has a session id sid.aead = (“aead′′, sid.fs, msg num) where sid.fs = (“fs aead”, sid = (sid′, pid0, pid1), epoch id) and party id pid. It uses a message authentication code (MAC, Verify) with key length λ. Encrypt: On receiving (Encrypt, m, N) from (Πfs aead, sid.fs, pid):
1. If this is not the ﬁrst activation or pid /∈(pid0, pid1), end the activation.
2. Provide input (RetrieveKey, pid) to (ΠmKE, sid.mKE, pid).
3. Upon receiving output (RetrieveKey, k) from (ΠmKE, sid.mKE, pid): • Let ℓ= |m| + λ. • Send (HashQuery, k, ℓ) to FpRO. • Upon receiving the output (HashQuery, msg key), parse msg key = kotp||kmac, where the kotp has length |m|, and kmac has length λ. • Compute ciphertext c′ = kotp ⊕m • Compute tag t = MAC(kmac, (c′, sid.aead, N)). • Finally, set c = (c′, t). • Delete msg key, k, m, and c and output (Encrypt, c) to (Πfs aead, sid.fs, pid).
4. If the response from (ΠmKE, sid.mKE, pid) is (RetrieveKey, Fail), then output (Encrypt, Fail) to (Πfs aead, sid.fs, pid). Decryption: On receiving (Decrypt, c = (c′, t), N) from (Πfs aead, sid.fs, pid):
1. If this is not the ﬁrst activation or pid /∈(pid0, pid1), end the activation.
2. Provide input (RetrieveKey, pid) to (ΠmKE, sid.mKE, pid).
3. Upon receiving output (RetrieveKey, k) from (ΠmKE, sid.mKE, pid): • Let ℓ= |m| + λ. • Send (HashQuery, k, ℓ) to FpRO. • Upon receiving the output (HashQuery, msg key), parse msg key = kotp||kmac, where the kotp has length |m|, and kmac has length λ. • If Verify(kmac, t, (c′, sid.aead, N)) ̸= 1, then output (Decrypt, Fail) to (Πfs aead, sid.fs, pid). • Else (the tag is valid), compute message m = kotp ⊕c′. • Delete msg key, k, m, and c and output (Decrypt, m) to (Πfs aead, sid.fs, pid).
4. If the response from (ΠmKE, sid.mKE, pid) is (RetrieveKey, Fail), then output (Decrypt, Fail) to (Πfs aead, sid.fs, pid). Corruption: On receiving (Corrupt) from (Πfs aead, sid.fs, pid): //Note that the Corrupt interface is not part of the “real” protocol; it is only included for UC-modelling purposes.
1. Set ℓ= |m| and m = 0ℓ.
2. Choose a random message key msg key $←{0, 1}ℓ+λ.
3. Parse msg key = kotp||kmac where |kotp| = ℓand |kmac| = λ.
4. Compute ciphertext c′ = kotp ⊕m and tag t = MAC(kmac, (c′, sid.aead, N)).
5. Finally, set c = (c′, t), and record (msg key, m, c, N) in stateI.
6. Return (stateI, Encrypt, pid, c). To compute I(stateI, Authenticate, pid, c, N):
1. Parse c∗= (c′, t′)
2. Let ℓ= |c′|.
3. If there is no record (msg key, m, c = (c′, t), N) in stateI then end the activation.
4. Else, parse msg key = kotp||kmac where |kotp| = |m| and |kmac| = λ.
5. If Verify(kmac, t′, (c′, sid.aead, N)) = 0: set v = ⊥.
6. Else (Verify(kmac, t′, (c′, sid.aead, N)) = 1): set v = m.
7. Return (stateI, v). Figure 37: Internal adversarial code Iaead Proof: The ideal-process adversary Saead is presented in Figure 38 and the internal adversarial code Iaead is presented in Figure
37. To demonstrate the validity of Saead, we show that no environment that has global access to FpRO, FΠmKE mKE = (SmKE, FmKE), FΠeKE eKE = (IeKE, SeKE, FeKE), FDIR, FLTM, Flib, can tell whether it is interacting with Πaead, or else with Faead, Iaead, and Saead. This is done as follows: We ﬁrst argue that, conditioned on two bad events not happening, the simulation is perfect. Then, we show that the bad events happen with negligible probability. The ﬁrst, Forge, is the event that the environment produces a verifying message tag pair (m′, t′) for a fresh message m′, when no party has been corrupted. The second, Collision, is the bad event that a message seed key provided by FΠmKE mKE collides with an input to the random oracle that was previously programmed by the environment or simulator. 86 Saead At ﬁrst activation: Send (Faead, I) to Flib. On receiving (stateI, ReportState, pid, k, m∗) from (Faead, sid.aead):
1. Initialize simulated state statepid = {k} and store the key k.
2. If k ̸= ⊥and there is a record (c = (c′, t), msg key, m, N, b) in stateI: • Parse msg key = kotp||kmac where |kotp| = |m∗|. • Let kotp∗= c′ ⊕m∗and msg key∗= kotp∗||kmac. • Send a backdoor message (Program, k, msg key∗) to FpRO. • On receiving (Program), continue.
3. Output (stateI, ReportState, pid, statepid) to (Faead, sid.aead). On receiving (stateI, Encrypt, pid, m, N): //This is called in the case that either party has been corrupted and no ciphertext was released yet. In this case Saead simply runs the instructions for Πaead.
1. If the stored key k = ⊥, then end the activation.
2. Set ℓ= |m|.
3. Send (HashQuery, k, ℓ+ λ) to FpRO. //Note that k is sent to Saead during ReportState
4. Upon receiving the output (HashQuery, msg key), set msg key = kotp||kmac where |kotp| = ℓand |kmac| = λ.
5. Compute ciphertext c′ = kotp ⊕m and tag t = MAC(kmac, (c′, sid.aead, N)).
6. Finally, set c = (c′, t) and record (msg key, m, c, N) in stateI.
7. Output (stateI, Encrypt, pid, c) to (Faead, sid.aead). On receiving (stateI, Inject, pid, c∗, N) from (Faead, sid.aead): //This is called in the case that either party has been corrupted and no output was generated yet. Saead simply runs the instructions for Πaead.
1. Parse c∗= (c′, t′)
2. Let ℓ= |c′|.
3. Send (HashQuery, k, ℓ+ λ) to FpRO. //Note that k is sent to Saead during ReportState
4. Upon receiving the output (HashQuery, msg key′), continue.
5. Parse msg key′ = kotp||kmac where |kotp| = ℓ, |kmac| = λ.
6. If Verify(kmac, t′, (c′, sid.aead, N)) = 0: set v = ⊥.
7. Else (Verify(kmac, t′, (c′, sid.aead, N)) = 1): compute v = kotp ⊕c′.
1. A key kmac $←Kmac is sampled uniformly.
2. The adversary A is given access to the MAC oracle MAC(kmac, ·) which on message m computes and outputs the tag t of that message under the MAC. Let Q denote the set of all queries that A makes to MAC(kmac, ·).
3. The adversary A then outputs (m′, t′)
4. The event Forge1 occurs if and only if Verify(kmac, m′, t′) = 1 and m′ /∈Q. We will call a successful forgery event of this kind Forge. Second Forgery Game Now we deﬁne a diﬀerent type of forgery:
1. Two keys kmac, kmac ′ $←Kmac are sampled uniformly and independently.
2. The adversary A is given access to the MAC oracle MAC(kmac, ·) which on message m computes and outputs the tag t of that message under the MAC.
3. The adversary A is given access to the Verify oracle Verify(kmac ′, ·, ·) which on input (m′, t′) outputs whether the message tag pair veriﬁes.
4. The adversary A then outputs (m′, t′)
5. The event Forge2 occurs if and only if Verify(kmac ′, m′, t′) = 1. We will call a successful forgery event of this kind Forge2. This experiment models the setting where the two parties have diverged and thus have inde- pendent MAC keys. Lastly, we deﬁne Collision to be the event that Env already programmed FpRO on input k. Lemma 18 If neither Forge nor Collision events happen during the executions, then the the simu- lation by Saead and Iaead is perfect. Proof:Assume that the bad events Forge and Collision do not occur during the executions. We will prove that, for all environments Env and adversaries A, the functionality Faead together with simulator Saead and internal adversarial code Iaead perfectly simulates the real-world views of Env and A when they interact with Πaead. Encryption Observe that encryption in the ideal world occurs exactly as in the real world, except that the Iaead module in Faead chooses a random key under which to encrypt the all 0’s message of the correct length using the one time pad to produce a ciphertext c. It then authenticates the produced ciphertext using the randomly chosen kmac. Later, when a corruption occurs, the simulator can easily use the leaked message m to compute a key kotp = c ⊕m that will decrypt the ciphertext to the correct message. It then uses the leaked key-seed and programs FpRO to output the key kotp ∥kmac on this seed. Decryption In the real world, Πaead retrieves the message key seed from ΠmKE, and if the key is available, Πaead queries FpRO to get the expanded msg key. If the tag t veriﬁes, then it decrypts the ciphertext using msg key; otherwise, it returns a failure message. If the adversary has compromised 88 the state of Πaead, then ΠmKE for the same epoch is compromised as well, and A will get the key seed (which it can expand to inject ciphertexts that will authenticate). In the ideal world, Faead retrieves the message key from ΠmKE and if the key is available, Faead returns the message m that it encrypted to c = (c′, t) in the case that the other party asks to decrypt c. This case is identical to the real world, by deﬁnition. If, on the other hand, Faead gets a diﬀerent ciphertext c∗̸= c, then Faead either runs the internal adversarial module Iaead on (Authenticate, c∗) or calls the adversary om (Inject, c∗). If it is not corrupted then Faead runs the internal adversarial code to see if it wants to au- thenticate this ciphertext c∗, and waits for a response value. (Iaead uses the kmac it used during encryption to verify the tag in c∗; if the tag fails to verify for c∗, then it returns v = ⊥.) In the case that the epoch is not compromised, Faead will check that Iaead’s returned value v ̸= ⊥. If v ̸= ⊥, then Faead will output the original message m. Assuming that Forge1 and Forge2 do not occur, the original m will be returned if and only if c is the input ciphertext. In the case that the epoch is compromised, Faead calls Saead which uses the message key seed k that it received from Faead to query the random oracle FpRO to expand the key. It then veriﬁes the tag and outputs the decryption of the ciphertext (which may be diﬀerent from m). In this case, Faead outputs the injected message from Saead. This is identical to the powers of the real-world adversary after a state compromise. Corruption Notice that the protocol Πaead has no persistent state besides its sid and whether it has been activated already. The message, ciphertext, tag, and keys are all deleted after its activation. Accordingly, Saead (and thus Faead) returns no state upon corruption. The main job of Saead on corruption is to equivocate on the ciphertext it provided during encryption by programming the random oracle. Importantly, encryption occurs at most once in Faead (and Πaead). Thus, the random oracle is programmed at most once, and since we are assuming that the bad event Collide (that FpRO was already programmed or queried on input k) does not occur, the message seed key will be programmable. Saead receives the correct message m∗along with the key seed k from Faead, after which it computes the message key from the ciphertext c it generated and m∗(and re-uses the MAC key kotp) and programs these in FpRO. 2 So, all that’s left to argue is why Forge and Collision do not occur. Notice that before corruptions the message key seeds provided by F Π mKE are uniformly random, so event Forge corresponds to the standard security game for message authentication codes. In particular, assuming that we have an environment that successfully induces a Forge event with non-negligible probability, we can construct a forger against (MAC, Verify), breaking our assumption. Thus, Forge happens with negligible probability. Next, we discuss the Collision event. Since the key seeds provided by F Π mKE are uniformly ran- dom and independent, and the space of inputs to FpRO is exponential in the security parameter δ, the probability that any two of them collide is negligible in the security parameter. Furthermore, since the environment runs in polynomial time with respect to the security parameter δ, the envi- ronment can only program a polynomial number of inputs. So, for a seed length that is θ(δ), the probability that the adversary programs an input that causes a collision is roughly 2θ(δ) −poly(δ). 2 References
[9] Bellare, M., Rogaway, P.: Provably secure session key distribution: The three party case. In: 27th ACM STOC.  ACM Press (May / Jun 1995)
[14] Blazy, O., Bossuat, A., Bultel, X., Fouque, P., Onete, C., Pagnin, E.: SAID: reshaping signal into an identity-based asynchronous messaging protocol with authenticated ratcheting. In: EuroS&P.  IEEE (2019) 90
[16] Borisov, N., Goldberg, I., Brewer, E.A.: Oﬀ-the-record communication, or, why not to use PGP. In: WPES.  ACM (2004)
[22] Canetti, R.: Universally composable security. J. ACM 67(5), 28:1–28:94 (2020)
[30] Chen, K., Chen, J.: Anonymous end to end encryption group messaging protocol based on asynchronous ratchet tree. In: Meng, W., Gollmann, D., Jensen, C.D., Zhou, J. (eds.) ICICS
[31] Cohn-Gordon, K., Cremers, C., Dowling, B., Garratt, L., Stebila, D.: A formal security analysis of the signal messaging protocol. In: EuroS&P.  IEEE (2017)
[34] Cohn-Gordon, K., Cremers, C.J.F., Garratt, L.: On post-compromise security. In: Hicks, M., K¨opf, B. (eds.) CSF 2016 Computer Security Foundations Symposium.  IEEE Computer Society Press (2016)
[36] Durak, F.B., Vaudenay, S.: Bidirectional asynchronous ratcheted key agreement with linear complexity. In: Attrapadung, N., Yagi, T. (eds.) IWSEC
[45] Krohn, M.: Zoom rolling out end-to-end encryption oﬀering. https://blog.zoom.us/ zoom-rolling-out-end-to-end-encryption-offering/ (2020)
[46] Marlinspike, M., Perrin, T.: The X3DH key agreement protocol. https://signal.org/docs/ specifications/x3dh/ (2016)
1. Springer, Heidelberg (Jan 2010)
[51] Open Whisper Systems: Technical information: Speciﬁcations and software libraries for de- velopers. https://signal.org/docs/ (2016)
[52] Perrin, T.: The noise protocol framework. https://noiseprotocol.org/noise.html (2018)
[54] R¨osler, P., Mainka, C., Schwenk, J.: More is less: On the end-to-end security of group chats in signal, whatsapp, and threema. In: EuroS&P.  IEEE (2018)
[57] Status: Private, secure communication. https://status.im (2022)
[58] Sylo: Comms for the metaverse. https://sylo.io (2022)
[61] Unger, N., Goldberg, I.: Improved strongly deniable authenticated key exchanges for secure messaging. PoPETs 2018(1), 21–66 (Jan 2018)
[63] WhatsApp LLC: About end-to-end encryption. https://faq.whatsapp.com/general/ security-and-privacy/end-to-end-encryption/ (2021)
15. Choudhuri, A.R., Jain, A., Jin, Z.: SNARGs for P from LWE. In: 62nd FOCS,  IEEE Computer Society Press (2022). https://doi.org/10.1109/FOCS52979. 2021.00016
16. Desmedt, Y.: Computer security by redeﬁning what a computer is. In: NSPW (1993)
24. Gentry, C.: Fully homomorphic encryption using ideal lattices. In: Mitzenmacher, M. (ed.) 41st ACM STOC,  ACM Press (2009). https://doi.org/10. 1145/1536414.1536440
25. Gentry, C., Wichs, D.: Separating succinct non-interactive arguments from all fal- siﬁable assumptions. In: Fortnow, L., Vadhan, S.P. (eds.) 43rd ACM STOC,  ACM Press (2011). https://doi.org/10.1145/1993636.1993651
27. Gorbunov, S., Vaikuntanathan, V., Wichs, D.: Leveled fully homomorphic signa- tures from standard lattices. In: Servedio, R.A., Rubinfeld, R. (eds.) 47th ACM STOC,  ACM Press (2015). https://doi.org/10.1145/2746539.2746576 350 G. Anthoine et al.
28. Hubacek, P., Wichs, D.: On the communication complexity of secure function eval- uation with long output. In: Roughgarden, T. (ed.) ITCS 2015,  ACM (2015). https://doi.org/10.1145/2688073.2688105
31. Kalai, Y.T., Paneth, O., Yang, L.: How to delegate computations publicly. In: Charikar, M., Cohen, E. (eds.) 51st ACM STOC,  ACM Press (2019). https://doi.org/10.1145/3313276.3316411
38. Samarin, S.D., Fiore, D., Venturi, D., Amini, M.: A compiler for multi-key homo- morphic signatures for turing machines. Theor. Comput. Sci. 889, 145–170 (2021). https://doi.org/10.1016/j.tcs.2021.08.002
1. Aggarwal, D., D¨ottling, N., Dujmovic, J., Hajiabadi, M., Malavolta, G., Obrem- ski, M.: Algebraic restriction codes and their applications. In: Braverman, M. (ed.) 13th Innovations in Theoretical Computer Science Conference (ITCS 2022). Leib- niz International Proceedings in Informatics (LIPIcs), vol. 215,  Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik, Dagstuhl, Germany (2022). https:// drops.dagstuhl.de/opus/volltexte/2022/15598
7. Badrinarayanan, S., Patranabis, S., Sarkar, P.: Statistical security in two-party computation revisited. In: Kiltz, E., Vaikuntanathan, V. (eds.) Theory of Cryp- tography. Lecture Notes in Computer Science, vol. 13748,  Springer Nature Switzerland, Cham (2022). https://doi.org/10.1007/978-3-031-22365-5 7
12. Boyle, E., Couteau, G., Gilboa, N., Ishai, Y., Kohl, L., Scholl, P.: Correlated pseu- dorandom functions from variable-density LPN. In: 61st FOCS, IEEE Computer Society Press, November 2020
24. Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters, B.: Candidate indistinguishability obfuscation and functional encryption for all circuits. In: 54th FOCS,  IEEE Computer Society Press, October 2013
27. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions. J. ACM 33(4), 792–807 (1986). https://doi.org/10.1145/6490.6503
28. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or a com- pleteness theorem for protocols with honest majority. In: Aho, A. (ed.) 19th ACM STOC,  ACM Press, May 1987
32. Ishai, Y., Kushilevitz, E.: Randomizing polynomials: a new representation with applications to round-eﬃcient secure computation. In: 41st FOCS, IEEE Computer Society Press, November 2000
41. Khurana, D., Sahai, A.: How to achieve non-malleability in one or two rounds. In: Umans, C. (ed.) 58th FOCS,  IEEE Computer Society Press, October 2017
43. Naor, M., Pinkas, B.: Eﬃcient oblivious transfer protocols. In: Kosaraju, S.R. (ed.) 12th SODA,  ACM-SIAM, January 2001
45. Peikert, C., Waters, B.: Lossy trapdoor functions and their applications. In: Ladner, R.E., Dwork, C. (eds.) 40th ACM STOC,  ACM Press, May 2008
2. Adleman, L.M., Kompella, K.: Using smoothness to achieve parallelism (abstract). In: 20th ACM STOC,  ACM Press (May 1988). https://doi.org/10. 1145/62212.62264
6. Atabaki, A.H., et al.: Integrating photonics with silicon nanoelectronics for the next generation of systems on a chip. Nature 556(7701), 349–354 (2018). https:// doi.org/10.1038/s41586-018-0028-z
7. Bach, E.: How to generate factored random numbers. SIAM J. Comput. 17(2), 179–193 (1988). https://doi.org/10.1137/0217012
10. Blum, M.: Coin ﬂipping by telephone. In: Proceedings of the IEEE Spring COM- PCOM,  (1982)
13. Brent, R.P., Kung, H.T.: A regular layout for parallel adders. IEEE Trans. Comput. 31(3), 260–264 (1982). https://doi.org/10.1109/TC.1982.1675982
14. Brent, R.P., Rung, H.: A systolic algorithm for integer GCD computation. In: 1985 IEEE 7th Symposium on Computer Arithmetic (ARITH),  IEEE (1985)
15. Buterin, V.: Randao++. https://redd.it/4mdkku (2017)
17. Cline, D., Dryja, T., Narula, N., CommitO: Clockwork: An exchange protocol for proofs of non front-running (2020)
21. Dickman, K.: On the frequency of numbers containing prime factors of a certain relative magnitude. Arkiv for matematik, astronomi och fysik 22(10), A–10 (1930)
22. Dobson, S., Galbraith, S.D., Smith, B.A.: Trustless unknown-order groups. ArXiv:abs/2211.16128, https://api.semanticscholar.org/CorpusID:236932351 (2022)
23. Drake, J.: Minimal vdf randomness beacon. https://ethresear.ch/t/minimal-vdf- randomness-beacon/3566 (2018)
24. Earle, J.: Latched carry-save adder. IBM Tech. Disclosure Bull. 7(10), 909–910 (1965)
26. Gordon, D.M.: Discrete logarithms in GF(P) using the number ﬁeld sieve. SIAM J. Discret. Math. 6(1), 124–138 (1993). https://doi.org/10.1137/0406010
28. Herold, G., et al.: Statement regarding the public report on the analysis of minroot. https://ethresear.ch/t/statement-regarding-the-public-report-on-the- analysis-of-minroot/16670 (Sep 2023) Cryptanalysis of Algebraic Veriﬁable Delay Functions 489
35. Mahmoody, M., Moran, T., Vadhan, S.P.: Publicly veriﬁable proofs of sequential work. In: Kleinberg, R.D. (ed.) ITCS 2013,  ACM (Jan 2013). https:// doi.org/10.1145/2422436.2422479
38. Montgomery, H.L., Vaughan, R.C.: Multiplicative number theory I: Classical the- ory. No. 97, Cambridge university press (2007)
39. Pietrzak, K.: Simple veriﬁable delay functions. In: Blum, A. (ed.) ITCS 2019. vol. 124, pp. 60:1–60:15. LIPIcs (Jan 2019). https://doi.org/10.4230/LIPIcs.ITCS. 2019.60
43. Savage, J.E.: Models of Computation, vol. 136. Addison-Wesley Reading, MA (1998) 490 A. Biryukov et al.
47. Shanks, D.: Class number, a theory of factorization, and genera. In: Proceedings of the Symp. Math. Soc., 1971. vol. 20,  (1971)
17. Birkhäuser (2012)
49. Sorenson, J.: Polylog depth circuits for integer factoring and discrete logarithms. Inf. Comput. 110(1), 1–18 (1994)
50. Sorenson, J.: Two fast GCD algorithms. J. Algorithms 16(1), 110–144 (1994). https://doi.org/10.1006/jagm.1994.1006
51. Sreedhar, K., Horowitz, M., Torng, C.: A fast large-integer extended GCD algo- rithm and hardware design for veriﬁable delay functions and modular inversion. IACR TCHES 2022(4), 163–187 (2022). https://doi.org/10.46586/tches.v2022.i4. 163-187
52. StarkWare: Presenting: VeeDo. https://medium.com/starkware/presenting-veedo- e4bbﬀ77c7ae (2020)
53. Supranational LLC: MinRoot VDF Hardware Engine (2022). https://github.com/ supranational/minroot_hardware
54. Supranational LLC: Minroot ASIC Driver (2023). https://github.com/ supranational/minroot_driver
55. Supranational LLC: MinRoot VDF ASIC (2023). private presentation
56. Valiant, L.G.: A scheme for fast parallel communication. SIAM J. Comput. 11(2), 350–361 (1982). https://doi.org/10.1137/0211027
57. Wallace, C.S.: A suggestion for a fast multiplier. IEEE Trans. Electron. Comput. 13(1), 14–17 (1964). https://doi.org/10.1109/PGEC.1964.263830
58. Wang, P.S.: A p-adic algorithm for univariate partial fractions. In: Wang, P.S. (ed.) Proceedings of the Symposium on Symbolic and Algebraic Manipulation, SYMSAC 1981, Snowbird, Utah, USA, August 5-7, 1981,  ACM (1981). https:// doi.org/10.1145/800206.806398
10. Bernstein, D.J.: ChaCha, a variant of Salsa20. In: Workshop Record of SASC, vol. 8,  (2008) 30 Z. Niu et al.
26. Kim, D., Kwon, D., Song, J.: Eﬃcient computation of boomerang connection prob- ability for ARX-based block ciphers with application to SPECK and LEA. IEICE Trans. Fundam. Electron. Commun. Comput. Sci. 103-A(4), 677–685 (2020)
27. Leurent, G.: https://who.paris.inria.fr/Gaetan.Leurent/arxtools.html
38. National Institute of Standards and Technology. Preliminary state standard of republic of Belarus (STBP 34.101.312011) (2011). https://apmi.bsu.by/assets/ ﬁles/std/belt-spec27.pdf
39. Niu, Z., Sun, S., Liu, Y., Li, C.: Rotational diﬀerential-linear distinguishers of ARX ciphers with arbitrary output linear masks (2022). https://eprint.iacr.org/ 2022/765
41. Needham, R.M., Wheeler, D.J.: TEA extensions. Report, Cambridge University (1997) 32 Z. Niu et al.
1. Abboud, A., Bringmann, K., Hermelin, D., Shabtay, D.: Seth-based lower bounds for subset sum and bicriteria path. In: Chan, T.M. (ed.) Proceedings of the Thir- tieth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2019, San Diego, California, USA, 6–9 January 2019,  SIAM (2019). https://doi. org/10.1137/1.9781611975482.3
3. Abboud, A., Williams, V.V.: Popular conjectures imply strong lower bounds for dynamic problems. In: 2014 IEEE 55th Annual Symposium on Foundations of Computer Science,  (2014). https://doi.org/10.1109/FOCS.2014.53
5. Ailon, N., Chazelle, B.: Lower bounds for linear degeneracy testing. J. ACM 52(2), 157–171 (2005). https://doi.org/10.1145/1059513.1059515
6. Alekhnovich, M.: More on average case vs approximation complexity. In: 44th Symposium on Foundations of Computer Science (FOCS 2003), Cambridge, MA, USA, 11–14 October 2003, Proceedings,  IEEE Computer Society (2003). https://doi.org/10.1109/SFCS.2003.1238204
12. Baran, I., Demaine, E.D., Pˇatra¸scu, M.: Subquadratic algorithms for 3sum. Algo- rithmica 50(4), 584–596 (2008). https://doi.org/10.1007/s00453-007-9036-3
13. Barequet, G., Har-Peled, S.: Polygon containment and translational min-hausdorﬀ- distance between segment sets are 3sum-hard. Int. J. Comput. Geometry Appl. 11, 465–474 (2001). https://doi.org/10.1142/S0218195901000596
15. Berthet, Q., Rigollet, P.: Complexity theoretic lower bounds for sparse princi- pal component detection. In: Annual Conference Computational Learning Theory (2013)
16. Berthet, Q., Rigollet, P.: Optimal detection of sparse principal components in high dimension. Ann. Stat. 41(4), 1780–1815 (2013). https://doi.org/10.1214/13- AOS1127
17. Blum, A., Kalai, A., Wasserman, H.: Noise-tolerant learning, the parity problem, and the statistical query model. J. ACM 50(4), 506–519 (2003). https://doi.org/ 10.1145/792538.792543
18. Boix-Adser`a, E., Brennan, M.S., Bresler, G.: The average-case complexity of count- ing cliques in erd˝os-r´enyi hypergraphs. In: Zuckerman, D. (ed.) 60th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2019, Baltimore, Mary- land, USA, 9–12 November 2019,  IEEE Computer Society (2019). https://doi.org/10.1109/FOCS.2019.00078
19. Bouillaguet, C., Delaplace, C., Joux, A.: Algorithms for sparse random 3XOR: the low-density case (2021), https://hal.science/hal-02306917. Working paper or preprint
20. Brakerski, Z., Stephens-Davidowitz, N., Vaikuntanathan, V.: On the hard- ness of average-case k-sum. In: Wootters, M., Sanit`a, L. (eds.) Approxima- tion, Randomization, and Combinatorial Optimization. Algorithms and Tech- niques, APPROX/RANDOM 2021, University of Washington, Seattle, Washing- ton, USA (Virtual Conference), 16–18 August 2021. LIPIcs, vol. 207, pp. 29:1– 29:19. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2021). https://doi.org/ 10.4230/LIPIcs.APPROX/RANDOM.2021.29
21. Bringmann, K.: A near-linear pseudopolynomial time algorithm for subset sum. In: Klein, P.N. (ed.) Proceedings of the Twenty-Eighth Annual ACM-SIAM Sympo- sium on Discrete Algorithms, SODA 2017, Barcelona, Spain, Hotel Porta Fira, 16–19 January 2017,  SIAM (2017). https://doi.org/10.1137/1. 9781611974782.69
24. Chan, T.M.: More logarithmic-factor speedups for 3sum, (median, +)-convolution, and some geometric 3sum-hard problems. ACM Trans. Algor. 16(1), 7:1–7:23 (2020). https://doi.org/10.1145/3363541
26. Dalirrooyfard, M., Lincoln, A., Williams, V.V.: New techniques for proving ﬁne- grained average-case hardness. In: Irani, S. (ed.) 61st IEEE Annual Symposium on k-SUM in the Sparse Regime: Complexity and Applications 349 Foundations of Computer Science, FOCS 2020, Durham, NC, USA, 16–19 Novem- ber 2020,  IEEE (2020). https://doi.org/10.1109/FOCS46700.2020. 00077
27. Dam, E.R.V., Koolen, J.H., Tanaka, H.: Distance-regular graphs. Electron. J. Comb. 1000 (2016). https://doi.org/10.37236/4925
28. Dietzfelbinger, M., Schlag, P., Walzer, S.: A subquadratic algorithm for 3xor. In: Potapov, I., Spirakis, P.G., Worrell, J. (eds.) 43rd International Symposium on Mathematical Foundations of Computer Science, MFCS 2018, Liverpool, UK, 27–31 August 2018. LIPIcs, vol. 117, pp. 59:1–59:15. Schloss Dagstuhl - Leibniz- Zentrum f¨ur Informatik (2018). https://doi.org/10.4230/LIPIcs.MFCS.2018.59
30. Dinur, I., Keller, N., Klein, O.: Fine-grained cryptanalysis: tight conditional bounds for dense k-sum and k-xor. In: 62nd IEEE Annual Symposium on Foundations of Computer Science, FOCS 2021, Denver, CO, USA, 7–10 February 2022, IEEE (2021). https://doi.org/10.1109/FOCS52979.2021.00017
31. Erickson, J.: Lower bounds for linear satisﬁability problems. In: Clarkson, K.L. (ed.) Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, San Francisco, California, USA, 22–24 January 1995, ACM/SIAM (1995). http://dl.acm.org/citation.cfm?id=313651.313772
34. Gamarnik, D., Zadik, I.: The landscape of the planted clique problem: dense subgraphs and the overlap gap property. CoRR http://arxiv.org/abs/1904.07174 (2019)
35. Gold, O., Sharir, M.: Improved Bounds for 3SUM, k-SUM, and Linear Degen- eracy. In: Pruhs, K., Sohler, C. (eds.) 25th Annual European Symposium on Algorithms (ESA 2017). Leibniz International Proceedings in Informatics (LIPIcs), vol. 87, pp. 42:1–42:13. Schloss Dagstuhl–Leibniz-Zentrum fuer Infor- matik, Dagstuhl (2017). https://doi.org/10.4230/LIPIcs.ESA.2017.42. http:// drops.dagstuhl.de/opus/volltexte/2017/7836
36. Goldreich, O., Levin, L.A.: A hard-core predicate for all one-way functions. In: Pro- ceedings of the Twenty-First Annual ACM Symposium on Theory of Computing, (1989)
37. Goldreich, O., Rothblum, G.N.: Counting t-cliques: worst-case to average-case reductions and direct interactive proof systems. In: Thorup, M. (ed.) 59th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2018, Paris, France, 7–9 October 2018,  IEEE Computer Society (2018). https:// doi.org/10.1109/FOCS.2018.00017
39. Grønlund, A., Pettie, S.: Threesomes, degenerates, and love triangles. J. ACM 65(4) (2018). https://doi.org/10.1145/3185378
40. Gupte, A., Vaikuntanathan, V.: The ﬁne-grained hardness of sparse linear regres- sion. CoRR (2021). https://arxiv.org/abs/2106.03131
41. Hirahara, S., Shimizu, N.: Hardness self-ampliﬁcation: simpliﬁed, optimized, and uniﬁed. Electron. Colloquium Comput. Complex. TR23-026 (2023). https://eccc. weizmann.ac.il/report/2023/026
42. Horowitz, E., Sahni, S.: Computing partitions with applications to the knapsack problem. J. ACM 21(2), 277–292 (1974). https://doi.org/10.1145/321812.321823
43. H˚Astad, J., Impagliazzo, R., Levin, L.A., Luby, M.: A pseudorandom generator from any one-way function. SIAM J. Comput. 28(4), 1364–1396 (1999). https:// doi.org/10.1137/S0097539793244708
44. Impagliazzo, R.: A personal view of average-case complexity. In: Proceedings of Structure in Complexity Theory. Tenth Annual IEEE Conference, IEEE (1995)
45. Impagliazzo, R., Jaiswal, R., Kabanets, V., Wigderson, A.: Uniform direct product theorems: simpliﬁed, optimized, and derandomized. SIAM J. Comput. 39(4), 1637– 1665 (2010). https://doi.org/10.1137/080734030
47. Jerrum, M.: Large cliques elude the metropolis process. Rand. Struct. Algor. 3(4), 347–360 (1992). https://doi.org/10.1002/rsa.3240030402
48. Jin, C., Wu, H.: A simple near-linear pseudopolynomial time randomized algorithm for subset sum. In: Fineman, J.T., Mitzenmacher, M. (eds.) 2nd Symposium on Simplicity in Algorithms, SOSA 2019, San Diego, CA, USA, 8–9 January 2019. OASIcs, vol. 69, pp. 17:1–17:6. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2019). https://doi.org/10.4230/OASIcs.SOSA.2019.17
51. Kopelowitz, T., Pettie, S., Porat, E.: Higher lower bounds from the 3sum con- jecture. In: Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2016,  Society for Industrial and Applied Mathematics, USA (2016)
52. Kopelowitz, T., Porat, E.: The strong 3sum-indexing conjecture is false. CoRR http://arxiv.org/abs/1907.11206 (2019)
53. Lagarias, J.C., Odlyzko, A.M.: Solving low-density subset sum problems. J. ACM 32(1), 229–246 (1985). https://doi.org/10.1145/2455.2461
62. Patrascu, M., Williams, R.: On the possibility of faster SAT algorithms. In: Charikar, M. (ed.) Proceedings of the Twenty-First Annual ACM-SIAM Sympo- sium on Discrete Algorithms, SODA 2010, Austin, Texas, USA, 17–19 January 2010,  SIAM (2010). https://doi.org/10.1137/1.9781611973075.86
63. Pettie, S.: Higher Lower Bounds from the 3SUM Conjecture, talk at the Com- putational Complexity of Low-Polynomial Time Problems workshop at the Simons Institute (2015). https://simons.berkeley.edu/talks/higher-lower-bounds- 3sum-conjecture
66. Trevisan, L.: Some applications of coding theory in computational complexity. arXiv preprint cs/0409044 (2004)
68. Williams, V.V.: On some ﬁne-grained questions in algorithms and complexity. In: Proceedings of the ICM, vol. 3,  World Scientiﬁc (2018)
17. Ito,M., Saito, A., Nishizeki, T.: Secret sharing schemes realizing general access structure. In: Proceedings of the IEEE Global Telecommunication Conference (Globecom’87),  (1987)
20. Poremba, A.: Quantum proofs of deletion for learning with errors. In: Tauman Kalai, Y. (ed.) 14th Innovations in Theoretical Computer Science Conference (ITCS 2023), volume 251 of Leibniz International Proceedings in Informatics (LIPIcs), pp. 90:1–90:14, Dagstuhl, Germany (2023). Schloss Dagstuhl – Leibniz- Zentrum f¨ur Informatik
21. Reed, I.S., Solomon, G.: Polynomial codes over certain ﬁnite ﬁelds. J. Soc. Ind. Appl. Math. 8(2), 300–304 (1960)
23. Shamir, A.: How to share a secret. Commun. Assoc. Comput. Mach. 22(11), 612– 613 (1979)
1. Ajtai, M.: Generating hard instances of lattice problems (extended abstract). In: 28th ACM STOC,  ACM Press (May 1996)
15. Canetti, R., et al.: Fiat-Shamir: from practice to theory. In: Charikar, M., Cohen, E. (eds.) 51st ACM STOC,  ACM Press (Jun 2019)
19. Dodis, Y., Ostrovsky, R., Reyzin, L., Smith, A.D.: Fuzzy extractors: How to gen- erate strong keys from biometrics and other noisy data. SIAM J. Comput. 38(1), 97–139 (2008)
21. Gennaro, R., Lindell, Y.: A framework for password-based authenticated key exchange. ACM Trans. Inform. Syst. Sec. 9(2), 181–234 (2006) 714 S. Han et al.
31. Lee, Y., Lee, D.H., Park, J.H.: Tightly CCA-secure encryption scheme in a multi-user setting with corruptions. Des. Codes Crypt. 88(11), 2433–2452 (2020). https://doi.org/10.1007/s10623-020-00794-z
41. Peikert, C., Waters, B.: Lossy trapdoor functions and their applications. In: Ladner, R.E., Dwork, C. (eds.) 40th ACM STOC,  ACM Press (May 2008)
[GKP+13] Goldwasser, S., Kalai, Y., Popa, R.A., Vaikuntanathan, V., Zeldovich, N.: Reusable garbled circuits and succinct functional encryption. In: STOC, (2013)
[JLS21] Jain, A., Lin, H., Sahai., A.: Indistinguishability obfuscation from well- founded assumptions. In: STOC,  (2021) 666 R. Yang et al.
[SW14] Sahai, A., Waters, B.: How to use indistinguishability obfuscation: deni- able encryption, and more. In: STOC,  (2014)
2. Babai, L.: The Fourier transform and equations over ﬁnite Abelian groups: an introduction to the method of trigonometric sums. Lecture notes (1989)
3. Barreto, P., Rijmen, V.: The Anubis block cipher. Primitive submitted to NESSIE (2020)
4. Barreto, P., Rijmen, V.: The Khazad legacy-level block cipher. Primitive submitted to NESSIE (2020)
16. Daemen, J., Van Assche, G., Peeters, M., Rijmen, V.: Noekeon. Primitive submit- ted to NESSIE (2000)
22. Hoeﬀding, W.: Probability inequalities for sums of bounded random variables. In: Fisher, N.I., Sen, P.K. (eds.) The Collected Works of Wassily Hoeﬀding,  Springer, Heidleberg (1994). https://doi.org/10.1007/978-1-4612-0865-5 26
33. Steinberger, J.P.: The sum-capture problem for abelian groups. arXiv preprint arXiv:1309.5582 (2013)
1. Albrecht, M., et al.: Homomorphic encryption standard. In: Lauter, K., Dai, W., Laine, K. (eds.) Protecting Privacy through Homomorphic Encryption, Springer, Cham (2021). https://doi.org/10.1007/978-3-030-77287-1_2
10. Brakerski, Z., Gentry, C., Vaikuntanathan, V.: (leveled) fully homomorphic encryp- tion without bootstrapping. In: ITCS 2012,  ACM (2012). https://doi. org/10.1145/2090236.2090262
12. Brakerski, Z., Vaikuntanathan, V.: Eﬃcient fully homomorphic encryption from (standard) LWE. SIAM J. Comput. 43(2), 831–871 (2014). https://doi.org/10. 1137/120868669
25. Fan, J., Vercauteren, F.: Somewhat practical fully homomorphic encryption. Cryp- tology ePrint Archive (2012)
28. Gentry, C.: Fully homomorphic encryption using ideal lattices. In: STOC 2009,  (2009). https://doi.org/10.1145/1536414.1536440 Fast Blind Rotation for Bootstrapping FHEs 35
35. Kluczniak, K.: NTRU-ν-um: secure fully homomorphic encryption from NTRU with small modulus,  (2022). https://doi.org/10.1145/3548606. 3560700
1. Adams, D.Q., et al.: Lower bounds for leakage-resilient secret-sharing schemes against probing attacks. In: IEEE International Symposium on Information The- ory, ISIT,  (2021) New Bounds on the Local Leakage Resilience 169
10. Chattopadhyay, E., et al.: Extractors and secret sharing against bounded collusion protocols. In: FOCS,  (2020)
11. Chaum, D., Cr´epeau, C., Damg˚ard, I.: Multiparty unconditionally secure protocols (extended abstract). In: STOC,  (1988)
12. Dav`ı, F., Dziembowski, S., Venturi, D.: Leakage-resilient storage. In: SCN,  (2010)
15. Faust, S., Rabin, T., Reyzin, L., Tromer, E., Vaikuntanathan, V.: Protecting cir- cuits from computationally bounded and noisy leakage. SIAM J. Comput. 43(5), 1564–1614 (2014)
17. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or A completeness theorem for protocols with honest majority. In: STOC, (1987)
18. Goyal, V., Kumar, A.: Non-malleable secret sharing. In: STOC,  (2018)
20. Guruswami, V., Wootters, M.: Repairing Reed-Solomon codes. IEEE Trans. Inf. Theory 63(9), 5684–5698 (2017)
24. Kumar, A., Meka, R., Sahai, A.: Leakage-resilient secret sharing against colluding parties. In: FOCS,  (2019)
27. Maji, H.K., Nguyen, H.H., Paskin-Cherniavsky, A., Wang, M.: Improved bound on the local leakage-resilience of Shamir’s secret sharing. In: IEEE International Symposium on Information Theory, ISIT,  (2022)
34. Santis, A.D., Desmedt, Y., Frankel, Y., Yung, M.: How to share a function securely. In: STOC,  (1994)
35. Shamir, A.: How to share a secret. Commun. ACM 22(11), 612–613 (1979)
1. Albrecht, M., et al.: Homomorphic encryption security standard. Technical report, HomomorphicEncryption.org, Toronto, Canada, November 2018. https:// homomorphicencryption.org/standard/
3. Canonne, C.L.: A survey on distribution testing: your data is big. But is it blue? Theory of Computing,  (2020)
5. Cheon, J.H., et al.: Toward a secure drone system: ﬂying with real-time homomor- phic authenticated encryption. IEEE Access 6, 24325–24339 (2018)
10. Cheon, J.H., Kim, D., Kim, Y., Song, Y.: Ensemble method for privacy-preserving logistic regression based on homomorphic encryption. IEEE Access 6, 46938–46948 (2018)
11. Devroye, L., Mehrabian, A., Reddad, T.: The total variation distance between high-dimensional Gaussians with the same mean. arXiv preprint arXiv:1810.08693 (2018)
13. Goldwasser, S., Micali, S.: Probabilistic encryption. J. Comput. Syst. Sci. 28(2), 270–299 (1984)
14. Han, K., Hong, S., Cheon, J.H., Park, D.: Logistic regression on homomorphic encrypted data at scale. In: AAAI 2019,  AAAI Press (2019)
15. HElib (release 2.2.0). https://github.com/homenc/HElib (2021). IBM
16. Kalamkar, D.D., et al.: A study of BFLOAT16 for deep learning training. arXiv preprint arXiv:1905.12322 (2019)
18. Lattigo 2.2.0. Online. http://github.com/ldsec/lattigo, July 2021. EPFL-LDS
20. Lyubashevsky, V., Peikert, C., Regev, O.: On ideal lattices and learning with errors over rings. J. ACM 60(6), 43:1–43:35 (2013)
23. Mironov, I.: R´enyi diﬀerential privacy. In: 2017 IEEE 30th Computer Security Foundations Symposium (CSF),  (2017)
25. Park, S., Lee, J., Cheon, J.H., Lee, J., Kim, J., Byun, J.: Security-preserving sup- port vector machine with fully homomorphic encryption. In: SafeAI@AAAI 2019, CEUR Workshop Proceedings, vol. 2301 (2019). CEUR-WS.org
27. Peikert, C., Regev, O., Stephens-Davidowitz, N.: Pseudorandomness of ring-LWE for any ring and modulus. In: STOC,  ACM (2017)
28. Polyakov, Y.: Personal communication, October 2020
29. Polyanskiy, Y., Wu, Y.: Lecture notes on information theory. Lecture Notes for ECE563 (UIUC) and 6(2012–2016):7 (2014)
32. Microsoft SEAL (release 3.6). https://github.com/Microsoft/SEAL, November 2020. Microsoft Research, Redmond, WA
33. Wang, N., Choi, J., Brand, D., Chen, C.-Y., Gopalakrishnan, K.: Training deep neural networks with 8-bit ﬂoating point numbers. In: Advances in Neural Infor- mation Processing Systems, vol. 31 (2018)
8. Damelin, S.B., Michalski, G., Mullen, G.L.: The cardinality of sets of k-independent vectors over ﬁnite ﬁelds. Monatshefte f¨ur Mathematik 150(4), 289–295 (2007)
9. Damelin, S.B., Michalski, G., Mullen, G.L., Stone, D.: The number of linearly independent binary vectors with applications to the construction of hypercubes and orthogonal arrays, pseudo (t, m, s)-nets and linear codes. Monatshefte f¨ur Mathematik 141(4), 277–288 (2004)
11. Dittmer, S., Ishai, Y., Ostrovsky, R.: Line-point zero knowledge and its applica- tions. In: ITC 2021 (2021). Full version: https://eprint.iacr.org/2020/1446
24. Yao, A.C.-C.: How to generate and exchange secrets (extended abstract). In: FOCS, (1986)
1. URL: https://falcon-sign.info/
2. URL: https://pq-crystals.org/dilithium/index.shtml
3. URL: https://sphincs.org/
4. URL: https://microsoft.github.io/Picnic/ Lattice-Based Succinct Arguments for NP 247
14. Beullens, W., Seiler, G.: LaBRADOR: compact proofs for R1CS from module - SIS (2022)
30. Chiesa, A., et al.: Post-quantum succinct arguments: breaking the quantum rewind- ing barriers. In: Proceedings of the 62nd Annual IEEE Symposium on Foundations of Computer Science. FOCS’21 (2021)
31. Conrad, K.: Cyclotomic Extensions (2013). https://kconrad.math.uconn.edu/ math5211s13/handouts/cyclotomic.pdf
43. Gentry, C., Wichs, D.: Separating succinct non-interactive arguments from all fal- siﬁable assumptions. In: Proceedings of the 43rd Annual ACM Symposium on Theory of Computing. STOC’11,  (2011)
47. Kilian., J.: A note on eﬃcient zero-knowledge proofs and arguments. In: Proceed- ings of the 24th Annual ACM Symposium on Theory of Computing. STOC’92,  (1992) 250 J. Bootle et al.
52. Lund, C., et al.: Algebraic methods for interactive proof systems. J. ACM 39(4), 859–868 (1992)
62. Reingold, O., Rothblum, G., Rothblum, R.: Constant-round interactive proofs for delegating computation. SIAM J. Comput. 50(3) (2021). Preliminary version appeared in STOC’16
63. Ron-Zewi, N., Rothblum, R.D.: Proving as fast as computing: succinct arguments with constant prover overhead. In: Proceedings of the 54th Annual ACM Sympo- sium on Theory of Computing. STOC’22,  (2022) Lattice-Based Succinct Arguments for NP 251
64. Thaler, J.: Proofs, arguments, and zero-knowledge. Unpublished manuscript (2022). https://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.pdf
1. Ducas, L., et al.: CRYSTALS-Dilithium - algorithm speciﬁcations and support- ing documentation (version 3.1). Technical report (February 2021). Speciﬁcation document
17. Avanzini, M., Barthe, G., Gr´egoire, B., Moser, G., Vanoni, G.: A mechanisation of the complexity analysis of skiplists. Unpublished manuscript (2023)
[Ajt96] Mikl´os Ajtai. Generating hard instances of lattice problems. In STOC 1996, pages 99–108, 1996.
[Bab86] L´aszl´o Babai. On lov´asz’ lattice reduction and the nearest lattice point problem. Combinatorica, 6(1):1–13, 1986.
[BVWW16] Zvika Brakerski, Vinod Vaikuntanathan, Hoeteck Wee, and Daniel Wichs. Obfuscating conjunctions under entropic ring lwe. In ITCS 2016, pages 147–156, 2016.
[CGM19] Yilei Chen, Nicholas Genise, and Pratyay Mukherjee. Approximate trapdoors for lattices and smaller hash-and-sign signatures. In ASI- ACRYPT 2019, pages 3–32, 2019.
[DP16] L´eo Ducas and Thomas Prest. Fast fourier orthogonalization. In ISSAC 2016, pages 191–198, 2016.
[EK20] Thomas Espitau and Paul Kirchner. The nearest-colattice algo- rithm: Time-approximation tradeoff for approx-cvp. ANTS XIV, 4(1):251–266, 2020.
[Gen09] Craig Gentry. Fully homomorphic encryption using ideal lattices. In STOC 2009, pages 169–178, 2009.
[GVW13] Sergey Gorbunov, Vinod Vaikuntanathan, and Hoeteck Wee. Attribute-based encryption for circuits. In STOC 2013, pages 545– 554, 2013.
[HPS+17] Jeff Hoffstein, Jill Pipher, John M Schanck, Joseph H Silverman, William Whyte, and Zhenfei Zhang. Choosing parameters for ntru- encrypt. In CT-RSA 2017, pages 3–18, 2017.
[HHP+03] Jeffrey Hoffstein, Nick Howgrave-Graham, Jill Pipher, Joseph H. Silverman, and William Whyte. NTRUSIGN: digital signatures using the NTRU lattice. In CT-RSA 2003, pages 122–140, 2003.
[JHT22] Huiwen Jia, Yupu Hu, and Chunming Tang. Lattice-based hash- and-sign signatures using approximate trapdoor, revisited. IET In- formation Security, 16(1):41–50, 2022.
[SE94] Claus-Peter Schnorr and Martin Euchner. Lattice basis reduction: Improved practical algorithms and solving subset sum problems. Mathematical programming, 66:181–199, 1994.
[Ajt96] Ajtai, M.: Generating hard instances of lattice problems. Quaderni di Matematica 13, 1–32 (2004). Preliminary version in STOC 1996
[CLSY93] Cai, J., Lipton, R.J., Sedgewick, R., Yao, A.C.: Towards uncheatable bench- marks. In: Structure in Complexity Theory Conference,  (1993) Cryptanalysis of Lattice-Based Sequentiality Assumptions 157
[MMV13] Mahmoody, M., Moran, T., Vadhan, S.P.: Publicly veriﬁable proofs of sequential work. In: Innovations in Theoretical Computer Science (ITCS), (2013)
[Pie19] Pietrzak, K.: Simple veriﬁable delay functions. In: Innovations in Theo- retical Computer Science Conference (ITCS), volume 124 of LIPIcs, pp. 60:1–60:15 (2019)
[Reg05] Regev, O.: On lattices, learning with errors, random linear codes, and cryp- tography. J. ACM 56(6), 1–40 (2009). Preliminary version in STOC 2005
[Sho94] Shor, P.W.: Polynomial-time algorithms for prime factorization and dis- crete logarithms on a quantum computer. SIAM J. Comput. 26(5), 1484– 1509 (1997). Preliminary version in FOCS 1994
1. FGS used in Figure 4 is replaced by protocol ΠGS
[BLO16] that computes a multi-party garbling and decoding information for the function f. Since FGS does not take the function inputs ⃗x, the execution of ΠGS is also independent of it. The protocol requires each of the garblers in PN to sample randomness and create the inputs that are listed in the description of FGS. Then the garblers execute a protocol that generates output of the functionality and this is also given to the evaluator Pn. The complete protocol ΠGS is secure against a semi-honest PPT adversary corrupting any subset Z of n−1 parties in P. Therefore, there exists a PPT simulator SimGS C that takes the inputs and outputs of all the corrupt parties and produces a view of the protocol that is computationally indistinguishable from the real view: ˆ View Z GS ←SimGS C (1κ, {λi w, ki w,0, ki w,1}w∈[n+q],Pi∈Z, {F i,j,g a,b }g∈[q],j∈[N],(a,b)∈{0,1}2,Pi∈Z, {Gj a,b}j∈[N],g∈[q],(a,b)∈{0,1}2, {λw}w∈[n+q−m,n+q], {λi}Pi∈Z) Here, ˆ View Z GS denotes the view of Z ⊂P output by simulator SimGS C .
2. FOT used in Figure 4 is replaced by a protocol ΠOT
[EGL82] that computes 2-party oblivious transfer. ΠOT is a protocol that is secure in the presence of a computationally unbounded semi-honest adversary corrupting the OT sender. That is, there exists a simulator SimOT S that takes the inputs of the sender and produces a view of the protocol that is statistically close to that of the real view: ˆ View S OT ←SimOT S (1s, s0, s1) 46 Authors Suppressed Due to Excessive Length ΠOT is also secure in the presence of a PPT semi-honest adversary corrupting the OT receiver. That is, there exists a PPT simulator SimOT C that takes the input and output of the receiver and produces a view of the protocol that is computationally indistinguishable from the real view: ˆ View R OT ←SimOT C (1κ, b, sb) Given the sub-protocols ΠGS and ΠOT as above, we are now ready to prove our theorem in the plain model. Let us first consider the case of statistical security against any Z ∈ZS where Z ⊆{Pi}i∈[n−1]. In the plain model, the PPT simulator SimS for Figure 4, making black-box calls to SimOT S , operates as follows:
1. SimS has the input of all the corrupt parties {xi}Pi∈Z and the function output f(x). Let R be the domain of each party’s randomness. SimS samples randomness {ri ←R}Pi∈Z for all corrupt parties.
2. In the Garbling Phase of Figure 4, SimS samples {ri ←R}Pi∈[n]−Z on behalf of all the honest garblers. It executes ΠGS as in the real execution with inputs derived from ⃗r = {ri}Pi∈[n]. Let ViewZ GS denote the view of Z in this execution of ΠGS.
3. In the OT Phase of Figure 4, first SimS computes {Λi}Pi∈Z for the corrupt parties. It then samples Λi ←{0, 1} uniformly at random for each honest party. Next, for each i ∈[n], Pj ∈Z, SimS makes black-box calls to SimOT S , obtaining the views: ∀i ∈[n], Pj ∈Z, ˆ View S OT,i,j ←SimOT S (1s, kj i,0, kj i,1)
4. Finally, in the Evaluation Phase, SimS sets f(⃗x) as the output. Let κ be the computational security parameter. The view of the adversary in the above execution of SimS is distributed as,  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ViewZ GS, { ˆ View S OT,i,j}i∈[n],Pj∈Z κ∈N,⃗r∈Rn Note that this view differs from the real view only in the view of the oblivious transfer. Let d = |Z|. For each i ∈[n], Pj ∈Z, let ViewS OT,i,j be the view of oblivious transfer in the real OT execution where Pj is the sender and Pn is the receiver for the choice bit Λi. In order to show that the simulated view and the real view of the protocol is statistically close, consider dn+1 hybrids of the form: – Hybrid H0,0. This is the distribution of the output of SimS. This is identical to the view in the real execution up to before the OT executions. H0,0 =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ViewZ GS, { ˆ View S OT,i,j}i∈[n],Pj∈Z κ∈N,⃗r∈Rn Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 47 – Hybrid Hi,j. For i ∈[n] and corrupted party Pj ∈Z, this hybrid experiment contains the real execution of Protocol 4 up to the OT execution where Pj is the sender and Λi is the input bit of Pn. The rest of the OT execution views are created as in the simulation using calls to SimOT S . Hi,j =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, ViewZ GS, {ViewS OT,i′,j′}i′∈[i−1],(i′=i,j′≤j), { ˆ View S OT,i′,j′}i′>i,(i′=i,j′>j) κ∈N,⃗r∈Rn – Hybrid Hn,d. This has the distribution of the view in the real execution of Protocol 4. Hn,d =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ViewZ GS, {ViewS OT,i,j}i∈[n],Pj∈Z κ∈N,⃗r∈Rn Claim. Assuming that the OT protocol ΠOT is secure against an unbounded semi-honest adversary corrupting the sender, the view in the hybrid distribution Hi,j is statistically indistinguishable from the view in Hi,j+1. Proof. Note that each adjacent pair of hybrids Hi,j and Hi,j+1 (similarly, H0,0 and H1,1, and each Hi,d and Hi+1,1) differ only in the view of one OT execution. In Hi,j, the view of the OT execution ˆ View S OT,i,j is the simulated OT view output by SimOT S . In Hi,j+1, this is ViewS OT,i,j, as in the real OT execution. The rest of the hybrid is created and distributed the same way. We already have that the view produced by SimOT S is statistically close to the real view of OT. Let ϵ be the statistical difference between the distributions { ˆ View S OT,i,j} and {ViewS OT,i,j} of the simulated and real OT execution. Then the statistical difference between the hybrid distributions Hi,j and Hi,j+1 is no more than ϵ. It follows from the triangle inequality of statistical differences that the difference between the distribution of the simulated view H0,0 output by SimS and the real view Hn,d in Figure 4 is ≤ndϵ. Therefore, the distributions of the real and simulated views are statistically close. It remains to handle the case of security against any Z ∈ZC. Here a PPT semi- honest adversary has in its view Z ⊆P. The difference between this case and the previous case is that the evaluator of the garbling, Pn, can also be corrupted by the adversary. As such the PPT simulator SimC needs to give the adversary a garbled circuit that evaluates to the correct function output, without knowing the inputs of the honest parties to this function. The simulator SimC for Figure 4 in the plain model, making black-box calls to SimGS C and SimOT C , works as follows:
1. SimC has as input the input of all the corrupt parties {xi}Pi∈Z and the function output f(⃗x). It samples randomness {ri}Pi∈Z for all corrupt parties. If Pn is not corrupted, SimC behaves the same as SimS. 48 Authors Suppressed Due to Excessive Length
2. Otherwise, in the Garbling Phase of Figure 4, SimC first samples random- ness on behalf of all the honest garblers and creates a garbling that always outputs f(⃗x). This is done by computing, Gj∗ a,b = N M i=1 F i,j,g a,b ! ⊕(λw||kj w,0) ∀j ∈[N], g ∈[q], (a, b) ∈{0, 1}2 λ∗ w = Λw ⊕yw′ ∀yw′ ∈f(⃗x), w = n + q −m + w′ That is, for a garbled gate g ∈[q] and j ∈[N], all the 4 ciphertexts mask the same label kj w,0. Finally, for each circuit output wire, the apparent value Λw is mapped to the output bit y ∈f(⃗x) by setting λw = Λw ⊕y. Next, SimC makes a black-box call to SimGS C with the inputs of the corrupted parties and the above garbling: ˆ View Z GS ←SimGS C (1κ, {λi w, ki w,0, ki w,1}w∈[n+q],Pi∈Z, {F i,j,g a,b }g∈[q],j∈[N],(a,b)∈{0,1}2,Pi∈Z, {Gj∗ a,b}j∈[N],g∈[q],(a,b)∈{0,1}2, {λ∗ w}w∈[n+q−m,n+q], {λi}Pi∈Z) Such a simulator exists
[BLO16] and produces a view ˆ View Z GS that is com- putationally indistinguishable from the view of Z in a real execution of ΠGS.
3. In the OT Phase of Figure 4, first SimC samples for each honest party Pi ∈P −Z, a random bit Λi ←{0, 1}. Next, for each i ∈[n], Pj ∈P −Z, SimC makes black-box calls to SimOT C , obtaining the views: ∀i ∈[n], Pj ∈P −Z, ˆ View R OT,i,j ←SimOT C (1κ, Λi, kj i,Λi)
4. Finally, in the Evaluation Phase, SimC accepts f(⃗x) as the result of gar- bling evaluation. Let κ be a computational security parameter and ⃗r be the randomness sampled for all the corrupt parties and internally in the garbling simulator SimGS C . The view of the adversary in the above execution of SimC is distributed as,  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ˆ View Z GS, { ˆ View R OT,i,j}i∈[n],Pj̸∈Z κ∈N,⃗r∈Rn It remains to argue that the above distribution is computationally indistinguish- able from that of the real view of the adversary in Figure
4. This view differs from the real view in that the garbling view ˆ View Z GS and the view of the OT executions { ˆ View R OT,i,j}i∈[n],Pj̸∈Z are created differently. Let d be the number of corrupt parties. In order to show that the distribution of the output of SimC is indistinguishable from the real view, consider the following set of n(n −d) + 2 hybrids: Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 49 – Hybrid H0. This is the distribution of the output of SimC. H0 =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, ˆ View Z GS, { ˆ View R OT,i′,j′}i′∈[n],Pj′̸∈Z κ∈N,⃗r∈Rn – Hybrid H1. This is an intermediate distribution where the view is generated by first executing the real Protocol 4 up to the end of ΠGS. Then the views of the OT protocols are generated as in the simulation SimC. H1 =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, ViewZ GS, { ˆ View R OT,i′,j′}i′∈[n],Pj′̸∈Z κ∈N,⃗r∈Rn This distribution differs from H0 only in that the view ViewZ GS here is derived from a real execution of ΠGS. – Hybrid Hi,j. For i ∈[n] and honest party Pj ̸∈Z, this hybrid experiment contains the view of the real execution of Protocol 4 up to the OT execution where Pj is the sender and Λi is the input bit of Pn. The rest of the OT execution views are created as in the simulation using calls to SimOT C . Hi,j =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, ViewZ GS, {ViewR OT,i′,j′}i′<i,(i′=i,j′≤j), { ˆ View R OT,i′,j′}i′>i,(i′=i,j′>j) κ∈N,⃗r∈Rn – Hybrid Hn,(n−d). This has the distribution of the view in the real execution of Protocol 4. Hn,(n−d) =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, ViewZ GS, {ViewR OT,i′,j′}i′∈[n],Pj′̸∈Z κ∈N,⃗r∈Rn Claim. Assuming that the protocol ΠGS is secure against a PPT semi-honest adversary corrupting any subset Z ⊂P of the parties, the view in the hybrid distribution H0 is computationally indistinguishable from that in H1. Proof. We show that if there existed a PPT distinguisher D that can distinguish between H0 and H1 with non-negligible advantage ϵ, then D can be used in a black-box way by a PPT adversary AGS that distinguishes between the distribu- tions {ViewZ GS}κ∈N,⃗r∈Rn from the real execution of ΠGS and { ˆ View Z GS}κ∈N,⃗r∈Rn from the output of SimGS C . The adversary works as follows: 50 Authors Suppressed Due to Excessive Length – The adversary AGS has the values (⃗x, f(⃗x)) and samples the randomness ⃗r ←Rn for all parties. – AGS sends (f(⃗x),⃗r) to the challenger C that internally samples a bit b. – If b = 0, C computes, Gj∗ a,b = N M i=1 F i,j,g a,b ! ⊕(λw||kj w,0) ∀j ∈[N], g ∈[q], (a, b) ∈{0, 1}2 λ∗ w = Λw ⊕yw′ ∀yw′ ∈f(⃗x), w = n + q −m + w′ ViewGS ←SimGS C (1κ, {λi w, ki w,0, ki w,1}w∈[n+q],Pi∈Z, {F i,j,g a,b }g∈[q],j∈[N],(a,b)∈{0,1}2,Pi∈Z, {Gj∗ a,b}j∈[N],g∈[q],(a,b)∈{0,1}2, {λ∗ w}w∈[n+q−m,n+q], {λi}Pi∈Z) Otherwise, C computes ViewGS to be the view of the parties in Z in the real execution of ΠGS. – C gives ViewGS to AGS and, with this, AGS computes the rest of the view View as in SimC. Note that if b = 0, View is distributed as in H0 and if b = 1, it distributed as in H1. – Finally, AGS passes View on to D and outputs whatever D outputs. In the above strategy, AGS has the same distinguishing advantage as D, which is non-negligible. However, since the protocol ΠGS is secure against a PPT semi- honest adversary corrupting any subset Z ⊂P of the parties, no such AGS can exist [LPSY15, BLO16], and it follows that no such D can exist. So the distributions H0 and H1 are computationally indistinguishable. Claim. Assuming that the OT protocol ΠOT is secure against a PPT semi- honest adversary corrupting the receiver, the view in the hybrid distribution Hi,j is computationally indistinguishable from the view in Hi,j−1. Proof. Note that each adjacent pair of hybrids Hi,j and Hi,j−1 (similarly, H1 and H1,1, and each Hi,(n−d) and Hi+1,1) differ only in the view of one OT execution. In Hi,j−1, the view of the OT execution ˆ View R OT,i,j is the simulated OT view output by SimOT C . In Hi,j, this is ViewR OT,i,j, as in the real OT execution. The rest of the hybrid is created and distributed the same way. We show that if there existed a PPT distinguisher D that can distinguish be- tween Hi,j and Hi,j−1 with non-negligible advantage ϵ, then D can be used in a black-box way by a PPT adversary AOT that distinguishes between the distribu- tions {ViewR OT,i,j}κ∈N,r∈R from the execution of ΠOT and { ˆ View R OT,i,j}κ∈N,r∈R from the output of SimOT C . The adversary works as follows: – AOT has the indices i, j and the values (⃗x, f(⃗x)). It samples randomness ⃗r ←Rn and computes ViewZ GS as in a real execution of the protocol ΠGS. Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 51 – Then, for all OT instances (i′, j′) where i′ < i or i′ = i and j′ < j, it creates ViewR OT,i′,j′ as in the real OT execution. For all OT instances (i′, j′) where i′ > i or i′ = i and j′ > j, it creates ˆ View R OT,i′,j′ as in the simulated OT execution. – Corresponding to the (i, j)th OT execution, AOT sends inputs kj i,0, kj i,1 and Λi to the challenger C. – C internally samples a bit b and if b = 0, it computes, ViewOT ←SimOT C (1κ, Λi, kj i,Λi) Otherwise it computes ViewOT to be the view of the receiver in the real execution of ΠOT. – C gives ViewOT to AOT and, with this, AOT completes the view View to be input to D. Note that if b = 0, View is distributed as in Hi,j−1 and if b = 1, it is distributed as in Hi,j. – Finally, AOT passes View to D and outputs whatever D outputs. In the above strategy, AOT has the same distinguishing advantage as D, which is non-negligible. However, since the protocol ΠOT is secure against a PPT semi- honest adversary corrupting the receiver, no such AOT can exist, and it follows that no such D can exist. So the distributions Hi,j and Hi,j−1 are computationally indistinguishable. Since none of the listed set of adjacent hybrids are distinguishable, it fol- lows that the real view of the protocol Hn,(n−d) and the simulated view H0 are computationally indistinguishable. A.2 Proof of Theorem 4.1 Proof. The proof of this theorem follows in two parts. First, we show that there exists a PPT simulator SimC that for any subset of parties Z ∈ZC = 2P can output a view that is computationally indistinguishable to the view in the real protocol. Next, we show that there exists a simulator SimS that for any subset of parties Z ∈ZS can output a view that is statistically close to the view in the real protocol. In order to examine the security of Figure 6 in the plain model, it becomes necessary to describe the properties of its building blocks:
1. Πstat is a virtual n-party protocol computing the function f on input ⃗x. Πstat is secure in the presence of a semi-honest unbounded adversary corrupting any subset Z ⊂V of the parties where Z ∈ZS. This means that there exists a simulator Simstat
[BGW88] that, given the inputs and outputs of the parties in Z can generate a view of this adversary that is statistically close to its view in the real execution of Πstat. ˆ View Z stat ←Simstat(1s, {xi}Vi∈Z, f(⃗x)) ˆ View Z stat κ∈N,⃗r∈Rn s≡ ViewZ stat κ∈N,⃗r∈Rn 52 Authors Suppressed Due to Excessive Length
2. Much like how Πstat can be written as the set of functions {NxtMsgj i}i∈[n],j∈[r], the simulator Simstat can also be written as, Simstat = {NxtMsgj∗ i }i∈[n],j∈[r] Here, for each corrupted party Vi ∈Z, the functions {NxtMsgj∗ i }j∈[r] = {NxtMsgj i}j∈[r] are as in the real protocol Πstat. However, for each honest party Vi ̸∈Z, for each round j ∈[r], the next-message function has the same structure as the real function but produces simulated messages that do not depend on the party’s input: {mj′ i→k}k̸=i∈[n] ←NxtMsgj∗ i ( ˆ View j−1 stat,i) Here ˆ View j−1 stat,i is the simulated view with all the messages that the corrupt party sends to Vi up to round j −1. The set {mj′ i→k}k̸=i∈[n] is the set of simulated messages output on behalf of Vi to the other parties in round j.
3. The real protocol Πin is composed of the set of protocols {ΠNxtMsgj i }i∈[n],j∈[r] corresponding to the Πstat in question. Each sub-protocol ΠNxtMsgj i works as described in Figure 4 with Pi as the evaluator and the rest of the parties as the garblers. Due to Theorem 3.4, we know that for a PPT semi-honest adversary corrupting Z ⊆P there exists a simulator Sim NxtMsgj i C that given the inputs and outputs of the parties in Z can produce a view that is compu- tationally indistinguishable to the distribution from a real execution of the sub-protocol: ˆ View Z NxtMsgj i ←Sim NxtMsgj i C (1κ,{[Viewj−1 Πstat,i]k, Mk}Pk∈Z, {ck = Mk ⊕{[mj i→i′]k}i′̸=i∈[n]}k∈[n]) ˆ View Z NxtMsgj i κ∈N,⃗r∈Rn c≡ ViewZ NxtMsgj i κ∈N,⃗r∈Rn We also have that for an unbounded semi-honest adversary corrupting Z ⊆ P −{Pi} there exists a simulator Sim NxtMsgj i S that, given the inputs and outputs of the parties in Z, can produce a view that is statistically close to the distribution from a real execution of the sub-protocol: ˆ View Z NxtMsgj i ←Sim NxtMsgj i S (1s,{[Viewj−1 Πstat,i]k, Mk}Pk∈Z, {ck = Mk ⊕{[mj i→i′]k}i′̸=i∈[n]}k∈[n]) ˆ View Z NxtMsgj i κ∈N,⃗r∈Rn s≡ ViewZ NxtMsgj i κ∈N,⃗r∈Rn Similarly to the above, if this simulator is given the inputs of the adversar- ial parties and the outputs are based on {[mj′ i→i′]k}i′̸=i∈[n]}k∈[n], as output Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 53 by the simulator of the virtual protocol NxtMsgj∗ i ∈Simstat, the view simu- lated is a view that is still statistically close to that in the real execution of ΠNxtMsgj i : ˆ View Z NxtMsgj∗ i ←Sim NxtMsgj i S (1s,{[ ˆ View j−1 stat,i]k, Mk}Pk∈Z, {ck = Mk ⊕{[mj′ i→i′]k}i′̸=i∈[n]}k∈[n]) ˆ View Z NxtMsgj∗ i κ∈N,⃗r∈Rn s≡ ViewZ NxtMsgj i κ∈N,⃗r∈Rn Given these building-blocks, we can prove the theorem in the plain model. Let us first consider the case of security against a PPT semi-honest adversary that corrupts any subset Z ⊆P of the parties. The simulator for Figure 6, making black-box calls to simulators in {Sim NxtMsgj i C }i∈[n],j∈[r], works as follows:
1. SimC has the input of all the corrupt parties {xi}Pi∈Z and the function output f(⃗x). It samples randomness {ri}Pi∈Z for all corrupt parties.
2. In the ‘Initialize shared state’ phase, SimC, on behalf of each honest party Pi′ ̸∈Z, samples a random input xi′ ←{0, 1} and creates shares {[xi′]i}i∈[n] ←Sharen,n(xi′). For each i′ ∈[n], it creates shares also of the randomnesses {[ri′]i}i∈[n] ←Sharen,n(ri′). It sends the set of shares {[xi′]i, [ri′]i}Pi′̸∈Z to the corrupt party Pi ∈Z.
3. For each virtual party Vi ∈V and each round j ∈[r] of the virtual protocol Πstat, for the protocol ΠNxtMsgj i as in Figure 4, SimC makes a black-box call to the PPT simulator Sim NxtMsgj i C that can simulate the view of the corrupt parties in a way that is computationally indistinguishable from the real view. Let this set of views be, { ˆ View Z NxtMsgj i }i∈[n],j∈[r]
4. In the phase to ‘Derive the output’, SimC gives the adversary shares of the output such that they reconstruct to {f(⃗x) = fi(⃗x)}Pi∈Z This completes the simulation. The view of the adversary in the above execution of SimC is distributed as,  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, { ˆ View Z NxtMsgj i }i∈[n],j∈[r] κ∈N,⃗r∈Rn It remains to argue that the above view is computationally indistinguishable to the real view of the adversary in Figure
6. Note that this view differs from the real view in the protocol in that the views of the next-message protocols are composed of calls to Sim NxtMsgj i C in the simulation. In order to show that the output of SimC is indistinguishable from the real view, consider the following set of rn + 1 hybrids: 54 Authors Suppressed Due to Excessive Length – Hybrid H0. This is the distribution of the output of SimC. H0 =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, { ˆ View Z NxtMsgj i }i∈[n],j∈[r] κ∈N,⃗r∈Rn – Hybrid Hi,j. For each i ∈[n] and j ∈[r], this hybrid experiment contains the view of parties in Z in the real protocol execution up to the execution of the sub-protocol ΠNxtMsgj i . The rest of the view is generated as in the simulation SimC. Hi,j =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, {ViewZ NxtMsgj′ i′ }i′<i,(i′=i,j′≤j), { ˆ View Z NxtMsgj′ i′ }i′>i,(i′=i,j′>j) κ∈N,⃗r∈Rn – Hybrid Hn,r. Note that the last hybrid of the above form is distributed exactly as the real execution of Protocol 6. Hn,r =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, {ViewZ NxtMsgj i }i∈[n],j∈[r] κ∈N,⃗r∈Rn Claim. Assuming that the protocol ΠNxtMsgj i is secure in the presence of a PPT semi-honest adversary corrupting any subset Z ⊆P of the parties, the view in the hybrid distribution Hi,j is computationally indistinguishable from that in Hi,j−1. Proof. Note that in the hybrid distributions described above, each pair of ad- jacent hybrids Hi,j and Hi,j−1 (similarly, H0 and H1,1; and each pair Hi,r and Hi+1,1) differ only the view of the execution of the sub-protocol ΠNxtMsgj i . In Hi,j−1, this view is the simulated view ˆ View Z NxtMsgj i output by Sim NxtMsgj i C . In Hi,j this is the view of the parties in Z in the real execution of ΠNxtMsgj i . We show that if there existed a PPT distinguisher D that can distinguish between the hybrid distributions Hi,j and Hi,j−1 with non-negligible advantage ϵ, then D can be used in a black-box way by a PPT adversary A that distinguishes between the distributions { ˆ View Z NxtMsgj i }κ∈N,⃗r∈Rn from the output of Sim NxtMsgj i C and {ViewZ NxtMsgj i }κ∈N,⃗r∈Rn from the real execution of the sub-protocol as in Figure
4. The adversary A works as follows: – A has the indices (i, j), the set of corrupted parties Z ⊆P and (⃗x, f). It samples randomness ⃗r ←Rn for all parties. – For the next message functions NxtMsgj′ i′ of Πstat where i′ < i or i′ = i and j′ < j, it creates the view as in the real protocol: ViewZ NxtMsgj′ i′ . For the instances where i′ > i or i′ = i and j′ > j, it creates the view as in the simulation ˆ View Z NxtMsgj′ i′ . Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 55 – Corresponding to the (i, j)th instance, A sends all the inputs and outputs to the challenger C that samples a bit b. If b = 0, C computes, ViewNxtMsg ←Sim NxtMsgj i C (1κ,{[Viewj−1 Πstat,i]k, Mk}Pk∈Z, {ck = Mk ⊕{[mj i→i′]k}i′̸=i∈[n]}k∈[n]) Otherwise it computes ViewNxtMsg to be the views of the parties in Z in the real execution of ΠNxtMsgj i . – C gives ViewNxtMsg to A and, with this, A completes the view View to be input to D. Note that if b = 0, View is distributed as in Hi,j−1 and if b = 1, it is distributed as in Hi,j. – Finally, A passes View to D and outputs whatever D outputs. In the above strategy, A has the same distinguishing advantage as D, which is non-negligible. However, since the protocol ΠNxtMsgj i is secure in the presence of a PPT semi-honest adversary corrupting any subset Z ⊆P of the parties, no such A can exist and therefore no such D can exist. So the distributions Hi,j and Hi,j−1 are computationally indistinguishable. Since none of the listed set of adjacent hybrids are distinguishable, it follows that the real view of the protocol Hn,r and the simulated view H0 are com- putationally indistinguishable. Therefore, it follows that the view produced by SimC is overall computationally indistinguishable to that of the real execution of Figure 6 for any Z ∈ZC. Let us now consider the case of statistical security against an unbounded semi- honest adversary corrupting any Z ∈ZS. Let ZV ⊂V be the set of cor- rupted parties such that ZV = {Vi}Pi∈Z. The virtual protocol Πstat is secure against an unbounded semi-honest adversary corrupting ZV since ZV ∈ZS. The simulator SimS for protocol 6, making black-box calls to the simulators in {Sim NxtMsgj i S }i∈[n],j∈[r], operates as follows:
1. SimS has the input of all the corrupt parties {xi}Pi∈Z and the function output f(⃗x). It samples randomness {ri}Pi∈Z for all corrupt parties.
2. In the ‘Initialize shared state’ phase, SimS, on behalf of each honest party Pi′ ̸∈Z, samples a random input xi′ ←{0, 1} and creates shares {[xi′]i}i∈[n] ←Sharen,n(xi′). For each i′ ∈[n], it creates shares of the ran- domnesses {[ri′]i}i∈[n] ←Sharen,n(ri′). It sends the set {[xi′]i, [ri′]i}Pi′̸∈Z to the corrupt party Pi ∈Z.
3. For each round j ∈[r], for each virtual party Vi ∈V where Pi ̸∈Z is honest, SimS computes the inputs and outputs of the simulator Simstat of the virtual protocol, {mj′ i→k}k̸=i∈[n] ←NxtMsgj∗ i ( ˆ View j−1 stat,i) 56 Authors Suppressed Due to Excessive Length Then, shares of these inputs and outputs are used to generate the view in the real protocol: ˆ View Z NxtMsgj∗ i ←Sim NxtMsgj i S (1s,{[ ˆ View j−1 stat,i]k, Mk}Pk∈Z, {ck = Mk ⊕{[mj′ i→i′]k}i′̸=i∈[n]}k∈[n]) For each round j ∈[r], for each virtual party Vi ∈V where Pi ∈Z is corrupted, SimS computes the inputs and outputs of the real-world execution of the virtual protocol, {mj i→k}k̸=i∈[n] ←NxtMsgj i( ˆ View j−1 stat,i) Then, shares of these inputs and outputs are used to generate the view in the real protocol: ViewZ NxtMsgj i ←ΠNxtMsgj i (1s, {[ ˆ View j−1 stat,i]k, Mk}k∈[n]) In the end of this phase, the adversary’s view consists of, ˆ View Z NxtMsgj∗ i j∈[r],Pi̸∈Z, ViewZ NxtMsgj i j∈[r],Pi∈Z
4. In the phase to ‘Derive the output’, SimS gives the adversary shares of the output such that when combined with the shares that it derives from its own views, they reconstruct to {f(⃗x) = fi(⃗x)}Pi∈Z This completes the simulation. The view of the adversary in the above execution of SimS is distributed as,  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ˆ View Z NxtMsgj∗ i j∈[r],Pi̸∈Z, ViewZ NxtMsgj i j∈[r],Pi∈Z κ∈N,⃗r∈Rn It remains to argue that the above view is statistically close to the real view of the adversary in Figure
6. For this, consider the following hybrids: – Hybrid H0. This is the distribution of the output of SimS. H0 =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ˆ View Z NxtMsgj∗ i j∈[r],Pi̸∈Z, ViewZ NxtMsgj i j∈[r],Pi∈Z κ∈N,⃗r∈Rn – Hybrid H1. An intermediate hybrid distribution with the simulated virtual protocol Simstat for the view of ZV but with each protocol execution among Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 57 the real parties P being a real execution: H1 =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ViewZ NxtMsgj∗ i j∈[r],Pi̸∈Z, ViewZ NxtMsgj i j∈[r],Pi∈Z κ∈N,⃗r∈Rn This differs from H0 in that the view of real protocol corresponding to the next-message functions of the simulator of the virtual protocol is generated as in a real execution of Protocol 4, instead of using the simulation. – Hybrid H2. The distribution of the view of the parties in Z in a real execution of Protocol 6. H2 =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ViewZ NxtMsgj i j∈[r],i∈[n] κ∈N,⃗r∈Rn Claim. Assuming that for each i ∈[n] and j ∈[r], the protocol ΠNxtMsgj i as in Protocol 4 is secure in the presence of a semi-honest unbounded adversary that can corrupt any subset of P −{Pi}, the view in the hybrid distributions H0 and H1 are statistically close. Proof. Let (n −d) be the number of honest parties and let r be the number of rounds in Πstat. In order to show that the hybrids H0 and H1 are statistically close, consider the following set of r(n −d) + 1 hybrids: – Hybrid A0. This is a hybrid that is distributed identically to H0. A0 =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ˆ View Z NxtMsgj∗ i j∈[r],Pi̸∈Z, ViewZ NxtMsgj i j∈[r],Pi∈Z κ∈N,⃗r∈Rn – Hybrid Ai,j. For each i ∈[n −d] and j ∈[r], this hybrid distribution is derived using the next message functions of the simulated virtual protocol Simstat where for the sub-protocols up to ΠNxtMsgj∗ i a view of the parties in Z of the real execution of the protocol is included, instead of a simulated one as in H0. The rest of the view is generated as in SimS. Ai,j =  {xi′}Pi′∈Z, f(⃗x), {ri′}Pi′∈Z, ViewZ NxtMsgj′∗ i′ i′<i,(i′=i,j′≤j), ˆ View Z NxtMsgj′∗ i′ i′>i,(i′=i,j′>j), ViewZ NxtMsgj′ i′ j′∈[r],Pi′∈Z κ∈N,⃗r∈Rn 58 Authors Suppressed Due to Excessive Length – Hybrid An−d,r. Note that the last hybrid distribution as above is distributed the same way as in H1. An−d,r =  {xi}Pi∈Z, f(⃗x), {ri}Pi∈Z, ViewZ NxtMsgj∗ i j∈[r],Pi̸∈Z, ViewZ NxtMsgj i j∈[r],Pi∈Z κ∈N,⃗r∈Rn In the above set of hybrids, note that adjacent pairs of hybrids Ai,j and Ai,j−1 (similarly, A0 and A1,1 and each Ai,r and Ai+1,1) differ only in the view of one execution of the sub-protocol ΠNxtMsgj∗ i where NxtMsgj∗ i ∈Simstat. In Ai,j−1, the view of this execution is the simulated view ˆ View Z NxtMsgj∗ i . In Ai,j, this is ViewZ NxtMsgj∗ i , as in the real execution. The rest of the hybrid is dis- tributed the same way. We already have that the simulated view produced by Sim NxtMsgj i S is distributed in a way that is statistically close to the real view of the protocol ΠNxtMsgj∗ i . Let ϵ be the statistical difference between the distributions { ˆ View Z NxtMsgj∗ i }κ∈N,⃗r∈Rn and {ViewZ NxtMsgj∗ i }κ∈N,⃗r∈Rn of the simulated and real executions respectively. Then the statistical difference between the hybrids is no more than ϵ. It also follows from the triangle inequality of statistical differences that the difference between the simulated view H0 output by SimS and the hybrid H1 is ≤r(n −d)ϵ. Therefore, these hybrid distributions are statistically close. Claim. Assuming that the protocol Πstat is secure in the presence of a semi- honest unbounded adversary with adversary structure ZS, the view in the hybrid distributions H1 and H2 are statistically close. Proof. We already have that the distribution of the view produced by Simstat is statistically close to that in the real execution of the protocol Πstat. Let ϵ be the statistical difference between these views. Since this is the only difference between the two hybrids H1 and H2, the statistical difference between them is also no more than ϵ. Therefore, these hybrid distributions are statistically close. So it follows that the view produced by SimS is statistically close to that of the real execution of Figure 6 for any Z ∈ZS. A.3 Proof of Lemma 5.6 Proof. The proof for Lemma 5.6 follows in two parts. First we show that Pro- tocol 5.4 is secure in the presence of a PPT malicious adversary corrupting any subset of the parties Z ⊆P. Next, we show that the same protocol is secure in the presence of an unbounded malicious adversary corrupting a subset of parties Z ∈ZS. In order to examine the security of Protocol 5.4 in the plain model, it becomes necessary to first prove the following lemma: Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 59 Lemma A.1 Let ComSB be a statistically binding commitment. Let ComSH be a statistically hiding commitment and let SZKAoK be a statistical zero-knowledge argument of knowledge protocol. Let ZKPoK be a zero-knowledge proof of knowl- edge protocol. Then the n-party commitment protocol ΠCom in Figure 12 is a maliciously fall-back secure realization of FCom tolerating ZS. Proof. The proof for this lemma follows in 2 parts. First, we need to show that Figure 12 securely realizes FCom in the presence of a PPT malicious adversary corrupting any subset of the parties Z ⊆P. Next we need to show that the same protocol realizes the functionality in the presence of an unbounded malicious adversary corrupting a subset of parties Z ∈ZS. Security against a PPT Adversary. Let A be a PPT adversary corrupting any subset of parties Z ⊂P. There exists a PPT simulator SimC that simulates the view of A in the protocol in the ideal world, in a way that is computationally indistinguishable from the view in the real execution. SimC would operate as follows: – If C is honest,
1. In the commit phase of ΠCom, first for each Pi ∈Z participate honestly in the commitment protocol Com with Pi as the committer. Note that for each such corrupted committer, this sub-protocol is computationally binding: • A PPT adversary corrupting an arbitrary subset of parties in P including the committer cannot equivocate the view of an opening to the commitment to the honest parties. This holds due to the fact that the statistically binding commitment used here for the input shares is also computationally binding. Further, the protocol also uses a statistically hiding commitment to commitment to the input as a whole, to each viewer. This scheme is computationally binding and so a PPT adversary cannot equivocate, no matter how large the collusion set. Then for each Pi ̸∈Z, such that Pi ̸= C, it acts honestly as in the protocol and creates the commitments with Com. Note that for each such honest committer, this sub-protocol is computationally hiding: • A PPT adversary corrupting an arbitrary subset of parties in P ex- cluding the committer cannot know any information about the value committed to. This holds directly from the fact that a statistically hiding commitment is also computationally hiding and the statisti- cally binding commitment is computationally hiding as well. So there must exist a simulator SimCom C that can simulate the view of the ad- versary in a way that is computationally indistinguishable from the real view.
2. For each j ∈[κ] it samples x∗at random and honestly computes what the committer C would with input x∗.
3. All parties decommit to Com from step 1 and SimC learns r. 60 Authors Suppressed Due to Excessive Length
4. Now SimC rewinds to Step 2 and for each j ∈[κ], it first samples νj ← {0, 1} at random and for the matrix Mj both elements in the r[j]th column is set as νj. In the other column, at random, one element is set as νj and the other is set as νj + 1.
5. Then the rest of the commit phase is executed honestly. Note here that the protocol ECom is also computationally hiding: • This is true due to the same reasons as for Com. Additionally, the SZKAoK and ZKPoK protocols used are zero-knowledge in the pres- ence of PPT verifiers.
6. In the decommit phase of ΠCom, simulator SimC learns x from FCom.
7. Now, for each j ∈[κ], in the (¬r[j])th column of matrix Mj, the simulator de-commits to the element containing νj + x[j]. – If A corrupts C,
1. In the commit phase of ΠCom, first for each Pi ∈Z participate honestly in the commitment protocol Com with Pi as the committer. Then for each Pi ̸∈Z, such that Pi ̸= C, it acts honestly as in the protocol and creates the commitments with Com.
2. For each j ∈[κ] it engages with the adversary A corrupting C in the 4 executions of ECom where, • Along with being computationally binding, the value committed in ECom is extractable. That is within the ‘commit phase’, when a PPT adversary is corrupting an arbitrary subset of parties in P including the committer, there exists an extractor that can interact with the adversary in the ideal execution and extract the input of the com- mitter. Such an extractor ECom.E∗ C would make a black-box call to the extractor of the SZKAoK, deriving the input to the statistically hiding commitment. So the simulator extracts from ECom all the elements of {Mj}j∈[κ] that C commits to.
3. These are used to derive x and this is given to FCom. If this extraction fails, or the matrices are not well-formed, send ⊥to FCom.
4. The rest of the protocol is executed honestly by the simulator on behalf of the honest parties. Let ViewCom Z,i (x) be the view of the adversary in a real execution of the proto- col Com where party Pi is the committer with input x. Similarly, let ViewECom Z,i (x) be the view of the adversary in a real execution of the protocol ECom where party Pi is the committer with input x. For the case that the committer C is honest, the view produced by SimC is distributed as: ViewCom Z,i (ri)}i∈[n], r, ViewECom Z,i (M ∗ j [a, b])}j∈[κ],a,b∈{0,1}, M ∗ j [r[j], a]}j∈[κ],a∈{0,1}, M ∗ j [¬r[j], bj]}j∈[κ],bj:M ∗ j [¬r[j],bj]−M ∗ j [r[j],a]=x This differs from that in the real distribution only in Step 4 where for all j ∈[κ], in one column, M ∗ j [¬r[j], ·], of matrix M ∗ j , the two values committed Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 61 to using ECom are not equal. This is not the case in the real distribution where both values in the column not checked in Mj are equal and they equal the sum of the value opened and the committer’s input to the commitment protocol. This amounts to having κ different commitments ECom in SimC with different messages from that in the real view. Everything other than these commitments are created identically. In order to argue that the view produced by the real protocol is distributed computationally indistinguishable from in the simulation, consider the following set of κ + 1 hybrids: – H0 : Let this be the distribution of the view as produced in the simulation. – ∀j ∈[κ], Hj : Let this be the distribution of the view in which the first j matrices committed to M1, · · · , Mj are created as in the real distribution and the rest are created as in the simulation. The last such hybrid Hκ is distributed as in the real view. Note here that adjacent hybrids ∀j ∈[κ], Hj and Hj−1 differ only in the value of one element in the matrix Mj. A PPT distinguisher that can distinguish be- tween these views with non-negligible advantage can be used in a black-box way by a PPT adversary A to break the computational hiding property of ECom. This is done by A first constructing the complete view except Mj, then the three other elements of Mj (the ones opened in the cut-and-choose, and the one opened in the release phase) and committing to them. The last element of Mj is directly replaced by the challenge commitment. If the underlying message equals the value opened in the release phase, the hybrid is Hj. Otherwise, this forms hybrid Hj−1. The adversary A passes this to the distinguisher and outputs whatever it outputs. Such an adversary would have the same advantage as the distinguisher, which is non-negligible. But since ECom is computationally hiding and no such adversary can exist, no such distinguisher can exist. Hence the dis- tributions of the simulated and real views are computationally indistinguishable. For the case that the committer C is corrupted, the view produced by SimC as indicated above, differs from that in the real distribution only in Step 2 where for all j ∈[κ], the extractor for ZKPoK is executed for all ECom executions for each element in the matrix Mj. This is not the case in the real distribution where the ECom protocol is honestly executed. This amounts to having 4κ dif- ferent commitment executions ECom in SimC. However, the transcripts produced by these are identical to that in the real execution. Therefore, the real and sim- ulated views are identically distributed. This holds for all executions for which a cheating committer is caught cheating in the cut-and-choose. If, however, a committer cheats in the cut-and-choose execution and is not caught in the real execution, its view would differ from the simulation where cheating will always be detected. The probability of success corresponds to the event in which it can guess the complete challenge r correctly and this happens with probability 1 2κ which is negligible in κ. Security against an Unbounded Adversary. Let A be an unbounded adversary corrupting any subset of parties Z ∈ZS. There exists a PPT simulator 62 Authors Suppressed Due to Excessive Length SimS that simulates the view of A in the protocol in the ideal world, in a way that is statistically indistinguishable from the view in the real execution. SimS would operate as follows: – If C is honest,
1. In the commit phase of ΠCom, first for each Pi ∈Z participate honestly in the commitment protocol Com with Pi as the committer. Note that for each such corrupted committer, this sub-protocol is statistically binding: • An unbounded adversary corrupting any Z ∈ZS that includes the committer cannot equivocate the view of an opening to that com- mitment to the honest parties. This is ensured owing to the fact that the committer uses a 2-party statistically binding commitment to interact with all other parties. It shares its input using SSZS and so it follows that the shares of the honest parties, when reconstructed uniquely determine the input. Therefore, corrupted viewers cannot change this value by falsely claiming to have shares. Then for each Pi ̸∈Z, such that Pi ̸= C, it acts honestly as in the protocol and creates the commitments with Com. Note that for each such honest committer, this sub-protocol is statistically hiding: • An unbounded adversary corrupting any Z ∈ZS not including the committer cannot know any information about the value committed to. This holds since the 2-party commitment used to commit to the input is statistically hiding. While it may be true that the statis- tically binding commitment is not hiding for this adversary, this is only used to commit to shares of the input. As such, since SSZS is used for secret-sharing, the adversary corrupting Z will never have enough shares to reconstruct the secret. So there exists a simulator SimCom S that can simulate the view of the adversary in a way that is statistically close to the real view.
2. For each j ∈[κ] it samples x∗at random and honestly computes what the committer C would with input x∗.
3. All parties decommit to Com from step 1 and SimS learns r.
4. Now SimS rewinds to Step 2 and for each j ∈[κ], it first samples νj ← {0, 1} at random and for the matrix Mj both elements in the r[j]th column is set as νj. In the other column, at random, one element is set as νj and the other is set as νj + 1.
5. Then the rest of the commit phase is executed honestly. Note here that the protocol ECom is also statistically hiding: • This also holds the same way as in Com. Additionally, although the ZKPoK used is only zero-knowledge for a PPT verifier, an unbounded adversarial verifier getting the witnesses still only gets shares of a SSZS secret-sharing and cannot reconstruct the input.
6. In the decommit phase of ΠCom, simulator SimS learns x from FCom.
7. Now, for each j ∈[κ], in the (¬r[j])th column of matrix Mj, the simulator de-commits to the element containing νj + x[j]. – If A corrupts C, Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 63
1. In the commit phase of ΠCom, first for each Pi ∈Z participate honestly in the commitment protocol Com with Pi as the committer. Then for each Pi ̸∈Z, such that Pi ̸= C, it acts honestly as in the protocol and creates the commitments with Com.
2. For each j ∈[κ] it engages with the adversary A corrupting C in the 4 executions of ECom where, • ECom is statistically binding for Z, same way as Com is. Additionally, note that the SZKAoK used is only sound for a PPT prover, but an unbounded adversarial prover still cannot cheat as it can’t equivocate in the statistically binding commitment. • Within the ‘commit phase’ of ECom, when an unbounded adversary corrupts any Z ∈ZS including the committer, there exists an ex- tractor that can interact with the adversary in the ideal execution and extract the input of the committer. For this case, such an ex- tractor ΠECom.E∗ S would work by participating in the commit phase on behalf of all the honest parties and making black-box calls to the extractor of the ZKPoK, deriving the shares that were committed to in each statistically binding commitment. Once all the honest par- ties’ shares have been extracted, these can be reconstructed to get the committer’s input. So the simulator extracts from ECom all the elements of {Mj}j∈[κ] that C commits to.
3. These are used to derive x and this is given to FCom. If this extraction fails, or the matrices are not well-formed, send ⊥to FCom.
4. The rest of the protocol is executed honestly by the simulator on behalf of the honest parties. Let ViewCom Z,i (x) be the view of the adversary in a real execution of the proto- col Com where party Pi is the committer with input x. Similarly, let ViewECom Z,i (x) be the view of the adversary in a real execution of the protocol ECom where party Pi is the committer with input x. For the case that the committer C is honest, the view produced by SimS is distributed as: ViewCom Z,i (ri)}i∈[n], r, ViewECom Z,i (M ∗ j [a, b])}j∈[κ],a,b∈{0,1}, M ∗ j [r[j], a]}j∈[κ],a∈{0,1}, M ∗ j [¬r[j], bj]}j∈[κ],bj:M ∗ j [¬r[j],bj]−M ∗ j [r[j],a]=x This differs from that in the real distribution only in Step 4 where for all j ∈[κ], in one column of matrix M ∗ j , the two values committed to using ECom are not equal. This is not the case in the real distribution where both values in the column not checked are equal and they equal the sum of the value opened and the value committed to. This amounts to having κ different commitments ECom in SimS with different messages from that in the real view. In order to argue that the view produced by the real protocol is distributed statistically indistinguishable than in the simulation, consider the following set of κ + 1 hybrids: 64 Authors Suppressed Due to Excessive Length – H0 : Let this be the distribution of the view as produced in the simulation. – ∀j ∈[κ], Hj : Let this be the distribution of the view in which the first j matrices committed to M1, · · · , Mj are created as in the real distribution and the rest are created as in the simulation. The last such hybrid Hκ is distributed as in the real view. Note here that adjacent hybrids ∀j ∈[κ], Hj and Hj−1 differ only in the value of one element in the matrix Mj and M ∗ j respectively. Such hybrid distributions are statistically close since ECom is a statistically hiding commitment. Since there are κ many such hybrids, it follows that the real and simulated distribution are statistically close. For the case that the committer C is corrupted, the view produced by SimS differs from that in the real distribution only in Step 2 where for all j ∈[κ], the extractor for SZKAoK is executed for all ECom executions for each element in the matrix Mj. This is not the case in the real distribution where the ECom protocol is honestly executed. This amounts to having 4κ different commitment executions ECom in SimS. However, the transcripts produced by these are iden- tical to that in the real execution. Therefore, the real and simulated views are identically distributed. It therefore follows that Figure 12 realizes FCom with fall-back security in the presence of malicious adversaries. Proof of Security for the Offline Phase against a PPT Adversary. We start by showing that for any PPT malicious adversary A corrupting any subset of parties Z ⊆P, there exists a PPT simulator SimC that can interact with it for an ideal execution of FAuthTriples (Figure 7) and produce a view that is computationally indistinguishable from the real view of Protocol 5.4. The simulator SimC works by playing the adversary in the execution of ΠAuthTriples and simulates the execution of the compiled protocol to A. SimC works as follows:
1. Simulating the Coin Toss Phase. In both the executions of the commit phase of Πcoin, SimC participates honestly with the following exception: – SimC uses ΠCom.SimC in each commitment protocol to extract the inputs of the corrupt parties. If this succeeds, compute ⃗r for the watch-list or ⃗d for the degree test in the Check Phase as required. – If extraction fails and returns ⊥, then SimC sets ⃗r =⊥or ⃗d =⊥as required and continues the execution.
2. Simulating the Input Commitment Phase. For all i ∈[n], SimC par- ticipates in the commit phase of each execution Πi Com as follows: – If Pi is honest, then SimC samples the elements in ⃗vi at random and hon- estly computes the protocol on its behalf, giving {Viewi,k Com,j,v}j∈[m],Pk∈Z to A. Here, each Viewi,k Com,j,v contains commitments that Pi gives to Pk corresponding to the jth virtual server execution. Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 65 – If Pi ∈Z, SimC receives {Viewi,k Com,j,v}j∈[m],Pk∈P−Z. For each j ∈[m], makes a black-box call to the extractor ΠECom.SimC and collects {⃗vj i }j∈[m]. – If this extractor fails and returns ⊥, then SimC stores ⃗vj i =⊥as the extracted input for this execution of Πi Com. At the end of this phase, SimC has the set of inputs {⃗vj i }j∈[m],i∈[n] out of which the adversary’s inputs are extracted and that of the honest parties is generated by SimC. Note again that this set may contain multiple ⊥symbols corresponding to executions in which extraction had failed.
3. Input Extraction. – SimC computes for each Pi ∈Z, the inputs ⃗vi ←Recont,m({⃗vj i }j∈[m]) where reconstruction is done with error-correction. – If reconstruction succeeds for all Pi ∈Z, SimC gives {⃗vi}Pi∈Z to FAuthTriples and receives the tuples {⃗si}Pi∈Z as output. It sets Flag = TRUE. – If for any Pi ∈Z, the reconstruction fails, then SimC sends ⊥to FAuthTriples and does not receive an output. It internally sets Flag = FALSE. For each Pi ∈Z, it samples ri ←F uniformly at random and assigns it to the output vector ⃗si. All other elements of this vector are as in the (partially reconstructed) input vector ⃗vi. If P1 ∈Z, it samples cj′ 1 , MAC1(aj′), MAC1(bj′), MAC1(cj′) ←F also uni- formly at random and assigns it to ⃗s1. The remaining elements of this vector are as in the (partially reconstructed) input vector ⃗v1.
4. Setting the Inputs and Outputs of each Πj S. This is a step in which SimC performs some internal computation, without interacting with the adversary A, in preparation for the Compute Phase. – If Flag = FALSE and the interaction with FAuthTriples was not successful, then on behalf of each honest party Pi ∈P −Z, SimC sets ⃗vj i as sampled and committed to in the Input Commitment Phase as the input to the execution Πj S. The randomness used is ri,j as will be derived in the Randomness Generation Phase next. – If Flag = TRUE but ⃗r =⊥, then also the same actions as above are taken. – Otherwise if Flag = TRUE and ⃗r ̸=⊥, then SimC knows which executions of Πj S will be checked in the watch-list step and which will not. The details of the simulators actions for the last case are given below: – For each watched instance j ∈⃗r, SimC internally simulates the actions of the adversary assuming it is semi-honest (not by interacting with the malicious adversary A), and derives the outputs and randomness of the malicious parties. • SimC sets {ri,j}i∈[n] sampled uniformly at random as the randomness used by each party in this execution. • It sets {⃗vj i }i∈[n] as derived from the Input Commitment Phase as the input used by each party in this execution. • SimC internally computes Πj S using this input and randomness to get {⃗sj i}i∈[n]. Let ViewΠj S be the view generated in this computation. 66 Authors Suppressed Due to Excessive Length The outputs of these executions and the output of FAuthTriples are required to set the outputs of the corrupt parties in the un-watched instances, that need to be input to Sim Πj S C . – For each un-watched instance j ∈[m] −⃗r, it suffices to initially only compute the output of the corrupted parties. • For each Pi ∈Z, SimC has ri ∈⃗si from FAuthTriples, or otherwise, sam- pled at random. It computes {[ri]j}j∈[m] ←Sharet,m(ri) under the constraint that {[ri]j}j∈⃗r are exactly as in the view of the watched executions {ViewΠj S}j∈⃗r computed above. • For each Pi ∈Z such that i ̸= 1, set the input as ⃗sj i as extracted from the Input Commitment Phase. Set the output as, ⃗sj i =              [∆i]j ∈⃗vj i , [ri]j [rk i ]j, [MACi(rk)]j ∈⃗vj i ∀k ∈[n] [aj′ i ]j, [bj′ i ]j, [cj′ i ]j ∈⃗vj i ∀j′ ∈[T] [MACi(aj′)]j, [MACi(bj′)]j, [MACi(cj′)]j ∈⃗vj i ∀j′ ∈[T] • If party P1 is corrupted, then ∀k ∈[n], SimC has received MAC1(rk) ∈ ⃗s1. It computes {[MAC1(rk)]j}j∈[m] ←Share2t,m(MAC1(rk)) such that {[MAC1(rk)]j}j∈⃗r are exactly as in the watched execution views {ViewΠj S}j∈⃗r. Similarly, ∀j′ ∈[T], SimC has received the computed values for cj′ 1 , MAC1(aj′), MAC1(bj′), MAC1(cj′) ∈⃗s1. It computes the sharings, {[cj′ 1 ]j}j∈[m] ←Share2t,m(cj′ 1 ) {[MAC1(aj′)]j}j∈[m] ←Share2t,m(MAC1(aj′)) {[MAC1(bj′)]j}j∈[m] ←Share2t,m(MAC1(bj′)) {[MAC1(cj′)]j}j∈[m] ←Share4t,m(MAC1(cj′)) such that the shares corresponding to j ∈⃗r are exactly as in the watched execution views {ViewΠj S}j∈⃗r. Then the output is set as, ⃗sj 1 =            [∆1]j ∈⃗vj 1, [r1]j [rk 1]j ∈⃗vj 1, [MAC1(rk)]j ∀k ∈[n] [aj′ 1 ]j, [bj′ 1 ]j ∈⃗vj 1 ∀j′ ∈[T] [cj′ 1 ]j, [MAC1(cj′)]j, [MAC1(aj′)]j, [MAC1(bj′)]j ∀j′ ∈[T] • SimC internally executes Sim Πj S C with these inputs and outputs and generates the random tapes {ri,j}Pi∈Z of the corrupt parties.
5. Simulating the Randomness Generation Phase. For all i ∈[n], j ∈[m], SimC participates in the commit phase of each execution Πi,j CTW as follows: Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 67 – For each honest party Pk ∈P −Z such that k ̸= i, SimC executes the simulator for commit phase ΠCom.SimC. – For each corrupt party Pk ∈Z such that k ̸= i, SimC receives from A the set of views {Viewk,k′,i,j Com }Pk′∈P−Z. Each such view contains the commitments that Pk gives to Pk′. – It also makes a black-box call to the extractor ΠCom.SimC and receives rk i,j. If this extractor fails and returns ⊥, then SimC stores ri,j =⊥as the extracted randomness for this execution of Πi,j CTW. – Then SimC sets the input in ΠCom.SimC for each honest party such that they sum to ri,j as given in Step
4. This execution is completed until the end of the commit phase. – For each Pk ∈P such that k ̸= i, SimC performs the decommit phase of each ΠCom.SimC and receives from A the randomness {rk i,j}Pk∈Z. If the adversary fails to decommit properly, SimC sends ABORT on behalf of the honest parties and halts the execution. – If extraction had succeeded for the execution of ΠECom.SimC, SimC com- putes ri,j = P k∈[n] rk i,j. At the end of this phase, SimC has the set of randomness {ri,j}i∈[n],j∈[m] where the adversary’s input randomnesses are as decided in Step
4. Note that this set may contain multiple ⊥symbols corresponding to executions in which extraction had failed.
6. Simulating the Compute Phase. If Flag = FALSE, or Flag = TRUE but ⃗r =⊥, then for each j ∈[m], SimC participates honestly in an execution of Πj S as in the real execution, on behalf of each honest party. It runs each honest party Pi ∈P −Z using the input ⃗vj i and randomness ri,j. Otherwise, if Flag = TRUE and ⃗r ̸=⊥, then for each j ∈[m], SimC simulates the watched and un-watched instances Πj S differently. – For each watched instance j ∈⃗r, SimC uses the honest party’s generated input shares {⃗vj i }Pi∈P−Z and randomness {ri,j}Pi∈P−Z and interacts with the adversary A as in a real execution of the protocol Πj S. Let View∗ Πj S be the view of the adversary in this interaction. – For each un-watched instance j ∈[m] −⃗r, • SimC internally uses the PPT semi-honest simulator Sim Πj S C with the adversary A’s inputs as {⃗vj i }Pi∈Z, the randomness {ri,j}Pi∈Z and output as {⃗sj i}Pi∈Z. Let this view be ViewΠj S. • Note that SimC, in its interaction with A, can detect where A devi- ates from semi-honest behaviour as it can compare the messages in the interaction with the expected messages in the view generated in ViewΠj S. • If there is an inconsistency and A has behaved maliciously, this cor- responds to that execution Πj S being corrupted. Since the protocol ΠAuthTriples is secure in the presence of semi-honest adaptive corrup- tion, this corresponds to SimC adaptively corrupting all the honest 68 Authors Suppressed Due to Excessive Length parties P −Z in the execution of ΠAuthTriples. SimC uses {⃗sj i, ⃗vj i }Pi∈Z to create the inputs of the honest parties as follows: – Let Pi∗∈P −Z be a designated honest party. For all honest parties Pi ̸= Pi∗, sample the values in ⃗vj i uniformly at random. – It remains to determine the inputs for Pi∗. This is set as follows: · For each Pk ∈Z, get [rk]j ∈⃗sj k, and the set {[rk i ]j ∈⃗vj i }Pi̸=Pi∗∈P. Set each [rk i∗]j = [rk]j −P i̸=i∗∈[n][rk i ]j and assign [rk i∗]j to ⃗vj i∗. · If P1 ̸∈Z, then sample the rest of the values in ⃗vj i∗uniformly at random. · Otherwise, sample [∆i∗]j ←F and for all j′ ∈[T], [aj′ i∗]j, [bj′ i∗]j ← F uniformly at random and assign them to ⃗vj i∗. For each k ∈[n], set [MACi∗(rk)]j such that computation in functionality FS (Figure 8) for [MAC′(rk)]j is the difference between [MAC1(rk)]j ∈⃗vj 1 and [MAC1(rk)]j ∈⃗sj 1. Similarly, for each j′ ∈[T], set the shares ([cj′ i∗]j, [MACi∗(aj′)]j, [MACi∗(bj′)]j, [MACi∗(cj′)]j) such that the computation in FS (Figure 8) gives the difference in the output shares in ⃗sj 1 and input shares in ⃗vj
1. These are also assigned in ⃗vj i∗. SimC sends the inputs of the honest parties {⃗vj i }Pi∈P−Z to Sim Πj S C . • Sim Πj S C gives to SimC the randomness that explains the transcript thus far with respect to these inputs. Then SimC uses this to continue the the execution of Πj S by interacting with A.
7. Simulating the Check Phase. Here, SimC first honestly executes the pro- tocol by emulating the honest parties in the interaction with A. If any of the checks fail or ⃗r =⊥, the simulator sends ABORT to the adversary. If Flag = FALSE then also SimC sends ABORT to the adversary. SimC addi- tionally checks if among all j ∈[m] −⃗r, there exist more than t instances of Πj S in which A has deviated from the protocol. If this holds, SimC sends ABORT in the interaction with the adversary. Otherwise SimC accepts. Note that for every adversary, if the execution of the protocol in the real world aborts, so does the simulated execution in the ideal world. Additionally, with negligible probability, it may be the case that the simulation aborts but the real execution does not. This happens when there is no ABORT in the check phase, but more that t un-watched executions of Πj S are corrupted. Another case where possibly the real execution can be accepting but the simulation aborts is if Flag = FALSE in the simulation but there is no abort in the check phase. However, note that if Flag = FALSE, this would imply that the inputs of the corrupted parties could not be extracted and are therefore not well-formed. If this occurs the degree-test would fail except with negligible probability in the size of the field F. If the execution doesn’t abort, the view generated by SimC is Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 69 distributed as, ViewΠi,j CTW}i∈[n],j∈[m], ViewΠi Com}i∈[n], ViewΠRt coin , ViewΠF2n+6T+3 coin }, View∗ Πj S ←Πj S({⃗vj i }i∈[n]; {ri,j}i∈[n]) j∈⃗r, ViewΠj S ←Sim Πj S C ({⃗vj i }Pi∈Z; {ri,j}Pi∈Z; {⃗sj i}Pi∈Z) j∈[m]−⃗r It remains to argue that the above view is computationally indistinguishable from the real view in Protocol 5.4. For this, consider the following hybrids:
1. Hybrid H0. This is constructed as the view of the environment in the real execution of the protocol.
2. Hybrid H1. This is constructed in the same way as H0, with the exception that in this experiment, the protocol aborts even in the case where there is no ABORT in the check phase, but more than t un-watched executions of Πj S are corrupted. The distribution of this view is statistically close to the that of the real distribution of hybrid H0. This stems from the fact that, as stated above, the probability of the difference in the abort conditions is negligible in the security parameter κ.
3. Hybrid H2. This is constructed in the same way as H1, except for the view in each un-watched execution of Πj S. For each of these executions, the view is generated using a call to the PPT semi-honest adaptive simulator Sim Πj S C with the correctly committed inputs and randomness, and outputs as would have been generated in H1 for the corrupted parties. The distributions of H1 and H2 can be shown as computationally indistin- guishable using a set of m −t 2 + 1 intermediate hybrid distributions wherein each hybrid H′ j has real executions views for each un-watched execution up to the jth run, and the rest of the views are simulated. Adjacent such hy- brids differ only in one execution of an un-watched Πj S. Such hybrids can be shown as computationally indistinguishable by reducing to the fall-back security of protocol Πj S. Hence, it follows that H1 and H2 are also computa- tionally indistinguishable.
4. Hybrid H3. In this hybrid, in the ‘Input Commitment Phase’, on behalf of the honest parties, different inputs are used corresponding to all the un-watched executions as compared to the inputs to the real protocol. The rest of the distribution is created using these inputs of the honest parties, as in H2. The distributions of H2 and H3 can be shown as computationally indistin- guishable by reducing to the ‘fall-back secure hiding property’ of the n-party commitment ΠCom. Let s be the number of executions of such commitment protocols where an honest party is a committer. Then we can define s + 1 different hybrids where in each hybrid H′ k all the executions of ΠCom up to the kth execution uses the real inputs of the honest parties in the protocol execution. Each execution beyond this generates its inputs independently 70 Authors Suppressed Due to Excessive Length and as in the simulation SimC. Each pair of adjacent hybrids differ only in the input to one execution of ΠCom and such adjacent hybrids can be show as computationally indistinguishable by reducing to the fall-back secure hiding property of ΠCom.
5. Hybrid H4. In this hybrid, in the ‘Randomness Generation Phase’, for all the parties, the commitments are created just as in SimΠCom C . The rest of distri- bution is created as in H3. The distributions of H4 and H3 can be shown as computationally indistin- guishable by reducing to the indistinguishability of the real execution of the n-party commitment ΠCom and the output distribution of SimΠCom C . Let s be the number of executions of such commitment protocols. Then we can define s + 1 different hybrids where in each hybrid H′ k all the executions of ΠCom up to the kth execution is the real execution of the commitment protocol. Each execution beyond this generates its inputs independently and as in the simulation SimC. Each pair of adjacent hybrids differ only in the input to one execution of ΠCom and such adjacent hybrids can be show as computationally indistinguishable by reducing to security of the simulation of ΠCom.
6. Hybrid H5. This hybrid is distributed in exactly the same way as the the output of SimC. This conceptually differs from the distribution of H4 in that the honest parties’ inputs are never used in creating its contents and the randomness for all corrupt parties is generated by the simulator Sim Πj S C . In both hybrids, the watched executions are generated and distributed the same way. For the un-watched executions, the output of corrupt parties that is input to the semi-honest simulator Sim Πj S C is generated using the output of the functionality FAuthTriples instead of being directly generated from the inputs of the honest party in the real protocol. However, both of these are identically distributed since in the real protocol, the complete protocol output would be generated in the same way as FAuthTriples does. For each individual execution of Πj S, the output is set as a share of a correct t-out-of-m secret-sharing in the simulation, same as in the real execution. Hence the hybrids H5 and H4 are identically distributed. Claim. The view in the hybrid distributions H0 and H1 are statistically close. Proof. The hybrid H0 is distributed as in the view of the environment in the real execution of the protocol. The hybrid H1 differs from this only in that for the protocol execution where it has not aborted in the check phase, but more than t un-watched semi-honest executions of Πj S are corrupted, the complete offline phase protocol execution aborts. Let X be the set of indices of corrupted Πj S executions and ⃗r be the set of t 2 checked instances. This case happens with the following probability over a random choice of ⃗r: Pr ⃗r∈Rt[(X ∩⃗r = Φ) ∧(|X| > t)] ≤ m−t t 2  m t 2  ≤ 1 −t m  t 2 Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 71 This is negligible in the security parameter κ = t. It therefore follows that the two distributions are statistically close. Claim. Assuming that the protocol Πj S is secure in the presence of a semi-honest PPT adaptive adversary arbitrarily corrupting the set of parties, the hybrid distributions H1 and H2 are computationally indistinguishable. Proof. In order to show that the distributions of H1 and H2 are computationally indistinguishable consider the following set of m −t 2 + 1 intermediate hybrid distributions: – Hybrid H′ 0 = H2. This hybrid distribution contains simulated views of all the un-watched protocol executions of ΠS. – Hybrid H′ j. For each j ∈[m −t 2], this hybrid experiment has real executions views for each un-watched execution of Πj S up to the jth run, and the rest of the views are simulated. – Hybrid H′ m−t 2 = H1. In this last hybrid, the views of all the un-watched executions of the protocols ΠS are real views of the semi-honest protocol execution. Adjacent such hybrids above differ only in one execution of an un-watched Πj S. We show that if there existed a distinguisher D that can distinguish between the adjacent hybrid distributions H′ j and H′ j−1 with non-negligible advantage ϵ, then D can be used in a black-box way by a PPT adversary A that distinguishes between the simulated distribution {ViewΠj S}κ∈N,⃗r∈Rn output by Sim Πj S C and the real distribution {View∗ Πj S}κ∈N,⃗r∈Rn of the protocol Πj S. The adversary A works as follows: – A has the index j, the set of corrupt parties Z ⊆P and the complete set of inputs. It samples randomness for all the parties. – It begins generating the view of the offline protocol exactly as in the real execution until before the compute phase. In the compute phase, for all the watched instances of the semi-honest virtual protocol, it creates a real view of the protocol. For each un-watched instance up to the execution of Πj−1 S , the view is generated according to the real execution again. – For the execution of Πj S, give the input and randomness of all the parties to the challenger. It will interact with the adversary (on behalf of all the honest parties) and return a view Viewj that is created either according to the real or the simulated distribution by the adaptive corruption simulator. – The rest of the un-watched execution view are created as in the simulation of the virtual protocol. The view of the whole protocol is then completed as in the real distribution, except that the execution aborts each time it would have aborted in the simulation. – This completed view is passed onto the distinguisher D and then A outputs whatever D outputs. 72 Authors Suppressed Due to Excessive Length In the above strategy, A has the same distinguishing advantage as D, which is non-negligible. However, since the protocol Πj S is secure in the presence of a PPT semi-honest adaptive adversary corrupting any subset Z ⊆P of the parties, no such A can exist and therefore no such D can exist. Hence, it follows that H1 and H2 are also computationally indistinguishable. Claim. Assuming that the protocol ΠCom securely realizes FCom producing a computationally hiding view in the presence of a malicious PPT adversary arbi- trarily corrupting any set of the parties, the hybrid distributions H2 and H3 are computationally indistinguishable. Proof. Let s be the number of executions of ΠCom in the protocol where an honest party is the committer. The distributions of H2 and H3 can be shown as computationally indistinguishable by considering the following set of s + 1 intermediate hybrid distributions: – Hybrid H′ 0 = H3. This is the hybrid distribution where all the inputs used for the honest parties are as in the protocol simulation SimC, independent of the real protocol inputs. The view produced here is composed of the view of these commitment protocols, and that of the rest of the real offline protocol created depending on these inputs, with the exception, of course, that all the un-watched executions of the virtual protocol are replaced by simulated views, and the protocol aborts whenever the SimC aborts. – Hybrid H′ k. For each k ∈[s], in this hybrid, in up to the kth execution of the commitment protocol, all the inputs used for the honest parties are as in the real execution and the rest are as in the protocol simulation SimC. – Hybrid H′ s = H2. This hybrid distribution contains all honest party inputs and commitment executions as in the real execution of the protocol. The rest of the view of the offline protocol is generated with this as the basis. Note that for k ∈[s], each pair of adjacent hybrids H′ k and H′ k−1 differ only in that the kth execution of ΠCom uses a different input. The rest of the view is generated on its basis, in the same way. Let x be the input to this protocol in the real execution and x′ be this input in the simulation. We show that if there existed a distinguisher D that can distinguish between the adjacent hybrid distributions H′ k and H′ k−1 with non-negligible advantage ϵ, then D can be used in a black-box way by a PPT adversary A that distinguishes between the distribution {ViewΠCom(x)}κ∈N,⃗r∈Rn as in SimC and the real distribution {ViewΠCom(x′)}κ∈N,⃗r∈Rn. The adversary A works as follows: – A has the index k, the set of corrupt parties Z ⊆P and the complete set of inputs including x and x′. It samples randomness for all the parties. – It begins generating the view of the offline protocol exactly as in the real execution until before the input commitment phase. In this phase, for all instances of ΠCom where an honest party is the committer, up to the k −1th execution, the view is generated using the inputs as in the real execution. – For the kth execution of ΠCom, give the inputs x and x′ to the challenger. It will return a view Viewk that is created either using x as the input to the commitment or with x′. Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 73 – The rest of the commitment execution views are created as in the simula- tion SimC. The view of the whole protocol is then completed as in the real distribution, except that all the un-watched virtual protocol executions are replaced by their simulations and the execution aborts each time it would have aborted in the simulation. – This completed view is passed onto the distinguisher D and then A outputs whatever D outputs. In the above strategy, A has the same distinguishing advantage as D, which is non-negligible. However, since the protocol ΠCom is secure in the presence of a PPT malicious adversary corrupting any subset Z ⊆P of the parties and will produce a view that computationally hides the input, no such A can exist and therefore no such D can exist. Hence, it follows that H3 and H2 are also computationally indistinguishable. Claim. Assuming that the protocol ΠCom securely realizes FCom in the presence of a malicious PPT adversary arbitrarily corrupting any set of the parties, the hybrid distributions H3 and H4 are computationally indistinguishable. Proof. Let s be the number of executions of ΠCom in the protocol in the ran- domness generation phase. The distributions of H4 and H3 can be shown as computationally indistinguishable by considering the following set of s+1 inter- mediate hybrid distributions: – Hybrid H′ 0 = H4. This is the distribution in which all the commitment proto- col executions in the randomness generation phase are replaced by executions of SimΠCom C . – Hybrid H′ k. For all k ∈[s], in this hybrid, in up to the kth instance of the commitment protocol, the real protocol ΠCom is executed, and all other executions are replaced by executions of SimΠCom C . – Hybrid H′ s = H3. In this distribution, all the commitment protocol executions in the randomness generation phase are executions of the real protocol ΠCom. Note that for k ∈[s], each pair of adjacent hybrids H′ k and H′ k−1 differ only in the view of the kth execution of ΠCom in the randomness generation phase. We show that if there existed a distinguisher D that can distinguish between the adjacent hybrid distributions H′ k and H′ k−1 with non-negligible advantage ϵ, then D can be used in a black-box way by a PPT adversary A that distinguishes between the distribution {ViewΠCom}κ∈N,⃗r∈Rn as output by SimΠCom C and the real distribution {View∗ ΠCom}κ∈N,⃗r∈Rn in the protocol ΠCom. The adversary A works as follows: – A has the index k, the set of corrupt parties Z ⊆P and the complete set of inputs. It samples randomness for all the parties. – It begins generating the view of the offline protocol as in the simulation until before the randomness generation phase. In this phase, for all instances of ΠCom up to the k −1th execution, the view is generated as in the real execution. 74 Authors Suppressed Due to Excessive Length – For the kth execution of ΠCom, give the input and randomness to the chal- lenger. It will return a view Viewk that is created either according to the real protocol execution or the simulation SimΠCom C . – The rest of the commitment execution views are created as in the simula- tion SimC. The view of the whole protocol is then completed as in the real distribution, except that all the un-watched virtual protocol executions are replaced by their simulations and the execution aborts each time it would have aborted in the simulation. – This completed view is passed onto the distinguisher D and then A outputs whatever D outputs. In the above strategy, A has the same distinguishing advantage as D, which is non-negligible. However, since the protocol ΠCom is secure in the presence of a PPT malicious adversary corrupting any subset Z ⊆P, no such A can exist and therefore no such D can exist. Hence, it follows that H3 and H4 are also computationally indistinguishable. Since we have now shown that hybrid H0 c≡H4 and H4 ≡H5, it holds that the simulated and the real view of the protocol are computationally indistin- guishable. Security for the Offline Phase against an Unbounded Adversary. Next we need to show that for any unbounded malicious adversary A corrupting any subset of parties Z ∈ZS, there exists a PPT simulator SimS that can interact with it for an ideal execution of FAuthTriples (Figure 7) and produce a view that is statistically indistinguishable from the real view of Protocol 5.4. The simulator SimS works in exactly the same way as SimC described above, with the following exceptions: – In the Randomness Generation Phase, Commit Phase, and Coin Toss Phase, for each instance of the ‘commit phase’ of the commitment protocol ΠCom, input extraction for the corrupt parties is no longer done using calls to ΠCom.SimC. Instead, for each honest party Pi ∈P −Z, SimS works by calling ΠCom.SimS to extract the inputs. If this extraction or reconstruction fails, then SimS works the same way as SimC would if a call to ΠCom.SimC returns ⊥. – Simulating the Compute Phase. When Flag = TRUE and ⃗r ̸=⊥, then for each un-watched instance j ∈[m] −⃗r, SimS works by using the PPT semi-honest simulator Sim Πj S S instead of Sim Πj S C . It is used in the same way as SimC does in the above simulation. Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 75 If the execution does not abort, the view generated by SimS is distributed as, ViewΠi,j CTW}i∈[n],j∈[m], ViewΠi Com}i∈[n], ViewΠRt coin , ViewΠF2n+6T+3 coin }, View∗ Πj S ←Πj S({⃗vj i }i∈[n]; {ri,j}i∈[n]) j∈⃗r, ViewΠj S ←Sim Πj S S ({⃗vj i }Pi∈Z; {ri,j}Pi∈Z; {⃗sj i}Pi∈Z) j∈[m]−⃗r It remains to argue that the above view is statistically indistinguishable from the real view in Protocol 5.4. For this, consider the following hybrids:
1. Hybrid H0. This is constructed as the view of the environment in the real execution of the protocol.
2. Hybrid H1. This is constructed the same way as H0, except that in this experiment, the protocol aborts even in the case where the check phase does not ABORT, but more than t un-watched executions of Πj S are corrupted. The distribution of this view is statistically close to the that of the real distribution of hybrid H0. This stems from the fact that the probability of the difference in the abort conditions is negligible in the security parameter κ. It has been formally shown in the security proof in the presence of a PPT adversary.
3. Hybrid H2. This is constructed in the same way as H1, except for the view in each un-watched execution of Πj S. For each of these executions, the view is generated using a call to the PPT semi-honest adaptive simulator Sim Πj S S with the correctly committed inputs and randomness, and outputs as would have been generated in H1 for the corrupted parties. The hybrid distributions H1 and H2 can be shown to be statistically in- distinguishable owing to the fact that each Sim Πj S S produces a view that is statistically close to the real view of the semi-honest protocol for any Z ∈ZS.
4. Hybrid H3. In this hybrid, in the ‘Input Commitment Phase’, on behalf of the honest parties, different inputs are used corresponding to all the un- watched executions as compared to the inputs to the real protocol. The rest of distribution is created as in H2. The distributions of H2 and H3 can be shown as statistically indistinguishable owing to the ‘fall-back secure hiding property’ of the n-party extractable commitment ΠCom.
5. Hybrid H4. In this hybrid, in the ‘Randomness Generation Phase’, for all the parties, the commitments are created just as in SimΠCom S . The rest of distribution is created as in H3. The distributions of H4 and H3 can be shown as statistically indistinguishable owing to the security of the simulation SimΠCom S of the n-party extractable commitment ΠCom.
6. Hybrid H5. This hybrid is distributed in exactly the same way as the the output of SimS. This conceptually differs from the distribution of H4 in that the honest parties’ inputs are never used in creating its contents and the 76 Authors Suppressed Due to Excessive Length randomness for all corrupt parties is generated by Sim Πj S S . However since the outputs of the corrupt parties derived from the ideal functionality and that in the real execution are identically distributed, it follows that both hybrids H5 and H4 are identically distributed. Claim. Assuming that the protocol Πj S is secure in the presence of a semi-honest computationally unbounded adaptive adversary with adversary structure ZS, the hybrid distributions H1 and H2 are statistically close. Proof. In order to show that the distributions of H1 and H2 are statistically close consider the following set of m −t 2 + 1 intermediate hybrid distributions: – Hybrid H′ 0 = H2. This hybrid distribution contains simulated views of all the un-watched protocol executions of ΠS. – Hybrid H′ j. For each j ∈[m −t 2], this hybrid experiment has real executions views for each un-watched execution of Πj S up to the jth run, and the rest of the views are simulated. – Hybrid H′ m−t 2 = H1. In this last hybrid, the views of all the un-watched executions of the protocols ΠS are real views of the semi-honest protocol execution. Adjacent such hybrids above differ only in one execution of an un-watched Πj S. Let ϵ be the statistical difference between the view output by Sim Πj S S and that in the real execution, which is negligible. Then the statistical difference between the adjacent hybrids can be no more than ϵ. It also follows from the triangle inequality of statistical differences that the difference between the hybrid distri- butions H1 and H2 is ≤(m −t 2)ϵ. Therefore these distributions are statistically close. Claim. Assuming that the protocol ΠCom securely realizes FCom producing a sta- tistically hiding view in the presence of a malicious computationally unbounded adversary with adversary structure ZS, the hybrid distributions H2 and H3 are statistically close. Proof. Let s be the number of executions of ΠCom in the protocol where an honest party is the committer. The distributions of H2 and H3 can be shown as statistically close by considering the following set of s + 1 intermediate hybrid distributions: – Hybrid H′ 0 = H3. This is the hybrid distribution where all the inputs used for the honest parties are as in the protocol simulation SimS, independent of the real protocol inputs. The view produced here is composed of the view of these commitment protocols, and that of the rest of the real offline protocol created depending on these inputs, with the exception, of course, that all the un-watched executions of the virtual protocol are replaced by simulated views, and the protocol aborts whenever the SimS aborts. Best of Both Worlds: Revisiting the Spymasters Double Agent Problem 77 – Hybrid H′ k. For each k ∈[s], in this hybrid, in up to the kth execution of the commitment protocol, all the inputs used for the honest parties are as in the real execution and the rest are as in the protocol simulation SimS. – Hybrid H′ s = H2. This hybrid distribution contains all honest party inputs and commitment executions as in the real execution of the protocol. The rest of the view of the offline protocol is generated with this as the basis. Note that for k ∈[s], each pair of adjacent hybrids H′ k and H′ k−1 differ only in that the kth execution of ΠCom uses a different input. The rest of the view is generated on its basis, in the same way. Let x be the input to this protocol in the real execution and x′ be this input in the simulation. Let ϵ be the sta- tistical difference between the distribution {ViewΠCom(x)}κ∈N,⃗r∈Rn as in SimS and the real distribution {ViewΠCom(x′)}κ∈N,⃗r∈Rn. Then the statistical differ- ence between the adjacent hybrids can be no more than ϵ, which is negligible. It follows from the triangle inequality of statistical differences that the difference between the distributions H2 and H3 is ≤sϵ. Therefore, these distributions are statistically close. Claim. Assuming that the protocol ΠCom securely realizes FCom in the presence of a malicious computationally unbounded adversary with adversary structure ZS, the hybrid distributions H3 and H4 are statistically close. Proof. Let s be the number of executions of ΠCom in the protocol in the ran- domness generation phase. The distributions of H4 and H3 can be shown as statistically close by considering the following set of s + 1 intermediate hybrid distributions: – Hybrid H′ 0 = H4. This is the distribution in which all the commitment proto- col executions in the randomness generation phase are replaced by executions of SimΠCom S . – Hybrid H′ k. For all k ∈[s], in this hybrid, in up to the kth instance of the commitment protocol, the real protocol ΠCom is executed, and all other executions are replaced by executions of SimΠCom S . – Hybrid H′ s = H3. In this distribution, all the commitment protocol executions in the randomness generation phase are executions of the real protocol ΠCom. Note that for k ∈[s], each pair of adjacent hybrids H′ k and H′ k−1 differ only in the view of the kth execution of ΠCom in the randomness generation phase. Let ϵ be the statistical difference between the distribution {ViewΠCom}κ∈N,⃗r∈Rn as in SimS and the real distribution {View∗ ΠCom}κ∈N,⃗r∈Rn. Then the statistical differ- ence between the adjacent hybrids can be no more than ϵ, which is negligible. It follows from the triangle inequality of statistical differences that the difference between the distributions H3 and H4 is ≤sϵ. Therefore, these distributions are statistically close. Since we have now shown that hybrid H0 s≡H4 and H4 ≡H5, it holds that the simulated and the real view of the protocol are statistically close.
43. Liu, G., Lu, J., Li, H., Tang, P., Qiu, W.: Preimage attacks against lightweight scheme Xoodyak based on deep learning. In: Arai, K. (ed.) FICC 2021. AISC, vol. 1364,  Springer, Cham (2021). https://doi.org/10.1007/978-3-030- 73103-8 45
46. The U.S. National Institute of Standards and Technology. SHA-3 standard: Permutation-based hash and extendable-output functions. Federal Information Processing Standard, FIPS 202, 5th August 2015
1. bellperson. https://github.com/ﬁlecoin-project/bellperson
2. neptune. https://github.com/ﬁlecoin-project/neptune
3. Nova: Recursive SNARKs without trusted setup. https://github.com/Microsoft/ Nova
4. Pasta curves. https://github.com/zcash/pasta
7. Bitansky, N., Canetti, R., Chiesa, A., Tromer, E.: From extractable collision resis- tance to succinct non-interactive arguments of knowledge, and back again. In: ITCS (2012)
8. Bitansky, N., Canetti, R., Chiesa, A., Tromer, E.: Recursive composition and boot- strapping for SNARKs and proof-carrying data. In: STOC (2013)
9. Boneh, D., B¨unz, B., Fisch, B.: A survey of two veriﬁable delay functions. Cryp- tology ePrint Archive, Report 2018/712 (2018)
13. Bowe, S., Grigg, J., Hopwood, D.: Halo2 (2020). https://github.com/zcash/halo2
24. Gentry, C., Wichs, D.: Separating succinct non-interactive arguments from all fal- siﬁable assumptions. In: STOC,  (2011)
25. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interactive proof-systems. In: STOC (1985)
29. Kilian, J.: A note on eﬃcient zero-knowledge proofs and arguments (extended abstract). In: STOC (1992)
33. Lee, J., Nikitin, K., Setty, S.: Replicated state machines without replicated execu- tion. In: S&P (2020)
35. Lund, C., Fortnow, L., Karloﬀ, H., Nisan, N.: Algebraic methods for interactive proof systems. In: FOCS, October 1990
36. Micali, S.: CS proofs. In: FOCS (1994)
37. Reingold, O., Rothblum, G.N., Rothblum, R.D.: Constant-round interactive proofs for delegating computation. In: STOC,  (2016)
40. Setty, S., Braun, B., Vu, V., Blumberg, A.J., Parno, B., Walﬁsh, M.: Resolving the conﬂict between generality and plausibility in veriﬁed computation. In: EuroSys, April 2013
44. Wahby, R.S., Tzialla, I., Shelat, A., Thaler, J., Walﬁsh, M.: Doubly-eﬃcient zkSNARKs without trusted setup. In: S&P (2018)
47. Zhang, Y., Genkin, D., Katz, J., Papadopoulos, D., Papamanthou, C.: vSQL: ver- ifying arbitrary SQL queries over dynamic outsourced databases. In: S&P (2017)
3. Backurs, A., Tzamos, C.: Improving viterbi is hard: better runtimes imply faster clique algorithms. In: Proceedings of the 34th International Conference on Machine Learning (ICML 2017), vol. 70,  JMLR.org (2017)
5. Barrington, D.A.M.: Bounded-width polynomial-size branching programs recog- nize exactly those languages in NC1. In: 18th ACM STOC,  ACM Press (1986)
9. Bringmann, K., Gawrychowski, P., Mozes, S., Weimann, O.: Tree edit distance cannot be computed in strongly subcubic time (unless APSP can). In: Czumaj, A. (ed.) 29th SODA,  ACM-SIAM (2018)
18. Goldreich, O., Levin, L.A.: A hard-core predicate for all one-way functions. In: STOC,  ACM (1989)
20. Håstad, J.: One-way permutations in NC0. Inf. Process. Lett. 26(3), 153–155 (1987)
25. Lincoln, A., Williams, V.V., Williams, R.R.: Tight hardness for shortest cycles and paths in sparse graphs. In: Czumaj, A. (ed.) 29th SODA,  ACM- SIAM (2018)
27. Merkle, R.C.: Secure communications over insecure channels. Commun. ACM 21(4), 294–299 (1978)
29. Razborov, A.A.: Lower bounds on the size of bounded depth circuits over a com- plete basis with logical addition. Math. Notes Acad. Sci. USSR 41(4) (1987)
31. Smolensky, R.: Algebraic methods in the theory of lower bounds for Boolean circuit complexity. In: Aho, A. (ed.) 19th ACM STOC,  ACM Press (1987) Fine-Grained Non-interactive Key-Exchange Without Idealized Assumptions 285
34. Zuckerman, D.: Simulating BPP using a general weak random source. In: 32nd FOCS,  IEEE Computer Society Press (1991)
2. Adleman, L.: Two theorems on random polynomial time. In: Symposium on Foun- dations of Computer Science, SFCS,  (1978)
7. Chung, K., Guo, S., Liu, Q., Qian, L.: Tight quantum time-space tradeoﬀs for function inversion. In: FOCS,  (2020)
16. Fiat, A., Naor, M.: Rigorous time/space trade-oﬀs for inverting functions. SIAM J. Comput. 29(3), 790–803 (1999)
21. Hellman, M.E.: A cryptanalytic time-memory trade-oﬀ. IEEE Trans. Inf. Theory 26(4), 401–406 (1980)
24. Merkle, R.C.: Secrecy, authentication and public key systems. Ph.D. thesis, UMI Research Press, Ann Arbor, Michigan (1982) On Time-Space Tradeoﬀs for Bounded-Length Collisions in MD Hashing 191
27. Moser, R.A., Tardos, G.: A constructive proof of the general lov´asz local lemma. J. ACM 57(2), 11:1–11:15 (2010)
29. Sr, R.H.M., Thompson, K.: Password security - a case history. Commun. ACM 22(11), 594–597 (1979)
31. Yao, A.C.: Coherent functions and program checkers (extended abstract). In: STOC,  (1990)
1. If for every PPT A the advantage AdvKEΠ,E A (λ) is negligible, and Setup and TSetup are indistinguishable, then we call Π knowledge sound. A.2 Commitments With standard arguments, we can prove the following lemma. Lemma 5 (Selective all-but-one hiding implies adaptive all-but-one hiding). Consider real-or-random hiding security of a vector commitment VC for all-but-one sets, i.e. sets of the form I = [N] \ {i∗}. For any adversary A against all-but-one adaptive hiding, there is an adversary B against all-but-one selective hiding with roughly the same running time such that AdvAdpHideVC A ≤ N · AdvSelHideVC B . Proof (Sketch). The reduction B simply guesses i∗and sends I = [N] \ {i∗} to its (static) hiding challenger and receives c. Then A′ runs I′ ←A(1λ, crs, c). If the guess i∗was wrong (i.e. I ̸= I′), A′ outputs a random bit. Otherwise it outputs whatever A eventually outputs. 20This coincides with the advantage in Definition 18 of the obvious (straightline) extractor Ext which can be constructed from Ext. 45 A.3 Extractable functions We define when a function family is extractable. In a sense, this is a weakening of trapdoor functions where only in the security proof an invertibility trapdoor is needed. Hence, random oracles can be extractable functions. Definition
23. Let F = (Setup, Eval) be a function family in the CRS+RO model. Let (TSetup, Ext) be pair of PPT algorithms such that – TSetupH(1λ) →(crs, td): Given security parameter λ, output a CRS crs and trapdoor td. – Ext(td, Q, y) →(mi)i∈[N]: Given the trapdoor td, a set of query-response pairs of random oracle queries, and a purported image y, output a preimage x. The extractability experiment (w.r.t. (TSetup, Ext)) for stateful adversary A is defined as follows:
1. (crs, td) ←TSetupH(1λ)
2. y ←AH(1λ, crs)
3. x′ ←Ext(td, Q, y) where Q is the set {(xi, H(xi))} of query-response pairs of queries A made to H.
4. x ←AH()
5. If x = x′, or Evalcrs(x) ̸= y, or x /∈Xcrs, output
0. Else output 1 (success). The distinguishing advantage AdvDist(Setup,TSetup) D for Setup and TSetup of an adversary D is defined as usual. The advantage AdvExt(TSetup,Ext) A of an adversary A is defined by as probability to win the experiment. By abuse of notation, we write AdvExtF A if the algorithms are clear from the context. A function family is (straightline) extractable w.r.t. (TSetup, Ext) if for any PPT adversaries A and D, their advantages AdvDist(Setup,TSetup) D and AdvExt(TSetup,Ext) A are negligible. Our notion of extractability is tailored to our setting and by definition straightline. We allow extraction to fail if A cannot produce a preimage, while requiring the exact same preimage if A has a preimage (implying a form collision resistance). Example 1 (Straightline extractable functions).
1. Random oracles are extractable functions for any superpolynomial codomain Y. Indeed, any q-query adversary has advantage at most (q + 1)2/ |Y|.
2. Any (injective) trapdoor one-way function TDF is straightline extractable. For this, let TSetup(1λ) run the key generation algorithm for TDF, and define crs as the function key of TDF and td as the invertibility trapdoor. B Details on the Instantiations B.1 ZK from Generalized sVOLE for Arbitrary Degree-d Relations We can easily generalize the method described in Section 6 for degree-2 relations to prove arbitrary degree-d polynomials. Let (w1, . . . , wℓ) ∈FkC·ℓ p be a witness and fi ∈Fp[X1, . . . , Xℓ]≤d, i ∈[t], be the set of polynomials over Fp with degree at most d, we want to prove that fi(w1, . . . wℓ) = 0, for each i ∈[t]. 46 We can proceed similarly to [YSWW21]. First, P and V call the sVOLE functionality with parameters p, C, 2(ℓ+ d), so that P obtains matrices U ∈F2(ℓ+d)×kC p , V ∈F2(ℓ+d)×nC p . As before, we can split these matrices as U = U1 R ! and V = V1 V2 ! , where each sub-matrix consists of ℓ+ d −1 rows. The prover uses the first ℓrows of U to commit to its witness, as described in Figure
6. Then, P opens S = R + W · ∆′, where ∆′ ←Fp is the challenge sent by V. The following relation holds: gi(Y ) = X h∈[0,d] fi,h(r1 + w1 · Y, . . . , rℓ+ wℓ· Y ) · Y d−h = X h∈[0,d] fi,h(w1, . . . , wℓ) · Y d + X h∈[0,d−1] Ai,h · Y h = fi(w1, . . . , wℓ) · Y d + X h∈[0,d−1] Ai,h · Y h, where Ai,h ∈FkC p is the aggregated coefficient of Y h. The key observation is that, if the prover P is honest, then fi(w1, . . . , wn) = 0 and gi(Y ) = P h∈[0,d−1] Ai,h · Y h. In order to send the aggregated values P i∈[t] Ai,h, h ∈[0, d −1], as in Πt 2D−LC, P needs d extra independent masks ah. These are computed using the matrices U1,[ℓ+1..ℓ+d−1] and R[ℓ+1..ℓ+d−1] as follows: – P sets p1(Y ) = rℓ+1 + uℓ+1 · Y and iteratively computes pi+1(Y ) = pi(Y ) · (rℓ+i+1 + uℓ+i+1 · Y ), for each i ∈[2, d −2] and the coefficients ah, h ∈[d −1], such that pd−1(Y ) = P [0,d−1] ah · Y h – V locally computes b1 = qℓ+1 and bi+1 = bi · qi+1, i ∈[2, d −2]. So that P h∈[0,d−1] ah · (∆′)h = bd−1. After the first commitment to the witness, the proof proceeds with the prover sending values eah = P i∈[t] χi · Ai,h + ah, h ∈[0, d −1], where χi ∈Fp are the challenges sent by the verifier. After the opening of S, the proof proceeds similarly to Πt 2D−LC. In particular, V first computes ci(∆′) = P [0,d] fi,h(s′ 1, . . . , s′ ℓ) · (∆′)d−h, where s′ i are defined as in Πt 2D−LC, then it checks that X h∈[0,d−1] χi · ci + bd−1 = X h∈[0,d−1] eah · (∆′)h and finally performs the consistency check. 47
4. Beaver, D., Micali, S., Rogaway, P.: The round complexity of secure protocols (extended abstract). In: 22nd Annual ACM Symposium on Theory of Computing, Baltimore, MD, USA, 14–16 May 1990,  ACM Press (1990). https:// doi.org/10.1145/100216.100287
11. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or A completeness theorem for protocols with honest majority. In: Aho, A. (ed.) 19th Annual ACM Symposium on Theory of Computing, New York City, NY, USA, 25–27 May 1987,  ACM Press (1987). https://doi.org/10.1145/28395. 28420
12. Goyal, V.: Constant round non-malleable protocols using one way functions. In: Fortnow, L., Vadhan, S.P. (eds.) 43rd Annual ACM Symposium on Theory of Computing, San Jose, CA, USA, 6–8 June 2011,  ACM Press (2011). https://doi.org/10.1145/1993636.1993729
13. Goyal, V., Richelson, S., Rosen, A., Vald, M.: An algebraic approach to non- malleability. In: 55th Annual Symposium on Foundations of Computer Science, Philadelphia, PA, USA, 18–21 October 2014,  IEEE Computer Society Press (2014). https://doi.org/10.1109/FOCS.2014.13
24. Naor, M., Pinkas, B.: Eﬃcient oblivious transfer protocols. In: Kosaraju, S.R. (ed.) 12th Annual ACM-SIAM Symposium on Discrete Algorithms, Washington, DC, USA, 7–9 January 2001,  ACM-SIAM (2001)
25. Pass, R.: Bounded-concurrent secure multi-party computation with a dishonest majority. In: Babai, L. (ed.) 36th Annual ACM Symposium on Theory of Comput- ing, Chicago, IL, USA, 13–16 June 2004,  ACM Press (2004). https:// doi.org/10.1145/1007352.1007393
28. Wee, H.: Black-box, round-eﬃcient secure computation via non-malleability ampli- ﬁcation. In: 51st Annual Symposium on Foundations of Computer Science, Las Vegas, NV, USA, 23–26 October 2010,  IEEE Computer Society Press (2010). https://doi.org/10.1109/FOCS.2010.87
29. Yao, A.C.C.: How to generate and exchange secrets (extended abstract). In: 27th Annual Symposium on Foundations of Computer Science, Toronto, Ontario, Canada, 27–29 October 1986,  IEEE Computer Society Press (1986). https://doi.org/10.1109/SFCS.1986.25
[PS00] in the context of signature schemes. The lemma was later reformulated by Bellare and Neven
[BN06] which extracts the purely proba- bilistic nature of the forking lemma. Below, we review the Bellare-Neven general forking lemma. Lemma A.13 (General Forking Lemma). Fix an integer q ě 1 and a set H of size h ě
9. Let frk “ Pr ” par $Ð IG; pb, pσ1, σ2qq $Ð ForkApparq : b “ 1 ı . Then, frk ě acc ¨ ˆacc q ´ 1 h ˙ . 50 Algorithm ForkApparq 1 : coin $Ð t0, 1uℓA // ℓA-bit randomness used by A 2 : ⃗h :“ ph1, ¨ ¨ ¨ , hqq $Ð Hq 3 : pJ, σq :“ Appar,⃗h; ρq 4 : if I “ 0 then 5 : return p0, pK, Kqq 6 : ph1 I, ¨ ¨ ¨ , h1 qq $Ð Hq´I`1 7 : ⃗h1 :“ ph1, ¨ ¨ ¨ , hI´1, h1 I, ¨ ¨ ¨ , h1 qq 8 : pJ1, σ1q :“ Appar,⃗h1; ρq 9 : if J “ J1 ^ hJ ‰ h1 J then 10 : return p1, pσ, σ1qq 11 : else 12 : return p0, pK, Kqq Figure 9: Description of the forking algorithm ForkA. B Details of Our 4-Round Threshold Raccoon B.1 Construction Here, we provide the construction of our 4-round threshold signature TRaccoonadp 4-rnd in Fig.
10. We only show the procedure of the singing protocol since the setup, key generation, and verification algorithms are the same as those of 5 round scheme TRaccoonadp 5-rnd in Fig.
4. Parameters, the helper algorithm ZeroShare, the signature scheme, and hash functions are identical to those in TRaccoonadp 5-rnd. For the detail of them, see Section 5.1. B.2 Security Below, we provide the main theorem establishing adaptive security of TRaccoonadp 4-rnd. Theorem B.1. The 4-round threshold signature TRaccoonadp 4-rnd in Figs. 4 and 10 is adaptive secure under the Hint-MLWE and MSIS assumptions. Formally, for any N and T with T ď N and an adversary A against the adaptive security game making at most QHc, QHcom, QHmask, and QS queries to the random oracles Hc, Hcom, and Hmask and the signing oracle, respectively, there exists adversaries B, B1, and BS against the Hint-MLWEq,ℓ,k,QS,σt,σw,C, SelfTargetMSISq,ℓ`1,k,Hc,C,Bstmsis problems, and the unforgeability of signatures, respectively, such that Advts-adp-uf TRaccoonadp 4-rnd,Ap1λ, N, T, 1q ď QHc ¨ AdvSelfTargetMSIS B1 p1λq ` AdvHint-MLWE B p1λq ` N ¨ Adveuf-cma S,BS pλq ` QS ¨ pQHcom ` QHc ` 2QSq 2n´1 ` QHmask 2λ ` pQHcom ` QSq2 ` QHcom 22λ ` neglpλq where TimepBq, TimepB1q, TimepBSq « TimepAq. From Lemma A.10, we can replace B1 by an adversary B2 against the MSISq,ℓ`1,k,2B problem with TimepB2q « 2 ¨ TimepB1q such that AdvSelfTargetMSIS B1 pλq ď b QHc ¨ AdvMSIS B2 pλq ` QHc |C| . 51 Sign1pvk, sid , SS, i, ski, stiq 1 : req JSS Ď rNsK ^ Ji P SSK 2 : parse ` si, pvkS,iqiPrNs, skS,i, ⃗ seedi ˘ Ð ski 3 : ctntw :“ 0}SS}sid 4 : r∆i :“ ZeroSharep ⃗ seedirSSs, ctntwq P Rk q 5 : pri, e1 iq $Ð Dℓ w ˆ Dk w 6 : wi :“ Ari ` e1 i P Rk q 7 : rwi :“ wi ` r∆i P Rk q 8 : cmti :“ Hcompi, rwiq 9 : sti Ð sti Y tpsid, SS, cmti, rwi, riqu 10 : return ppm1,i :“ cmti, stiq Sign2pvk, sid , SS, M, i, ppm1,jqjPSS, ski, stiq 1 : req Jpsid, SS, pm1,i, ¨, ¨q P stiK 2 : pick psid, SS, cmti, rwi, riq from sti 3 : parse pcmtjqjPSSztiu Ð ppm1,jqjPSSztiu with pm1,i “ cmti 4 : MS :“ SS}M}sid}pcmtjqjPSS 5 : σS,i $Ð SignSpskS,i, MSq 6 : sti Ð stiztpsid, SS, cmti, rwi, riqu 7 : sti Ð sti Y tpsid, SS, M, pcmtjqjPSS, σS,i, rwi, riqu 8 : return ppm2,i :“ σS,i, stiq Sign3pvk, sid , SS, M, i, ppm2,jqjPSS, ski, stiq 1 : req Jpsid, SS, M, ¨, pm2,i, ¨, ¨q P stiK 2 : pick psid, SS, M, pcmtjqjPSS, σS,i, rwi, riq from sti with pm2,i “ σS,i 3 : parse pσS,jqjPSSztiu Ð ppm2,jqjPSSztiu 4 : MS :“ SS}M}sid}pcmtjqjPSS 5 : req J@j P SSztiu, VerifySpvkS,j, σS,j, MSq “ JK 6 : sti Ð stiztpsid, SS, M, pcmtjqjPSS, σS,i, rwi, riqu 7 : sti Ð sti Y tpsid, SS, M, pcmtjqjPSS, rwi, riqu 8 : return ppm3,i :“ rwi, stiq Sign4pvk, sid , SS, M, i, ppm3,jqjPSS, ski, stiq 1 : req Jpsid, SS, M, ¨, pm3,i, ¨q P stiK 2 : parse p rwjqjPSSztiu Ð ppm3,jqjPSSztiu 3 : pick psid, SS, M, pcmtjqjPSS, rwi, riq from sti with pm3,i “ rwi 4 : req J@j P SS, cmtj “ Hcompj, rwjqK 5 : ctntz :“ 1}SS}M}sid}pcmtjqjPSS}p rwjqjPSS 6 : w :“ [ ÿ jPSS rwj W νw P Rk qνw 7 : c :“ Hcpvk, M, wq // c P C 8 : ∆i :“ ZeroSharep ⃗ seedirSSs, ctntzq P Rℓ q 9 : rzi :“ c ¨ LSS,i ¨ si ` ri ` ∆i P Rℓ q 10 : sti Ð stiztpsid, SS, M, pstrj, cmtjqjPSS, rwi, riqu 11 : return ppm4,i :“ rzi, stiq Aggpvk, SS, M, ppmb,jqpb,jqPr4sˆSSq 1 : parse p rwj, rzjqjPSS Ð ppm3,j, pm4,jqjPSS 2 : w :“ [ ÿ jPSS rwj W νw 3 : z :“ ÿ jPSS rzj P Rℓ q 4 : c :“ Hcpvk, M, wq 5 : y :“ tAz ´ 2νt ¨ c ¨ tsνw P Rk qνw 6 : h :“ w ´ y P Rk qνw 7 : return sig :“ pc, z, hq Figure 10: The signing protocol of our four round threshold signature TRaccoonadp 4-rnd. In the above, LSS,i denotes the Lagrange coefficient of user i in the set SS Ď rNs (see Section 2.3 for the definition), and sid is a session identifier that is never been reused. pick X from Y denotes the process of picking an element X from the set Y. The setup Setup, key generation KeyGen, verification TSV f algorithm are identical to those of TRaccoonadp 5-rnd in Fig. 4. 52 We omit the formal proof and only provide the rough proof sketch since the proof of this theorem is almost identical to the proof of Theorem 6.1. The main difference is that the modification in Game2 in the proof of Theorem 6.1 is not required. Recall that this modification is to ensure that the same ctntw is never reused in the singing oracle by showing that the same string stri is never generated twice. On the other hand, in TRaccoonadp 4-rnd, this statement is immediately guaranteed by non-reuseability of the session identifier sid. In the remaining parts of proof, we can argue similarly to the proof of Theorem 6.1, using the fact that sid is never reused instead of the fact that pstrjqjPSS is not reused. Eventually, we can bound the advantage of the adversary A as in the above theorem. Notice that the loss Q2 S{22λ, that arises from the modification in Game2, is disappeared compared to Theorem 6.1. C Details of Our 4-Round Threshold Schnorr C.1 Construction Here, we provide the construction of our 4-round threshold signature TSchnorradp 4-rnd in Fig.
11. We only show the procedure of the singing protocol since the setup, key generation, and verification algorithms are the same as those of 5 round scheme TSchnorradp 5-rnd in Fig.
6. Parameters, the helper algorithm ZeroShare, the signature scheme, and hash functions are identical to those in TSchnorradp 5-rnd. For the detail of them, see Section 7. C.2 Security Below, we provide the main theorem establishing adaptive security of TSchnorradp 4-rnd. Theorem C.1. The 5-round threshold signature TSchnorradp 4-rnd in Figs. 6 and 11 is adaptive secure under the SelfTargetDL assumption. Formally, for any N and T with T ď N and an adversary A against the adaptive security game making at most QHc, QHcom, QHmask, and QS queries to the random oracles Hc, Hcom, and Hmask and the signing oracle, respectively, there exists adversaries B and BS against the DL problem and the unforgeability of signatures, respectively, such that Advts-adp-uf TSchnorradp 4-rnd,Ap1λ, N, T, 1q ď QHc ¨ AdvSelfTargetDL B p1λq ` N ¨ Adveuf-cma S,BS pλq ` QS ¨ pQHcom ` QHc ` 2QSq p ` QHmask 2λ ` pQHcom ` QSq2 ` QHcom 22λ , where TimepBq « TimepAq and TimepBSq « TimepAq. From Lemma A.12, we can replace B by an adversary B1 against the DL problem with TimepB1q « 2 ¨ TimepBq such that AdvSelfTargetDL B pλq ď b QHc ¨ AdvDL B1 pλq ` QHc p . This theorem also immediately is obtained from Theorem 7.1. The idea of the proof is identical to that of TRaccoonadp 4-rnd. For the details of the idea, see
6. Bao, F., Deng, R.H., Zhu, H.: Variations of diﬃe-hellman problem. In: ICICS (2003) A More Complete Analysis of the Signal Double Ratchet Algorithm 811
10. Borisov, N., Goldberg, I., Brewer, E.: Oﬀ-the-record communication, or, why not to use PGP. In: Proceedings of the 2004 ACM Workshop on Privacy in the Electronic Society,  (2004)
20. Cohn-Gordon, K., Cremers, C.J.F., Garratt, L.: On post-compromise security. In: Hicks, M., K¨opf, B. (eds.) CSF 2016 Computer Security Foundations Symposium, IEEE Computer Society Press, Lisbon, Portugal, June 27–1 2016
21. Cramer, R., Shoup, V.: Design and analysis of practical public-key encryption schemes secure against adaptive chosen ciphertext attack. SIAM J. Comput. 33(1), 167–226 (2003)
22. Dobson, S., Galbraith, S.D.: Post-quantum signal key agreement with sidh. Cryp- tology ePrint Archive, Report 2021/1187 (2021) 812 A. Bienstock et al.
23. Dodis, Y., Karthikeyan, H., Wichs, D.: Updatable public key encryption in the standard model (2021)
26. FIPS, P.: 180–1. secure hash standard. National Institute of Standards and Tech- nology 17, 45 (1995)
29. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interactive proof systems. SIAM J. Comput. 18(1), 186–208 (1989). https://doi.org/10.1137/ 0218012
40. Marlinspike, M., Perrin, T.: The Double Ratchet Algorithm (11 2016). https:// whispersystems.org/docs/speciﬁcations/doubleratchet/doubleratchet.pdf
41. Marlinspike, M., Perrin, T.: The X3DH Key Agreement Protocol (11 2016). https://signal.org/docs/speciﬁcations/x3dh/x3dh.pdf
47. Sipser, M.: Introduction to the theory of computation. PWS Publishing Company (1997)
49. Unger, N., Goldberg, I.: Improved strongly deniable authenticated key exchanges for secure messaging. Proc. Priv. Enhancing Technol. 2018(1), 21–66 (2018)
2. Applebaum, B., Ishai, Y., Kushilevitz, E.: How to garble arithmetic circuits. In: Ostrovsky, R. (ed.) 52nd Annual Symposium on Foundations of Computer Science, Palm Springs, CA, USA, 22–25 October 2011,  IEEE Computer Society Press (2011)
5. Asmuth, C., Bloom, J.: A modular approach to key safeguarding. IEEE Trans. Inf. Theory 29(2), 208–210 (1983)
10. Bernstein, D.J.: Scaled remainder trees (2004)
11. Borodin, A., Moenck, R.: Fast modular transforms. J. Comput. Syst. Sci. 8(3), 366–386 (1974)
13. Chaum, D., Crépeau, C., Damgård, I.: Multiparty unconditionally secure protocols (extended abstract). In: 20th Annual ACM Symposium on Theory of Computing, Chicago, IL, USA, 2–4 May 1988,  ACM Press (1988)
23. Franklin, M.K., Yung, M.: Communication complexity of secure computation (extended abstract). In: 24th Annual ACM Symposium on Theory of Comput- ing, Victoria, BC, Canada, 4–6 May 1992,  ACM Press (1992)
24. Fürer, M.: Faster integer multiplication. In: Proceedings of the Thirty-Ninth Annual ACM Symposium on Theory of Computing,  (2007)
28. Gentry, C.: Fully homomorphic encryption using ideal lattices. In: Mitzenmacher, M. (ed.) 41st Annual ACM Symposium on Theory of Computing, Bethesda, MD, USA, 31 May–2 June 2009,  ACM Press (2009)
29. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or a com- pleteness theorem for protocols with honest majority. In: Aho, A. (ed.) 19th Annual ACM Symposium on Theory of Computing, New York City, NY, USA, 25–27 May 1987,  ACM Press (1987) Scalable Multiparty Computation from Non-linear Secret Sharing 417
30. Goldreich, O., Ron, D., Sudan, M.: Chinese remaindering with errors. In: 31st Annual ACM Symposium on Theory of Computing, Atlanta, GA, USA, 1–4 May 1999,  ACM Press (1999)
34. Harvey, D., Van Der Hoeven, J.: Integer multiplication in time o(nlog\, n). Ann. Math. 193(2), 563–617 (2021)
35. Harvey, D., Van Der Hoeven, J., Lecerf, G.: Even faster integer multiplication. J. Complex. 36, 1–30 (2016)
42. Rudra, A.: (dense structured) matrix vector multiplication (2023)
43. Strassen, V., Schönhage, A.: Schnelle multiplikation großer zahlen. Computing 7(3/4), 281–292 (1971)
44. von zur Gathen, J., Seroussi, G.: Boolean circuits versus arithmetic circuits. Inf. Comput. 91(1), 142–154 (1991)
45. Yao, A.C.-C.: How to generate and exchange secrets (extended abstract). In: 27th Annual Symposium on Foundations of Computer Science, Toronto, Ontario, Canada, 27–29 October 1986,  IEEE Computer Society Press (1986)
18. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions (extended abstract). In: 25th Annual Symposium on Foundations of Computer Science, Singer Island, Florida, 24–26 October 1984,  IEEE Computer Society Press (1984)
31. Sahai, A., Waters, B.: How to use indistinguishability obfuscation: deniable encryp- tion, and more. In: Shmoys, D.B. (ed.) 46th Annual ACM Symposium on Theory of Computing, New York, NY, USA, 31 May–3 June 2014,  ACM Press (2014)
[BCCT12] Bitansky, N., Canetti, R., Chiesa, A., Tromer, E.: From extractable col- lision resistance to succinct non-interactive arguments of knowledge, and back again. In: ITCS (2012)
[BCPR14] Bitansky, N., Canetti, R., Paneth, O., Rosen, A.: On the existence of extractable one-way functions. In: STOC (2014)
[BHK17] Brakerski, Z., Holmgren, J., Kalai, Y.T.: Non-interactive delegation and batch NP veriﬁcation from standard computational assumptions. In: STOC (2017)
[CCH+19] Canetti, R., et al.: Fiat-Shamir: from practice to theory. In: STOC (2019)
[CGH98] Canetti, R., Goldreich, O., Halevi, S.: The random oracle methodology, revisited (preliminary version). In: STOC (1998)
[CJJ21b] Choudhuri, A.R., Jain, A., Jin, Z.: SNARGs for P from LWE. In: FOCS (2021) Batch Arguments for NP 461
[GKR08] Goldwasser, S., Kalai, Y.T., Rothblum, G.N.: Delegating computation: interactive proofs for muggles. In: STOC (2008)
[GW11] Gentry, C., Wichs, D.: Separating succinct non-interactive arguments from all falsiﬁable assumptions. In: STOC (2011)
[HW15] Hubácek, P., Wichs, D.: On the communication complexity of secure func- tion evaluation with long output. In: ITCS (2015)
[JKKZ21] Jawale, R., Kalai, Y.T, Khurana, D., Zhang, R.Y.: SNARGs for bounded depth computations and PPAD hardness from sub-exponential LWE. In: STOC (2021)
[KPY19] Kalai, Y.T., Paneth, O., Yang, L.: How to delegate computations publicly. In: STOC (2019)
[KRR13] Kalai, Y.T., Raz, R., Rothblum, R.D.: Delegation for bounded space. In: STOC (2013)
[KRR14] Kalai, Y.T., Raz, R., Rothblum, R.D.: How to delegate computations: the power of no-signaling proofs. In: STOC (2014)
[LFKN90] Lund, C., Fortnow, L., Karloﬀ, H.J., Nisan, N.: Algebraic methods for interactive proof systems. In: FOCS (1990)
[RRR16] Reingold, O., Rothblum, G.N., Rothblum, R.D.: Constant-round interac- tive proofs for delegating computation. In: STOC (2016)
[RRR18] Reingold, O., Rothblum, G.N., Rothblum, R.D.: Eﬃcient batch veriﬁca- tion for UP. In: CCC (2018)
[Sha90] Shamir, A.: IP=PSPACE. In: FOCS (1990)
[SW14] Sahai, A., Waters, B.: How to use indistinguishability obfuscation: deni- able encryption, and more. In: STOC (2014)
[Wic22] Wichs, D.: Personal communication (2022)
1. Set count := 0, ﬂag := false.
2. While ﬂag = false: (a) Let y := h(m || count) where m || count is interpreted as a 2λ length bit string. (b) Run PrimalityTest to check if 2λ + y is a prime. If it is a prime, set ﬂag := true and em := 2λ + y. Otherwise, set count := count + 1. 47 Output em. Theorem B.1 (Eﬃcient and Adaptive Programmable Enumeration in ROM). If Hλ is modeled as a random oracle, then (PrimeSeqH, PrimeSampH) satisﬁes the following properties: Eﬃcient Sampling. For every λ ∈N, m ∈{0, 1}λ, the prime sampling algorithm PrimeSampH runs in expected polynomial time, where the probability is taken over the coins of setup algorithm PrimeSeqH. Adaptive Non-Colliding Prime Enumeration. For any PPT adversary A, there exists a neg- ligible function negl(·), such that for all λ ∈N, we have that Pr[PrimeSampH(samp, m1) = PrimeSampH(samp, m2) ∧m1 ̸= m2 : samp ←PrimeSeqH(1λ) (m1, m2) ←A(1λ, samp)  ≤negl(λ) Programmable Prime Enumeration. PrimeSampH behaves as a programmable random prime oracle. Proof. The proof of this theorem is similar to that of Theorem 5.1 with the modiﬁcation that now since Hλ is modeled as a random oracle, thus the resulting prime sequence enumerator can be modeled as a “programmable" random prime oracle. Note that the adaptive non-colliding prime enumeration property simply follows from collision resistance of the hash function, and we do not need to model the hash function as a random oracle for that. Remark B.2 (Eﬃciency of Sampling). We would like to point out that for our above samplers we only prove eﬃciency in the average case, thus the running time of sampler could be exponential in the worst case. However, we could prove worst case running time to be polynomial as well if we assume the well-known prime gap conjectures such as Cramér’s conjecture [Cra36], or even weaker variants of those conjectures which state that the prime gaps are bounded poly-logarithmically in the prime value. Thus, by relying on such prime gap conjectures, we get that worst case running time of sampling will also be polynomial. In order to complete the argument, we would need to make minor edit to the sampling procedure where instead of now evaluating the function on m || 0, m || 1, m || 2, . . . and so on, we would simply evaluate the function on m and then ﬁnd the closest prime greater than or equal to the function evaluation on m. Thus, by prime gap conjectures, this can always be computed in time poly(λ). 48
12. Chen, J., Micali, S.: Algorand: a secure and eﬃcient distributed ledger. Theor. Comput. Sci. 777, 155–183 (2019)
21. Desmedt, Y., Jajodia, S.: Redistributing secret shares to new access structures and its applications. Technical Report, Citeseer (1997)
23. Feldman, P., Micali, S.: Byzantine agreement in constant expected time (and trust- ing no one). In: 26th FOCS,  IEEE Computer Society Press, October 1985
24. Fitzi, M., Garay, J.A.: Eﬃcient player-optimal protocols for strong and diﬀerential consensus. In: Borowsky, E., Rajsbaum, S. (eds.) 22nd ACM PODC. ACM, July 2003
25. Fitzi, M., Liu-Zhang, C.D., Loss, J.: A new way to achieve round-eﬃcient byzan- tine agreement. In: Proceedings of the 2021 ACM Symposium on Principles of Distributed Computing,  (2021)
27. Gennaro, R., Ishai, Y., Kushilevitz, E., Rabin, T.: The round complexity of veriﬁ- able secret sharing and secure multicast. In: 33rd ACM STOC,  ACM Press, July 2001
33. Halevi, S., Ishai, Y., Jain, A., Kushilevitz, E., Rabin, T.: Secure multiparty com- putation with general interaction patterns. In: Sudan, M. (ed.) ITCS 2016,  ACM, January 2016
37. Kushilevitz, E., Lindell, Y., Rabin, T.: Information-theoretically secure proto- cols and security under composition. SIAM J. Comput. 39(5), 2090–2112 (2010). https://doi.org/10.1137/090755886
39. Maurer, U.: Secure multi-party computation made simple. Discrete Appl. Math. 154(2), 370–381 (2006)
40. Micali, S.: Very simple and eﬃcient byzantine agreement. In: Papadimitriou, C.H. (ed.) ITCS 2017, vol. 4266, pp. 6:1–6:1. LIPIcs, 67, January 2017
41. Ostrovsky, R., Yung, M.: How to withstand mobile virus attacks (extended abstract). In: Logrippo, L. (ed.) 10th ACM PODC,  ACM, August 1991
43. Schultz, D., Liskov, B., Liskov, M.: Mpss: mobile proactive secret sharing. ACM Trans. Inf. Syst. Secur. (TISSEC) 13(4), 1–32 (2010)
44. Wong, T.M., Wang, C., Wing, J.M.: Veriﬁable secret redistribution for archive systems. In: First International IEEE Security in Storage Workshop, 2002. Pro- ceedings,  IEEE (2002)
[Bea96] Beaver, D.: Correlated pseudorandomness and the complexity of private computations. In: 28th ACM STOC,  ACM Press, May 1996
[CB04] Cassuto, Y., Bruck, J.: A combinatorial bound on the list size. Technical report, California Institute of Technology (2004)
[CW79] Carter, J.L., Wegman, M.N.: Universal classes of hash functions. J. Com- put. Syst. Sci. 18(2), 143–154 (1979)
[GGM86] Goldreich, O., Goldwasser, S., Micali, S.: How to construct random func- tions. J. ACM 33(4), 792–807 (1986)
[GKWY20] Guo, C., Katz, J., Wang, X., Yu, Y.: Eﬃcient and secure multiparty com- putation from ﬁxed-key block ciphers. In: 2020 IEEE Symposium on Secu- rity and Privacy, , May 2020
[Imp95] Impagliazzo, R.: A personal view of average-case complexity. In: Proceed- ings of Structure in Complexity Theory. Tenth Annual IEEE Conference (1995)
[KOS21] Keller, M., Orsini, E., Scholl, P.: Actively secure OT extension with opti- mal overhead. Unpublished draft of full version (2021)
[TE76] Twogood, R.E., Ekstrom, M.P.: An extension of Eklundh’s matrix trans- position algorithm and its application in digital image processing. IEEE Trans. Comput. C-25(9), 950–952 (1976)
[AGS11] Aguilar, C., Gaborit, P., Schrek, J.: A new zero-knowledge code based identiﬁcation scheme with reduced communication. In: 2011 IEEE Infor- mation Theory Workshop,  (2011)
[BDK+21a] Bai, S., et al.: Crypstals-dilithium - algorithm speciﬁcations and sup- porting documentation. Version 3.1, 8 February 2021 (2021). https://pq- crystals.org/dilithium/data/dilithium-speciﬁcation-round3-20210208.pdf 570 T. Feneuil et al.
[BGKM22] Bidoux, L., Gaborit, P., Kulkarni, M., Mateu, V.: Code-based signatures from new proofs of knowledge for the syndrome decoding problem (2022)
[Can89] Cantor, D.G.: On arithmetical algorithms over ﬁnite ﬁelds. J. Combin. Theory Ser. A 50, 285–300 (1989)
[CDG+20] Chase, M., et al.: The picnic signature scheme - design document. Version 2.2, 14 April 2020 (2020). https://raw.githubusercontent.com/microsoft/ Picnic/master/spec/design-v2.2.pdf
[FHK+20] Fouque, P.-A., et al.: Falcon: fast-fourier lattice-based compact signatures over NTRU. Version 1.2, 1 October 2020 (2020). https://falcon-sign.info/ falcon.pdf
[GG07] Gaborit, P., Girault, M.: Lightweight code-based identiﬁcation and sig- nature. In: IEEE International Symposium on Information Theory, ISIT 2007, Nice, France, 24–29 June 2007,  IEEE (2007)
[GPS22] Gueron, S., Persichetti, E., Santini, P.: Designing a practical code-based signature scheme from zero-knowledge proofs with trusted setup. Cryp- tography 6(1), 5 (2022)
[IKOS07] Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A.: Zero-knowledge from secure multiparty computation. In: Johnson, D.S., Feige, U. (eds.) 39th ACM STOC,  ACM Press, June 2007
[KZ20b] Kales, D., Zaverucha, G.: Improving the performance of the Picnic signa- ture scheme. IACR TCHES 2020(4), 154–188 (2020). https://tches.iacr. org/index.php/TCHES/article/view/8680
[vzGG03] von zur Gathen, J., Gerhard, J.: Modern Computer Algebra. Cambridge University Press, Cambridge (2003)
[WZ88] Wang, Y., Zhu, X.: A fast algorithm for the Fourier transform over ﬁnite ﬁelds and its VLSI implementation. IEEE J. Sel. Areas Commun. 6(3), 572–577 (1988)
[16] we show that for any q and any simulator S we have Advindif F,S (q, q) ⩽Advseq-indif F,S (q, q) + SD (q, S) + FP (q, S) . (3) 646 A. Gunsing et al. 4.4 Mennink-Preneel Simulator We aim to employ (3) with the same simulator used in
[26] to achieve security up to 22n/3/n queries. This simulator is identical to the uniform simulator from Deﬁnition 5 with ℓ=
2. From now on, we denote this simulator by S. First we show in the full version
[16] that the simulator has a limited proba- bility to fail. That is, for the simulator S we have FP (q, S) ⩽2q 2n + 13q3 22n . (4) We continue with the main part of the proof, showing that the sequential diﬀer- ence of S is bounded by O  q3/22n . Lemma
1. For Mennink-Preneel’s simulator S, we have SD (q, S) ⩽46q3 22n . Proof. Fix an adversary D. For any τ = (τ1, . . . , τ2q) ∈T D⩾ good, let Cτ denote the partially sampled R as revealed to the adversary through all the construction queries in the game, and let DCτ and RCτ be respectively the domain and range of Cτ. For some τ = (τ1, . . . , τ2q) ∈T D⩾ good, consider primitive queries τi = (x, y0, y1), τj = (x′, y′ 0, y′ 1) with i < j, and let R0 and R1 respectively denote the range of P0 and the range of P1 right before the i-th query. We call the pair (τi, τj) erratic when it satisﬁes one of the following: – τj is queried to S+, and {Cτ(x) ⊕y′ 1, y1 ⊕Cτ(x′)} ∩R0 ̸= ∅; – τj is queried to S+, and {Cτ(x) ⊕y′ 0, y0 ⊕Cτ(x′)} ∩R1 ̸= ∅; – τj is queried to S− b , and yb ⊕y′ 1−b ∈RCτ . As y0, y1, y′ 0 and y′ 1 are all sampled uniformly from at most 2n −2q values and y′ 1−b is sampled from 2n −q values when x′ /∈DCτ , and the event x′ ∈DCτ happens with probability at most q/(2n −q), we can bound the probability by Pid [(τi, τj) erratic] ⩽max 2q 2n −2q + 2q 2n −2q , q 2n −q + q 2n −q ⩽max 4q 2n + 4q 2n , 2q 2n + 2q 2n = 8q 2n , (5) using that q ⩽2n−2. We partition T D⩾ good into the set T D⩾ ill of ill-behaved tran- scripts, and the set T D⩾ well of well-behaved transcripts, based on the following criterion: τ ∈T D⩾ ill if for some x, x′, x′′ ∈DCτ , Cτ(x) = Cτ(x′) = Cτ(x′′). We have that  τ∈T D⩾ ill Pid [τ] ⩽q3 22n . (6) Revisiting the Indiﬀerentiability of the Sum of Permutations 647 Fix a transcript τ ∈T D⩾ well , and let C := Cτ. We ﬁrst observe that responses obtained from the random oracles are sampled independent of the rest of the game, and D (eventually) sees the random oracle outputs of all x that occur in primitive query-response triples, so we can always condition on the outputs of all the construction queries when computing the probabilities of simulator responses. In the analysis that follows we assume that all the probabilities are implicitly conditioned on the random oracle outputs (which is the same as assum- ing that the random oracle output C(x) is known for each triple (x, y0, y1)). We will ﬁnd it useful to derive expressions for Pid [τi | τ1, . . . , τi−1] for any i ∈p(τ). Fix i, and deﬁne τhead := (τ1, . . . , τi−1). First let τi = (x, y0, y1)+. Let R0 and R1 be the ranges of the partial permutations P0 and P1 respectively just before the i-th query. Writing z := C(x), we have Pid [τi | τhead] = 1 2n −|R0 ∪(R1 ⊕z)|. (7) Next let τi = (x, y0, y1)− 0 . For arbitrary G ⊆DC and H ⊆{0, 1}n deﬁne SG→H := {x ∈G | C(x) ∈H ∩RC}, the set of elements in G which have an image under C in H. Finally, let D ⊆DC be the shared domain of P0 and P1 just before the i-th query. (Note that all these sets are functions of τhead.) In the full version
[16] we show that Pid [τi | τhead] = SDC\D→R1⊕y0  + 2n −q|D|/2n (2n −|D|)2 . (8) We are now ready to derive the bound claimed in the lemma statement. Deﬁne Δτ := Pid [τ] −Pid [ τ] . For each construction-query index i ∈c(τ), let i∗denote the companion primitive-query index in p(τ) (i.e., τi = (x, z) and τi∗= (x, y0, y1) for some x, y0, y1, z). We recall that we construct τ from τ as follows: – for each i ∈c(τ), if i < i∗then put τi∗at position i while pushing each of τi, . . . , τi∗−1 one place to the right. – once all construction queries are to the right of their companion primitive queries, push all the construction queries to the end. We ﬁrst observe that the second step above does not aﬀect the probability of the transcript, because the output of the construction queries is already ﬁxed from the companion primitive queries. (Note that this may not hold for certain simulators which try to cheat by returning a query-response triple (x, y0, y1) without ensuring that y0 ⊕y1 = R(x), but it holds for our simulator.) Thus, when computing Pid [ τ] we can pretend that the second step did not happen. In the ﬁrst step, we can assume that we check each i ∈c(τ) in order. Consider the smallest i ∈c(τ) satisfying i < i∗. Then, τi∗moves i∗−i places to the left. 648 A. Gunsing et al. This can be seen as a sequence of i∗−i adjacent transpositions, where the j-th transposition consists of swapping τi∗with τi∗−j. Let τ (i,j) denote the transcript obtained after j transpositions, with the convention that τ (i,0) = τ; also let τ [i] := τ (i,i∗−i) denote the transcript at the moment when τi∗has reached the target position. We also add i to a (mutable) set I, initialised as empty, which will eventually hold all the indices which need to be processed as above through a sequence of adjacent transpositions. We can inductively extend this notation for the rest of the transpositions as follows: having obtained τ [i′] for the latest (and largest) i′ ∈I, we look for the smallest i ∈c  τ [i′] satisfying i < i∗; we then move τ [i′] i∗ i∗−i places to the left through i∗−i adjacent transpositions, the j-th of which swaps τ [i′] i∗ with τ [i′] i∗−j; and ﬁnally, i is added to I. τ (i,j) continues to denote the transcript obtained after j transpositions, with the convention that τ (i,0) = τ [i′], and τ [i] := τ (i,i∗−i) now denotes the transcript at the moment when τ [i′] i∗ has reached the target position. For the last i to be added to I, τ [i] = τ. Remark
3. We point out that it would be diﬃcult to deﬁne the notation by listing out at the outset all the i ∈c(τ) satisfying i < i∗and going through them one by one; this is because processing the i-th entry changes the positions of the next i∗−i entries, which could contain the next candidate to be processed. We further point out that the above notation is nevertheless well-deﬁned, because the positions of the candidate entries can only increase during the handling of previous candidates, and we process them in increasing order, thus ensuring the same i is never repeated. Remark
4. One part of the notation we abuse is i∗, which we assume is deﬁned at every stage in accordance with the transcript τ (i,0) = τ [i′] for the immediate predecessor i′ of i in I, i.e., it shows the position of a query in p  τ [i′] . Making its dependence on τ explicit would make the notation more cumbersome, so we deem it best for the sake of clarity to leave this dependence implicit and add this clarifying remark. It may be worth noting that the condition i < i∗is invariant under the processing of previous entries, even with the lazy deﬁnition of i∗. For an i ∈I and a j ∈[i∗−i], we observe that the ﬁrst i∗−j −1 entries are identical in τ (i,j−1) and τ (i,j); we call this common preﬁx τ (i,j) head . Similarly, the last σ −i∗+ j −1 entries of the transcripts are also identical, forming a common suﬃx we call τ (i,j) tail . Then we see that Pid  τ (i,j−1) = Pid  τ (i,j) head  · Pid  τi∗−j | τ (i,j) head  · Pid  τi∗| τi∗−j, τ (i,j) head  · Pid  τ (i,j) tail | τi∗, τi∗−j, τ (i,j) head  , Pid  τ (i,j) = Pid  τ (i,j) head  · Pid  τi∗| τ (i,j) head  · Pid  τi∗−j | τi∗, τ (i,j) head  · Pid  τ (i,j) tail | τi∗−j, τi∗, τ (i,j) head  . Revisiting the Indiﬀerentiability of the Sum of Permutations 649 We deﬁne ρ(i,j) τ := Pid  τ (i,j−1) Pid  τ (i,j) = Pid  τi∗−j | τ (i,j) head  · Pid  τi∗| τi∗−j, τ (i,j) head  Pid  τi∗| τ (i,j) head  · Pid  τi∗−j | τi∗, τ (i,j) head  . (9) For each i ∈I, we further deﬁne ρ[i] τ :=  j∈[i∗−i] ρ(i,j) τ = Pid  τ (i,0) Pid  τ [i] , and ﬁnally, we deﬁne ρτ :=  i∈I ρ[i] τ = Pid [τ] Pid [ τ]. Using this, and the fact that 1/(1 + x) ⩾1 −x for all x, we can write Δτ = 1 −1 ρτ · Pid [τ] = ⎛ ⎝1 −  i∈I  j∈[i∗−i] 1 ρ(i,j) τ ⎞ ⎠· Pid [τ] ⩽ ⎛ ⎝1 −  i∈I  j∈[i∗−i]  1 −(ρ(i,j) τ −1) ⎞ ⎠· Pid [τ] ⩽  i∈I  j∈[i∗−i] (ρ(i,j) τ −1) · Pid [τ] . We next try to to ﬁnd a suitable upper bound for ρτ. Fix an i ∈I and a j ∈[i∗−i]. Our ﬁrst task will be to ﬁnd an upper bound for ρ(i,j) τ . In the full version
[16] we ﬁnd one depending on whether (τi∗−j, τi∗) is an erratic pair or not. We get ρ(i,j) τ ⩽Φ(i,j)(τ) := 1 + 5 22n if (τi∗−j, τi∗)is erratic, 1 + 5q 22n otherwise, for all τ ∈T D⩾ well . Furthermore, as the probability that (τi∗−j, τi∗) is an erratic pair is at most 8q/2n by (5) we derive for Φ(i,j) that Eid  Φ(i,j)(τ)  ⩽ 1 + 5 2n Pid [(τi, τj) erratic] + 1 + 5q 22n Pid [(τi, τj) not erratic] ⩽1 + 40q 22n + 5q 22n = 1 + 45q 22n , 650 A. Gunsing et al. Using this bound and the one in (6), and extending the deﬁnition of Δτ to all of T D⩾ good, we have SD (q, S) = max D  τ∈T D⩾ good Δτ = max D ⎛ ⎜ ⎝  τ∈T D⩾ well Δτ +  τ∈T D⩾ ill Δτ ⎞ ⎟ ⎠ ⩽max D ⎛ ⎜ ⎝  τ∈T D⩾ well  i∈I  j∈[i∗−i] (ρ(i,j) τ −1) · Pid [τ] +  τ∈T D⩾ ill Pid [τ] ⎞ ⎟ ⎠ ⩽max D ⎛ ⎜ ⎝  i∈I  j∈[i∗−i] Eid  Φ(i,j)(τ) −1  +  τ∈T D⩾ ill Pid [τ] ⎞ ⎟ ⎠ ⩽max D 45q3 22n + q3 22n = 46q3 22n , thus establishing Lemma 1. ⊓⊔ Using Eqs. (3), (4) and Lemma 1, and the observation from
[15] that [26, Theorem 2] implies sequential indiﬀerentiability with the same advantage, we get the following full indiﬀerentiability bound. Corollary
1. For 9n ⩽q ⩽2n−2, there exists a simulator S making at most 2q queries to R such that Advindif F,S (q, q) ⩽ 9nq3 22n + 2q 2n + 59q3 22n . 5 Sequential Diﬀerence ‘Fresh Ideal World’ In this section, we show an attack with complexity O  23n/4 that can distinguish the ideal world from the ‘fresh ideal world’ as described in Sect. 3.2. It works for any uniform simulator as described in Deﬁnition
5. Moreover, the attack makes primitive queries before making construction queries, meaning that the simpliﬁcation of considering random oracle outputs fresh is even problematic when considering the weaker sequential indiﬀerentiability setting. The intuition behind this attack is that in the regular ideal world the con- struction oracle output C(x) is uniformly at random and independently selected from {0, 1}n at start and does not change during the interaction. However, in the fresh ideal world the output C(x) is not ﬁxed at the start but is redrawn every time. Consequently, some biases introduced when making well-tailored backward queries, where the simulator does not select values with speciﬁc construction ora- cle outputs, are not present. We can exploit this ﬂaw to diﬀerentiate between these worlds using O  23n/4 queries as shown below. Revisiting the Indiﬀerentiability of the Sum of Permutations 651 5.1 Attack Setup Let q = 2k for some k with q ⩽2n−1. We make at most 2q queries to the primitive oracle and at most q queries to the construction oracle. We deﬁne the distinguisher D as follows:
1. Let X ⊆{0, 1}n be an arbitrary set of size q;
2. Call P−1 0 (0n−k ∥y) for all y ∈{0, 1}k;
3. Call P−1 1 (0n−k ∥y) for all y ∈{0, 1}k;
4. Call C(x) for all x ∈X;
5. Count the number of x ∈X such that ⌊C(x)⌋n−k = 0n−k and call it c;
6. Return 1 when c is lower than some cutoﬀd and 0 otherwise. Note that as pointless queries are not made, the value of C(x) can be deter- mined in either step (2), (3) or (4). The cutoﬀd is the midpoint between the expected values in the two diﬀerent worlds. The distinguisher D is formally given in Algorithm 4, with implicit calls by the simulator made explicit. We will compute the expectation and variance of c in both the regular ideal world (μ1 and σ2 1) and the fresh ideal world (μ2 and σ2 2). These values will be used to determine the advantage. 5.2 Ideal World In the regular ideal world, we can view C(x) to be ﬁxed at the start for all x. It does not matter whether the attacker retrieves it in step (2), (3) or (4), the probability that ⌊C(x)⌋n−k = 0n−k for a ﬁxed x ∈X is always 1/2n−k = q/2n. As every x is also independent from the other values, the total count is distributed as the binomial distribution B(q, q/2n), leading to μ1 = q2 2n , σ2 1 = q2 2n  1 −q 2n ⩽q2 2n . 5.3 Fresh Ideal World In the fresh ideal world, however, C(x) is not ﬁxed at the start but is sampled fresh at every invocation. This means that we have to separate the diﬀerent steps. Let c(2) 2 , c(3) 2 and c(4) 2 denote the subcounts in step (2), (3) and (4), respectively, so that c2 = c(2) 2 + c(3) 2 + c(4) 2 . We compute them separately. For c(2) 2 we consider the output of an arbitrary query made in step (2). As the simulator samples x uniformly from all possibilities, the probability that x ∈X is q/2n. Furthermore, the simulator samples C(x) uniformly over all possibilities such that C(x) /∈R1 ⊕(0n−k ∥y). As the previous queries are also sampled fresh, R1 is uniformly distributed over all possible subsets, hence there is no bias 652 A. Gunsing et al. Algorithm
4. Distinguisher between the normal and ‘fresh ideal world’ 1: function DP,C 2: X ←{0n−k ∥x : x ∈{0, 1}k} 3: c(2) ←CountInverse(0) 4: c(3) ←CountInverse(1) 5: c(4) ←CountConstruction() 6: c ←c(2) + c(3) + c(4) 7: if c ⩽d then 8: return 1 9: else 10: return 0 1: function CountInverse(b) 2: c ←0 3: for y ∈{0, 1}k do 4: yb ←0n−k ∥y 5: if yb /∈range(Pb) then 6: x ←P−1 b (yb) 7: y1−b ←P1−b(x) 8: z ←yb ⊕y1−b 9: if x ∈X and ⌊z⌋n−k = 0n−k then 10: c ←c + 1 11: return c 1: function CountConstruction 2: c ←0 3: for x ∈X do 4: if x /∈domain(P0) then 5: z ←C(x) 6: if ⌊z⌋n−k = 0n−k then 7: c ←c + 1 8: return c leading to q/2n for the probability that ⌊C(x)⌋n−k = 0n−k happens. Finally, as there are always q queries made in step (2), we get E  c(2) 2  = q · q 2n · q 2n = q3 22n . For c(3) 2 we simply have that ⌊C(x)⌋n−k = 0n−k is not possible, as the simula- tor rejects any x with C(x) ∈R0⊕(0n−k ∥y′) and {0n−k ∥y : y ∈{0, 1}k} ⊆R0. As a consequence, c(3) 2 = 0. Note that the number of queries made in step (3) is not always q as there can pointless queries that are already made in step (2). This happens whenever the simulator sets P1(x) as 0n−k ∥y′ for a y′ ∈{0, 1}k, which happens exactly when ⌊C(x)⌋n−k = 0n−k which has a probability of q/2n. Therefore, the number of queries made in step (3) has an expected value of q −q2/2n. Revisiting the Indiﬀerentiability of the Sum of Permutations 653 For c(4) 2 we have that C(x) is freshly sampled, hence the probability that ⌊C(x)⌋n−k = 0n−k happens is q/2n. We still have no bias in the chosen x, so the probability that x ∈X for a speciﬁc x is also still q/2n. However, we do not necessarily make the maximum possible number of q queries as we ignore pointless queries. Let q(2) and q(3) denote the number of queries made in step (2) and (3), respectively, of which the output lies within X. Then, we have that E  c(4) 2  q(2), q(3) = (q −q(2) −q(3)) q 2n . As E  q(2) = q2/2n and E  q(3) = (q −q2/2n)q/2n = q2/2n −q3/22n, we get by the law of total expectation that E  c(4) 2  =  q −E  q(2) −E  q(3 q 2n = q −2q2 2n + q3 22n q 2n = q2 2n −2q3 22n + q4 23n . Combining all this gives μ2 = E  c(2) 2 + c(3) 2 + c(4) 2  = q3 22n + 0 + q2 2n −2q3 22n + q4 23n = q2 2n −q3 22n + q4 23n ⩽q2 2n − q3 22n+1 , using that q ⩽2n−1. For the variance we have that every single query is a Bernoulli variable. In step (2) the probability is q2/22n and in step (3) the probability is q/2n, giving variances of q2/22n(1−q2/22n) ⩽q2/22n and q/2n(1− q/2n) ⩽q/2n, respectively. The variance of a sum of variables is the sum of the variances of the individual variables with the covariances between the variables added. But in our case the variables in step (2) negatively inﬂuence future queries and variables in step (3) have no inﬂuence, leading to a negative correlation, hence σ2 2 ⩽q3 22n + q2 2n ⩽2q2 2n , where we additionally use the fact that at most q queries are made in both step (2) and (4). 5.4 Advantage In the full version
[16] we show, directly from the means and variances, that the advantage is at least Advseq-indif (R,S),(R′,S)(D) ⩾1 −4(σ2 1 + σ2 2) (μ1 −μ2)2 ⩾1 −12q2 2n 24n+2 q6 ⩾1 −23n+6 q4 , where Advseq-indif (R,S),(R′,S)(·) denotes the sequential indiﬀerentiability advantage between the ideal world (R, S) and the fresh ideal world (R′, S) with R′ the modiﬁed random oracle that always gives fresh results. 654 A. Gunsing et al. 6 Generic Diﬀerentiability Attack In this section, we show an attack with complexity O  25n/6 that can distinguish the ideal world with the uniform simulator from the real world. The intuition behind this attack is that the uniform forward simulator returns a value uni- formly sampled from all possibilities. While this sounds reasonable it turns out that this actually does not exactly match the real world for all interactions. This uniformity changes the distribution of outputs when the order of the queries is changed in the ideal world, while the order does not matter in the real world. We can exploit this ﬂaw to attack the uniform simulator using O  25n/6 queries as shown below. 6.1 Attack Setup Let q = 2k for some k with q ⩽2n−3. We make at most 3q queries to the primitive oracle and at most q queries to the construction oracle.
1. Call P−1 1 (0n−k ∥y) for all y ∈{0, 1}k;
2. Call C(xi) = zi for q fresh xi;
3. Let I be the index set consisting of all i such that ⌊zi⌋n−k = 0n−k in the previous step;
4. Call P0(xi) for all i ∈I (optional);
5. Call P0(xj) = yj for q fresh xj;
6. Count the number of j such that ⌊yj⌋n−k = 0n−k and call it c;
7. Return 1 when c is lower than some cutoﬀd and 0 otherwise. Step (4) is denoted as optional. We deﬁne two related distinguishers depending on whether step (4) is executed or not. We denote D∅for the distinguisher that skips (4) and DI for the distinguisher that executes (4). Again, the cutoﬀd is the midpoint between the expected values in the two diﬀerent worlds. The distinguishers D∅and DI are formally given in Algorithm 5, with again implicit calls by the simulator made explicit. By the triangle inequality we get that P  DR,S,S−1 ∅ = 1  −P  DR,S,S−1 I = 1  (10) ⩽ P  DR,S,S−1 ∅ = 1  −P  DF,Π,Π−1 ∅ = 1  + P  DF,Π,Π−1 ∅ = 1  −P  DF,Π,Π−1 I = 1  + P  DF,Π,Π−1 I = 1  −P  DR,S,S−1 I = 1  = Advindif F,S (D∅) + 0 + Advindif F,S (DI) ⩽2 max  Advindif F,S (D∅), Advindif F,S (DI) , where the reasoning for the 0 is given in Sect. 6.2. This means that if we show that there is a non-negligible diﬀerence between adding the queries I or not in Revisiting the Indiﬀerentiability of the Sum of Permutations 655 Algorithm
5. Distinguisher on the uniform simulator, with the highlighted lines 9–11 included in DI but not in D∅ 1: function DP,C 2: for y ∈{0, 1}k do 3: y1 ←0n−k ∥y 4: x ←P−1 1 (y1) 5: y0 ←P0(x) 6: for 1 ⩽i ⩽q do 7: x $←−{0, 1}n \ (domain(P0) ∪domain(C)) 8: z ←C(x) 9: if ⌊z⌋n−k = 0n−k then 10: y0 ←P0(x) 11: y1 ←P1(x) 12: c ←0 13: for 1 ⩽j ⩽q do 14: x $←−{0, 1}n \ (domain(P0) ∪domain(C)) 15: y0 ←P0(x) 16: y1 ←P1(x) 17: if ⌊y0⌋n−k = 0n−k then 18: c ←c + 1 19: if c ⩽d then 20: return 1 21: else 22: return 0 the ideal world, i.e., there is a non-trivial lower bound for (10), there is a dis- tinguisher (either D∅or DI) that has a non-negligible advantage on the original construction. In Sect. 6.3 we will derive such a lower bound on (10), leading to 2 max  Advindif F,S (D∅), Advindif F,S (DI) ⩾1 −O 25n q6 . 6.2 Real World In the real world, the construction oracle is deﬁned as F(x) = Π0(x) ⊕Π1(x). This means that a construction query F(x) will behave the same as the two prim- itive queries Π0(x) and Π1(x). Therefore, the primitive queries Π0(xi) optionally made in step (4) have no inﬂuence as they are already implicitly executed in the construction query F(xi) in step (3). As the only diﬀerence between D∅and DI are these ‘extra’ primitive queries, their output probabilities do not diﬀer, and hence P  DF,Π,Π−1 ∅ = 1  −P  DF,Π,Π−1 I = 1  = 0. 656 A. Gunsing et al. 6.3 Ideal World In this section we focus on ﬁnding a lower bound for P  DR,S,S−1 ∅ = 1  −P  DR,S,S−1 I = 1  . In order to do this, we will compute the expectation and variance of c for both D∅(μ∅and σ2 ∅) and DI (μI and σ2 I). These values will be used to determine the advantage. We are mostly interested in the diﬀerence between the expectations which we can denote as μI −μ∅=  j δj, δj = pI,j −p∅,j, where p∅,j = P∅  ⌊yj⌋n−k = 0n−k and pI,j = PI  ⌊yj⌋n−k = 0n−k , where P∅[·] (resp., PI [·]) denotes the probability is taken when interacting with distinguisher D∅(resp., DI). Now we will look at the probability that ⌊yj⌋n−k = ⌊S0(xj)⌋n−k = 0n−k for a ﬁxed j when I is excluded or included. By the behavior of the simulator, the probability is of the form pj = P  ⌊yj⌋n−k = 0n−k = E q −Wj 2n −Vj , where Wj denotes the number of elements that exclude ⌊yj⌋n−k = 0n−k from occurring and Vj denotes the number of excluded values to draw. This notation is more generic and we denote W∅,j and V∅,j when interacting with D∅and similar for DI. In the full version
[16] we show that δj ⩾ q3 23n+2 + O q4 24n . The intuition behind this diﬀerence is that the queries i ∈I satisfy ⌊zi⌋n−k = 0n−k, which means that ⌊S0(xi)⌋n−k ̸= 0n−k. Therefore, these queries do not directly exclude possibilities for ⌊yj⌋n−k to hit 0n−k, while excluding other options. This slightly increases the probability of ⌊yj⌋n−k = 0n−k, leading to the diﬀerence. As μI −μ∅=  j δj, this implies that μI −μ∅⩾ q4 23n+2 + O q5 24n = Ω q4 23n , 1 (μI −μ∅)2 = O 26n q8 . Furthermore, in the full version
[16] we show that the expectation for a single event in both cases is p∅,j, pI,j = q 2n + O q3 23n , Revisiting the Indiﬀerentiability of the Sum of Permutations 657 immediately giving its variance of at most the same value. Furthermore, the variance of a sum of variables is the sum of the variables, with the pairwise correlations added. In our case the variables are negatively correlated as when ⌊yj⌋n−k = 0n−k happens one more possibility to hit is discarded for future queries, reducing its probability. This means that we can upper bound the vari- ances as σ2 I, σ2 ∅⩽q2 2n + O q4 23n = O q2 2n . Finally, in the full version
[16] we show, directly from the means and variances, that the advantage is at least (10) ⩾1 −4(σ2 I + σ2 ∅) (μI −μ∅)2 = 1 −O q2 2n O 26n q8 = 1 −O 25n q6 , as desired. 7 Conclusion The contributions of this work are both negative and positive. On the negative side, we demonstrated that previous best security result on the sum of per- mutations is ﬂawed and not easily ﬁxed as there is an attack in 25n/6 queries. On the positive side, the security claim of the second-best result, guaranteeing 22n/3/n security, can be reattained. The two results, albeit highly technical and non-trivial, admit a gap. We expect that security beyond 22n/3/n may still be possible but that such result will require resorting to a more sophisticated simu- lator and/or following an entirely diﬀerent proof approach. Indeed, to be precise, our 22n/3/n security result for the simulator of Deﬁnition 5 with ℓ= 2 took the result of Mennink and Preneel, with 22n/3/n sequential indiﬀerentiability, as a black box and performed a query shuﬄing approach that was valid as long as the number of queries is at most 22n/3/n. Going beyond this security bound thus requires resolving both bottlenecks.
6. Canetti, R., Goldreich, O., Halevi, S.: The random oracle methodology, revisited (preliminary version). In: 30th ACM STOC,  ACM Press, Dallas, TX, USA (1998). https://doi.org/10.1145/276698.276741
18. Meier, L.: Idealized models for free (podcast) (2023). https://cronokirby.substack. com/p/idealized-models-for-free Generic and Algebraic Computation Models 45
23. Schul-Ganz, G., Segev, G.: Generic-group identity-based encryption: a tight impos- sibility result. In: Tessaro, S. (ed.) 2nd Conference on Information-Theoretic Cryp- tography (ITC 2021). Leibniz International Proceedings in Informatics (LIPIcs), vol. 199, pp. 26:1–26:23. Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl, Germany (2021). https://doi.org/10.4230/LIPIcs.ITC.2021.26
1. Ajtai, M.: Secure computation with information leaking to an adversary. In: Fort- now, L., Vadhan, S.P. (eds.) 43rd Annual ACM Symposium on Theory of Com- puting.  ACM Press, San Jose, CA, USA (Jun 6–8, 2011). https: //doi.org/10.1145/1993636.1993731 21
12. Boucheron, S., Lugosi, G., Massart, P.: Concentration inequalities: A nonasymp- totic theory of independence. Oxford university press (2013) 22
13. Broughan, K.A.: The gcd-sum function. J. Integer Seq. 4(2.2) (2001) 14
18. Chari, S., Jutla, C.S., Rao, J.R., Rohatgi, P.: Towards sound approaches to coun- teract power-analysis attacks. In: Wiener [53],  https://doi.org/10. 1007/3-540-48405-1_26 2
20. Coron, J.S.: Higher order masking of look-up tables. In: Nguyen and Oswald [44], https://doi.org/10.1007/978-3-642-55220-5_25 23
21. Coron, J.S., Prouﬀ, E., Rivain, M., Roche, T.: Higher-order side channel secu- rity and mask refreshing. In: Moriai [43],  https://doi.org/10.1007/ 978-3-662-43933-3_21 3
23. Cover, T.M., Thomas, J.A.: Elements of information theory (2. ed.). Wiley (2006) 25, 27, 28
25. Duc, A., Dziembowski, S., Faust, S.: Unifying leakage models: From probing attacks to noisy leakage. In: Nguyen and Oswald [44],  https://doi.org/10. 1007/978-3-642-55220-5_24 3, 4, 8, 21, 22
36. Jog, V.S., Anantharam, V.: The entropy power inequality and mrs. ger- ber’s lemma for groups of order 2n. IEEE Trans. Inf. Theory 60(7), 3773– 3786 (2014). https://doi.org/10.1109/TIT.2014.2317692, https://doi.org/ 10.1109/TIT.2014.2317692 15
38. Kocher, P.C., Jaﬀe, J., Jun, B.: Diﬀerential power analysis. In: Wiener [53],  https://doi.org/10.1007/3-540-48405-1_25 1
40. Mangard, S., Oswald, E., Popp, T.: Power analysis attacks - revealing the secrets of smart cards. Springer (2007) 9
41. Mangard, S., Oswald, E., Standaert, F.: One for all - all for one: unify- ing standard diﬀerential power analysis attacks. IET Inf. Secur. 5(2), 100– 110 (2011). https://doi.org/10.1049/iet-ifs.2010.0096, https://doi.org/ 10.1049/iet-ifs.2010.0096 9
49. Cardoso dos Santos, L., Gérard, F., Großschädl, J., Spignoli, L.: Rivain-Prouﬀon steroids: Faster and stronger masking of the AES. In: Buhan, I., Schneider, T. (eds.) Smart Card Research and Advanced Applications.  Springer International Publishing, Cham (2023) 10, 13
50. Shulman, N., Feder, M.: The uniform distribution as a universal prior. IEEE Trans. Inf. Theory 50(6), 1356–1362 (2004). https://doi.org/10.1109/TIT.2004. 828152, https://doi.org/10.1109/TIT.2004.828152 11, 12, 28
52. Tunstall, M., Whitnall, C., Oswald, E.: Masking tables - an underesti- mated security risk. In: Moriai [43],  https://doi.org/10.1007/ 978-3-662-43933-3_22 23
54. Wyner, A.D., Ziv, J.: A theorem on the entropy of certain binary sequences and applications-i. IEEE Trans. Inf. Theory 19(6), 769–772 (1973). https://doi.org/ 10.1109/TIT.1973.1055107, https://doi.org/10.1109/TIT.1973.1055107 15 37
[ALM+92] Arora, S., Lund, C., Motwani, R., Sudan, M., Szegedy, M.: Proof veri- ﬁcation and hardness of approximation problems. In: FOCS, (1992)
[ALM+98] Arora, S., Lund, C., Motwani, R., Sudan, M., Szegedy, M.: Proof ver- iﬁcation and intractability of approximation problems. J. ACM 45(3), 501–555 (1998)
[AS92] Arora, S., Safra, S.: Probabilistic checking of proofs; A new characteriza- tion of NP. In: FOCS,  (1992)
[AS98] Arora, S., Safra, S.: Probabilistic checkable proofs: a new characterization of NP. J. ACM 45(1), 70–122 (1998)
[BFLS91] Babai, L., Fortnow, L., Levin, L., Szegedy, M.: Checking computations in polylogarithmic time. In: STOC,  (1991)
[BGH+05] Ben-Sasson, E., Goldreich, O., Harsha, P., Sudan, M., Vadhan, S.: Short PCPs veriﬁable in polylogarithmic time. In: CCC,  (2005)
[BGKS20] Ben-Sasson, E., Goldberg, L., Kopparty, S., Saraf, S.: DEEP-FRI: sam- pling outside the box improves soundness. In: ITCS, pp. 5:1–5:32 (2020)
[BKK+16] Ben-Sasson, E., Kaplan, Y., Kopparty, S., Meir, Or., Stichtenoth, H.: Con- stant rate PCPs for circuit-SAT with sublinear query complexity. J. ACM 63(4), 32:1–32:57 (2016)
[BS06] Ben-Sasson, E., Sudan, M.: Robust locally testable codes and products of codes. Random Struct. Alg. 28(4), 387–402 (2006)
[Din07] Dinur, I.: The PCP theorem by gap ampliﬁcation. J. ACM 54(3), 12 (2007)
[FS11] Fortnow, L., Santhanam, R.: Infeasibility of instance compression and succinct PCPs for NP. J. Comput. Syst. Sci. 77(1), 91–106 (2011)
[GKR15] Goldwasser, S., Kalai, Y.T., Rothblum, G.N.: Delegating computation: interactive proofs for muggles. J. ACM 62(4):27:1–27:64 (2015)
[GMR85] Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of inter- active proof-systems (extended abstract). In: STOC,  (1985)
[HVW21] Hazay, C., Venkitasubramaniam, M., Weiss, M.: ZK-PCPs from leakage- resilient secret sharing. In: ITC, pp. 6:1–6:21 (2021)
[IKOS07] Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A.: Zero-knowledge from secure multiparty computation. In: STOC,  (2007)
[Kil92] Kilian, J.: A note on eﬃcient zero-knowledge proofs and arguments. In: STOC,  (1992)
[KLR06] Kushilevitz, E., Lindell, Y., Rabin, T.: Information-theoretically secure protocols and security under composition. : STOC,  ACM (2006)
[KPT97] Kilian, J., Petrank, E., Tardos, G.: Probabilistically checkable proofs with zero knowledge. In: STOC,  (1997)
[LFKN92] Lund, C., Fortnow, L., Karloﬀ, H.J., Nisan, N.: Algebraic methods for interactive proof systems. J. ACM 39(4), 859–868 (1992)
[Mei13] Meir, O.: IP = PSPACE using error-correcting codes. SIAM J. Comput. 42(1), 380–403 (2013)
[Mei14] Meir, O.: Combinatorial PCPs with eﬃcient veriﬁers. Comput. Complex. 23(3), 355–478 (2014)
[Mic00] Micali, S.: Computationally sound proofs. SIAM J. Comput. 30(4), 1253– 1298 (2000)
[Ran13] Randriambololona, H.: An upper bound of singleton type for component- wise products of linear codes. IEEE Trans. Inf. Theory 59(12), 7936–7939 (2013)
[RR19] Ron-Zewi, N, Rothblum, R.: Local proofs approaching the witness length. Electronint Colloquium on Computational Complexity TR19-127, Revi- sion 2 (2019)
[RR20] Ron-Zewi, N., Rothblum, R.D.: Local proofs approaching the witness length [extended abstract]. In: FOCS,  (2020)
[RR22] Ron-Zewi, N., Rothblum, R.: Proving as fast as computing: succinct argu- ments with constant prover overhead. In: STOC,  (2022) Zero-Knowledge IOPs Approaching Witness Length 137
[RRR17] Reingold, O., Rothblum, G.N., Rothblum, R.D.: Personal Communication (2017)
[RS60] Reed, I.S., Solomon, G.: Polynomial codes over certain ﬁnite ﬁelds. SIAM J. Soc. Ind. Appl. Math. 8(2), 300–304 (1960)
[RS96] Rubinfeld, R., Sudan, M.: Robust characterization of polynomials with applications to program testing. SIAM J. Comput. 25(2), 252–271 (1996)
[Sud00] Sudan, M.: Probabilistically checkable proofs - lecture notes (2000). http://madhu.seas.harvard.edu/MIT/pcp/pcp.ps
[Vid15] Viderman, M.: A combination of testability and decodability by tensor products. Random Struct. Alg. 46(3), 572–598 (2015)
[ZXZS20] Zhang, J., Xie, T., Zhang, Y., Song, D.: Transparent polynomial delega- tion and its applications to zero knowledge proof. In: S&P, (2020)
0. It runs A on inputs ¯A = [A|I] and t. In the first stage, A outputs an index i∗. In the second stage, W answers hash queries from A as described in Fig.
0. Then we have Advsel-UF-KOA DualMS (A) ≤εW + AdvMLWEq,k,l,η(D) + Q2 h |C| + 2( 2 qN/2 )k. (5) Inner forking algorithm. Then we construct the inner forking algorithm B′. It takes as inputs A, B, t∗ 1 which are uniformly distributed over Rk×l q , Rk×l′ q , and Rk q, respectively, and a(1), . . . , a(Qh) which are uniformly distributed over C. It runs ForkW(X), where the input X consists of A, B, t∗ 1, and a(1), . . . , a(Qh), and the inputs c(1), . . . , c(Qh) of W are interpreted as h1, . . . , hQ in Lemma 13. All the outputs of W other than I are interpreted as the side output Y in Lemma 13. If ForkW outputs ⊥, then B′ outputs J =
0. If ForkW gives a non-⊥output, then suppose the side outputs Y and Y ′ of W in the two executions consist of J, ˜w, ˜z, ˜r, ˜e,˜t∗, c, L∗, a1, . . . , an, and J′, ˜w′, ˜z′, ˜r′, ˜e′,˜t∗′, c′, L∗′, a′ 1, . . . , a′ n, respectively. We argue that: J = J′, ˜w = ˜w′,˜t∗= ˜t∗′, L∗= L∗′, a1 = a′ 1, . . . , an = a′ n. This is because the two executions of W are identical until W assigns c(I) to Tsig[˜t∗, µ∗, ˜w]. It immediately follows that ˜t∗= ˜t∗′ and ˜w = ˜w′ as index I are the same in the two executions. Note that AggOrd and AggCol did not occur in both executions, and we assumed at the beginning of Section 4 that query Hcom(˜t∗, µ∗) was made earlier than Hsig(˜t∗, µ∗, ˜w). Hence, L∗was queried to Hagg earlier than the assignment to Tsig[˜t∗, µ∗, ˜w], and it is the only public-key list ever queried that is aggregated into ˜t∗. All the other equations follow. On the other hand, we have c ̸= c′ by the description of ForkW in Lemma 13. Then we have A˜z + B˜r + ˜e = ˜w + c˜t∗and A˜z′ + B˜r′ + ˜e′ = ˜w + c′˜t∗ as W outputs I ̸= 0 only if the forgery given by A is valid. Subtract the second equation from the first, and let ˆz = ˜z −˜z′, ˆr = ˜r −˜r′, ˆe = ˜e −˜e′ and ˆc = c −c′ ̸=
0. Then we have Aˆz + Bˆr + ˆe = ˆc˜t∗= ˆc n X i=1 aiti, where {t1, . . . , tn} = L∗and t1 = t∗
1. Algorithm B′ outputs J, ˆz, ˆr, ˆe, ˆc, L∗, a1, . . . , an. 28 Let εB′ be the probability that B′ outputs J ̸=
0. By Lemma 13, εW ≤Qh |C| + p QhεB′. (6) Outer forking algorithm. Finally, we construct the outer forking algorithm B. It takes as inputs a k × (1 + l + l′) matrix over Rq and partitions it as [t∗ 1|A|B]. It runs ForkB′(X), where the input X consists of A, B, and t∗ 1, and the inputs a(1), . . . , a(Qh) of B′ are interpreted as h1, . . . , hQ in Lemma
13. The output J of B′ are interpreted as I in Lemma 13, and all other outputs as side output Y . If ForkB′ outputs J ̸= 0, then suppose the side outputs Y and Y ′ of B′ in the two executions consist of ˆz, ˆr, ˆe, ˆc, L∗= {t1, . . . , tn}, a1, . . . , an, and ˆz′, ˆr′, ˆe′, ˆc′, L′∗= {t′ 1, . . . , t′ n}, a′ 1, . . . , a′ n, respectively. We argue that L∗= L∗′, and ai = a′ i for every ti ̸= t∗
1. This is because the four executions of W during the two executions of B′ are identical until W assigns a(J) to Tagg[L∗, t∗ 1]. It immediately follows that L∗= L∗′ by the fact that index J are the same in the four executions. Other equations follow from the fact that W assigns Tagg[L∗, ti] for ti ̸= t∗ 1 earlier than Tagg[L∗, t∗ 1]. On the other hand, we have a1 ̸= a′ 1 again by the definition of ForkB′. Suppose that t∗ 1 occurs n∗times in L∗. Then we have Aˆz + Bˆr + ˆe = ˆc(n∗a1t∗ 1 + X ti̸=t∗ 1 aiti) and Aˆz′ + Bˆr′ + ˆe′ = ˆc′(n∗a′ 1t∗ 1 + X ti̸=t∗ 1 aiti). By multiplying the first equation by ˆc′ and the second by ˆc, we have A(ˆc′ˆz −ˆcˆz′) + B(ˆc′ˆr −ˆcˆr′) + ˆc′ˆe −ˆcˆe′ = n∗ˆcˆc′(a1 −a′ 1)t∗ 1. Then we rearrange the equation and have [t∗ 1|A|B|I]   n∗ˆcˆc′(a1 −a′ 1) ˆc′ˆz −ˆcˆz′ ˆc′ˆr −ˆcˆr′ ˆc′ˆe −ˆcˆe′  = 0. Note that ˆc, ˆc′, and ˆa are not zeros and also not zero-divisors by Lemma 1, so n∗ˆcˆc′ˆa ̸=
0. The L2-norm of the vector is q ∥n∗ˆcˆc′ˆa∥2 2 + ∥ˆc′ˆz −ˆcˆz′∥2 2 + ∥ˆc′ˆr −ˆcˆr′∥2 2 + ∥ˆc′ˆe −ˆcˆe′∥2 2 ≤8κ p ˆn2κ3 + B2n + B′2 n + B′′2 n = β. To see the inequality, first note that ∥n∗ˆcˆc′ˆa∥2 ≤ˆn∥ˆc∥1∥ˆc′∥1∥ˆa∥2, where ∥ˆc∥1, ∥ˆc′∥1 ≤2κ and ∥ˆa∥2 ≤2√κ. Moreover, we have ∥ˆc′ˆz −ˆcˆz′∥2 ≤∥ˆc′∥1∥ˆz∥2 + ∥ˆc∥1∥ˆz′∥2, where ∥ˆz∥2, ∥ˆz′∥2 ≤2Bn. Similar bounds hold for ∥ˆc′ˆr −ˆcˆr′∥2 and ∥ˆc′ˆe −ˆcˆe′∥2. Thus, B successfully obtains a solution to MSISq,k,1+l+l′,β with respect to [t∗ 1|A|B]. By Lemma 13, we have εB′ ≤Qh |C| + q QhAdvMSISq,k,1+l+l′,β(B). (7) Combining Eqs. (5) to (7) we have Advsel-UF-KOA DualMS (A) ≤ s Q2 h |C| + Qh q QhAdvMSISq,k,1+l+l′,β(B) + AdvMLWEq,k,l,η(D) + Qh(Qh + 1) |C| + 2( 2 qN/2 )k. 29 Lemma 11 ([BTT22b]). Pr[AggOrd] ≤Qh |C| + ( 2 qN/2 )k. Proof. Note that t∗ 1 = [t∗ 1,1, . . . , t∗ 1,k]⊺is a vector that consists of k elements uniformly distributed over Rq. By Lemma 1, except with probability at most (2/qN/2)k, one of the k elements is invertible. We condition on this event and assume t∗ 1 is invertible without loss of generality. We bound the probability that a list of public keys L = {t∗ 1, t2, . . . , tn} queried to Hagg later than the i∗-th fresh Hcom query, where t∗ 1 occurs n∗times, is aggregated into ˜t∗. This event occurs only if the first element of t∗ 1, . . . , tn aggregate into the first element of ˜t∗. More specifically, let ti,1 be the first element of ti for i ∈[n] and ˜t1 the first element of ˜t∗. Then L is aggregated into ˜t∗only if n∗a1t∗ 1,1 + X ti̸=t∗ 1 aiti,1 = ˜t1. As an integer, n∗is invertible, so it follows that a1 = n∗−1t∗−1 1 (˜t1 − X ti̸=t∗ 1 aiti,1). Since a1 is uniformly distributed over C, it occurs with probability at most 1/|C|. We can conclude the proof by the union bound. Lemma 12 ([BTT22b]). Pr[AggCol] ≤Qh(Qh −1) |C| + ( 2 qN/2 )k. Proof. The reason is basically the same as Lemma
5. Similarly, in the dual signing, d1 is split into p′′ with Gaussian width s′ 1 and z′′ 1 with Gaussian width s2. Therefore, rather than √ s2 + s′2 where s > max(s1, s2) and s′ > max(s′ 1, s′ 2) as in our scheme specification, the Gaussian width of e1 can be reduced to max( p s2 1 + s′2 2 , p s′2 1 + s2 2). 5https://eprint.iacr.org/archive/2023/263/20230222:193121 31
6. Blundo, C., De Santis, A., Persiano, G., Vaccaro, U.: Randomness complexity of private computation. Comput. Complex. 8(2), 145–168 (1999)
7. Blundo, C., Galdi, C., Persiano, G.: Low-randomness constant-round private XOR computations. Int. J. Inf. Sec. 6(1), 15–26 (2007)
11. Chaum, D., Cr´epeau, C., Damgard, I.: Multiparty unconditionally secure protocols. In: STOC 1988,  (1988)
12. Chor, B., Goldreich, O., Hasted, J., Freidmann, J., Rudich, S., Smolensky, R.: The bit extraction problem or t-resilient functions. In: FOCS 1985,  (1985)
13. Chor, B., Kushilevitz, E.: A communication-privacy tradeoﬀfor modular addition. Inf. Process. Lett. 45(4), 205–210 (1993)
16. Data, D., Prabhakaran, V.M., Prabhakaran, M.M.: Communication and random- ness lower bounds for secure computation. IEEE Trans. Inf. Theor. 62(7), 3901– 3929 (2016)
18. G´al, A., Ros´en, A.: A theorem on sensitivity and applications in private computa- tion. SIAM J. Comput. 31(5), 1424–1437 (2002)
21. G´al, A., Ros´en, A.: Ω(log n) lower bounds on the amount of randomness in 2- private computation. SIAM J. Comput. 34(4), 946–959 (2005). Earlier version in STOC 2003
23. Ishai, Y., Malkin, T., Strauss, M.J., Wright, R.N.: Private multiparty sampling and approximation of vector combinations. Theor. Comput. Sci. 410(18), 1730–1745 (2009)
26. Knuth, D., Yao, A.: The complexity of nonuniform random number generation. In: Algorithms and Complexity: New Directions and Recent Results. Academic Press (1976)
27. Kushilevitz, E., Mansour, Y.: Randomness in Private Computations. SIAM J. Dis- crete Math. 10(4), 647–661 (1997). Earlier version in PODC 1996 Tight Bounds on the Randomness Complexity of Secure MPC 513
29. Kushilevitz, E., Ostrovsky, R., Ros´en, A.: Characterizing linear size circuits in terms of privacy. In: STOC 1996,  (1996)
30. Kushilevitz, E., Ostrovsky, R., Ros´en, A.: Amortizing randomness in private mul- tiparty computations. SIAM J. Discrete Math. 16(4), 533–544 (2003)
31. Kushilevitz, E., Ros´en, A.: A randomness-rounds tradeoﬀin private computation. SIAM J. Discrete Math. 11(1), 61–80 (1998)
22. Nielsen, M.A., Chuang, I.L.: Quantum Computation and Quantum Information (10th Anniversary edition). Cambridge University Press (2016)
25. Unruh, D.: Revocable quantum timed-release encryption. J. ACM 62(6), 49:1– 49:76 (2015). https://doi.org/10.1145/2817206 324 J. Ge et al.
2. Bellare, M., Desai, A., Jokipii, E., Rogaway, P.: A concrete security treatment of symmetric encryption. In: 38th FOCS,
9. Biham, E.: How to decrypt or even substitute des-encrypted messages in 228 steps. Inf. Process. Lett. 84(3), 117–124 (2002)
19. Cogliati, B., Patarin, J.: Mirror theory: A simple proof of the pi+pj theorem with ξmax =
22. Dutta, A., Nandi, M., Saha, A.: Proof of mirror theory for ξmax =
2. IEEE Trans. Inf. Theory 68(9), 6218–6232 (2022)
4. Bostanci, J., Efron, Y., Metger, T., Poremba, A., Qian, L., Yuen, H.: Unitary complexity and the uhlmann transformation problem (2023)
6. Broadbent, A., Grilo, A.B.: QMA-hardness of consistency of local density matrices with applications to quantum zero-knowledge. SIAM J. Comput. 51(4), 1400–1450 (2022). https://doi.org/10.1137/21m140729x
7. Chailloux, A., Kerenidis, I., Rosgen, B.: Quantum commitments from complexity assumptions. Comput. Complex. 25(1), 103–151 (2016). https://doi.org/10.1007/ s00037-015-0116-5
8. Chung, K.M., Guo, S., Liu, Q., Qian, L.: Tight quantum time-space tradeoﬀs for function inversion. In: 61st FOCS,  IEEE Computer Society Press (2020). https://doi.org/10.1109/FOCS46700.2020.00068 90 T. Morimae et al.
15. Goldreich, O., Krawczyk, H.: Sparse pseudorandom distributions. Rand. Struct. Algor. 3(2), 163–174 (1992). https://doi.org/10.1002/RSA.3240030206
16. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interactive proof systems. SIAM J. Comput. 18(1), 186–208 (1989)
18. Harrow, A., Montanaro, A.: Testing product states, quantum merlin-arthur games and tensor optimization. J. ACM (2013)
19. H˚astad, J., Impagliazzo, R., Levin, L.A., Luby, M.: A pseudorandom generator from any one-way function. SIAM J. Comput. 28(4), 1364–1396 (1999). https:// doi.org/10.1137/S0097539793244708
27. Koshiba, T., Odaira, T.: Non-interactive statistically-hiding quantum bit commit- ment from any quantum one-way function. arXiv:1102.3441 (2011). https://doi. org/10.48550/ARXIV.1102.3441
29. Lo, H.K., Chau, H.F.: Is quantum bit commitment really possible? Phys. Rev. Lett. (1997)
31. Mayers, D.: Unconditionally secure quantum bit commitment is impossible. Phys. Rev. Lett. 78, 3414–3417 (1997)
37. Ostrovsky, R., Wigderson, A.: One-way fuctions are essential for non-trivial zero- knowledge. In: Second Israel Symposium on Theory of Computing Systems, ISTCS 1993, Natanya, Israel, 7–9 June 1993, Proceedings,  IEEE Computer Soci- ety (1993). https://doi.org/10.1109/ISTCS.1993.253489
38. Qian, L.: Unconditionally secure quantum commitments with preprocessing (2023). Private communication
39. Rastegin, A.E.: Trace distance from the viewpoint of quantum operation tech- niques. J. Phys. A: Math. Theor. 40(31), 9533–9549 (2007). https://doi.org/10. 1088/1751-8113/40/31/026
40. Uhlmann, A.: The “transition probability” in the state space of a *-algebra. Rep. Math. Phys. 9(2), 273–279 (1976) 92 T. Morimae et al.
42. Vadhan, S.: An unconditional study of computational zero knowledge. SIAM J. Comput. 36(4), 1160–1214 (2006)
43. Watrous, J.: Zero-knowledge against quantum attacks. SIAM J. Comput. 39(1), 25–58 (2009)
2. Applebaum, B., Brakerski, Z., Tsabary, R.: Perfect secure computation in two rounds. SIAM J. Comput. 50(1), 68–97 (2021). https://doi.org/10.1137/19M1272044
13. Chaum, D., Crépeau, C., Damgård, I.: Multiparty unconditionally secure protocols (extended abstract). In: Simon, J. (ed.) Proceedings of the 20th Annual ACM Symposium on Theory of Computing, May 2-4, 1988, Chicago, Illinois, USA,  ACM (1988). https://doi. org/10.1145/62212.62214
14. Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters, B.: Candidate indistin- guishability obfuscation and functional encryption for all circuits. In: FOCS (2013)
21. Jain, A., Lin, H., Sahai, A.: Indistinguishability obfuscation from well-founded assumptions. In: Khuller, S., Williams, V.V. (eds.) STOC ’21: 53rd Annual ACM SIGACT Symposium on Theory of Computing, Virtual Event, Italy, June 21-25, 2021,  ACM (2021). https://doi.org/10.1145/3406325.3451093
22. Long, D.L., Wigderson, A.: The discrete logarithm hides o(log n) bits. SIAM J. Comput. 17(2), 363–372 (1988). https://doi.org/10.1137/0217021
27. Sahai, A.: Non-malleable non-interactive zero knowledge and adaptive chosen-ciphertext security. In: 40th Annual Symposium on Foundations of Computer Science, FOCS ’99, 17-18 October, 1999, New York, NY, USA,  IEEE Computer Society (1999). https://doi.org/10.1109/SFFCS.1999.814628
28. Schnorr, C.: Security of allmost ALL discrete log bits. Electron. Colloquium Com- put. Complex. TR98-033 (1998). https://eccc.weizmann.ac.il/eccc-reports/1998/TR98-033/ index.html
29. Yao, A.C.C.: How to generate and exchange secrets. In: 27th Annual Symposium on Founda- tions of Computer Science (SFCS 1986),  (1986). https://doi.org/10.1109/SFCS. 1986.25
5. hσ is good with probability at least 1/2 over hσ ←Hℓ m. Proof: By Proposition A.3 and a Union Bound, a random hσ is good with probability at least 1 −2−log |S|+m+3 −2−ℓ+m−3 ≥1 2. We next claim that given a good hash function hσ, there exists a short program of size roughly log |S| that produce the string x. Claim
6. For any good hash function hσ ∈Hℓ m, there exists a program Π of length at most O(log ℓ) + ⌈log 1/px⌉ that, given hσ as input, outputs the string x within time O(ℓ3). Proof: Since hσ is good, and let s be an string ∈S such that hσ(s) = 0m. Note that if s can be produced using a short program, x can be generated by running M(1n, s), which adds |M| = c bits to the description and can be done in time tD(n). 22 Finally, we show how to produce s using linear algebra. Recall that the hash function hσ(x) is deﬁned to be Ax + b where σ = (A, b), A, b are a binary matrix and a binary vector. We can use the Gaussian Elimination algorithm to ﬁnd an vector v ∈{0, 1}ℓsuch that Av + b = 0m and a basis (b1, . . . , bd) for the kernel of A. Note that each y ∈h−1(0m) can be represented by a d-bit coordinate vector (under the basis (b1, . . . , bd) and with respect to the oﬀset vector v). So d ≤ℓ−m + 1 and s can also be represented a coordinate vector of ℓ−m + 1 bits (and let e denote this vector). We then use this fact to construct a program Π with length ≤4 log ℓ+ ℓ−m + O(1) bits to produce the string x. Π has the integers n, ℓ, the coordinate vector, and the code of M hardcoded (≤4 log ℓ+ ℓ−m + 1 + O(1) bits). On input a hash function description σ, it computes v and (b1, . . . , bd) using Gaussian Elimination and Gram Schmidt, and computes s = P i∈[d] bi · ei + v. Finally, Π outputs M1(1n, s). Notice that Π runs in time O(ℓ3) + tD(n) = O(tD(n)3) ≤t(n). Also notice that Π can be described by 4 log ℓ+ ℓ−m + 1 + O(1), and we ﬁx c to be the constant such that Π can be described using 4 log ℓ+ ℓ−m + c bits. Finally, we are ready to show that px ≤δ(n)2−pKt(x). Towards this, we will prove that pKt(x) ≤O(log ℓ) + ⌈log 1/px⌉ and the aforementioned inequality will follow if we set δ(n) = ℓO(1) = tD(n)O(1) to be a large polynomial. Consider any random string r ∈{0, 1}2n(ℓm+m), and we view r as r = σ1||σ2|| . . . ||σ2n where each σi is a description of a random hash function hσi ←Hℓ m. By Claim 5, with probability at least 1 −2−2n ≥2/3, there exists i ∈[2n] such that hσi is a good hash function. By Claim 6, there exists a program Π′ that on input hσi, outputs the string x. Thus, let Π be a program with the index i and Π′ hardcoded, and Π on input r simply outputs Π′(hσi). Note that Π can be implemented using O(log ℓ) + ⌈log 1/px⌉bits, and it terminates within time O(ℓ3). By picking γ(n) = O(n3), it follows that Π runs in O(ℓ3) ≤γ(ℓ) ≤γ(tD(n)) ≤t(n). 23
[Ajt96] Ajtai, M.: Generating hard instances of lattice problems (extended abstract). In: STOC,  ACM (1996)
[Bab86] Babai, L.: On lov´asz’lattice reduction and the nearest lattice point prob- lem. Combinatorica 6(1), 1–13 (1986)
[Bou21] Boudgoust, K.: Theoretical hardness of algebraically structured learn- ing with errors. Ph.D. thesis, Universite Rennes 1 (2021). https://tel. archives-ouvertes.fr/tel-03534254/document
[CDW21] Cramer, R., Ducas, L., Wesolowski, B.: Mildly short vectors in cyclotomic ideal lattices in quantum polynomial time. J. ACM (JACM) 68(2), 1–26 (2021)
[Con] Conrad, K.: The diﬀerent ideal. https://kconrad.math.uconn.edu/blurbs/ gradnumthy/diﬀerent.pdf. Accessed 16 Feb 2022
[HKJL+00] Hoﬀstein, J., Kaliski, B.S., Jr., Lieman, D.B., Robshaw, M.J.B., Yin, Y.L.: Secure user identiﬁcation based on constrained polynomials, 13 June 2000. US Patent 6,076,163. Filed 20 October 1997
[Lan02] Lang, S.: Algebra. Springer, Heidelberg (2002). https://doi.org/10.1007/ 978-1-4613-0041-0
[LS15] Langlois, A., Stehl´e, D.: Worst-case to average-case reductions for module lattices. Des. Codes Crypt. 75(3), 565–599 (2014). https://doi.org/10. 1007/s10623-014-9938-4
[Mar77] Marcus, D.A.: Number Fields, vol.
2. Springer, Heidelberg (1977). https://doi.org/10.1007/978-1-4684-9356-6
[PML21] Porter, C., Mendelsohn, A., Ling, C.: Subﬁeld algorithms for ideal- and module-SVP based on the decomposition group. arXiv preprint arXiv:2105.03219 (2021)
[SE94] Schnorr, C.-P., Euchner, M.: Lattice basis reduction: improved practical algorithms and solving subset sum problems. Math. Program. 66, 181– 199 (1994)
[Was82] Washington, L.C.: Introduction to Cyclotomic Fields, vol.
83. Springer, Berlin (1982). https://doi.org/10.1007/978-1-4684-0133-2
22. Brakerski, Z., Jain, A., Komargodski, I., Passel`egue, A., Wichs, D.: Non-trivial witness encryption and null-io from standard assumptions. In: SCN (2018)
23. Brakerski, Z., Vaikuntanathan, V.: Lattice-inspired broadcast encryption and suc- cinct ciphertext policy ABE. In: ITCS (2022)
28. Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters, B.: Candidate indistinguishability obfuscation and functional encryption for all circuits. In: FOCS (2013). http://eprint.iacr.org/
29. Gay, R., Pass, R.: Indistinguishability obfuscation from circular security. In: Pro- ceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, (2021)
33. Naor, M., Reingold, O.: Number-theoretic constructions of eﬃcient pseudo-random functions. In: 38th FOCS.  IEEE Computer Society Press (Oct 1997). https://doi.org/10.1109/SFCS.1997.646134
[Ajt96] Ajtai, M.: Generating hard instances of lattice problems (extended abstract). In: 28th ACM STOC,  ACM Press (1996)
[BK97] Babai, L., Kimmel, P.G.: Randomized simultaneous messages: solution of a problem of yao in communication complexity. In: Twelfth Annual IEEE Conference on Proceedings of Computational Complexity, (1997)
[BLV19] Boyle, E., LaVigne, R., Vaikuntanathan, V.: Adversarially robust property- preserving hash functions. In: Blum, A., (ed.) ITCS 2019, vol. 124, pp. 16:1–16:20. LIPIcs (2019)
[BZ82] Blokh, E.L., Zyablov, V.: Linear concatenated codes. Nauka (1982)
[DORS08] Dodis, Y., Ostrovsky, R., Reyzin, L., Smith, A.D.: Fuzzy extractors: how to generate strong keys from biometrics and other noisy data. SIAM J. Comput. 38(1), 97–139 (2008)
[GHK10] Guruswami, V., Hastad, J., Kopparty, S.: On the list-decodability of random linear codes. In: Schulman, L.J. (ed.) Proceedings of the 42nd ACM Sym- posium on Theory of Computing, STOC 2010, Cambridge, Massachusetts, USA, 5–8 June 2010,  ACM (2010)
[GR09] Guruswami, V., Rudra, A.: Better binary list decodable codes via multilevel concatenation. IEEE Trans. Inf. Theory 55(1), 19–26 (2009)
[IM98] Indyk, P., Motwani, R.: Approximate nearest neighbors: towards removing the curse of dimensionality. In: Vitter, J.S., (ed.) Proceedings of the Thirti- eth Annual ACM Symposium on the Theory of Computing, Dallas, Texas, USA, May 23–26, 1998,  ACM (1998)
[KOR00] Kushilevitz, E., Ostrovsky, R., Rabani, Y.: Eﬃcient search for approximate nearest neighbor in high dimensional spaces. SIAM J. Comput. 30(2), 457– 474 (2000)
[MNP07] Motwani, R., Naor, A., Panigrahy, R.: Lower bounds on locality sensitive hashing. SIAM J. Discret. Math. 21(4), 930–935 (2007)
[MNS08] Mironov, I., Naor, M., Segev, G.: Sketching in adversarial environments. In: Ladner, R.E., Dwork, C., (eds.) 40th ACM STOC,  ACM Press, May 2008
[NS96] Newman, I., Szegedym M.: Public versus private coin ﬂips in one round communication games (extended abstract). In: 28th ACM STOC,  ACM Press, May 1996
[OWZ11] O’Donnell, R., Wu, Y., Zhou, Y.: Optimal lower bounds for locality sensi- tive hashing (except when q is tiny). In: Chazelle, B. (ed.) Innovations in Computer Science - ICS 2011. Tsinghua University, Beijing, China, January 7–9, 2011. Proceedings,  Tsinghua University Press (2011)
[Pet60] Peterson, W.: Encoding and error-correction procedures for the Bose- Chaudhuri codes. IRE Trans. Inf. Theory 6(4), 459–470 (1960)
[RRR21] Reingold, O., Rothblum, G.N., Rothblum, R.D.: Constant-round interactive proofs for delegating computation. SIAM J. Comput. 50(3) (2021)
16. De Santis, A., Desmedt, Y., Frankel, Y., Yung, M.: How to share a function securely. In: 26th ACM STOC,  ACM Press, May 1994
19. Feldman, P.: A practical scheme for non-interactive veriﬁable secret sharing. In: 28th FOCS,  IEEE Computer Society Press, October 1987
27. Goldwasser, S., Micali, S., Rivest, R.L.: A digital signature scheme secure against adaptive chosen-message attacks. SIAM J. Comput. 17(2), 281–308 (1988)
33. Libert, B., Joye, M., Yung, M.: Born and raised distributively: fully distributed non-interactive adaptively-secure threshold signatures with short shares. In: Halld´orsson, M.M., Dolev, S. (eds.) 33rd ACM PODC,  ACM, July 2014
36. Shamir, A.: How to share a secret. Commun. Assoc. Comput. Mach. 22(11), 612– 613 (1979)
12. Berthomieu, J., Neiger, V., Safey El Din, M.: Faster change of order algorithm for Gröbner bases under shape and stability assumptions. In: Proceedings of the 2022 International Symposium on Symbolic and Algebraic Computation. pp. 409418 (2022)
14. Bosma, W., Cannon, J., Playoust, C.: The Magma algebra system, I. The User Language. J. Symbolic Comput. 24(3-4), 235265 (1997), http://dx.doi.org/10. 1006/jsco.1996.0125, computational algebra and number theory (London, 1993)
16. Buchberger, B.: A theoretical basis for the reduction of polynomials to canonical forms. ACM SIGSAM Bulletin 10(3), 1929 (1976)
17. Buchmann, J., Pyshkin, A., Weinmann, R.P.: A Zero-Dimensional Gröbner Basis for AES-128. In: Robshaw, M. (ed.) Fast Software Encryption. Lecture Notes in Computer Science, vol. 4047, pp. 7888. Springer Berlin Heidelberg, Berlin, Hei- delberg (2006)
20. Cantor, D.G., Kaltofen, E.: On Fast Multiplication of Polynomials over Arbitrary Algebras. Acta Informatica 28(7), 693701 (1991)
22. Cox, D., Little, J., OShea, D.: Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra. Springer Science & Business Media (2013)
23. Cox, D.A., Little, J.B., O'Shea, D.: Using Algebraic Geometry, Graduate Texts in Mathematics, vol. 185. Springer (1998). https://doi.org/10.1007/ 978-1-4757-6911-1
26. Eisenbud, D.: Commutative Algebra: With a View Toward Algebraic Geometry, vol. 150. Springer Science & Business Media (2013)
27. Faugère, J.C., Mou, C.: Sparse FGLM algorithms. Journal of Symbolic Computa- tion 80, 538569 (2017)
28. Faugère, Jean-Charles and Gaudry, Pierrick and Huot, Louise and Renault, Gué- naël: Sub-cubic change of ordering for Gröbner basis: a probabilistic approach. In: Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation. pp. 170177 (2014)
29. Faugère, Jean-Charles and Gianni, Patrizia and Lazard, Daniel and Mora, Teo: E cient computation of zero-dimensional Gröbner bases by change of ordering. Journal of Symbolic Computation 16(4), 329344 (1993)
30. Faugère, J.C.: A new e cient algorithm for computing Gröbner bases (F4). Journal of pure and applied algebra 139(1-3), 6188 (1999)
31. Faugère, J.C.: A new e cient algorithm for computing Gröbner bases without reduction to zero (F5). In: Proceedings of the 2002 international symposium on Symbolic and algebraic computation. pp. 7583 (2002)
34. Giorgi, P., Jeannerod, C.P., Villard, G.: On the Complexity of Polynomial Matrix Computations. In: Proceedings of the 2003 international symposium on Symbolic and algebraic computation. pp. 135142 (2003)
38. Hart, W.B.: Flint: Fast Library for Number Theory. Computeralgebra-Rundbrief: Vol. 49 (2011) 35
39. Hyun, S.G., Neiger, V., Schost, É.: Implementations of E cient Univariate Polyno- mial Matrix Algorithms and Application to Bivariate Resultants. In: Proceedings ISSAC 2019. pp. 235242. ACM (2019). https://doi.org/10.1145/3326229.3326272, https://github.com/vneiger/pml
43. Moenck, R.T.: Practical fast polynomial multiplication. In: Proceedings of the third ACM symposium on Symbolic and algebraic computation. pp. 136148 (1976)
44. Neiger, V., Schost, É.: Computing syzygies in nite dimension using fast linear alge- bra. J. Complex. 60, 101502 (2020). https://doi.org/10.1016/J.JCO.2020.101502, https://doi.org/10.1016/j.jco.2020.101502
45. Roy, A., Steiner, M.J., Trevisani, S.: Arion: Arithmetization-Oriented Permuta- tion and Hashing from Generalized Triangular Dynamical Systems (2023), https: //arxiv.org/abs/2303.04639
47. The PML team: PML: Polynomial Matrix Library (2023), version 0.3, https:// github.com/vneiger/pml
49. V. Shoup, et al.: NTL: A Library for Doing Number Theory. https://libntl.org/
50. Von Zur Gathen, J., Gerhard, J.: Modern Computer Algebra. Cambridge university press (2013) A Computing a Reduced Gröbner Basis for ⟨PG⟩ As noted at the end of Section 3.4, we do not generate the polynomial system PG directly in practice. Rather, we construct a related polynomial system iteratively while reducing as many monomials as possible along the way. More formally, for a polynomial h and an ordered sequence of polynomials H, we let Red(h, H) denote the operation of reducing h by H (according to a speci ed monomial order). That is, Red(h, H) is the remainder after performing multivariate division of h by H (see [22, Ch. 2, 3]). For a tuple of polynomials h = (h1, . . . , ht), we 36 write Red(h, H) = (Red(h1, H), . . . , Red(ht, H)). Now x a monomial order, and de ne z′ 0 = z0. We generate p′ i = (p′ i,1, . . . , p′ i,li) and the reduced states z′ i recursively as follows for 1 ≤i ≤r and 1 ≤j ≤li. p′ i,j = Red xαi,j i,j −Li,j(z′ i−1), {p′ 1 . . . , p′ i−1}  , z′ i = Red Gi(z′ i−1, xi), {p′ 1, . . . , p′ i}  , where Li,j is the polynomial from (3). Finally, we de ne g′ = Red [Gr(z′ r−1, xr)]1, {p1, . . . , pr}  , and write P ′ G = {p′ 1, . . . , p′ r, g′}. Since the construction of P ′ G only dirs from that of PG by reductions with generators in the ideal IG = ⟨PG⟩their ideals should, intuitively speaking, be identical. This intuition is con rmed by the following lemma. Lemma
6. For any xed monomial order we have IG = ⟨PG⟩= ⟨P ′ G⟩. Proof. For any polynomial h and polynomial sequence H, we can write the reduction operation as Red(h, H) = h + W, for some polynomial W ∈⟨H⟩. Since the Gi's used in the construction of p′ i and z′ i are polynomial functions, one can show by induction that p′ i,j ∈pi,j + ⟨{p1 . . . , pi−1}⟩, z′ i,j ∈zi,j + ⟨{p1, . . . , pi}⟩ (10) holds for all 1 ≤i ≤r and 1 ≤j ≤li. In particular, we have g′ ∈g + ⟨{p1, . . . , pr}⟩. Thus it is clear that PG and P ′ G generate the same polynomial ideal. ⊓⊔ The following result relates P ′ G and PG when Proposition 6 holds. Recall that we write d≤i = d1 · · · di, where di = deg(Gi). Proposition
9. Let PG satisfy the condition of Proposition
6. Then constructing P ′ G w.r.t. ≺G is also a FreeLunch system. Moreover, replacing g′ in P ′ G with g′/LC(g′) yields the unique reduced Gröbner basis for IG w.r.t. ≺G. Proof. By de nition of polynomial division, we have wt(LM(Red(h, H))) ≤ wt(LM(h)). Since LM(pi,j)′ cannot be reduced by {p′ 1 . . . , p′ i−1} under ≺G, it follows from (10) and the prior discussion that LM(p′ i,j) = LM(pi,j). For the similar statement on LM(g′), we note that the condition LM(g) = x d≤r 0 can only hold if for every i there exist a ji such that LM(zi,ji) = x d≤i 0 . By construction of ≺G, this monomial will not be reduced by {p′ 1 . . . , p′ i−1}. Again, it follows from (10) that LM(z′ i,ji) = x d≤i 0 . In particular, LM(g′) = LM(g), hence P ′ G is also a FreeLunch system. For the last assertion, one observes from the way pi,j only depends on the variables x0, x1, . . . , xi−1, xi,j that Red(p′ i,j, P ′ G \ {p′ i,j}) = Red(p′ i,j, {p1 . . . , pi−1}) , 37 holds for ≺G. Hence P ′ G is already fully reduced, and replacing g′ with g′/LC(g′) makes all polynomials monic. ⊓⊔ Remark
2. Recall from Proposition 2 that if H is a Gröbner basis for ⟨H⟩, then Red(h, H) does not depend on the order of the sequence H. It follows from Proposition 9 that if PG satis es the condition of Proposition 6, then the reduc- tions in the construction of p′ i,j, z′ i and g′ are independent of the order of the sequence {p1, . . . pi}, w.r.t. ≺G. Complexity of computing P ′ G. We are left with bounding the complexity of computing P ′ G, which will yield our estimate for the sysGen step. In the setting we will be interested in, this is expected to be dominated by the cost of applying the last round function Gr to compute g′, and its reduction by {p′ 1 . . . , p′ r}. Our insight is that the reductions involved in the sysGen process are cheaper than the reductions required in matGen, since the reductions are performed on a smaller Gröbner basis; but we do not have a proof for such a statement. However, it is possible to bound the cost of the multiplications performed on the state z′ r−1 when applying Gr. Let m denote the number of these multiplication, where we recall that m is typically small by design. We reduce by {p′ 1 . . . , p′ r} after each multiplication, and will assume that this reduction is negligible compared to the cost of the multiplications themselves. Thus we have m multiplications of multivariate polynomials of maximal degree d≤r in x0 and αi,j −1 in xi,j, for 1 ≤i ≤r, 1 ≤j ≤li. We can then use the Kronecker trick presented by Moenck [43, Section 3.4] to perform these multiplications in an e cient manner. In short, the Kronecker trick starts by transforming the multivariate polynomials to univariate polynomials. This allows us to perform the multiplication using an e cient univariate multiplication algorithm, before converting the result back to a multivariate polynomial. Moenck describes the algorithm and proves its correctness for any bound on the degree of each variable in both polynomials in the input of multiplication, but only gives a complexity estimate when all bounds are equal. It is, however, easy to verify that the complexity formula for the multivariate multiplication algorithm in our setting will be: ˜O(d≤r Y 1≤i≤r 1≤j≤li 2αi,j) , when applying either the Fast Fourier Transform, or Schönhage & Strassen's algorithm to perform the univariate multiplication [50, Chapter 8]. Repeating this m times yields our estimate for cost of multiplications in the sysGen step: ˜O(md≤r Y 1≤i≤r 1≤j≤li 2αi,j) . In comparison, recall that the polyDet step of our analysis is expected by Theorem 1 to require ˜O(d≤r( Y 1≤i≤r 1≤j≤li αi,j)ω) 38 operations in F. Thus, when m remains small, we do not expect the multiplica- tions in sysGen to be the bottleneck of the overall attack. Use in Experiments. We implemented the Kronecker trick for the experiments we ran with the Flint library [38], using the NTL library
[49] for the univariate multiplication; the mapping between int and NTL polynomial representations was performed by hand. The multivariate multiplications performed for experi- ments with Magma and SageMath used their own built-in functionalities. B Bypassing the rst rounds of Griffin The number of rounds that can be bypassed before we need to introduce x1 depends on the number of branches. For t ≥12 branches we can nd an easily computable set of input states that allows to bypass the rst three rounds of Griffin, so x1 only appears in the fourth round. We explain in detail how this can be done for t =
12. After that it will become clear that three rounds can also be bypassed for t ∈{16, 20, 24}, and how to determine how many rounds can be bypassed for t < 12. Denote the input state to Griffin as (a0x0 + b0, a1x0 + b1, a2x0 + b2, . . . , a10x0 + b10, 0). The ai and bj are constants in F that we now proceed to determine. Once the ai and bj are xed the variable x0 can be varied freely over F, generating a set of input states for the CICO problem that all have constant input to the x1/α function in the three rst rounds. Figure 6 illustrates the evolution of one of the chosen input states up to the start of round 3. The values of ai and bj in Figure 6 can be determined as follows. After the initial linear transformation before the rst round, all branches can be expressed as li(a)x0 + li(b) for 0 ≤i ≤11, where li(·) is a known linear combination. To get 0 on the branches indicated in Figure 6, the ai's and bj's need to satisfy the following linear equations l0(a) = 0 l0(b) = 0 l1(a) = 0 l1(b) = 0 l3(a) = 0 l3(b) = 0 l5(a) = 0 l5(b) = 0 l7(a) = 0 l7(b) = 0 l9(a) = 0 l9(b) = 0 l10(a) = 0 l10(b) = 0. With 0 on any two adjacent branches, the input to F will either be all 0, with F(0, 0, 0) being equal to a constant, or the output of F will be multiplied with 0, making sure the value on the branch remains
0. This ensures that the algebraic expressions on the branches stay linear in x0, a and b after the a ne transformation at the start of the second round. The need to have input 0 to x1/α and xα in the second round gives four more linear constraints 39 Fig. 6: Evolution of chosen set of input states to Griffin with 12 branches. Red values give conditions on the ai and bj such that the input of x1/α in the third round becomes a known constant independent of x0. 40 l17(a) = 0 l17(b) = 0 l18(a) = 0 l18(b) = 0, where the γi are known constants. Before the a ne transformation in the second round, most branches will have cubic polynomials in x0 as their values (the hi(x0) in Figure 6). These are again linearly mixed in the a ne transformation at the end of round two, producing the cubic polynomial h9(x0) = c3(a, b)x3 0 + c2(a, b)x2 0 + c1(a, b)x0 + c0(a, b) on the rst branch. We want to enforce that c3(a, b) = c2(a, b) = c1(a, b) = 0 such that the input to the x1/α function in round three becomes a known constant independent from x0. The expressions for the coe cients are cubic in the ai and bj, but note that all the polynomials hi(x0) for 0 ≤i ≤8 are made as products of linear factors as (li(a)x0 + li(b))(lj(a)x0 + lj(b))(lk(a)x0 + lk(b)), and that h9(x0) is a sum of these. By calculating the coe cients for the x3 0, x2 0, and x0 terms, we see that c3(a, b) is cubic in a, but does not contain b at all. Similarly, c2(a, b) is quadratic in a and linear in b and c1(a, b) is linear in a and quadratic in b. We can now use the 9 linear equations in a introduced above to eliminate a2, . . . , a10 from c3(a). This leaves c3 as c3(a0, a1), a cubic expression in a0 and a1. Next we x a1 to an arbitrary non-zero value (to avoid the trivial solution a0 = . . . = a10 = 0) and solve for c3(a0) = 0 using a root- nding algorithm for univariate polynomials. With a0 and a1 xed, all the other ai gets xed as well from the linear constraints from rounds 1 and 2. Once all ai have been found, c2(a, b) = 0 just becomes a linear equation in b. Using this linear equation together with the 9 from above, we can eliminate b1, . . . , b10 from the last coe cient c1(a, b). With all the ai xed, c1 then just becomes c1(b0), a quadratic expression in b0 and we easily solve c1(b0) =
0. This determines all the values for the bi. With the ai and bj now xed, we know that the input state from our chosen set will generate polynomials in x0 of degree 6α + 3 on the branches at the start of round
4. We can then start the basic attack from there, adapting the weighted order of the variables accordingly. When the number of xi-variables is reduced by 3 and with the degree of x0 bounded to 6α + 3 until the fourth round, the dimension of the Gröbner basis ideal becomes much smaller, which again reduces the overall attack complexity signi cantly. When there are more than 12 branches we can do the exact same trick as explained above. The only dirence is that there will be more values of ai and bj that can be chosen arbitrarily when solving for c3(a, b) = c2(a, b) = c1(a, b) =
0. When there are less than 12 branches, there is not enough degrees of freedom to make it through the third round. For t = 8 we can bypass the two rst rounds, so x1 only needs to be introduced in round 3, and for t = 3, 4 it is possible to bypass the rst round and introduce x1 in round 2. 41 C Solutions to the CICO problem with respect to Griffin In this section we give explicit solutions to the CICO problem related to a Griffin permutation whose characteristics are speci ed below. Everything dis- cussed here can be checked by the reviewers using the
3. Aragon, N., Gaborit, P., Hauteville, A., Tillich, J.: A new algorithm for solving the rank syndrome decoding problem. In: 2018 IEEE International Symposium on Information Theory, ISIT 2018, Vail, CO, USA, June 17–22, 2018, IEEE (2018). https://doi.org/10.1109/ISIT.2018.8437464
9. Bl¨aser, M., et al.: The alteq signature scheme: Algorithm speciﬁcations and sup- porting documentation (2023). https://pqcalteq.github.io/ALTEQ spec 2024.03. 05.pdf
12. B¨urgisser, P., Ikenmeyer, C.: Geometric complexity theory and tensor rank. CoRR abs/1011.1350 (2010). http://arxiv.org/abs/1011.1350
18. Couvreur, A., Debris-Alazard, T., Gaborit, P.: On the hardness of code equivalence problems in rank metric. CoRR abs/2011.04611 (2020). https://arxiv.org/abs/ 2011.04611
25. Fulman, J., Goldstein, L.: Stein’s method and the rank distribution of random matrices over ﬁnite ﬁelds. Ann. Probab. 43(3) (2015). https://doi.org/10.1214/ 13-aop889
26. Goldreich, O., Micali, S., Wigderson, A.: Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems. J. ACM 38(3), 690–728 (1991). https://doi.org/10.1145/116825.116852
27. Grochow, J.A., Qiao, Y.: On the complexity of isomorphism problems for tensors, groups, and polynomials I: tensor isomorphism-completeness. In: Lee, J.R. (ed.) 12th Innovations in Theoretical Computer Science Conference, ITCS 2021, January 6–8, 2021, Virtual Conference. LIPIcs, vol. 185, pp. 31:1–31:19. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2021). https://doi.org/10.4230/LIPICS.ITCS. 2021.31, https://doi.org/10.4230/LIPIcs.ITCS.2021.31
28. Grochow, J.A., Qiao, Y., Tang, G.: Average-case algorithms for testing isomor- phism of polynomials, algebras, and multilinear forms. In: Bl¨aser, M., Monmege, B. (eds.) 38th International Symposium on Theoretical Aspects of Computer Sci- ence, STACS 2021, March 16-19, 2021, Saarbr¨ucken, Germany (Virtual Confer- ence). LIPIcs, vol. 187, pp. 38:1–38:17. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2021). https://doi.org/10.4230/LIPICS.STACS.2021.38
29. H˚astad, J.: Tensor rank is NP-complete. J. Algorithms 11(4), 644–654 (1990). https://doi.org/10.1016/0196-6774(90)90014-6
30. Hillar, C.J., Lim, L.: Most tensor problems are NP-hard. J. ACM 60(6), 45:1–45:39 (2013). https://doi.org/10.1145/2512329
35. Leon, J.: Computing automorphism groups of error-correcting codes. IEEE Trans. Inf. Theory 28(3), 496–511 (1982)
46. Schaefer, M., Stefankovic, D.: The complexity of tensor rank. Theory Comput. Syst. 62(5), 1161–1174 (2018). https://doi.org/10.1007/S00224-017-9800-Y
1. SageMath code from
11. If the linear mapping defined by matrix M ∈Fk×k has the maximal branch number, then all entries of M are non-zero. Proof. Proof by contradiction. Assume M has zero entry. W.l.o.g., assume M1,1 =
0. Consider the vector x = (1, 0, . . . , 0) that is zero everywhere except the first coordinate. Then Mx is the first column of M, so wt(Mx) ≤k −1. The branch number of M is no more than wt(x) + wt(Mx) = k. Lemma
12. If the linear mapping defined by matrix M ∈Fk×k has the maximal branch number, then k < |F|. Proof. Proof by contradiction, assume k ≥|F|. Consider Mi,1/Mi,2 for all i ∈[k]. Their values lie in F \ {0} (Lemma 11). By the pigeonhole principle, there exist distinct i, j such that Mi,1/Mi,2 = Mj,1/Mj,2. Denote the ratio by c. Define vector x that is zero everywhere except x[1] = 1 and x[2] = −c. Then the i-th and j-th entry of Mx equal
0. The branch number of M is no more than wt(x) + wt(Mx) = k. For any I, J ⊆[k], the set LM I,J := x ∀i ∈I, x[i] = 0 ∧∀j ∈J, (Mx)[j] = 0 (17) is a linear subspace of Fk. Then for any I′ ⊇I and J′ ⊇J, dim LM I′,J′ ≤dim LM I,J, dim LM I′,J′ ≥dim LM I,J −|I′ \ I| −|J′ \ J|. (18) The first says adding constraints cannot increase the solution space dimension. The second says adding one constraint can decrease the solution space by at most 1. When the matrix M has the maximal branch number, the dimension of the solution space has a clean expression. Lemma
28. Equivalently, the MixColumns operation acts as four maximal-branch-number mixing maps being applied to each column of blocks separately. If we write the columns of layouts I′ and J as {I′ i}i∈[4] and {Ji}i∈[4] respectively, then MC(I′, J) is the product of the transition probabilities between the 4 columns under a maximal-branch-number mixing layer. MC(I′, J) = 4 Y i=1 trans-prob(I′ i, Ji) Now we have a way to compute the transition probabilities for AES mixing and random S-boxes, which means we can compute the distance of AES∗from pairwise independence using the powers of its transition matrix. The size of the transition matrix is (216 −1) × (216 −1), since it stores the probabilities between any pair of layouts. Raising this matrix to a power is not a trivial task even for today’s computing capabilities. A final optimization comes from the observation that the transition matrix has rank at most 54. Recall that trans-prob(Ii, Ji) only depends on free(Ii) + free(Ji). This means that knowing the Hamming weights (free(I′ i))i∈[4] and (free(Ji))i∈[4] is sufficient if one wishes to compute MC(I′, J). Let us denote the tuple (free(I′ i))i∈[4] as the compressed layout representation of layout I′. Since a compressed layout is defined by 4 weights in the range {0, . . . , 4}, there are at most 54 compressed layouts. For emphasis, we will refer to our original non-compressed definition of layouts as “full layouts”. The AES mixing transition matrix can now be expressed in terms of these compressed layouts, by first projecting a full layout to its compressed representation, computing applying the MixColumns operation to the compressed layout, and then expanding it to the full layout 35 representation. Formally, the transition matrix T can be written as T = SR · MC = SR · P · MCcompr · Pinv. The descriptions of the 3 new matrices are below:
1. Matrix P. Projects a layout to its compressed layout. In other words, a compressed layout will have probability mass equal to the total probability mass of the layouts it contains. Matrix P has size (216 −1) × 54.
2. Matrix MCcompr. Applies MixColumns to the compressed layout. We have seen above that the compressed layout description is sufficient to determine the transition probability. MCcompr is a 54 × 54 stochastic matrix.
3. Matrix Pinv. Expands the compressed layouts to the original layout space. In particular, the total probability mass of a compressed layout is evenly distributed to the layouts it contains. Matrix Pinv has size 54 × (216 −1). Now we can define the (216 −1) × 54 matrix FC := SR · P · MCcompr (which stands for Full-to- Compressed) and the 54×(216−1) matrix CF := Pinv (Compressed-to-Full). Our transition matrix T is then the product of these lower-rank matrices, which allows for more efficient computation of its powers. T r = (FC · CF)r = FC · (CF · FC)r−1 · CF = FC · CCr−1 · CF where CC := FC · CF is a 54 × 54 stochastic matrix (Compressed-to-Compressed). Dealing with precision errors. Our goal is to compute the statistical distance from the sta- tionary distribution up to a precision of at least 2−128. To avoid floating-point arithmetic errors, we only operate on multiples of the matrices with integer entries. Thus our calculations are exact and the final result is obtained by normalizing at the very end. This allows us to make sure that no precision errors accumulate throughout the intermediate steps of our computation. With the above set of optimizations, we are able to experimentally prove Theorem 6, Lemma 14, and complete Table 2. Lemma
14. The 3-round AES∗is 2−23.42-close to pairwise independent. C Implementation details for AES S-box composition To obtain the tighter total variation (TV) distance bounds of Table 3, we model the AES S-box (XOR-key followed by patched inversion over F2b) as a Markov chain over F28 \ {0}. The transition probabilities can be computed exactly by iterating over all 28 possible choices of the random key. Then we compute the powers of the (28 −1) × (28 −1) transition matrix and compute the largest TV distance from the uniform distribution over all 28 −1 = 255 possible starting states, which is at most the TV distance of distribution from uniform over F28 \ {0}, due to the convexity of the metric. 36 INV Repetitions r log2(TV distance to random S-box) 1 −0.99 2 −7.11 8 −29.39 11 −40.24 Table 3: Statistical distance upper bound of (AES S-box)⊗r from pairwise random S-box over F28 \ {0}. Similar to our AES∗implementation, we only store and operate on a scaled version of the transition matrix such that the entries are integers to avoid accumulating precision errors from floating-point operations. The final TV distance is normalized at the very end. A summary of our experimental results is in Table 3. D Approximating a random S-box via INV S-boxes In this section, we formally prove our claim that a random S-box over F2b can be approximated via the sequential composition of alternating AddRoundKey and INV S-box operations. Theorem
8. The sequential composition of O b · 22b · log(1/ϵ)  alternating AddRoundKey and INV S-box operations generates a permutation that is ϵ-close to t-wise independent over F2b (random S-box) for t < 2b −2. We do this by representing the above procedure as a random walk and bounding its mixing time using the comparison method of Diaconis and Saloff-Coste [DSC93]. The Markov chain M we consider is the graph over the alternating group A2b of even permutations of length 2b. Note that the number of states in this Markov chain is Θ((2b)!) = Θ(2b·2b). The generating set of this graph will be the set of permutations we can obtain via the composition of an AddRoundKey, an INV S-box, and another AddRoundKey operation (with possibly a different key). Namely, the generating set is the following: T = {π : x →INV(x + r1) + r2 | r1, r2 ∈F2b}. Obtaining mixing time bounds on M implies bounds on the number of INV S-boxes required to approximate a truly random S-box. This is because k steps of the random walk on M by following permutations σ1, . . . , σk are the same as composing k INV S-boxes: π = σk ◦· · · ◦σ1 =⇒π : x →INV  . . . INV  INV(x + r(1) 1 ) + r(1) 2 + r(2) 1  + r(2) 2 + . . .  + r(k) 2 = INV (. . . INV (INV(x + ρ1) + ρ2) + ρ3 + . . . ) + ρk. Where we used r(i) 1 , r(i) 2 to denote the random keys of permutation σi. 37 Representing permutations. For ease of notation, we will denote the permutation σ generated by adding key r1, applying the INV S-box, and adding key r2 using the pair r1, r2 in square brackets [r1, r2]. This is to avoid confusion with the transposition between elements r1 and r2. As a concrete example, the permutations σi defined in the previous paragraph would be denoted by [r(i) 1 , r(i) 2 ]. To denote the permutation one obtains after composing k + 1 AddRoundKey operations with k INV S-boxes, we write the keys of each AddRoundKey operation in the square brackets. In the example above, we would use the following notation to represent π = σk ◦· · · ◦σ1: π = [r(1) 1 , r(1) 2 + r(2) 1 , r(2) 2 + r(3) 1 , . . . , r(k) 2 ] = [ρ1, ρ2, . . . , ρk]. Prior work. The comparison method is used to relate the mixing time of two Markov chains M and M′, by constructing a flow between each edge of M′, using paths of M. In our case, this means constructing a transposition between 0 and i ∈F2b using AddRoundKey ◦INV ◦AddRoundKey. Our result can be seen as a generalization of a result of Carlitz [Car53, Zie13], which shows that we can construct a transposition (0, i) by composing degree-one polynomials and INV. Our result differs from this prior work in two ways: First, we only allow AddRoundKey operations, which is a subset of the degree-one polynomials (polynomials whose linear coefficient is equal to 1). Secondly, we give a bound on the number of AddRoundKey operations that one needs to compose to obtain a random transposition of the form (0, i). The main technical ingredient of this section is Lemma 15, which shows how to generate a transposition by alternating AddRoundKey and INV S-boxes. Lemma
15. For any α, β, γ ∈F2b such that αβ ̸= 1, α(β + 1) ̸= 1, and β ̸∈{0, 1}, we can generate the transposition  α + β αβ+1, α + β+1 αβ+α+1  using the following sequence of AddRoundKey and INV S-box operations [α, α, β, INV(γ) + 1, γ, INV(γ), γ, INV(γ), γ + 1, β + 1, α, α] . This construction can be easily adapted to give transpositions with a fixed element, i.e. (0, i) for non-zero i ∈F2b. Corollary
2. For any α, β, γ ∈F2b such that αβ ̸= 1, α(β + 1) ̸= 1, and β ̸∈{0, 1}, we can generate the transposition  0, β αβ+1 + β+1 αβ+α+1  using the following sequence of AddRoundKey and INV S-box operations  β αβ + 1, α, β, INV(γ) + 1, γ, INV(γ), γ, INV(γ), γ + 1, β + 1, α, β αβ + 1  . Proof. For any two x, y ∈F2b, x, y ̸= 0, we can obtain the transposition (0, x + y) by composing (x, y) with two AddRoundKey permutations ARKδ : z →z + δ as follows: (0, x + y) = ARKx ◦(x, y) ◦ARKx . Indeed (ARKx ◦(x, y) ◦ARKx)(0) = (ARKx ◦(x, y))(x) = ARKx(y) = x + y (ARKx ◦(x, y) ◦ARKx)(x + y) = (ARKx ◦(x, y))(y) = ARKx(x) = 0 (ARKx ◦(x, y) ◦ARKx)(z) = (ARKx ◦(x, y))(x + z) = ARKx(x + z) = z 38 where z is not equal to 0 or x + y, and thus x + z is not equal to x or y. Now note that composing two AddRoundKey operations gives another AddRoundKey operation with key equal to the sum of the two original round keys. Hence we add α + β αβ+1 to the first and last keys of the tuple of Lemma 15 and obtain the desired result. Before we proceed with the proof of Lemma 15, let us consider what transpositions we can create using the above construction by studying the distribution of β αβ+1 + β+1 αβ+α+1 over F2b. µ = β αβ + 1 + β + 1 αβ + α + 1 = β(αβ + α + 1) + (β + 1)(αβ + 1) (αβ + 1)(αβ + α + 1) = αβ2 + αβ + β + αβ2 + β + αβ + 1 (αβ + 1)(αβ + α + 1) = 1 (αβ + 1)(αβ + α + 1). We can see that µ is non-zero, hence we consider the distribution of its inverse for random valid α, β. Claim 1 below shows that any non-zero value of µ (except 1) appears 2b −4 times, whereas µ = 1 will appear roughly twice as often. We conclude that if we choose α, β at random, we will get (0, µ) with roughly uniform probability (up to a constant factor) for all non-zero µ ∈F2b. Claim
1. The number T(κ) of solutions α, β to the equation (αβ + 1)(αβ + α + 1) = κ that satisfy β ̸∈{0, 1}, and αβ ̸= 1, α(β + 1) ̸= 1 is T(κ) =      0 κ = 0 2 · 2b −4 κ = 1 2b −4 κ ̸∈{0, 1} . Proof. We first consider κ =
0. For the RHS to equal 0, either αβ = 1, or α(β + 1) = 1, which is not a valid parameter setting by our assumption. Thus, T(0) = 0. Set α =
0. Then for all 2b −2 valid values of β ∈F2b \ {0, 1}, we have that κ = 1. We now consider the case when α ̸=
0. If we expand the expression and divide by α2, we get that β(β + 1) = κ + α + 1 α2 . It is well known that the quadratic equation above has 2 solutions if the trace of the RHS is equal to 0, and no solutions otherwise. The trace of the RHS equals Tr κ + α + 1 α2  = Tr  κ α2  + Tr  1 α  + Tr  1 α2  = Tr  κ α2  . 39 Where the first equality follows from the linearity of trace and the second equality from the fact that Tr(x2) = Tr(x). The square is an injective map over F2b, and thus κ α2 obtains every value over F2b \ {0}. Since Tr(·) = 0 defines a subspace, the number of α’s the make the RHS have 0 trace is exactly 2b−1 −1 (we exclude zero, since κ α2 is never zero. All of these values are valid, except α = κ + 1, for κ ̸=
1. This is because even though Tr  κ (κ + 1)2  = Tr  1 κ + 1 + 1 (κ + 1)2  = 0, the RHS is equal to 0, and thus the two solutions to this equation are β = 0, 1, which are not valid. The remaining 2b−1 −2 values of α give 2 valid solutions for β, which means that all κ ̸∈{0, 1} have 2b −4 solutions for non-zero α. The case of κ = 1 has the 2b −2 solutions with α = 0 and 2 solutions for the 2b−1 −1 non-zero valid values of α. Thus T(1) = 2 · 2b −4. Our proof of Lemma 15 will follow from Claims 2 and
3. Note that Claim 2 is already enough to give us a bound on the number of operations required to simulate a random S-box. We use Claim 3 to get an improved comparison constant and get a better quantitative bound. A note on notation. In the proofs of Claims 2 and 3, we will make frequent use of the following notation when computing the image of x ∈F2b under the permutation [k1, . . . , kn]: x k1 −→x + k1 k2 −→INV(x + k1) + k2 k3 −→INV(INV(x + k1) + k2) + k3 . . . kn −→INV(. . . INV(INV(x + k1) + k2) . . . ) + kn. Observe that the first arrow only applies AddRoundKey with the key being k1 to the input, whereas the ith arrow (for i > 1) applies the INV operation and then AddRoundKey with ki as key. Claim
2. For any α, β ∈F2b such that αβ ̸= 1, α(β + 1) ̸= 1, and β ̸∈{0, 1}, we can generate the transposition  α + β αβ+1, α + β+1 αβ+α+1  using the following sequence of AddRoundKey and INV S- box operations [α, α, β, 1, 1, β + 1, α, α] . Proof. Denote the permutation defined by the sequence of the statement by π. Our proof will proceed as follows:
1. Prove the statement for α = 0.
2. Prove the general statement (a) Assume that no input to INV(·) is equal to zero. Thus all intermediate values we obtain during our calculations will be denoted by rational expressions. (b) Consider the cases when we compute the inverse of a zero value separately. 40 Case
1. α = 0: We will show that the sequence [0, 0, β, 1, 1, β+1, 0, 0] generates the transposition (β, β + 1). We consider first the application of π on some x that is not equal to β or β + 1. x 0−→x 0−→INV(x) β−→x + β 1−→ 1 x + β + 1 = x + β + 1 x + β 1−→ x + β x + β + 1 + 1 = 1 x + β + 1 β+1 −−→x 0−→INV(x) 0−→x. Now consider what happens when x = β: β 0−→β 0−→INV(β) β−→0 1−→1 1−→0 β+1 −−→β + 1 0−→INV(β + 1) 0−→β + 1. And when x = β + 1: β + 1 0−→β + 1 0−→INV(β + 1) β−→1 1−→0 1−→1 β+1 −−→β 0−→INV(β) 0−→β. Case 2: We will now prove the result for all valid parameters α ̸= 0, β and inputs x that do not make an input to INV(·) to vanish. Thus, for these calculations, we will use the fact that y · INV(y) = 1 for all non-zero y. Also for brevity, we will use INV(y) and 1 y interchangeably. x α−→x + α α−→ 1 x + α + α = αx + α2 + 1 x + α β−→ x + α αx + α2 + 1 + β = (αβ + 1)x + α2β + β + α αx + α2 + 1 1−→ αx + α2 + 1 (αβ + 1)x + α2β + β + α + 1 = (αβ + α + 1)x + α2β + β + α + α2 + 1 (αβ + 1)x + α2β + β + α 1−→ (αβ + 1)x + α2β + β + α (αβ + α + 1)x + α2β + β + α + α2 + 1 + 1 = αx + α2 + 1 (αβ + α + 1)x + α2β + β + α + α2 + 1 β+1 −−→(αβ + α + 1)x + α2β + β + α + α2 + 1 αx + α2 + 1 + β + 1 = x + α αx + α2 + 1 α−→αx + α2 + 1 x + α + α = 1 x + α α−→x + α + α = x So we have seen that for α, β, x such that no input to INV(·) is zero, π acts like the identity and maps x to itself. To complete our proof, we now consider what happens if some input to INV(·) equals
0. This happens when one of the following equalities hold: (a) x + α = 0 =⇒x = α. (b) αx + α2 + 1 = 0 =⇒αx = α2 + 1 =⇒x = α + 1 α, since the equality doesn’t hold if α = 0. 41 (c) (αβ + 1)x + α2β + β + α = 0 =⇒x = α + β αβ+1, since we have imposed that αβ ̸= 1. (d) (αβ + α + 1)x + α2β + β + α + α2 + 1 = 0 =⇒x = α + β+1 αβ+α+1, since we have imposed that α(β + 1) ̸= 1. Note that the third and fourth cases are the claimed non-fixed points of π. Looking forward, we will verify that π transposes these two inputs. Case 2(a). x = α ̸= 0: The permutation π maps α to itself as we show below: α α−→α + α = 0 α−→0 + α = α β−→1 α + β = αβ + 1 α 1−→ α αβ + 1 + 1 = αβ + α + 1 αβ + 1 1−→ αβ + 1 αβ + α + 1 + 1 = α αβ + α + 1 β+1 −−→αβ + α + 1 α + β + 1 = 1 α α−→α + α = 0 α−→0 + α = α Note that in all the above computations, we have only evaluated INV(·) at the values α, αβ + 1, and αβ + α + 1, which are non-zero. Case 2(b). x = α + 1 α: The permutation π maps α + 1 α to itself as we show below: α + 1 α α−→α + 1 α + α = 1 α α−→α + α = 0 β−→0 + β = β 1−→1 β + 1 = β + 1 β 1−→ β β + 1 + 1 = 1 β + 1 β+1 −−→0 α−→α α−→1 α + α 42 Note that in all the above computations, we have only evaluated INV(·) at the values α, β, and β + 1, which are non-zero. Case 2(c). x = α + β αβ+1: The permutation π maps α + β αβ+1 to α + β+1 αβ+α+1 as we show below: α + β αβ + 1 α−→α + β αβ + 1 + α = β αβ + 1 α−→αβ + 1 β + α = 1 β β−→β + β = 0 1−→0 + 1 = 1 1−→1 + 1 = 0 β+1 −−→0 + β + 1 = β + 1 α−→ 1 β + 1 + α = αβ + α + 1 β + 1 α−→ β + 1 αβ + α + 1 + α Note that in all the above computations, we have only evaluated INV(·) at the values αβ + 1, αβ + α + 1, β, and β + 1, which are non-zero. 43 Case 2(d). x = α + β+1 αβ+α+1: The permutation π maps α + β+1 αβ+α+1 to α + β αβ+1 as we show below: α + β + 1 αβ + α + 1 α−→α + β + 1 αβ + α + 1 + α = β + 1 αβ + α + 1 α−→αβ + α + 1 β + 1 + α = 1 β + 1 β−→β + 1 + β = 1 1−→1 + 1 = 0 1−→0 + 1 = 1 β+1 −−→1 + β + 1 = β α−→1 β + α = αβ + 1 β α−→ β αβ + 1 + α Note that in all the above computations, we have only evaluated INV(·) at the values αβ + 1, αβ + α + 1, β, and β + 1, which are non-zero. Claim
3. The following two sequences of AddRoundKey and INV S-box operations implement the same permutations [1, 1] ≡[INV(γ) + 1, γ, INV(γ), γ, INV(γ), γ + 1] Proof. Denote by πLHS, πRHS as the permutations of the LHS and RHS respectively. Then πLHS maps x →INV(x + 1) +
1. We will show that this is the case of πRHS. For simplicity, we will first compute the image of x under πRHS, assuming that no input to INV(·) is equal to zero. Thus, we will use the fact that y · INV(y) = 1 for all non-zero y. Also for brevity, we will use INV(y) and 1 y interchangeably. x INV(γ)+1 −−−−−−→x + 1 γ + 1 = xγ + γ + 1 γ γ−→ γ xγ + γ + 1 + γ = xγ2 + γ2 xγ + γ + 1 INV(γ) −−−−→xγ + γ + 1 xγ2 + γ2 + 1 γ = 1 xγ2 + γ2 γ−→xγ2 + γ2 + γ INV(γ) −−−−→ 1 xγ2 + γ2 + γ + 1 γ = xγ + γ xγ2 + γ2 + γ = x + 1 xγ + γ + 1 γ+1 −−→xγ + γ + 1 x + 1 + γ + 1 = xγ + γ + 1 + (xγ + x) + (γ + 1) x + 1 = x x + 1 = INV(x + 1) + 1 44 To complete our proof, we now consider what happens if some input to INV(·) equals
0. Thus, we will consider the following cases separately:
1. γ = 0,
2. xγ + γ + 1 = 0 =⇒x = γ+1 γ
3. xγ2 + γ2 = 0 =⇒x = 1
4. x + 1 = 0 =⇒x = 1. Case
1. γ = 0: For γ = 0, πRHS becomes the permutation denoted by [1, 0, 0, 0, 0, 1]. This permutation maps x 1−→x + 1 0−→INV(x + 1) 0−→x + 1 0−→INV(x + 1) 0−→x + 1 1−→INV(x + 1) + 1. Note that in the above expression, we only used the fact that INV(INV(y)) = y, which holds for all y. Hence the above mapping holds for all x. Case
2. x = γ+1 γ : For simplicity we will assume that γ ̸= 0, as this case was already covered above. This allows us to replace INV(γ) + 1 with 1 γ + 1 = γ+1 γ . The permutation πRHS maps γ+1 γ to γ + 1 γ INV(γ)+1 −−−−−−→γ + 1 γ + γ + 1 γ = 0 γ−→0 + γ = γ INV(γ) −−−−→INV(γ) + INV(γ) = 0 γ−→0 + γ = γ INV(γ) −−−−→INV(γ) + INV(γ) = 0 γ+1 −−→0 + γ + 1 = γ + 1. Note that INV(x + 1) + 1 = INV γ + 1 γ + 1  + 1 = INV 1 γ  + 1 = γ + 1. Thus πRHS maps this value of x to the same image as the [1, 1] permutation. Case
3. x = 1: For simplicity we will assume that γ ̸= 0, as this case was already covered above. This allows us to replace INV(γ) + 1 with 1 γ + 1 = γ+1 γ . The permutation πRHS maps γ+1 γ 45 to 1 INV(γ)+1 −−−−−−→1 + INV(γ) + 1 = INV(γ) γ−→γ + γ = 0 INV(γ) −−−−→0 + INV(γ) = INV(γ) γ−→γ + γ = 0 INV(γ) −−−−→0 + INV(γ) = INV(γ) γ+1 −−→γ + γ + 1 = 1. Again, INV(1 + 1) + 1 = 1, thus πRHS maps x = 1 to the same image as the [1, 1] permutation. Comparison method. Now we will employ the comparison method to obtain mixing time bounds on our Markov chain M with respect to the mixing time of the random walk of the Markov chain M′ on the Cayley graph generated by the transpositions of the form (0, y) for non-zero y. We start with a short overview of the comparison method, partially taken verbatim from [DGJM06]. Suppose that M is an ergodic Markov chain on state space Ωwith transition matrix P and stationary distribution π, and that M′ is another ergodic Markov chain on the same state space with transition matrix P ′ and stationary distribution π′. For every edge (x, y) of M′, let Px,y be the set of paths from x to y using transitions of M. More formally, let Px,y be the set of paths γ = (x = x0, x1, . . . , xk = y) such that each (xi, xi+1) is in M. We write |γ| to denote the length of path γ. So, for example, if γ = (x0, . . . , xk) we have |γ| = k. Let P = ∪(x,y) in M′Px,y. An (M, M′)-flow is a function f from P to the interval [0, 1] such that for every (x, y) in M′, X γ∈Px,y f(γ) = π′(x)P ′(x, y). The flow is said to be an odd (M, M′)-flow if it is supported by odd-length paths. That is, for every γ ∈P, either f(γ) = 0 or |γ| is odd. Let r((z, w), γ) be the number of times that the edge (z, w) appears on path γ. For every (z, w) in M, the congestion of edge (z, w) in the flow f is the quantity Az,w(f) = 1 π(z)P(z, w) X γ∈P:(z,w)∈γ r((z, w), γ) · |γ| · f(γ). The congestion of the flow is the quantity A(f) = max (z,w) in M Az,w(f). Having a flow between two Markov chains allows one to compare their mixing times. In partic- ular, 46 Theorem 9 (Theorem 8 of [DGJM06]). Suppose that M is a reversible ergodic Markov chain with stationary distribution π and that M′ is another reversible ergodic Markov chain with the same stationary distribution. Suppose that f is an odd (M, M′)-flow. Then, for any 0 < δ < 1 2, τx(M, ϵ) ≤A(f) τ(M′, δ) ln(1/2δ) + 1  ln 1 ϵπ(x). Proof of Theorem
8. We will construct an odd (M, M′)-flow with low congestion. In particular, we will use Corollary 2 to construct for every edge (σ, (0, y)◦σ) of M′ a set of paths Pσ,(0,y)◦σ using transitions of M. We want the total flow through these paths to be equal to π′(σ)·P ′(σ, (0, y)◦σ). Since the stationary distribution of M′ is the uniform distribution, and each edge is chosen with the same probability, the total flow through each edge has to be the same. Thus for simplicity, we will denote by C the value of π′(x)P ′(x, y) for all edges (x, y) of M′. Our paths will be constructed as in Corollary
2. In particular, for every α, β, γ ∈F2b such that αβ ̸= 1, α(β + 1) ̸= 1, and β ̸∈{0, 1}, we will define Pσ,  0, β αβ+1 + β+1 αβ+α+1  ◦σ to include all paths of the form:  β αβ + 1, α, β, INV(γ) + 1, γ, INV(γ), γ, INV(γ), γ + 1, β + 1, α, β αβ + 1  . Recall that to construct these paths, we will use the edges of M as follows:  β αβ + 1, r1  ,  r′ 1, r2  , [r′ 2, r3], . . . ,  r′ 10, β αβ + 1  that satisfy r1 + r′ 1 = α, r2 + r′ 2 = β, r3 + r′ 3 = INV(γ) + 1, and so on. Thus, our paths are parametrized by 3 variables α, β, γ, and 10 ‘auxiliary’ variables r1, . . . , r10. Thus |P| = Θ 213b , and Claim 1 shows that each edge (x, y) of M′ will be satisfied roughly the same number of times as the other edges of M′ (up to a small constant factor). Since M′ has Θ(2b) edges |Px,y| = Θ 212b . Additionally, all paths have lengths of exactly 11 edges. If we push the same amount of flow through each such path, Claim 1 implies that all edges will get the same total amount of flow, except the edges of the form (σ, (0, 1) ◦σ), which will receive roughly twice as much flow. Thus we will reduce the flow through these paths accordingly to get the same total flow as the rest of the edges. Note that 2·2b−4 2b−4 ≤3 for b ≥3, and thus there exists some flow value f∗such that f∗≤f(γ) ≤3f∗for all γ ∈P. The total flow equality then gives X γ∈Px,y f(γ) = π′(x)P ′(x, y) =⇒|Px,y| · Θ (f∗) = C =⇒Θ  212bf∗ = C =⇒f∗= Θ  C · 2−12b . We will now bound the number of paths γ ∈P that use some edge (z, w) of M. We will show that due to the way we constructed our paths, (z, w) is only used by Θ(211b) paths. First, we show in Claim 4 that M has no parallel edges, thus the edge (z, w) specifies a specific transition [s, t] in M. 47 As an example, let’s consider the number of paths γ that have (z, w) as their second edge. From the structure of our paths, we know that r′ 1 = s and r2 = t. This specifies two equations that the parameters of a candidate path γ must satisfy to include edge (z, w). Since each path has 13 parameters, there are 11 remaining degrees of freedom, and each edge can be in a constant number (at most 11) of locations in a path, the total number of paths passing through any edge is at most Θ(211b). Now lets compute the congestion of edge (z, w) of M: Az,w(f) = 1 π(z)P(z, w) X γ∈P:(z,w)∈γ r((z, w), γ) · |γ| · f(γ) ≤ 11 π(z)P(z, w) X γ∈P:(z,w)∈γ r((z, w), γ) · f(γ) ≤ 112 π(z)P(z, w) X γ∈P:(z,w)∈γ f(γ) ≤ 3 · 112 π(z)P(z, w) · f∗· (# of paths (z, w) appears in) ≤ 3 · 112 π(z)P(z, w) · Θ  C 212b · 211b  = 3 · 112 π(z)P(z, w) · Θ π′(x)P ′(x, y) 2b  = Θ  P ′(x, y) P(z, w) · 2b  = Θ (1) . Where the last equality follows because the degree of M is Θ(22b), whereas the degree of M′ is Θ(2b). It follows from a result of Friedman [Fri00], that the spectral gap of M′ is Θ  1 2b  , and thus its mixing time is bounded by τ(M′, δ) = O  b · 22b + 2b · log(1/δ)  . We conclude that Theorem 9 for a small enough δ implies τ(M, ϵ) = O  b · 22b · log(1/ϵ)  . Claim
4. The Markov chain M does not have any parallel edges. Formally, if there exists σ ∈A2b such that ARKi ◦INV ◦ARKj ◦σ = ARKk ◦INV ◦ARKℓ◦σ, then (i, j) = (k, ℓ). 48 Proof. First, observe that if i = k, then the statement is true. Indeed, we can apply the permutation INV ◦ARKi to both sides and obtain ARKj ◦σ = ARKℓ◦σ =⇒j = ℓ. Similarly, if j = ℓ, then the statement also holds. Hence we proceed by considering the case when both i ̸= k, and j ̸= ℓ. Now choose an input x such that σ(x) ̸∈{j, ℓ}. Thus we can write the value of x on the two sides as a fraction: iy + ij + 1 y + j = ky + kℓ+ 1 y + ℓ =⇒iy2 + (ij + 1 + iℓ)y + ijℓ+ ℓ= ky2 + (kℓ+ 1 + kj)y + jkℓ+ j. For the above equality to be true for more than 2 values of y, it must hold that i = k. This concludes the proof. 49
2. Benedetti, V., Manivel, L., Tanturri, F.: The geometry of the Coble cubic and orbital degeneracy loci. Mathe. Ann. 379(1–2), 415–440 (2021)
9. Carlitz, L.: Representations by quadratic forms in a ﬁnite ﬁeld (1954)
14. Goldreich, O., Micali, S., Wigderson, A.: Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems. J. ACM 38(3), 691–729 (1991)
15. Grochow, J.A., Qiao, Y.: On the complexity of isomorphism problems for ten- sors, groups, and polynomials I: tensor isomorphism-completeness. In: 12th Innova- tions in Theoretical Computer Science Conference (ITCS 2021). Schloss Dagstuhl- Leibniz-Zentrum f¨ur Informatik (2021)
16. Gruson, L., Sam, S.V.: Alternating trilinear forms on a nine-dimensional space and degenerations of (3,3)-polarized Abelian surfaces. Proc. London Math. Soc. 110(3), 755–785 (2015)
17. Gruson, L., Sam, S.V., Weyman, J.: Moduli of Abelian varieties, Vinberg θ-groups, and free resolutions. In: Peeva, I. (ed.) Commutative Algebra: Expository Papers Dedicated to David Eisenbud on the Occasion of His 65th Birthday, Springer, New York (2013). https://doi.org/10.1007/978-1-4614-5292-8 13
18. Hora, J., Pudl´ak, P.: Classiﬁcation of 8-dimensional trilinear alternating forms over GF(2). Comm. Algebra 43(8), 3459–3471 (2015)
19. Hora, J., Pudl´ak, P.: Classiﬁcation of 9-dimensional trilinear alternating forms over GF(2). Finite Fields Appl. 70, 101788 (2021)
23. Rains, E., Sam, S.: Invariant theory of 3(9) and genus-2 curves. Algebra Number Theory 12(4), 935–957 (2018)
24. Sutherland, A.: Isogeny volcanoes. Open Book Ser. 1(1), 507–530 (2013)
26. Tang, G., Qiao, Y., Grochow, J.A.: Average-case algorithms for testing isomor- phism of polynomials, algebras, and multilinear forms. J. Groups Complex. Cryp- tol. 14 (2022)
14. Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters, B.: Candidate indistinguishability obfuscation and functional encryption for all circuits. In: 54th FOCS,  IEEE Computer Society Press (2013). https://doi.org/10.1109/ FOCS.2013.13
21. Jain, A., Lin, H., Sahai, A.: Indistinguishability obfuscation from well-founded assumptions. In: Khuller, S., Williams, V.V. (eds.) 53rd ACM STOC, ACM Press (2021). https://doi.org/10.1145/3406325.3451093
9. Intermediate procedure T describing X. Claim 2 There exists a negligible ε such that for any distribution D over {0, 1}n, given k ←$ Gen(1λ) and x ←$ D, Pr [A∗ x ̸= Ak,x] ≤ε(λ). Claim 3 There exists a negligible ε such that for any distribution D over {0, 1}n, given k ←$ Gen(1λ) and x ←$ D, ∆((k, A∗ x), (k, Ak,x)) ≤ε(λ). Claim 4 Given k ←Gen(1λ), x1 ←$ {0, 1}n and x2 ←$ Samp(1λ) then ∆((k, A∗ x1), (k, A∗ x2)) = 0. Claim 5 Given k ←Gen(1λ), x1 ←$ {0, 1}n and x2 ←$ Samp(1λ) then ∆((k, fk(x1)), (k, fk(x2))) ≤ε(λ). Claim 6 ∃ε negligible s.t. for all GPPT adversaries A , given k ←$ Gen(1λ), Pr [A(k) →(x1, x2), x1, x2 ∈X, x1 ̸= x2, fk(x1) = fk(x2)] ≤ε(λ). Proof of Claim
1. By inspection Memb(x) returns 1 if and only if x ∈X and is a GPPT algorithm since both T is, as no GGM query is ever performed. Analogously by construction F : {0, 1}n →X, so Samp(1λ) always returns an element in X. Proof of Claim
10. Reduction A finding a linear relation among κ elements k. First of all we observe that inductively A can store a representation of each element in base k as initially ki = e⊤ i k, with ei being 1 in the i-th position and 0 elsewhere. Next, if A ever executes line 10, it returns a linear relation since b = 1 implies a⊤ 1 k = a⊤ 2 k and therefore (a1 −a2)⊤k. Finally, if line 10 is never executed, then E receives 1 from Oeq only when a1 ̸= a2, implying that A correctly simulates simultaneously the standard GGM and the generic group modeling Gκ. Thus in this case A∗ x = Ak,x. In conclusion, (A →⊥) ⇒A∗ x = Ak,x, therefore Pr  A(k) →v, v⊤k = 0  ≥Pr [A∗ x ̸= Ak,x] . Since finding linear relations on a vector of random group elements is equivalent to the discrete logarithm problem, we have that Pr [A∗ x ̸= Ak,x] is negligible. Proof of Claim
3. To simplify notation, the summations below are taken for all k0 ∈Gκ, A0 ∈Fm,κ q and x0 ∈{0, 1}n. ∆((k, A∗ x), (k, Ak,x)) = = 1 2 · X k0, A0 Pr  k = k0, A∗ k,x = A0  −Pr [k = k0, Ak,x = A0] ≤ X k0, A0, x0 1 2 Pr  A∗ k,x = A0 k = k0, x = x0  −Pr [Ak,x = A0|k = k0, x = x0] . . . · Pr [k = k0, x = x0] = X k0, x0 Pr [A∗ x ̸= Ak,x|k = k0, x = x0] · Pr [k = k0, x = x0] = Pr [A∗ x ̸= Ak,x] ≤ε where in last step we applied Claim 2 and in the third step we used the fact that X A0 1 2 Pr  A∗ k,x = A0 k = k0, x = x0  −Pr [Ak,x = A0|k = k0, x = x0] is equal to Pr [A∗ x ̸= Ak,x|k = k0, x = x0] because – If A∗ x0 = Ak0,x0 then the summation only contains terms that are 0, as A0 is either different or equal to both matrices. Thus the above sum is 0, and so is the probability of the two matrices being different when k = k0 and x = x0. – If A∗ x0 ̸= Ak0,x0 then the only non zero terms of the summation are those in which A0 is equal to either A∗ x0 or Ak0,x0. This yield only two terms both equal to 1/2, implying that the sum equals 1, and so does the probability of the two matrix being different when k = k0 and x = x0. Proof of Claim
4. We begin observing that k is independent from both x1 and x2, therefore ∆((k, A∗ x1), (k, A∗ x2)) = ∆(k, k) + ∆(A∗ x1, A∗ x2) = ∆(A∗ x1, A∗ x2). From the way we defined Samp, see Figure 9, there exists a random variable x3 uniformly distributed over {0, 1}n such that x2 = F(x3). Thus, since for each element z, F satisfy the identity A∗ z = A∗ F (z), we have that ∆(A∗ x1, A∗ x2) = ∆(A∗ x1, A∗ F (x3)) = ∆(A∗ x1, A∗ x3) = 0 where the last equation follows as x1 and x3 are both uniformly distributed. Proof of Claim
5. First of all we observe that ∆((k, fk(x1)), (k, fk(x2))) ≤∆((k, Ak,x1), (k, Ak,x2)) since the two distribution on the left hand can be obtained from those in the right hand through the map (k, A) 7→(k, A · k) where we use the fact that Ak,x·k = fk(x) by the way these matrices are defined. Next let z1, z2 be two random variables, with z1 ←$ {0, 1}n and z2 ←$ Samp(1λ). Applying the triangular inequality twice we get ∆((k, A∗ x1), (k, Ax2)) ≤∆((k, Ak,x1), (k, A∗ z1)) + ∆((k, A∗ z1), (k, A∗ z2)) + ∆((k, A∗ z2), (k, Ak,x2)) ≤2ε where we the first and last term are smaller than ε from Claim 3 and the central term is zero from Claim 4. Proof of Claim
11. Reduction A finding a linear relation among κ elements k. Let coll be the event that the condition at step 2 is not satisfied, i.e. the event in which A returns a valid collision, and equal be the event A∗ xb = Ak,xb for b ∈{0, 1}. If coll and ¬equal occurs, B finds a linear relation with probability 1, as observed in the proof of Claim
2. Conversely, if coll and equal we have that fk(xb) = Ak,xb · k = A∗ xb · k. fk(x1) = fk(x2) ⇒ A∗ x1k = A∗ x2k. Which implies that (A∗ x1 −A∗ x2) vanishes on k. Furthermore this is a non trivial relation since x1, x2 ∈X, x1 ̸= x2 ⇒ A∗ x1 ̸= A∗ x2 ⇒ A∗ x1 −A∗ x2 ̸= 0. We can thus conclude that if coll occurs, then A finds a a linear relation which implies that Pr
[coll] is negligible. A.2 Hard-Core Predicates Proof sketch of Theorem
1. We will revise the textbook proof of the result in [GL89], pointing out where necessary why it still applies in the setting of GPPT adversaries. Assume there exists a GPPT adversary A such that, given k ←$ Gen(1λ), x ←Samp(1λ), r ←$ {0, 1}n, with probability ε = poly(λ) Pr  A(k, fk(x), r) →b, b = x⊤r  ≥1 2 + ε The first step is proving the following claim Claim 1 There exists a set X0 ⊆X such that Pr [x ∈X0] ≥1/2 and for each x ∈X0 Pr  A(k, fk(x), r) →b, b = x⊤r  ≥1 2 + ε 2. Given this and conditioning on x ∈X0, we describe an adversary B that guesses through brute-force the value of ℓindependent hard-core predicate bits b1, . . . , bℓfor uniformly sampled r1, . . . , rℓ. These are expanded to 2ℓ−1 bits b′ i, r′ i by linearity, i.e. such that ∀S ⊆[ℓ], S ̸= ∅ r′ S = M j∈S rj, b′ S = M j∈S bj (1) up to mapping non-empty subsets of [ℓ] to integers in [2ℓ−1]. For each of its guess, B will try to extract the j-th bit of x by querying A on A(k, y, ej ⊕r′ i) →β′ i. If the initially guessed bits are correct, which will happen after at most 2m guesses, by linearity β′ i = x⊤r′ i. Thus A receives 2ℓ−1 pair-wise independent random guesses and, if it replies correctly then β′ i ⊕b′ i = x⊤(ej ⊕r′ i) ⊕x⊤r′ i = x⊤ej = xj Thus B will chose the majority bit among all the replies it gets from A as a candidate value for xi. Note each β′ i ⊕b′ i is correct with probability 1/2 + ε/2. Applying Chebyshev inequality, if 2ℓ−1 ≥2n ε2 , then the majority bit chosen by A is the wrong one with probability smaller than 1 2n. A union bound then implies that B obtain the right x with probability grater than 1/2. A full description of B appears in Figure 12 We remark that B runs in GPPT time since ℓ= O(log(λ)), and thus only O(poly(λ)) executions of A and fk(·) are performed. The only potentially ineffi- cient step is the check x∗∈X, which however can be computed in GPPT time by Lemma 1. B(k, y): 1 : Chose ℓsuch that 2ℓ−1 ≥2n ε2 2 : Sample r1, . . . , rℓ←$ {0, 1}n 3 : For (b1, . . . , bℓ) ∈{0, 1}ℓ: // Brute-force guess ℓhardcore bits 4 : For j ∈{1, . . . , n} 5 : Compute b′ i, r′ i for i ∈[2ℓ−1] as in Equation 1 6 : Get β′ i ←A(k, y, ej ⊕ri) 7 : Set x∗ j as the majority bit in {β′ i ⊕b′ i : i ∈[2ℓ−1]} 8 : If fk(x∗) = y and x∗∈X: Return x∗ 9 : Return ⊥// Abort if nothing was found Fig.
12. Reduction B executed in the hiding game of Fig. 2. A.3 Hiding VC Proof of Proposition
1. We begin observing that one implication is trivially true: Given a VC that is hiding with respect to the game ExpHide in Figure 1, then any adversary A executed in ExpHideVC, defined in Figure 2, also succeeds with negligible advantage. To this goal we describe B, executed in ExpHide that on input pp, executes A(pp) and forward its chosen vectors x0, x1 to the challenger. It then queries opening proofs Λj for all valid positions, i.e. all except for the i-th, the only one in which x0 and x1 are allowed to differ. Finally, it forwards (Λj)j̸=i to A and when A returns a bit, it output the same bit. Clearly B perfectly simulate the challenger defined in ExpHideVC and guesses correctly if and only if A does. Therefore Adv(A) = B. Regarding the converse we will build a sequence of hybrid games H0, . . . , Hn where in Hi the challenger commits to the first i entries of x0 and the remaining n −i entries of x1. In this way H0 is equivalent to ExpHideVC with β = 0 and Hn is equivalent to ExpHideVC with β =
1. In all hybrid games, opening queries for position j are only answered if x0 j = x1 j. To conclude, we will show that any GPPT adversary D, its advantage at distinguishing Hi−1 from Hi is negligible. We do this by describing a GPPT algorithm B that used D to win at the game ExpHideVC. A description of B appears in Figure 13. First of all we observe that conditioning on x0 i ̸= x1 i , A perfectly simulates Hi−1 if executed with challenge bit β = 0 and Hi otherwise. Next, we point out that the advantage of D when x0 i = x1 i is zero as the two games becomes B(pp) 1 : Run x0, x1 ←D(pp) 2 : If x0 i = x1 i : Return 1 // Abort the execution 3 : Compute and send to the challenger z0, z1 such that: 4 : z0 = (x0 1, . . . , x0 i−1, x0 i , x1 i+1, . . . , x1 n) 5 : z1 = (x0 1, . . . , x0 i−1, x1 i , x1 i+1, . . . , x1 n) 6 : On input (c, (Λj)j̸=i) from the challenger, forward D ←c 7 : When D queries j with x0 j = x1 j: 8 : Forward the right opening proof D ←Λj 9 : When b ←D: Return b Fig.
13. Reduction B using D to win at ExpHideVC. identical. Thus, calling eq the event x0 i = x1 i and eq its negation, Adv(D) = |Pr [D →0|Hi−1] −Pr [D →1|Hi]| ≤|Pr [D →0|Hi−1, eq] −Pr [D →0|Hi, eq]| + . . . + |Pr [D →0|Hi−1, eq] −Pr [D →0|Hi, eq]| = |Pr [B →0|β = 0] −Pr [B →0|β = 1]| ≤Adv(B). Thus Adv(D) is negligible, concluding the proof. A.4 Hiding VC to Signatures Proof of Proposition
2. Given an adversary A breaking unforgeability of the sig- nature scheme described in Fig. 3, we build in Figure 14 an adversary B playing against the (simpler) hiding game for Vector Commitment described in Fig. 2. We first state the following claim, where b is the challenge bit chosen by B’s challenger and forge the event 1 ←VC.Vfy(pp, c, x∗ k, k, Λ∗ k). Claim 1 Exists ε negligible such that Pr  forge, k = i, x∗ k ̸= x0 i b = 0  ≤ε. These claims implies the thesis since 2 · Adv(B) = |Pr [B →0 | b = 0] −Pr [B →0 | b = 1]| ≥Pr [B →0 | b = 0] ≥Pr  forge, k = i, x∗ k = x0 i b = 0  ≥Pr [forge, k = i | b = 0] −Pr  forge, k = i, x∗ k ̸= x0 i b = 0  ≥Pr [forge | b = 0, k = i] Pr [k = i | b = 0] −ε ≥Adv(A) · 1 n −ε B(pp): 1 : Guess the index A is going to forge, i ←$ [n] 2 : Sample x0 i , x1 i ←$ VC.M with x0 i ̸= x1 i 3 : For all j ̸= i: xj ←$ VC.M, and set x0 j ←xj, x1 j ←xj 4 : Query x0, x1 and wait for (c, (Λj)j̸=i) 5 : Run A(pp, c) 6 : When A queries j: 7 : If j = i: Return 1 // i.e. abort 8 : Else: A ←(xj, Λj) 9 : When A returns (k, x∗ k, Λ∗ k) 10 : If k ̸= i or 0 ←VC.Vfy(pp, c, x∗ k, k, Λ∗ k) or x∗ k = x1 i : 11 : Return 1 12 : Else: Return 0 Fig.
14. Reduction B executed in the hiding game of Fig. 2. where we used the fact that A has no information on i, thus Pr [k = i] = 1/n and forge is independent on k = i. Thus Adv(A) ≤2nAdv(B) + nε, that is negligible. Next we prove the Claim providing a reduction C that uses A to break position binding. The idea is that C can emulate the behavior of B when b = 0 until the final step. If the adversary manages to produce an opening to a message x∗ k for the right position k = i but with x∗ k ̸= x0 i , then C breaks position binding returning this opening for x∗ k, and the correct one he can generate for x0 i . A full description appears in Figure 15. By inspection C simulates B when b = 0 and x = x0 correctly. Note that there is no need to simulate x1 as when b = 0, A gets no information about it. Finally, if the condition at step 9 is executed, C breaks position binding correctly since x∗ k ̸= xi, 1 ←VC.Vfy(pp, c, x∗ k, k, Λ∗ k) and, by correctness, 1 ← VC.Vfy(pp, c, xi, i, Λi) with i = k. Hence Adv(C) = Pr  forge, k = i, x∗ k ̸= x0 i b = 0  . which proves the claim. A.5 Hard Subset Membership Problem Proof of Lemma
2. We will show the Lemma holds using the following claim which we prove later on Claim 1 Given bi ←$ {0, 1}, b∗ i ←$ {0, 1} and xi such that bi = 0 ⇒xi ←$ SampBad(1λ), bi = 1 ⇒xi, wi ←$ SampGood(1λ). C(pp): 1 : // Simulate B and its challenger 2 : Sample i ←$ [n] and x ←$ VC.Mn 3 : (c, aux) ←VC.Com(pp, x) 4 : Run A(pp, c) 5 : When A queries j: 6 : If j = i: Return ⊥ 7 : Else: πj ←VC.Open(pp, j, aux), A ←(xi, Λi) 8 : When A return (k, x∗ k, Λ∗ k) 9 : If k ̸= i and VC.Vfy(pp, c, x∗ k, k, Λk) and x∗ k ̸= xi: 10 : Λi ←VC.Open(pp, i, aux) 11 : Return (c, i, x∗ k, Λ∗ k, xi, Λi) 12 : Else: Return ⊥ Fig.
15. Reduction C breaking position binding. for i ∈[λ], then the distributions (x, b) and (x, b∗) are hard to distinguish, i.e. ∃ε negligible such that for all GPPT adversaries D Adv(D) = |Pr [D(x, b) →0] −Pr [D(x, b∗) →0]| ≤ε. Assuming the claim holds, let A be an adversary trying to solve λ hard subset membership challenges we can build a trivial distinguisher D that on input (x, c), executes A(x) →b′ and returns 0 if c = b′ and 1 otherwise. If D is executed with c = b, then the probability that it returns 0 is by definition Adv(A), where Adv(A) = Pr [A(x) →b′, b′ = b] . Conversely, if c = b∗then A has no information on b∗. Therefore its guess is independent from it and Pr [b′ = b∗] = 2−λ. In conclusion we have that Adv(D) = Adv(A) −1 2λ ⇒ Adv(A) ≤ 1 2λ + Adv(D) ≤ 1 2λ + ε(λ). which proves the Lemma. Proof of Claim
1. With the above notation we define the following hybrid dis- tributions σi = (x, b1, . . . , bi, b∗ i+1, . . . , b∗ λ) and claim that distinguishing σi−1 from σi is hard for all i, which implies the thesis. First of all, for notational convenience, we will call τi = (x, b1, . . . , bi−1, b∗ i+1, . . . , b∗ λ) which contains all the entries that σi−1 and σi have in common, so that up to reordering σi−1 = (τi, bi), σi = (τi, b∗ i ). Next we study the advantage of a given GPPT algorithm D distinguishing σi−1 from σi Adv(D) = |Pr [D(τi, bi) →0] −Pr [D(τi, b∗ i ) →0]| = 1 2 Pr [D(τi, 0) →0|bi = 0] + 1 2 Pr [D(τi, 1) →0|bi = 1] −1 4 Pr [D(τi, 0) →0|bi = 0] −1 4 Pr [D(τi, 1) →0|bi = 0] −1 4 Pr [D(τi, 0) →0|bi = 1] −1 4 Pr [D(τi, 1) →0|bi = 1] ≤ 1 4 · Pr [D(τi, 0) →0|bi = 0] −1 4 · Pr [D(τi, 0) →0|bi = 1] + + 1 4 · Pr [D(τi, 1) →0|bi = 0] −1 4 · Pr [D(τi, 1) →0|bi = 1] . where the second equation follow conditioning on all possible values of bi and b∗ i and observing that D on a fixed input does not depend on b∗ i (although it does depend on bi since xi depends on bi). Thus it suffice to show that this two terms are negligible. Toward this goal we build two adversaries B0 and B1, each trying to solve a single hard subset membership problem. Bβ(x) begins sampling bj, b∗ j and xj as in the claim statement for all j ̸= i. Then it calls xi = x and returns the bit it gets from D(τi, β) (note β is a constant value here). The probability that Bβ guesses correctly is then, calling b = bi the challenge bit it has to guess |Pr [Bβ(x) →0|b = 0] + Pr [Bβ(x) →0|b = 1]| = |Pr [D(τi, β) →0|b = 0] −Pr [D(τi, β) →0|b = 1]| By Definition 4 we have that the left hand side is smaller than a negligible ε for all β ∈{0, 1}, eventually implying that Adv(D) ≤ε/2. A.6 Preliminary Adversary Proof of Lemma
3. In order to provide a description of A, we begin by building a signature scheme given a NIZK whose message space has only one element. This will allow us to use the adversary B described in
[CFGG23] which, on an algebraic signature scheme with a single message, either produces a forgery or finds a linear relation among the group elements of the verification key. The idea is, given a NIZK for an hard subset membership problem, to set the verification key as the crs and a false statement x, and the signing key is the simulation trapdoor td. A signature for the only message 0 is then any proof π for x. In this way the signer can create a proof for x using the simulation trapdoor, while S.Setup(1λ): 1 : Sample (crs, td) ←S(1λ), x ←$ SampBad(1λ) 2 : Set vk ←(crs, x), sk ←td and Return (vk, sk) S.Sign(sk, 0): 1 : Return π ←S(td, x) S.Vfy(vk, 0, π): 1 : Return b ←V(crs, x, π) Fig.
16. Signature scheme from any NIZK for a hard subset membership problem. no adversary can provide a proof for x unless soundness does not hold. A full description of the scheme is presented in Fig. 16. Given this signature scheme, calling x = (Z, x′) ∈Gm × {0, 1}∗and crs = (Y, c′) ∈Gn × {0, 1}∗, we claim as in
[CFGG23] that Claim 1 There exists a GPPT adversary B such that, given V ≤Fn q and W ≤ Fm q containing respectively the discrete logarithm of Y and Z, either – B(V, W, vk) →(π, L), with π a valid forgery – B(V, W, vk) queries a signature for 0 and upon receiving a valid π, such that B(V, W, vk) →(⊥, L) ⇒ L ⪇V × W, (Y, Z) ∈L · G. Note that this adversary almost satisfies the property we wish A to have. However, when no forgery is found, it instead returns a linear relation among all the group elements in the verification key (Y, Z) and not only Y. This means that linear relations found could be trivial in Y. In order to refine this adversary we use a technique also introduced in [CFGG23]: The idea is to run B several times in a simulated environment with the real state- ment x and a fresh crs∗generated with a trapdoor td∗. In this simulation either A returns a bad L from which B can extract a linear relation among the elements of x, or for sufficiently many times L satisfies L ∩(Fn q × {z}) ⪇V × {z} If this is the case, then A executes B one last time with the real crs it receives and, if needed, replies to the signature query from B using its only simulation query. Since the space L satisfied the above property for sufficiently many iterations, it will likely be satisfied also in this last one. One issue with this approach is that z is not known to A, so testing L∩(Fn q × {z}) ⪇V × {z} might be hard. The next claim address this. Claim 2 Given V ≤Fn q , W ≤Fm q and L ≤V × W affine spaces and calling η2 : Fn q × Fm q →Fm q the projection on the second entry11, then for all z ∈W L ≤V × W, η2(L) = W ⇒ L ∩(Fn q × {z}) ⪇V × {z}. 11 i.e. η(x, y) = y. Typically projections are denoted with π, but we have to depart from this notation to avoid any confusion as π already denotes proofs. We are now ready to give a description of the adversary A parametrized by a polynomially bounded t, which appears in Fig. 17. Given this algorithm we break the proof that At is indeed the right algorithm for some t into the following claims. Claim 3 A is GPPT. Claim 4 For each step of the execution of A, calling x = (Z, x′) ∈Gm×{0, 1}∗, then Z ∈W · G. Claim 5 For any choice of t = poly(λ) Pr [A(V, crs, x) →⊥] ≤m + 1 t + 1 . These claims imply the thesis since A only uses the group efficiently and, setting t = (m + 1) · p(λ) −1, aborts with probability p(λ)−1. Finally, if it does not abort either it returns a proof π for x, which happens without performing any query since A ask for a proof if and only if B ask for a signature, or it outputs L with η2(L) = W. In this latter case, since z ∈W by Claim 4, Claim 2 implies that L ∩(Fn q × {z}) ⪇V × {z} where we used the fact that by Claim 1, A returns L ⊆V × W. Proof of Claim
2. By contradiction assume L ∩Fn q × {z} = V × {z}. Then for all (v, w) ∈V × W, since η2(L) = W there exists a point u ∈V such that (u, w) ∈L. Using the initial hypothesis we also have that (u, z), (v, z) ∈L ⇒ (u, w) + (v, z) −(u, z) ∈L ⇒ (v, w) ∈L. Hence V × W ≤L which is a contradiction as we assumed L ⪇V × W. Proof of Claim
3. Since t and m are polynomially bounded, it suffice to show that each individual line can be computed in GPPT time. This is evident for all commands with the exception of Line
3. That step however can be computed inefficiently, but with only polynomially many group operations. This is done first computing the conditional distribution of the exponents of the crs, conditioned to Y ∈V · G, sampling from this distribution (which take exponential space), and finally computing crs from the sampled exponents, which takes polynomially many group operations. Proof of Claim
4. We proceed by induction. Initially Z ∈W · G since W = Fm q . Next assume that until the i-th iteration of the outer for-loop, Z ∈W ·G. At the end of the loop either W ′ = W, implying that the thesis still holds, or W ′ ̸= W. In this second case W ′ = η2(L) with L being the output of B(V, W, crs∗, x). Since by hypothesis Y ∈V · G and Z ∈W · G, we have that (Y, Z) is contained in V ×W. Calling y, z the discrete logarithm respectively of Y and Z, we have that (y, z) ∈L ⇒ z = η2(y, z) ∈η2(L) = W ′ ⇒ Z ∈W ′ · G. At(V, crs, x): 1 : Initialize W ←Fm q the space of possible exponents for Z 2 : For j ∈{1, . . . , m + 1}: // Each execution tries to reduce dim W 3 : Set W ′ ←W an affine space storing information on x gathered later on 4 : For i ∈{1, . . . , t}: 5 : Sample (crs∗, td∗) ←S(1λ) with crs∗= (Y∗, c∗) and Y∗∈V · G 6 : Run B(V, W, crs∗, x) 7 : When B queries a signature for 0: 8 : Compute a simulated proof π ←S(td∗, x) and send it B ←π 9 : When B returns (π, L): 10 : If η2(L) ̸= W: Store the result W ′ ←η2(L) 11 : If W ′ ⪇W: Update W ′ ←W 12 : Else: Break the outer for-loop // Execute B one last time with the real crs 13 : Run B(V, W, crs, x) 14 : When B queries a signature for 0: 15 : Return query and on input π send B ←π 16 : When B returns (π, L) 17 : If π is a valid proof: Return π 18 : Elif η2(L) = W: Return L 19 : Else: Return ⊥ Fig.
17. Adversary At parametrized by t = poly(λ). Proof of Claim
5. We define J a random variable denoting the value index j has before terminating the outer loop by executing Line
12. Note that J is well defined since each time Line 12 is not executed, setting W ←W ′ reduces the dimension of W by 1 which can only happens at most m times. Next we define the event Ei,j as J ≥j and at the i-th iteration of the inner for loop, the condition of Line 10 is not satisfied. We further let Fail be the event A(V, crs, x) →⊥. Note that the events Ei,j are also well defined since either J < j or when J ≥j the inner loop is executed for all i. Next we observe that, for each j, the inner loop runs A with the same vector spaces (V, W) and equally distributed crs∗and x. Thus we have that Pr [Ei,j] is constant for all j, allowing us to define pj = Pr [E1,j] = . . . = Pr [Et,j] . Next, we observe that conditioning on J = j, Fail occurs if and only if B(V, W, crs, x) returns a vector space L satisfying η2(L) = W with crs following the same dis- tribution simulated in Line
3. Thus Pr [A(V, crs, x) →⊥| J = j] = 1 −pj In conclusion Pr [A(V, crs, x) →⊥] ≤ Xm+1 j=1 Pr [A(V, crs, x) →⊥| J = j] Pr [J = j] ≤ Xm+1 j=1 (1 −pj) Pr [E1,j ∧. . . ∧Et,j] ≤ Xm+1 j=1 (1 −pj) · pt j ≤ Xm+1 j=1 1 t + 1 ≤m + 1 t + 1 . where in the third step we used the fact that the events Ei,j for a fixed j are mutually independent and in the second to last step, we upper bound (1 −pj) · pt j ≤(t + 1)−1 since pj ∈[0, 1].
4. Bentov, I., Gabizon, A., Zuckerman, D.: Bitcoin beacon. CoRR abs/1605.04559 (2016). http://arxiv.org/abs/1605.04559
8. Chaum, D., Cr´epeau, C., Damg˚ard, I.: Multiparty unconditionally secure protocols (extended abstract). In: Simon, J. (ed.) Proceedings of the 20th Annual ACM Symposium on Theory of Computing,  ACM (1988). https://doi.org/10. 1145/62212.62214
15. Maurer, U.: Secure multi-party computation made simple. Discrete Appl. Math. 154(2), 370–381 (2006). https://doi.org/10.1016/j.dam.2005.03.020
16. Micali, S.: ALGORAND: the eﬃcient and democratic ledger. CoRR abs/1607.01341 (2016). http://arxiv.org/abs/1607.01341
17. Santha, M., Vazirani, U.V.: Generating quasi-random sequences from slightly- random sources (extended abstract). In: 25th Annual Symposium on Foundations of Computer Science,  IEEE Computer Society (1984). https://doi. org/10.1109/SFCS.1984.715945
1. Direct correspondences with Kevin Lewi and other members of the WhatsApp engineering team, 2022–2023
11. Casacuberta, S., Hesse, J., Lehmann, A.: SoK: oblivious pseudorandom functions. In: IEEE EuroS&P 2022. IEEE (2022)
12. Cathcart, W.: (2022). https://twitter.com/wcathcart/status/16006038264776171 52
14. Cohn-Gordon, K., Cremers, C., Dowling, B., Garratt, L., Stebila, D.: A formal security analysis of the signal messaging protocol. In: EuroS&P,  IEEE (2017)
18. Doussot, G., Lacharit´e, M.S., Schorn, E.: End-to-End Encrypted Backups Security Assessment (2021). https://research.nccgroup.com/wp-content/uploads/2021/10/ NCC Group WhatsApp E001000M Report 2021-10-27 v1.2.pdf
27. Novak, M.: Paul Manafort Learns That Encrypting Messages Doesn’t Matter If the Feds Have a Warrant to Search Your iCloud Account (2018). https://gizmodo. com/paul-manafort-learns-that-encrypting-messages-doesnt-ma-1826561511
28. Perrin, T.: The noise protocol framework. http://noiseprotocol.org/noise.html
29. R¨osler, P., Mainka, C., Schwenk, J.: More is less: on the end-to-end security of group chats in signal, whatsapp, and threema. In: EuroS&P,  IEEE (2018)
[4] Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval Ishai. Lightweight techniques for private heavy hitters. pages 762–776, 2021.
[9] Elette Boyle, Geoffroy Couteau, Niv Gilboa, and Yuval Ishai. Compressing vector ole. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 896–912, 2018.
[21] Benny Chor, Oded Goldreich, Eyal Kushilevitz, and Madhu Sudan. Private information retrieval. In Proceedings of IEEE 36th Annual Foundations of Computer Science, pages 41–50. IEEE, 1995.
[28] Jack Doerner and Abhi Shelat. Scaling oram for secure computation. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pages 523–535, 2017.
[31] Oded Goldreich, Shafi Goldwasser, and Silvio Micali. How to construct random functions. J. ACM, 33(4):792–807, August 1986.
[33] Russell Impagliazzo, Leonid A Levin, and Michael Luby. Pseudo-random generation from one-way functions. In Proceedings of the twenty-first annual ACM symposium on Theory of computing, pages 12–24, 1989.
[41] Rafail Ostrovsky and Victor Shoup. Private information storage (extended abstract). In STOC 1997, pages 294–303, 1997.
[45] Andrew Chi-Chih Yao. Theory and applications of trapdoor functions (extended abstract). In FOCS 1982, pages 80–91. 35
4. Aragon, N., et al.: BIKE: bit ﬂipping key encapsulation (2020)
8. Chen, C., et al.: NTRU algorithm speciﬁcations and supporting documentation (2019). https://ntru.org/f/ntru-20190330.pdf
12. Espitau, T., Fouque, P.A., G´erard, B., Tibouchi, M.: Side-channel attacks on BLISS lattice-based signatures: exploiting branch tracing against strongswan and elec- tromagnetic emanations in microcontrollers. In: Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, (2017)
15. Goldwasser, S., Kalai, Y.T., Peikert, C., Vaikuntanathan, V.: Robustness of the learning with errors assumption. In: ICS,  Tsinghua University Press, Beijing (2010)
16. Halderman, J.A., et al.: Lest we remember: cold-boot attacks on encryption keys. Commun. ACM 52(5), 91–98 (2009) Partial Key Exposure Attacks on BIKE, Rainbow and NTRU 375
22. Melchor, C.A., et al.: Hamming quasi-cyclic (HQC) (2020)
25. Polanco, R.V.: Cold boot attacks on post-quantum schemes. Ph.D. thesis, Royal Holloway. University of London (2019)
26. Prange, E.: The use of information sets in decoding cyclic codes. IRE Trans. Inf. Theory 8(5), 5–9 (1962)
28. Villanueva-Polanco, R.: Cold boot attacks on LUOV. Appl. Sci. 10(12), 4106 (2020). http://orcid.org/10.3390/app10124106
[21] is a hash-based one-time signature that is built on the Winternitz signature [31]. The latter is preferable to Lamport signatures [25], as it reduces the length of signatures and keys by signing the representa- tion of a message m ∈{0, 1}h in base w, for some w ∈N (WOTS+ with w = 2 is essentially Lamport signatures). The construction relies on a chaining func- tion ck, that is, a function that applies a second-preimage resistant, somewhat pseudorandom one-way function f for w −1 times to each secret key x: ck(x) =  x if k = 0 f(ck−1(x)) otherwise where f is a ﬁxed public function chosen at random from a family Fn := {f : {0, 1}n →{0, 1}n}. The chaining function c takes as input some randomness too, but we ignore it here for simplicity. The construction yields ℓ1 chains, where ℓ1 = ⌈h/ log w⌉, i.e., one chain per component of the representation of m in base w (denoted by [m]w from now on). Let mi be the ith component of [m]w: the ith component of the signature would be cmi(ski) (Fig. 2). 1 2( 1) ℓ ……….. 2( 2) 1( ℓ) 2( ℓ) 1( 1) 1( 2) ℓ 1 2 2 ℓ ℓ( 1) ℓ( 2) ℓ( ℓ) Given a message = 1, 2, … , ℓ Public key: ℓ 1 , ℓ 2 , … , ℓ ℓ The signature on ∈[0, −1] is: = For example: ℓ= 3, = 5, = , = , = The signature: , = = = Fig.
[24] observed that, if an adversary A is not able to correctly guess one of the hidden values in the chain, a forged signature implies that A has found a collision somewhere in the chain. An honest signer could easily recover the collision using its secret key, and use it as a proof that a more powerful machine generated the disputed signature: the signer being a PPT machine could not have broken collision-resistance. A necessary but not suﬃcient condition to prevent an unbounded adversary from recovering a preimage in the chain is that an evaluation y = ck(ski) statisti- cally hides ski (cf. Lemma 1), and that multiple choices of ski can correspond to the same y. However, this is not true when WOTS+ is instantiated with a standard hash function. In [24], the authors propose as workaround to change the chaining function to a compressing one-way function, and assume it to be a random oracle2 (so that the number of preimages is distributed in the same way as for random functions). Inspired by this approach, our FSS.WOTS (formally described in Protocol 1) relies on compressing hash functions. On the Use of Compressing, Tweakable Hash Functions (THF). In FSS.WOTS hash chains are built using compressing hash functions, so that even if an adversary recovers a possible sk∗, there is still a chance that it is not the preimage chosen by the honest signer. This technique increases the size of the sk by a compression factor 3 c, but the size is still linear in w. Modeling the secu- rity of this function requires some care. Usually, in the security experiment the adversary has oracle access to the function, thus it can query the evaluation of the function on any input x of its choice. This is not the case in the unforgeabil- ity game of WOTS+ (and, analogously, of FSS.WOTS): here the adversary can only choose the position in the chain that will be opened, not its input (which is given by the iterative application of the function on the secret key). In [7], they model the index of the chain as a tweak of the function: in the security game the input of the function is uniformly chosen (and diﬀerent for every chain), while the adversary can query the oracle on tweaks of its choice. To make sure that the public key hides the secret key one has to assume undetectability of the 2 This assumption is already present in SPHINCS+. Indeed, in
[24] implicitly assumed that the adversary cannot on average ﬁnd the right preimage of a point in the chain. However, we assume that hav- ing an unbounded adversary means that A can enumerate all preimages of a given point: assuming that ﬁnding a preimage is a probabilistic algorithm, the adversary can simply repeat it a logarithmic number of times to ﬁnd all of the preimages. This can be done for all the points in all of the chains. So, if there is even a single point in one chain with only one preimage, the adversary can ﬁnd it and break the FSS. Thus, we need to make sure that the probability that every point in every chain has only a single preimage is negligible, not just the expected probability of choosing the correct preimage over all of the points. Lemma 3 shows our analysis. Observe that even though the adversary 4 This is the speciﬁc choice for SPHINCS+. In general, we need |T | ≥wℓ. 126 C. Boschini et al. can enumerate all the preimages in the chains, it cannot win with overwhelming probability as long as the output of Th does not leak information about the preimage used by the signer. Lemma 3 (implicit in [24, Lemma 1]). Let f : {0, 1}n+δ →{0, 1}n, n ≫1, δ > 0 be chosen uniformly at random from the set of all functions from {0, 1}n+δ to {0, 1}n. Then, the probability that a point y in the image has strictly more than one preimage can be bounded as Pr[∃S ⊆{0, 1}n+δ, |S| > 1 : f(x) = y ∀x ∈S] ≥1 −2 exp(−2δ) . The proof is similar to [24], and can be found in the full version [9]. To use Lemma 3 in our analysis we still need the QROM assumption to ensure that the output of a tweakable hash function on a randomly sampled input is indistinguishable from random, even by a powerful adversary. Theorem 2 (Security for the Signer). If Th is a family of compressing THF then there exist a constant value for the compression factor c such that FSS.WOTS is ε-secure for the signer in the QROM for ε = 1/2. Proof. Let A be an adversary in Experiment
1. Then its success probability is Pr[Expss A,Σ(λs, λr) = 1] = Pr[σ∗= σ′ | σ′ ←Signsk(m∗)] (2) i.e., the adversary wins if it has guessed correctly all the ℓpreimages in σ∗. As we assume the adversary to be unbounded, if there is any unopened point in any chain that has exactly one preimage, then A is always successful (as inverting the hash on one chain is enough to generate a forgery). Lemma 3 combined with the observation that the outputs of c0,j(ski, i, Seed) are uniformly random and independent (by the QROM assumption on the construction of the THF from hash functions) yields that this happens with probability Pr[∃i ∈{1, . . . , ℓ}, j ∈{1, . . . , w −1} | c0,j(ski, i, Seed) has only one preimage] ≤ℓ(w −1)2 exp(−2c) (3) which for n = l = 128 and w = 16 (the usual choice for SPHINCS+) is already less than 2−81 for c =
5. We assume a very powerful (exponential-time) adversary able to break the security assumptions of the XMSS scheme with security parameter λr. Under this assumption, if XMSS uses a PRF with a key of size λr to generate the pri- vate keys, we assume that the attacker can recover the single possible Seedsk after seeing enough outputs and perfectly impersonate a honest signer. However, we assume that if we increase the size of the PRF’s key even by a small constant factor cs > 1, we make such a key recovery attack exponentially harder. Follow- ing Deﬁnition 5 with our PRF as the function f, we assume that with a when using a secret key of size cs · λr our adversary is unable to distinguish between the output of the PRF and random samples. To motivate our assumption, consider the generic classical brute force attack, with an attacker that runs in time O(2λr) and can enumerate all possible keys and ﬁnd the correct one. However, when we increase the key size to cs · λr, the attacker is required to run in time O(2cs·λr). Even for a quantum adversary, the runtime of the generic attack using Grover algorithm
[17] will increase exponen- tially from O(2 λr 2 ) to O(2 cs·λr 2 ).6 To conclude, we assume a powerful adversary, able to break at least one of the security assumptions of the XMSS scheme with non-negligible property for security parameter λr but that has only a negligible 6 Note that in a real-world instantiation of the PRF the function’s state size must be large enough to accommodate the entire Seedsk to avoid analogous exploits to [34]. That’s Not My Signature! Fail-Stop Signatures for a Post-quantum World 129 probability of breaking the security of our PRF when using a larger security parameter cs · λr; cs is treated as third security parameter, alongside λr and λs. 5.2 Construction of FSS.XMSS Let H = {Hi}i be a family of (compressing) THF, where Hi : P×T ×{0, 1}λr·i → {0, 1}λr. Analogously to XMSS, FSS.XMSS allows to sign N = 2h messages of l bits by combining N parallel instantiations of FSS.WOTS in a binary tree. Such tree is constructed using the THF H := H2. An internal state allows the signer to keep track of which keys have been already used. FSS.WOTS with Public Key Compression. As the public key pk of FSS.WOTS has a size linear in the length of the messages, in XMSS and FSS.XMSS it is compressed using a THF F := Hℓinto a n-bits long string lf. The {lfi}i constitutes the leaves of the binary tree. The secret keys of the var- ious FSS.WOTS instances are generated using the PRF PRF1 : {0, 1}csλr × T → {0, 1}λr+c(w−1) from a secret seed Seedsk and from the address adrs, and the chains are generated from the same seed Seedpk. We abuse the notation and give (Seedsk, Seed,pk , adrs) as input to the key generation of FSS.WOTS. Analogously, the FSS.WOTS veriﬁcation now also checks that the tops of the chains obtained from the signature hash to the correct value lfi. Diﬀerent public keys hashing to the same leaf constitute a valid proof of forgery for this modiﬁed FSS.WOTS. As XMSS is a stateful signature, the syntax of the FSS is adapted accordingly. The proof of forgery can be derived either from a collision on the tree, or as in FSS.WOTS, thus π contains a bit b that speciﬁes which case it is. Lemma 4 (Non-adaptive Unforgeability). If FSS.WOTS is an unforgeable FSS, PRF1 is a PRF, and H and F are SM-TCR secure THFs, then FSS.XMSS is unforgeable under non-adaptive CMA. Proof (sketch). Consider the following sequence of hybrid games: – H1 : this is the non-adaptive unforgeability experiment for FSS.XMSS. – H2 : Same as H1, but the sk’s are random strings instead of output by PRF1. – H3 : Same as H2, but the winning condition now excludes cases when the forgery contains a collision on the tree. – H4 : Same as H3, but the winning condition now excludes cases when the forgery contains a collision on a leaf. Clearly, distinguishing H1 from H2 requires distinguishing outputs of the PRF from random. To distinguish H2 from H3 (resp., H3 from H4), the adversary has to return a collision on the tree (resp., on a leaf). This happens only if A returns a forgery σ∗where the tree path is computed from a diﬀerent leaf than what was used to generate the root (resp., where the leaf is obtained hashing diﬀerent values than the FSS.WOTS key pki). This means that the FSS.WOTS signature in σ∗has to verify w.r.t. a key pk that was not among the ones generated by the challenger. Hence a successful distinguisher can be used to break the SM-TCR 130 C. Boschini et al. security of H (resp., of F). Finally, to win H4 Adv has only one option: forging a signature using one of the FSS.WOTS keys generated by the challenger. Thus winning H4 is essentially equivalent to breaking the unforgeability of FSS.WOTS. A tighter proof can be obtained not relying on the unforgeability of FSS.WOTS as a black-box, but by reducing to the security of Th following the same steps as in the proof of Lemma
[26] already provide an open framework for publicly logging and monitoring the issuance of digital certiﬁcates, oﬀering a comprehensive log ﬁle of all signed certiﬁcates for improved transparency and security. As mentioned above, for some signature schemes such as FORS and SPHINCS+, the adversary can target some “inter- leaved” combination of the previously signed digest values. The log ﬁle can also be used to prove forgery in this case, providing the set of honest messages that were “interleaved” to match the target forged digest. In case we do not want to log the signed message (as it might contain sensitive information or due to size constraints), we can slightly modify the hash phase of the signing process such that we will only need to store an intermediate randomized digest value of the message. Based on our ﬁne-grained assumption, we will use an intermediate strong hash function HASH′ : {0, 1}∗→{0, 1}cs·λr, this hash function as a larger digest and we assume that even our strong adversary can’t break it. Our modiﬁed signing process will be σ = SIGNsk(HASH(HASH′(R||M))). In our log ﬁle we will only need to store d′ = HASH′(R||M). Note that we assume that the adversary cannot ﬁnd a collision on d′, but it can ﬁnd a collision on d = HASH(HASH′(R||M)). cs Parallel Signatures: To avoid the log ﬁle requirement, we propose another solution that is based on the ﬁne-grained assumption of the adversary capabil- ities presented in Sect. 5.1. Recall that we assume that our (exponential-time) adversary can break the security assumptions of our scheme (including ITSR) for some security parameter λ. However, we assume this adversary is not powerful enough to break our security assumption of a larger security parameter cs · λ. To use this assumption, our FSS version will now include cs signatures (or ⌈cs⌉ if cs /∈Z). We use a variant of the method used in
8. Boneh, D., Bünz, B., Fisch, B.: A survey of two veriﬁable delay functions. Cryp- tology ePrint Archive, Report 2018/712 (2018), https://eprint.iacr.org/2018/712
15. Cohen, H., Lenstra, H.W.: Heuristics on class groups of number ﬁelds. In: Number Theory Noordwijkerhout 1983 (1984)
25. Feldman, P.: A practical scheme for non-interactive veriﬁable secret sharing. In: 28th FOCS.  IEEE Computer Society Press (October 1987). https:// doi.org/10.1109/SFCS.1987.4
35. Pietrzak, K.: Simple veriﬁable delay functions. In: Blum, A. (ed.) ITCS 2019. vol. 124, pp. 60:1–60:15. LIPIcs (Jan 2019). https://doi.org/10.4230/LIPIcs.ITCS.2019. 60
37. Shamir, A.: How to share a secret. Commun. Assoc. Comput. Mach. 22(11), 612– 613 (1979)
38. Tucker, I.: Chiﬀrement fonctionnel et signatures distribuées fondés sur des fonc- tions de hachage à projection, l’apport des groupes de classes. Ph.D. thesis, École normale supérieure de Lyon (2020)
[Bid+23] Bidoux, L., Chi-Dom´ınguez, J.-J., Feneuil, T., Gaborit, P., Joux, A., Rivain, M., Vin¸cotte, A.: RYDE: a digital signature scheme based on rank-syndrome-decoding problem with MPCitH paradigm (2023). arXiv: 2307.08726 [cs.CR]
[Duc+18] Ducas, L., Kiltz, E., Lepoint, T., Lyubashevsky, V., Schwabe, P., Seiler, G., Stehl´e, D.: CRYSTALS-Dilithium: a lattice-based digital signature scheme. IACR TCHES 2018(1), 238–268 (2018). https://doi.org/10.13154/tches. v2018.i1.238-268. https://tches.iacr.org/index.php/TCHES/article/view/ 839. issn: 2569-2925
[GGM84] Goldreich, O., Goldwasser, S., Micali, S.: How to construct random func- tions (extended abstract). In: 25th FOCS. IEEE Computer Society Press, October 1984. https://doi.org/10.1109/SFCS.1984.715949
[Ish+07] Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A.: Zero-knowledge from secure multiparty computation. In: Johnson, D.S., Feige, U. (eds.) 39th ACM STOC,  ACM Press, June 2007. https://doi.org/10.1145/ 1250790.1250794
[Lei18] Leichtle, D.: Post-quantum signatures from identiﬁcation schemes. Master’s thesis, Technische Universiteit Eindhoven (2018). https://pure.tue.nl/ws/ portalﬁles/portal/125545339/Dominik Leichtle thesis ﬁnal IAM 307.pdf
1. Choose n new unique message-IDs mid1, . . . , midn.
2. Initialize 2n new variables Dmid1 := DMAX mid1 . . . := Dmidn := DMAX midn := 1 and a per message- delay ∆midi = ∆for i ∈[n].
3. Set ⃗M := ⃗M ∥(m, mid1, Dmid1, P1) ∥. . . ∥(m, midn, Dmidn, Pn).
4. Send (diffuse, sid, m, Ps, (P1, mid1), . . . , (Pn, midn)) to the adversary.  Upon receiving (fetch, sid) from P ∈P, or from A on behalf of a corrupted party P:
1. For all tuples (m, mid, Dmid, P) ∈⃗M, set Dmid := Dmid −1.
2. Let ⃗M P 0 denote the subvector ⃗M including all tuples of the form (m, mid, Dmid, P) with Dmid ≤0 (in the same order as they appear in ⃗M). Delete all entries in ⃗M P 0 from ⃗M and in case some (m, mid, Dmid, P) is in ⃗M P 0 , where P is honest, set ∆mid′ = ∆for any (m, mid′, Dmid′, (·, sid)) in ⃗M and replace this record by (m, mid′, min{Dmid′, ∆}, P′).
3. Output ⃗M P 0 to P (if P is corrupted, send ⃗M P 0 to A). Additional adversarial capabilities:  Upon receiving (diffuse, sid, m) from some corrupted Ps ∈P (or from A on behalf of Ps if corrupted), execute it the same way as an honest-sender diffuse, with the only difference that ∆midi = ∞.  Upon receiving (delays, sid, (Tmidi1, midi1), . . . , (Tmidiℓ, midiℓ)) from the adversary do the following for each pair (Tmidij , midij): if DMAX midij + Tmidij ≤∆midij and midij is a message-ID of receiver P = (·, sid) registered in the current ⃗M, set Dmidij := Dmidij +Tmidij and set DMAX midij := DMAX midij +Tmidij ; otherwise, ignore this pair.  Upon receiving (swap, sid, mid, mid′) from the adversary, if mid and mid′ are message-IDs registered in the current ⃗M, then swap the triples (m, mid, Dmid, (·, sid)) and (m, mid′, Dmid′, (·, sid)) in ⃗M. Return (swap, sid) to the adversary.  Upon receiving (get-reg, sid) from A, return the response (get-reg, sid, P) to A. Functionality 5: The diffusion network. Random oracle for PoW and its wrapper. Our random oracle for generating PoW follows that in
[BMTZ17] except that now it is a shared functionality. Functionality GRO The functionality is parameterized by a security parameter κ. State Variable Description 44 P ←∅ The set of registered parties. H ←∅ A dynamically updatable function table where H[x] = ⊥denotes the fact that no pair of the form (x, ·) is in H.  Eval. Upon receiving (eval, sidRO, x) from some party P ∈P (or from A on behalf of a corrupted P), do the following:
1. If H[x] = ⊥sample a value y uniformly at random from {0, 1}κ and set H[x] ←y.
2. Return (eval, sid, x, H[x]) to the requestor. Functionality 6: The global random oracle. In order to limit the adversary on making a certain number of queries per round, we adopt a functionality wrapper
[BMTZ17] that wraps the corresponding resource to capture such restrictions. Note that since now GRO is shared among different sessions, the adversary can ask the environment to make queries on his behalf. Hence, our wrapper W(GRO) also puts restrictions on queries that are made by the environment. Functionality W(GRO) This functionality maintains state variables as follows. State Variable Description P ←∅ The set of registered parties; the current set of corrupted parties is denoted by P′. τ ←0 The (real-time) clock tick counter. hτ An upper bound which restricts the F-evaluations of all alert parties at time τ. qH, qA ←0 The alert/adversary evaluation counter. Relaying inputs to the random oracle:  Upon receiving (eval, sid, x) from A on behalf of a corrupted party P ∈P′ or a de-synchronized party P, first execute Round Reset, then do the following.
1. Set qA ←qA + 1.
2. If qA ≤hτ then forward the request to GRO and return to A whatever GRO returns.  Upon receiving (eval, sid, x) from an alert party P, first execute Round Reset, then do the follow- ing.
1. Set qH ←qH + 1.
2. If qH ≤hτ then forward the request to GRO and return to P whatever GRO returns.
3. If qH ≥hτ then send (clock-update, sidC) to GClock. Corruption handling:  Upon receiving (corrupt, sid, P) from the adversary, set P′ ←P′ ∪P. Procedure Round-Reset: Send (clock-read, sidC) to GClock and receive (clock-read, sidC, τ ′) from GClock. If |τ −τ ′| > 0, then set qH, qA ←0 and τ ←τ ′. 45 Functionality 7: The random oracle wrapper. Global random oracle. The restricted programmable and observable global random oracle GrpoRO follows the modelling in [CDG+18]. We allow the adversary to observe and program the GRO; meantime, every party (in the same session) can check if a point is programmed by calling the “IsProgrammed” interface. Functionality GrpoRO The functionality is parameterized by the security parameter κ. It maintains a dynamically updatable list H and prog Initially, H = prog = ∅.  Eval. Upon receiving (eval, m) from a party (P, sid) or from the adversary, do the following:
1. If H[m] = ⊥, sample a value h uniformly at random from {0, 1}κ and set H[m] ←h.
2. Parse m as (s, m′).
3. If the query is made by the adversary, or if s ̸= sid, then add (s, m′, h) to the (initailly empty) list of illegitimate queries Qs.
4. Output (eval, m, h) to the requestor.  Observe. Upon receiving (observe, sid) from the adversary: If Qsid does not exist, set Qsid = ∅. Output (observe, Qsid) to the adversary.  Program. Upon receiving (program, m, h) with h ∈{0, 1}κ from the adversary, do the following:
1. If ∃h′ ∈{0, 1}κ such that H[m] = h′ and h ̸= h′, ignore this input.
2. Set H[m] ←h and prog ←prog ∪{m}.
3. Output (program, ok) to the adversary.  IsProgrammed. Upon receiving (is-programmed, m) from a party (P, sid) or from the adver- sary, do the following:
1. If the input was given by (P, sid), parse m as (s, m′). If s ̸= sid, ignore this input.
[CGL16] Chattopadhyay, E., Goyal, V., Li, X.: Non-malleable extractors and codes, with their many tampered extensions. In: Wichs, D., Mansour, Y. (eds.), 48th ACM STOC, , Cambridge, MA, USA, 18–21 June 2016. ACM Press
[GGH+13] Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters. B.: Can- didate indistinguishability obfuscation and functional encryption for all cir- cuits. In: 54th FOCS, , Berkeley, CA, USA, 26–29 October 2013. IEEE Computer Society Press
[GK96b] Goldreich, O., Krawczyk, H.: On the composition of zero-knowledge proof systems. SIAM J. Comput. 25(1), 169–192 (1996)
[GLOV12] Goyal, V., Lee, C.K., Ostrovsky, R., Visconti, I.: Constructing non- malleable commitments: a black-box approach. In: 53rd FOCS, , New Brunswick, NJ, USA, 20–23 October 2012. IEEE Computer Society Press
[Goy11] Goyal. V.: Constant round non-malleable protocols using one way functions. In: Fortnow, L., Vadhan, S.P. (eds.) 43rd ACM STOC, , San Jose, CA, USA, 6–8 June 2011. ACM Press
[GPR16] Goyal, V., Pandey, O., Richelson, S.: Textbook non-malleable commitments. In: Wichs, D., Mansour, Y. (eds.) 48th ACM STOC, , Cam- bridge, MA, USA, 18–21 June 2016. ACM Press
[HIK+11] Haitner, I., Ishai, Y., Kushilevitz, E., Lindell, Y., Petrank, E.: Black-box constructions of protocols for secure computation. SIAM J. Comput. 40(2), 225–266 (2011) Round-Optimal Black-Box MPC in the Plain Model 425
[MOSV22] Madathil, V., Orsini, C., Scafuro, A., Venturi. D.: From privacy-only to simulatable OT: black-box, round-optimal, information-theoretic. In: ITC 2022, vol. 230, pp.5:1–5:20 (2022)
[NP01] Naor, M., Pinkas. B.: Eﬃcient oblivious transfer protocols. In: Rao Kosaraju, S. (ed.) Proceedings of the Twelfth Annual Symposium on Dis- crete Algorithms, 7–9 January 2001, Washington, DC, USA., ACM/SIAM (2001)
[Wee10] Wee. H.: Black-box, round-eﬃcient secure computation via non-malleability ampliﬁcation. In: 51st FOCS, , Las Vegas, NV, USA, October 23–26, 2010. IEEE Computer Society Press
[arm] armfazh. ﬂo-shani-aesni. https://github.com/armfazh/ﬂo-shani-aesni
[aur] libIOP. https://github.com/scipr-lab/libiop
[BFR+13] Braun, B., Feldman, A.J., Ren, Z., Setty, S.T.V., Blumberg, A.J., Walﬁsh, M.: Verifying computations with state. In: SOSP (2013)
[CRVW02] Capalbo, M., Reingold, O., Vadhan, S., Wigderson, A.: Randomness con- ductors and constant-degree lossless expanders. In: STOC (2002)
[CS07] Czumaj, A., Sohler, C.: Testing expansion in bounded-degree graphs. In: IEEE FOCS (2007)
[Din70] Dinic, E.A.: Algorithm for solution of a problem of maximum ﬂow in networks with power estimation. In: Soviet Math. Doklady (1970)
[DIO21] Dittmer, S., Ishai, Y., Ostrovsky, R.: Line-point zero knowledge and its applications. In: ITC (2021)
[Gil52] Gilbert, E.N.: A comparison of signalling alphabets. Bell Syst. Tech. J. 31(3), 504–522 (1952)
[GKR08] Goldwasser, S., Kalai, Y.T., Rothblum, G.: Delegating computation: inter- active proofs for muggles. In: STOC (2008) Orion: Zero Knowledge Proof with Linear Prover Time 327
[GMR89] Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of inter- active proof systems. SIAM J. Comput. 18(1), 186–208 (1989)
[Gol84] Goldberg, A.V.: Finding a maximum density subgraph. University of Cal- ifornia Berkeley (1984)
[HLW06] Hoory, S., Linial, N., Wigderson, A.: Expander graphs and their applica- tions. Bull. Amer. Math. Soc. 43(4), 439–561 (2006)
[Kil92] Kilian, J.: A note on eﬃcient zero-knowledge proofs and arguments (extended abstract). In: STOC (1992)
[KS16] Khot, S., Saket, R.: Hardness of bipartite expansion. In: ESA (2016)
[Mic00] Micali, S.: Computationally sound proofs. SIAM J. Comput. 30(4), 1253– 1298 (2000)
[Mie09] Mie, T.: Short PCPPs veriﬁable in polylogarithmic time with O(1) queries. Ann. Math. Artif. Intell. 56(3), 313–338 (2009)
[NS07] Nachmias, A., Shapira, A.: Testing the expansion of a graph. Electr. Col- loquium Comput. Complex. (ECCC) 14, 01 (2007)
[Pip] Pippenger, N.: On the evaluation of powers and related problems. In: SFCS, IEEE Computer Society (1976)
[RZR20] Ron-Zewi, N., Rothblum, R.D.: Local proofs approaching the witness length. In: FOCS (2020)
[Spi96] Spielman, D.A.: Linear-time encodable and decodable error-correcting codes. IEEE Trans. Inf. Theor. 42(6), 1723–1731 (1996)
[SZT02] Song, D., Zuckerman, D., Tygar, J.D.: Expander graphs for digital stream authentication and robust overlay networks. In: S&P, IEEE (2002)
[Var57] Varshamov, R.R.: Estimate of the number of signals in error correcting codes. Docklady Akad. Nauk, SSSR 117, 739–741 (1957)
[Wla] Wahby, R.S.: lcpc authors. lcpc. https://github.com/conroi/lcpc
[WTS+18] Wahby, R.S., Tzialla, I., Shelat, A., Thaler, J., Walﬁsh, M.: Doubly- eﬃcient zkSNARKs without trusted setup. In: S&P (2018)
[WYKW20] Weng, C/. Yang, K., Katz, J., Wang, X.: Wolverine: fast, scalable, and communication-eﬃcient zero-knowledge proofs for boolean and arithmetic circuits. In: S&P (2020)
[zca] Zcash. https://z.cash/
[ZGK+17a] Zhang, Y., Genkin, D., Katz, J., Papadopoulos, D., Papamanthou, C.: vSQL: verifying arbitrary SQL queries over dynamic outsourced databases. In: S&P (2017)
[ZGK+18] Zhang, Y., Genkin, D., Katz, J., Papadopoulos, D., Papamanthou, C.: vRAM: faster veriﬁable RAM with program-independent preprocessing. In: S&P (2018)
[zkr] An incomplete guide to rollups. https://vitalik.ca/general/2021/01/05/ rollup.html
[ZXZS20] Zhang, J., Xie, T., Zhang, Y., Song, D.: Transparent polynomial delega- tion and its applications to zero knowledge proof. In: S&P, IEEE (2020)
[1] Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L.: Deep learn- ing with diﬀerential privacy. In: Proceedings of the 2016 ACM SIGSAC conference on computer and communications security.  (2016)
[2] Asi, H., Feldman, V., Koren, T., Talwar, K.: Private stochastic convex optimization: Optimal rates in l1 geometry. In: International Conference on Machine Learning.  PMLR (2021)
[3] Asi, H., Feldman, V., Talwar, K.: Optimal algorithms for mean estimation under local diﬀerential privacy. arXiv preprint arXiv:2205.02466 (2022)
[4] Balle, B., Barthe, G., Gaboardi, M.: Privacy ampliﬁcation by subsampling: Tight analyses via couplings and divergences. Advances in Neural Information Processing Systems 31 (2018)
[6] Bassily, R., Groce, A., Katz, J., Smith, A.: Coupled-worlds privacy: Exploiting adversarial uncertainty in statistical data privacy. In: 2013 IEEE 54th Annual Symposium on Foundations of Computer Science. IEEE (2013)
[7] Bassily, R., Nissim, K., Smith, A., Steinke, T., Stemmer, U., Ullman, J.: Algorithmic stability for adaptive data analysis. In: Proceedings of the forty-eighth annual ACM symposium on Theory of Computing.  (2016)
[8] Bassily, R., Smith, A., Thakurta, A.: Private empirical risk minimization: Eﬃcient algorithms and tight error bounds. In: 2014 IEEE 55th annual symposium on foundations of computer science. IEEE (2014)
[10] Belghazi, M.I., Baratin, A., Rajeswar, S., Ozair, S., Bengio, Y., Courville, A., Hjelm, R.D.: Mine: mutual information neural estimation. arXiv preprint arXiv:1801.04062 (2018)
[15] Butte, A.J., Kohane, I.S.: Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements. In: Biocomputing 2000,  World Scientiﬁc (1999)
[16] Chatzikokolakis, K., Chothia, T., Guha, A.: Statistical measurement of information leakage. In: In- ternational Conference on Tools and Algorithms for the Construction and Analysis of Systems.  Springer (2010) 24
[17] Chatzikokolakis, K., Palamidessi, C., Panangaden, P.: Probability of error in information-hiding proto- cols. In: 20th IEEE Computer Security Foundations Symposium (CSF’07).  IEEE (2007)
[18] Chaudhuri, K., Monteleoni, C., Sarwate, A.D.: Diﬀerentially private empirical risk minimization. Jour- nal of Machine Learning Research 12(3) (2011)
[19] Chaudhuri, K., Sarwate, A., Sinha, K.: Near-optimal diﬀerentially private principal components. Ad- vances in neural information processing systems 25 (2012)
[21] Cheng, P., Hao, W., Dai, S., Liu, J., Gan, Z., Carin, L.: Club: A contrastive log-ratio upper bound of mutual information. In: International conference on machine learning.  PMLR (2020)
[23] Cohen, A., Nissim, K.: Towards formalizing the gdpr’s notion of singling out. Proceedings of the National Academy of Sciences 117(15), 8344–8352 (2020)
[24] Cover, T.M.: Elements of information theory. John Wiley & Sons (1999)
[25] Cramer, R., Damgård, I.B., et al.: Secure multiparty computation. Cambridge University Press (2015)
[26] Davies, S., Mazumdar, A., Pal, S., Rashtchian, C.: Lower bounds on the total variation distance between mixtures of two Gaussians. In: International Conference on Algorithmic Learning Theory. PMLR (2022)
[27] Devroye, L., Mehrabian, A., Reddad, T.: The total variation distance between high-dimensional gaus- sians. arXiv preprint arXiv:1810.08693 (2018)
[28] Dong, J., Roth, A., Su, W.J.: Gaussian diﬀerential privacy. arXiv preprint arXiv:1905.02383 (2019)
[30] Erlingsson, Ú., Feldman, V., Mironov, I., Raghunathan, A., Talwar, K., Thakurta, A.: Ampliﬁcation by shuﬄing: From local to central diﬀerential privacy via anonymity. In: Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms.  SIAM (2019)
[31] Erlingsson, Ú., Feldman, V., Mironov, I., Raghunathan, A., Talwar, K., Thakurta, A.: Ampliﬁcation by shuﬄing: From local to central diﬀerential privacy via anonymity. In: Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms.  SIAM (2019)
[33] Feldman, V., Koren, T., Talwar, K.: Private stochastic convex optimization: optimal rates in linear time. In: Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing.  (2020)
[36] Goldwasser, S., Klein, S., Mossel, E., Tamuz, O.: Publicly veriﬁable randomness (2018)
[37] Goldwasser, S., Micali, S.: Probabilistic encryption & how to play mental poker keeping secret all partial information. In: Proceedings of the fourteenth annual ACM symposium on Theory of computing.  (1982)
[38] Goldwasser, S., Micali, S.: Probabilistic encryption. Journal of computer and system sciences 28(2), 270–299 (1984)
[39] Guo, C., Karrer, B., Chaudhuri, K., van der Maaten, L.: Bounding training data reconstruction in private (deep) learning. arXiv preprint arXiv:2201.12383 (2022)
[41] Hardt, M., Talwar, K.: On the geometry of diﬀerential privacy. In: Proceedings of the forty-second ACM symposium on Theory of computing.  (2010)
[43] Jin, C., Netrapalli, P., Ge, R., Kakade, S.M., Jordan, M.I.: A short note on concentration inequalities for random vectors with subgaussian norm. arXiv preprint arXiv:1902.03736 (2019)
[44] Kasiviswanathan, S.P., Lee, H.K., Nissim, K., Raskhodnikova, S., Smith, A.: What can we learn privately? SIAM Journal on Computing 40(3), 793–826 (2011)
[45] Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features from tiny images (2009)
[46] LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436–444 (2015)
[47] LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P.: Gradient-based learning applied to document recogni- tion. Proceedings of the IEEE 86(11), 2278–2324 (1998)
[48] Makhdoumi, A., Salamatian, S., Fawaz, N., Médard, M.: From the information bottleneck to the privacy funnel. In: 2014 IEEE Information Theory Workshop (ITW 2014).  IEEE (2014)
[49] Mironov, I.: Rényi diﬀerential privacy. In: 2017 IEEE 30th computer security foundations symposium (CSF).  IEEE (2017)
[50] Moon, Y.I., Rajagopalan, B., Lall, U.: Estimation of mutual information using kernel density estimators. Physical Review E 52(3), 2318 (1995)
[55] Serjantov, A., Danezis, G.: Towards an information theoretic metric for anonymity. In: Privacy En- hancing Technologies: Second International Workshop, PET 2002 San Francisco, CA, USA, April 14–15, 2002 Revised Papers
2.  Springer (2003) 26
[56] Shannon, C.E.: Communication theory of secrecy systems. The Bell system technical journal 28(4), 656–715 (1949)
[58] Shorten, C., Khoshgoftaar, T.M.: A survey on image data augmentation for deep learning. Journal of big data 6(1), 1–48 (2019)
[59] Stefanov, E., Dijk, M.V., Shi, E., Chan, T.H.H., Fletcher, C., Ren, L., Yu, X., Devadas, S.: Path ORAM: an extremely simple oblivious RAM protocol. Journal of the ACM (JACM) 65(4), 1–26 (2018)
[60] Steinbrecher, S., Köpsell, S.: Modelling unlinkability. In: International workshop on privacy enhancing technologies.  Springer (2003)
[61] Stock, P., Shilov, I., Mironov, I., Sablayrolles, A.: Defending against reconstruction attacks with r\’enyi diﬀerential privacy. arXiv preprint arXiv:2202.07623 (2022)
[62] Tishby, N., Pereira, F.C., Bialek, W.: The information bottleneck method. arXiv preprint physics/0004057 (2000)
[63] Valiant, L.G.: A theory of the learnable. Communications of the ACM 27(11), 1134–1142 (1984)
[64] Vershynin, R.: High-dimensional probability: An introduction with applications in data science, vol. 47. Cambridge university press (2018)
[66] Xiao, X., Tao, Y.: Output perturbation with query relaxation. Proceedings of the VLDB Endowment 1(1), 857–869 (2008)
[67] Xu, A., Raginsky, M.: Information-theoretic analysis of generalization capability of learning algorithms. Advances in Neural Information Processing Systems 30 (2017)
[68] Yeom, S., Giacomelli, I., Fredrikson, M., Jha, S.: Privacy risk in machine learning: Analyzing the connection to overﬁtting. In: 2018 IEEE 31st computer security foundations symposium (CSF).  IEEE (2018) 27
1. Ajtai, M.: Generating hard instances of lattice problems (extended abstract). In: Twenty-Eighth Annual ACM Symposium on Theory of Computing. STOC ’96,  (1996)
4. Ames, S., Hazay, C., Ishai, Y., Venkitasubramaniam, M.: Ligero: lightweight sub- linear arguments without a trusted setup. In: 2017 ACM SIGSAC Conference on Computer and Communications Security,  (2017)
9. Becker, A., Ducas, L., Gama, N., Laarhoven, T.: New directions in nearest neighbor searching with applications to lattice sieving. In: 27th SODA. ACMSIAM, , January 2016
15. Bitansky, N., Canetti, R., Chiesa, A., Tromer, E.: Functional commitments for all functions, with transparent setup. In: ITCS 2012,  ACM, January 2012
16. Bitansky, N., Canetti, R., Chiesa, A., Tromer, E.: Progression-free sets and sublin- ear pairing-based non-interactive zero-knowledge arguments. In: 45th ACM STOC, ACM Press, June 2013
37. Gentry, C., Peikert, C., Vaikuntanathan, V.: Faster Gaussian sampling for trapdoor lattices with arbitrary modulus. In: Fortieth Annual ACM Symposium on Theory of Computing. STOC ’08,  (2008)
44. Kilian, J.: A note on eﬃcient zero-knowledge proofs and arguments (extended abstract). In: Symposium on the Theory of Computing (1992)
2. Ajtai, M.: Generating hard instances of lattice problems. In: Proceedings of the Twenty-eighth Annual ACM Symposium on Theory Of Computing, (1996)
3. Albrecht, M., et al.: Homomorphic encryption standard. In: Lauter, K., Dai, W., Laine, K. (eds.) Protecting Privacy through Homomorphic Encryption, Springer, Cham (2021). https://doi.org/10.1007/978-3-030-77287-1_2
12. Brakerski, Z., Gentry, C., Vaikuntanathan, V.: (leveled) fully homomorphic encryp- tion without bootstrapping. ACM Trans. Comput. Theor. (TOCT) 6(3), 1–36 (2014)
13. Brakerski, Z., Langlois, A., Peikert, C., Regev, O., Stehlé, D.: Classical hardness of learning with errors. In: Proceedings of the Forty-ﬁfth Annual ACM Symposium On Theory Of Computing,  (2013)
19. Fan, J., Vercauteren, F.: Somewhat practical fully homomorphic encryption. Cryp- tology ePrint Archive (2012)
27. Lyubashevsky, V., Nguyen, N.K., Seiler, G.: Practical lattice-based zero-knowledge proofs for integer relations. In: Proceedings of the 2020 ACM SIGSAC Conference On Computer And Communications Security,  (2020)
[BS21] Bronchain, O., Standaert, F.X.: Breaking masked implementations with many shares on 32-bit software platforms. IACR TCHES 2021(3), 202– 234 (2021). https://tches.iacr.org/index.php/TCHES/article/view/8973
[CFG+10] Clavier, C., Feix, B., Gagnerot, G., Roussellet, M., Verneuil, V.: Horizontal correlation analysis on exponentiation. In: Soriano, M., Qing, S., López, J. (eds.) ICICS
[CN16] De Cnudde, T., Nikova, S.: More eﬃcient private circuits II through thresh- old implementations. In: FDTC 2016,  IEEE Computer Society (2016)
[CS20] Cassiers, G., Standaert, F.-X.: Trivially and eﬃciently composing masked gadgets with probe isolating non-interference. IEEE Trans. Inf. Forensics Secur. 15, 2542–2555 (2020)
[LFZD14] Luo, P., Fei, Y., Zhang, L., Ding, A.A.: Side-channel power analysis of diﬀerent protection schemes against fault attacks on AES. In: ReConFig 2014,  IEEE (2014) Combined Fault and Leakage Resilience 409
[RP12] Roche, T., Prouﬀ, E.: Higher-order glitch free implementation of the AES using secure multi-party computation protocols - extended version. J. Cryp- togr. Eng. 2(2), 111–127 (2012)
[SFRES18] Seker, O., Fernandez-Rubio, A., Eisenbarth, T., Steinwandt, R.: Extend- ing glitch-free multiparty protocols to resist fault injection attacks. IACR TCHES 2018(3), 394–430 (2018). https://tches.iacr.org/index.php/ TCHES/article/view/7281
[CJJ22] and many others [GKW17, WZ17, GKW18, BCM+18, Mah18b]. The hardness of the LWE problem has been extensively studied. It was shown that the hardness of LWE is implied by the worst-case hardness of certain lattice problems such as GapSVP [Reg05, Pei09, LM09, BLP+13], which is widely believed to be subexpo- nentially hard for a range of parameters. Many variants of the LWE problems have been explored, encompassing 1) the use of struc- tured secrets, such as binary random secrets and entropic secrets, 2) the use of structured noise, e.g., binary random noise, uniform random noise of bounded magnitude, and rounded version known as Learning With Rounding (LWR) [BPR12], and 3) the use of structured matrices, such as those implicit in Ring LWE (RLWE)
[ADI+17a] generalized the assumption to large fields Fq. These assumptions have been used in a number of applications, for example [Ale03, AIK06, IKOS08, ABW10, CRR21, DIJL23]. Among them, the work of
[ABW10] constructed a public-key encryption scheme from k-sparse LPN for a constant k ≥3 and bounded polynomial number of samples, while the recent work of
[DIJL23] constructed multi-party Homomorphic Secret Sharing and multi-party computation protocols with sublinear communication from k-sparse LPN for any polylogarithmic k and un- bounded polynomial number of samples. The related assumption of local PRGs
[GPV08a] is that when m = O(n log p), the distribution (A, Ar mod p) for a vector r ∈Zm p is statistically close to random in Zn p provided r is chosen from a polynomially wide discrete Gaussian over Zm. This might be useful for the design of public-key primitives. 4) While we don’t know how to sample random sparse matrices with trapdoors when m = O(n log p), we can design an efficient algorithm for sampling such matrices together with trapdoors when the dimension is n × m = O(n2 log n log p). • Cryptanalysis. Examining existing attacks on the LWE problem, the structure of sparse matri- ces does not naively speed up combinatorial [BKW03], lattice reduction [LLL82, Sch94], or algebraic attacks [AG11]. Moreover, many attacks that would typically apply to sparse LPN become harder to apply to sparse LWE due to the fact that the noise is dense (though small). We also explore attacks that directly leverage sparsity, and show that they are ineffective when the sparsity parameter k is polylogarithmic and number of samples m is (unbounded) polynomial. Overall, our initial cryptanalysis optimistically suggests that when all other pa- rameters are equal, namely the modulus p, the noise width σ, and polynomial number of 2 samples m, polylogarithmic-sparse LWE with slightly larger dimension n′ = Θ(n), is com- parable to LWE with dimension n. We also give some concrete parameters based on our initial cryptanalysis. • Applications. The hardness of sparse LWE implies very efficient homomorphic encryption schemes for low degree computations. In particular, we obtain the first secret key Linearly Homomorphic Encryption (LHE) schemes with slightly super-constant, or even constant, over- head, which further has applications to private information retrieval, private set intersection, etc. We also obtain secret key homomorphic encryption for arbitrary constant-degree poly- nomials with slightly super-constant, or constant, overhead. In comparison, to the best of our knowledge, previous homomorphic encryption schemes have (large) polylogarithmic overhead [GHS12]. In particular, our LHE scheme is concretely efficient. We emphasize that our cryptanalysis is preliminary, and more thorough study must be con- ducted before we can rest our confidence on the hardness of sparse LWE. Nevertheless, in order to assess the potential benefits of sparse LWE and provide motivation for further study, we make tentative suggestions for concrete parameters to facilitate comparison of efficiency. Comparison of sparse LWE with LWE and RLWE The main motivation behind introduction of sparse LWE is efficiency. Storing and computing sparse LWE samples are roughly eO(n/k) times more efficient compared to plain LWE. Game-changing efficiency improvements have been af- forded by Ring LWE
[LPR10] due to its nice properties (such as SIMD compatibility [SV14]). However, there are few settings where rings may not be ideal, for instance, when we want to access data as integer elements rather than as ring elements. A good example of this is private- information retrieval applications [HHC+23]. We believe that in those settings sparse LWE might form an appealing alternative to ring LWE. Open Problems Our work leaves a great supply of open problems from various angles. On the complexity side, we ask if there are new attacks on sparse LWE? Can we show worst-case to average-case reductions or leakage resilience properties similar to LWE? Similarly, it is completely unclear if sparse LWE with small secrets is hard. On the concrete attacks and algorithms side, a systematic study of concrete parameters is warranted. On the applications side, it would be good to study more applications of sparse LWE beyond what we mentioned. 2 Technical Outline We now describe our results with more context. The sLWE assumption is parameterized by a sparsity parameter k, dimension n, sample complexity m, noise parameter σ and prime modulus p. It posits that (A, sA + e mod p) is indistinguishable from (A, u) where A is a random matrix in Zn×m p such that each column is k-sparse, s ←Z1×n p is randomly chosen, e ∈Z1×m is generated from discrete Gaussian with width σ and u ∈Z1×m p is randomly chosen. Our results can be divided into three categories: Foundations, Cryptanalysis and Applications. 2.1 Foundations We start by investigating some basic properties of sparse LWE. A very natural question to ask is how much is the minimum distance of the lattice L = L(A) given by L = {xA + pZm : x ∈Z1×n} as a function of k, n, m and p. This should be as large as possible, and certainly much larger 3 than the norm of the error vector, so that given m sLWE samples the planted secret s is uniquely determined. In section 4.1, we show that when m = Ω(n log p) as long as k > 1 and p is polynomial in n, the minimum distance is Ω(p). In particular, once the number of samples exceeds 8n log n, the minimum distance properties of L behave roughly similarly as in regular LWE samples. An immediate consequence of this from the Transference theorems of Banaszczyk
[Ban93] (and as argued in corollary 3.1) is that the there exist m linearly independent vectors of bounded poly- nomial norm in the lattice L⊥(A) = {x ∈Zm : Ax = 0} once m = Ω(n log p). Thus, in principle when m = Ω(n log p), A satisfies nice properties similar to a dense matrix corresponding to LWE distribution. For instance, one immediate consequence from the work of
[MP13] show how to convert X to a trapdoor for [A|V]. This approach does not work directly for us because unlike the case with dense matrices, V = AR + G is not sparse anymore. The main technical highlight of our algorithm is a novel combinatorial approach to get around this issue and sample random sparse matrices along with trapdoors. We then ask if we can show asymptotic polynomial time hardness of sparse LWE. It would be nice to show a result of the form: “if LWE is hard, then sparse LWE is also hard”. Such results are not known even in the setting of LPN/sparse LPN which has received a lot of study. While we do not have a fully general result here, in section 5, we show quite an interesting reduction. Specifically, sparse LWE with sparsity parameter k, dimension n > k, sample complexity m, prime modulus p and the noise parameter σ is harder than LWE with dimension k, sample com- plexity m, modulus p and the noise parameter σ. Our reduction is oblivious to the error model and also applies to the case of sparse LPN/LPN. Assuming subexponential hardness for LWE, this establishes polynomial time hardness for sparse LWE provided k is polylogarithmic. We leave showing such hardness results for constant k to future work. 2.2 Cryptanalysis We perform some preliminary cryptanalysis of this new assumption and also suggest some con- crete parameters based on that. We stand on the tall shoulders of a body of great work done in analyzing security of sparse LPN [Gol00, CM01, Fei02, Ale03, MST03, AIK06, IKOS08, ABW10, AOW15, AL16, KMOW17] as well as LWE [ACF+15, APS15, Pla18, ADRSD15, ACF+14]. In sLWE sparsity creates some interesting effects. For example, when m ≥k n k  + 1 we are guaranteed to find at least k+1 samples supported on the same set of k variables, which might be enough to distinguish a random vector from one close to the lattice. More generally, one can potentially use an algorithm that breaks LWE for some small dimension whenever there exists a set of t samples supported on less than t distinct variables, with t being sufficiently small. How- ever, we believe that once k is large enough, we can release polynomially many samples without 4 compromising security. Most of our cryptanalysis deals with the case of k = O(log n) so that we do not have to worry about this effect. We now discuss a few different types of attacks against sparse LWE. Some of our attacks are inspired by existing algorithms for sparse LPN and LWE attacks, while others leverage the sparsity of A more directly. Sparse LPN Style Attacks We first observe that many of the attacks that apply to sparse LPN do not apply in this case because our error vectors are dense as opposed to being sparse. In the main attack that still might apply how it does for sparse LPN, one aims to find sparse vectors x ∈Zm p so that Ax =
[Pla18] for LWE, based on the dense-minor model we can use it as a benchmark for finding pa- rameters for sparse LWE. For example, for our required number of samples m, and the required level of security (say 128 bits), one could use the Lattice Estimator
2. Another issue is that the BGV modulus reduction performs rounding on the ci- phertexts and requires the secret to be short, in order to bound the error introduced by rounding. When using sparse LWE, we would like to rely on large secrets, since small secret sparse LWE is not equivalent to sLWE. Instead, we perform flipped modulus reduction – rounding the secret instead of the ciphertexts. We describe our LHE and constant-degree HE schemes based on sparse LWE, in Section 8.1 and Section 8.2 respectively. We also give comparisons with other lattice-based schemes proposed in the literature. In short, to the best of our knowledge, no prior HE scheme achieves constant or super-constant overhead, even for the simplest linear evaluation. Their overheads usually grows at least linearly with λ, with the exception of
[GHS12] that achieves fully homomorphic encryption with (large) polylogarithmic overheads. They are also limited to quasipolynomially large modu- lus, whereas our scheme can handle any message space Zp that is not too small log p = Ω(log n). 3 Preliminaries Let N = {1, 2, . . . } be the natural numbers, and define [a, b] := {a, a + 1, . . . , b}, [n] := [1, n]. Our logarithms are in base
2. For a finite set S, we write x ←S to denote uniformly sampling x from S. We denote the security parameter by λ; our parameters depend on λ, e.g. n = n(λ), and we often drop the explicit dependence. We abbreviate PPT for probabilistic polynomial-time. Our adversaries are non-uniform PPT ensembles A = {Aλ}λ∈N. We write negl(λ) to denote negligible functions in λ. Two ensembles of distributions {Dλ}λ∈N and {D′ λ}λ∈N are computationally indis- tinguishable if for any non-uniform PPT adversary A there exists a negligible function negl such that A can distinguish between the two distributions with probability at most negl(λ). For any binary outcome adversary A we define its distinguishing advantage in distinguishing {Dλ}λ∈N and {D′ λ}λ∈N as: | Pr x←Dλ[Aλ(1λ, x) = 1] − Pr x←D′ λ [Aλ(1λ, x) = 1]| 7 We will use matrices and vectors throughout. Both of them will be represented in boldface letters. Matrices are represented using capital bold letters (such as A, B) and vectors using lowercase bold letters (such as a, b). To refer to ith index of any vector v, we denote it by v[i]. For matrices, we denote that by A[i, j]. 3.1 Lattice Preliminaries A lattice L is a discrete subgroup of Rm, or equivalently the set L(b1, . . . , bn) = ( n X i=1 xibi : xi ∈Z ) of all integer combinations of n linearly independent vectors b1, . . . , bn ∈Rm. Such bi’s form a basis of L. The lattice L is said to be full-rank if n = m. We denote by λ1(L) the first minimum of L, defined as the length of a shortest non-zero vector of L. Definition 3.1 (Successive Minima). Given a lattice L and an integer 1 ≤k ≤n, define the k-th successive minimum λk(L) as the smallest possible length of a set of k linearly independent vectors in L. Equivalently, λk(L) is the smallest value r such that a ball of radius r (centered on the origin) contains k linearly independent lattice points. For a rank n lattice L ⊂Rn, the dual lattice, denoted L∗, is defined as the set of all points in span(L) that have integer inner products with all lattice points, L∗= {w ∈span(L) : ∀y ∈L, ⟨w, y⟩∈Z} . Similarly, for a lattice basis B = (b1, . . . , bn), we define the dual basis B∗= (b∗ 1, . . . , b∗ n) to be the unique set of vectors in span(L) satisfying ⟨b∗ i , bj⟩= 1 if i = j, and 0, otherwise. It is easy to show that L∗is itself a rank n lattice and B∗is a basis of L∗. Given a lattice B = (b1, . . . , bn), we denote ∥B∥2 = max i ∥bi∥. An important property of the dual lattice is the following transference theorem, shown in Theorem 2.1 of [Ban93]. Lemma 3.1 (Transference Theorem). For any n-rank lattice L, 1 ≤λ1(L) · λn(L∗) ≤n. Discrete Gaussian and Related Distributions For any s > 0, define ρs(x) = exp(−π∥x∥2/s2) for all x ∈Rn. We write ρ for ρ1. For a discrete set S, we extend ρ to sets by ρs(S) = P x∈S ρs(x). Given a lattice L, the discrete Gaussian DL,s is the distribution over L such that the probability of a vector y ∈L is proportional to ρs(y): Pr X←DL,s[X = y] = ρs(y) ρs(L). Using standard sub-Gaussian tail-bounds, one can show we can show the following claim. Claim 3.1. Let m ∈N, σ > 0, then it holds that: Pr e←DZm,σ [∥e∥> mσ] < exp(−eΩ(m)). We define the truncated discrete Gaussian as a distribution statistically close to discrete Gaus- sian where one samples the vectors from discrete Gaussian conditioned on their norm being upper bounded by mσ. 8 Trapdoor Sampling We will need the following definition of a lattice trapdoor [GPV08b, MP13, Vai20]. For A ∈Zn×m p , we define the rank m lattice L⊥(A) = {z ∈Zm : Az = 0 (mod q)} . A lattice trapdoor for A is a set of short linearly independent vectors in L⊥(A). Definition 3.2. A matrix T ∈Zm×m is a β-good lattice trapdoor for a matrix A ∈Zn×m p if
1. AT = 0 (mod p).
2. For each column vector ti of T , ∥ti∥∞≤β.
1. Let C ←Zk×n p be the Vandermonde matrix whose entries are defined as C[i][j] := ji mod p
2. Randomly select the locality pattern for a matrix with n rows and m columns. Formally, we randomly sample m subsets {Si}i∈[m] of [n] each of size k. The elements of Si corre- spond to the row indices which may contain a nonzero element in column i.
3. Initialize a matrix A′ of size n × m to all zeros.
4. For i := 1, 2, . . . , m : 4.1. Define D to be the square matrix of size k obtained by concatenating the columns of C indexed by Si. Formally, the entry in row u, column v of D is D[u][v] := C[u][Si[v]] = (Si[v])u mod p 4.2. Let A[i] be the ith column of A. Define r := D−1A[i]. Fill in the nonzero entries of column i of A′ with the entries of r. Formally, set A′[Si[j]][i] := r[j] ∀1 ≤j ≤k
5. Sample v ←Z1×n p
6. Return A (A′, vA′ + b) We first prove a few properties of B. Lemma 5.1. CA′ = A Proof. If we denote the ith columns of A and A′ by t and t′ respectively, we just need to show that Ct′ = t. Since t′ is mostly full of zeros except the indices in Si, we can express Ct′ as Dr where r[j] := A′[Si[j]][i] & D[u][v] := C[u][Si[v]] The desired equality now follows directly from line 4.2. Lemma 5.2. The matrix D defined in line 4.1 is invertible. 16 Proof. Observe that regardless of what Si is, D always satisfies D[i][j] = xi j for some distinct values xj. This is a square Vandermonde matrix; its determinant is given by Q i<j(xj −xi). As long as each column uses a different xj, this determinant is nonzero and hence D−1 exists. By construction of C, each column uses a different x since the number of columns m is less than p. Hence, regardless of which columns of C are chosen to construct D, we always have xi ̸= xj for any i ̸= j. Lemma 5.3. The columns of A′ are independent and follow the coefficient distribution Dcoeff,n,k,p. Proof. The locality pattern of A′ is chosen randomly, and the nonzero values of each column are obtained by the formula D−1t where t ←Zk p. Even though the D used for different columns are not independent, the ts are all i.i.d and hence so are the products D−1t. Proof of theorem 5.1. We will consider the two possible ways of sampling b separately. Let us first handle the case where b ←Z1×m p . Since A and b are independent, so are A′ and b. Since b is uniformly random and independent of vA′, so is the sum b + vA′. Therefore the two inputs to A are independent and both follow the right distribution for sLWEn,k,m,p,σ where the target vector is random. Hence in this case A succeeds with probability γ. Now consider the other sampling procedure for b. CA′ = A =⇒b = sA + e = sCA′ + e =⇒vA′ + b = s′A′ + e where s′ = sC + v We will now argue that the input to A, (A′, vA′ + b) has exactly the same distribution as expected by average-case sparse LWE oracle. A sparse LWE instance where we follow the second sampling procedure for the target vector can be characterized by the matrix, the secret vector and the error vector. The error remains unchanged in the reduction. The new secret is uniformly random and independent of A′ since v is chosen independently uniformly at random. The matrix is sampled from Dm coeff,n,k,p. Hence A succeeds with probability γ in this case as well. Therefore, the failure probability of B is exactly the same as that of A. Remark 5.1. We needed p to be a prime in order for Zp to be a field. This allowed us to invert matrices. Remark 5.2. We need m to be large enough in order for A to have any chance of solving sLWE. This is, however, not a problem. As long as we start with m > k log p, it is always possible to generate more LWE samples by taking small linear combinations. We use this procedure to modify the input and increase m, if necessary, before we begin to run B. Remark 5.3. Analogously to sLWE, it is possible to define a sparse variant of the LPN problem [ADI+17b]. Our reduction works exactly as is in that setting, since we don’t depend on or change the error distribution in any way. Thus a PPT algorithm for sLPNn,k,m,p,σ implies a PPT algorithm for LPNk,m,p,σ. 17 6 Trapdoor Sampling for Sparse LWE 6.1 Overview We are going to present an algorithm for sampling pairs of matrices A, T where A is a n×m sparse matrix and T is a trapdoor for A. The distribution of each column of A should be statistically close to independent samples from Dcoeff,n,k,p. Our approach stands on the shoulders of amazing prior work of [MP12]. Recall that they showed how to sample a matrix V ∈Zn×m p for m = O(n log p) that is statistically close to random along with a full-rank square matrix TV of norm O(m) in the nullspace of V (TV can be converted to a basis generically as shown by lemma 7.1 of
[MG02] to a basis for L⊥(V)). The idea is that first we sample a matrix A ←Zn×m′ p for m′ > 2n log p at random. Then we sample a random binary matrix R ←{0, 1}m′×n⌈log p⌉, and consider V = [A|AR+G] where G is the gadget matrix defined as In ⊗g where g = [1 2 4 . . . 2⌈log p⌉−1]. Notice that there is a small-norm square matrix D which satisfies VD = [X|G]. In particular, we can pick D := I −R 0 I  This is enough to obtain a short trapdoor; consider the matrix E :=  0 I TG −G−1(X)  where TG is a trapdoor for G (1) It is easy to check that the product DE is short (since both D and E have low norm), has full rank (since both D and E are nonsingular), and lies in the nullspace of V. Note that this approach fails completely for sparse matrices. Even if we sample A to be sparse, AR will not be sparse anymore. Our idea is to start exactly as in the step above to construct V. However, this matrix is not sparse at all. We come up with a procedure to “sparsify ” V to obtain a wider k-sparse matrix C. We take each column of V and replace it by a n × n log n sparse matrix whose columns add up to the column we are replacing. We construct a matrix C of the form [C1|...|CL] as follows (L is the width of V). • Each column of Ci has a random locality pattern chosen from n k  . • The columns of Ci sum up to the ith column vi of V. • Subject to the first two constraints Ci is random. Such a C can be easily found provided the width of each Ci is large enough (n log n suffices). At this point, C is from the right distribution. Its locality pattern is randomly chosen, and because the distribution of V is statistically close to random, so is the distribution of C. This C is indeed our matrix. We will now show how to construct the trapdoor. We try to find a small-norm full rank square matrix D such that CD has the form [X|G]. Notice that if we can find this D, we are already done (similar to [MP12]). We again use the same E from eq. (1). The trapdoor we are looking for is the product DE, since it satisfies the following 3 properties: • CDE = 0 • DE has small norm. • The columns of DE are linearly independent. 18 Let us now describe how we can find D. Recall that we started with a matrix V such that V · −R I  = G By construction, we also have Ci[1 1 · · · 1]T = Vi for each column vi of V. Therefore, for any matrix U, we can write VU = C(U ⊗[1 1 · · · 1]T ) So now our last equation gives us C ·      −R I  ⊗   1 1 ... 1            n log n     = G So now we have found a matrix F which satisfies CF = G, which was the difficult part. To extend it so that we can obtain CD = [X|G], we just choose an arbitrary full rank matrix not in the column span of F to concatenate to the left of F until the resulting matrix becomes square. We can do this by picking columns from the identity matrix until there is a linear dependence. 6.2 Formal Description Theorem 6.1. There is a PPT algorithm that on input 1n, p, m ≥3n2 log p log n, k > 1 outputs a matrix A distributed statistically close to Dm coeff,n,k,p, and a O(m)-good lattice trapdoor T for A with success probability 1 −o(1). This is an analog of theorem 3.1 for sparse LWE. Note that our algorithm requires a much higher number of samples as compared to the regular LWE trapdoor sampling process, O(n2 log n) instead of O(n). We will follow a very similar approach to
[MP12] in our construction. 19 Algorithm SAMP
1. Define ℓ:= m n log n −⌈n log p⌉
2. Let G := In ⊗g where g = [1 2 4 . . . 2⌈log p⌉−1].
3. Sample matrices A ←Zn×ℓ p and R ←{0, 1}ℓ×⌈n log p⌉
4. Define V := [A|AR + G]. We will denote the ith column of V by vi.
5. For i ∈[1, 2, . . . , ℓ+ ⌈n log p⌉] : (a) Sample a n×n log n sparse matrix Ci (with k nonzero entries in every column) with a random locality pattern such that the columns sum up to vi. If this is impossible because one or more rows of Ci are all 0s, abort.
6. Define C := [C1|C2| · · · |Cℓ+⌈n log p⌉]
7. Let D ∈{−1, 0, 1}m×m be a full rank square matrix such that CD = [X|G]. We claim such a matrix is easy to find (see lemma 6.2 for proof).
8. Define the G−1 function and trapdoor TG for G the same way as in [MP12].
9. Define E :=  0 I TG −G−1(X) 
10. Return the sparse matrix C and the trapdoor DE. We will first prove two properties of the above algorithm. Lemma 6.1. SAMP aborts with probability o(1). Proof. Our procedure only aborts if one of the Ci matrices sampled in step 5a contains at least one row with all zeros. Because the locality pattern is chosen randomly, the probability of any particular row being all zeros is  1 −k n n log n ≤exp(−k log n) < nk Applying an union bound over all rows, we can conclude that the abort probability is at most n−(k−1) = o(1). Lemma 6.2. There is an efficient algorithm to find D in step 7 of SAMP. Proof. Denote the n log n × 1 all-1s vector by h. Observe that step 5 ensures that Cih = vi for all i. 20 Therefore, the following must hold for any matrix U with ℓ+ ⌈n log p⌉= m/(n log n) rows: C · (Im/(n log n) ⊗h) = V =⇒VU = (C · (Im/(n log n) ⊗h)) · U = C · ((Im/(n log n) ⊗h) · U) = C · ((Im/(n log n) ⊗h) · (U ⊗[1])) = C · ((Im/(n log n) · U) ⊗(h · [1])) = C(U ⊗h) By construction, V · −R I  = G =⇒C · −R I  ⊗h  = G We have thus found a full rank matrix F whose infinity norm is 1, whose columns are inde- pendent, and which satisfies CF = G. We can now try to construct D = [S|F] where S ∈ {0, 1}m×(m−⌈n log p⌉). The columns of S are chosen from the columns of the identity matrix such that no linear dependence is formed. In other words, we can start with the matrix [Im|F] and then iteratively remove n log p columns from the Im component which were in the column span of the other remaining columns. Proof of theorem 6.1. First, we will show that DE is a valid trapdoor. • It is a square matrix since both D and E are. • D is full rank by construction, and E is full rank since I and TG are both full rank. Therefore their product is also full rank. • Recall that GTG = 0 and GG−1(X) = X by construction. Therefore, the product C(DE) = (CD)E = [X|G]E = [GTG|X −GG−1(X)] = 0 So the matrix DE is in the nullspace of C. • Both TG and G−1(X) have infinity norm at most
2. Therefore, ∥E∥∞≤2. We also have ∥D∥∞= 1 by construction. Hence their product has infinity norm at most 2m. We will now argue that C is statistically close to Dm coeff,n,k,p. Note that it suffices to show that V is statistically close to uniform, since each Ci is chosen independently from Dn log n coeff,n,k,p subject only to the constraint that their columns sum to vi. This follows from a straightforward application of the leftover hash lemma since ℓ≥2n log p. Remark 6.1. Our algorithm requires a much higher number of samples as compared to the regular LWE trapdoor sampling process, O(n2 log n) instead of O(n). 21 7 Cryptanalysis 7.1 Sparse Vectors in the Kernel One potential approach to attack sparse LWE could be (in the same vein as sparse Learning Parity with Noise) finding sparse vectors x ∈Zm×1 p (not necessarily small) so that Ax =
0. If this is true, given a t sparse x and a sLWE tuple (A, b = sA + e mod p), one can observe that: b · x = e · x. If the error coordinates for e lie in [−B, B] for some B and t is sufficiently small so that (2B + 1)t ≪p, then this will give an attack that runs in time roughly BO(t). The idea is that since x is t sparse, the product e·x touches upon only t coordinates of e. There are 2B +1 possible choices for each coordinate. One could brute-force and check if there is a setting that yields the inner product b · x. One can show that for a typical x only one choice of e will agree with p when (2B + 1)t is sufficiently smaller than p. To rule out such attacks we ask for what sparsity t does there exist solutions to Ax =
0. One can show a naive bound by lifting off analysis for the sparse LPN assumption. Such analysis has been done for sparse LPN over Z2 that can be helpful here. The above attack can be significant if there exist very sparse vectors in the kernel. For instance, if t is a constant and B is polynomial, this attack could be implemented in polynomial time. Notice that when the number of samples m ≥k n k  + 1, by pigeonhole principle there must exist k + 1 coefficient vectors supported on the same set of k input variables. Since there are at least k + 1 vectors supported on the same set of k variables they must be linearly dependent. This allows us to find a t-sparse vector in the nullspace of A for t ≤k + 1. Inspired by the literature on random k-XOR in the field of average case complexity, we analyze a certain graph expansion condition corresponding to the locality set of the column vectors of A. If this condition is met, we would be guaranteed with high probability that t is not too small. As we will describe later, this condition turns out to be conservative. 7.1.1 Locality Graph Expansion Our main theorem is the following: Theorem 7.1. Let A be a sLWEn,k,m,p,σ matrix. With probability 1 −o(1), there does not exist any vector x in the kernel of A which has L or fewer nonzero entries in either of the following cases: • k ≥3 is a constant, m = nδ k 2 for some δ < 1, and L = Θ(n1−δ). • k = poly(log n), m = poly(n), and L = Θ(n) We observe that if Ax = 0 for a t-sparse x, the following holds. Let us denote by S1, . . . , Sm ⊂ [n] the locality sets (see Definition 4.2) corresponding to the column vectors of A ∈Zn×m p . Observe that if there exist a t sparse x so that Ax = 0 this necessarily means that the following expansion property is satisfied: [ i:x[i]̸=0 Si < k · t 2 . (2) This is because each column of A is exactly k sparse. A t sparse combination that yields the all 0 must cancel any variable that appears in the combination. Thus, each variable must appear 22 at least twice. We also state that this condition is a bit conservative. It is plausible that each variables appear multiple times yet the column vectors are linearly independent. This might be more prominent for large p’s. We discuss this issue shortly. We now compute an upper-bound on the probability of the above condition (Equation 2 being violated) as a function of n, k, m (note that the condition is independent of p). From this we can get the desired tradeoffs for n, k, m. This is a routine calculation. Lemma 7.1. For n, m, k and t > k if the sets S1, . . . , Sm are chosen at random from n k  then the proba- bility that the condition in Equation 2 is violated is bounded by fSPARSE(k, n, m)t where fSPARSE(k, n, m) = e1+3k/2 · (k/2)k/2 · m·tk/2−1 nk/2 . Proof. We observe that there are m t  ways of sampling t sets, and  n kt 2  ways of choosing indices in [n]. Once t sets are selected, the probability that each set is supported only over the chosen kt 2 indices is bounded by (kt/2 k ) (n k) . The required probability is upper bounded by (using a union bound): m t  ·  n kt 2  · kt/2 k  n k  !t We now use the naive Binomial approximation  a b b ≤ a b  ≤eb  a b b. Rephrasing it, we get the following upper bound: et+kt/2+kt m t · 2n kt k/2 ·  kt 2n k!t . We remove all powers of t to examine the probability. We collect some other terms and re- arrange them. fSPARSE(k, n, m) = e1+3k/2 · (k/2)k/2 · m · tk/2−1 nk/2 . (3) Our intention should be to set k and m as a function of n so that fSPARSE is small for a large t. One can examine that for a constant k, t is some polynomial provided m = O(nk/2(1−ϵ)) for some constant ϵ >
0. When m = Ω(nk/2), one can find a constant number of subsets that violate Equation 2. We now do some (asymptotic) case analysis for a constant k and setting m = nk/2(1−ϵ). To set fSPARSE to be o(1), we consider another function gSPARSE that is only bigger than fSPARSE but more amenable to analysis. gSPARSE(k, n, m) = m · (e3 · k · t)k/2 nk/2 . (4) To ensure gSPARSE is small, we set: 23 m2/ke3 · k · t ≪n Thus, this holds for: t < n m2/k · e3 · k (5) Proof of theorem 7.1. The theorem statement follows directly from eq. (5) by plugging in the appro- priate values of n, m, k and setting L to the highest value of t that satisfies the inequality. For concrete parameter estimation one can compute exact values of eq. (5) and find out how this attack performs in practice. We anticipate if Bt ≫p, then, the attack does not apply. 7.1.2 Large p effect It is clear that for the analysis for this attack we were overly conservative. Not every collection of t sets with less than kt 2 neighbours is likely to give a sparse vector in the kernel. Moreover, if p increases the chances of this happening should be really small. Nevertheless as described before while the calculation predicts security against polynomial time adversaries with m ≪n k 2 when k is a constant, system over any p can be broken when m > (k + 1) n k  . Thus, the prediction in terms of sample complexity is potentially only off by a square-root factor. We leave the analysis that utilizes the largeness of p for future work as a great open question. We show how to loosely incor- porate this above so that it is better for concrete parameter estimation. Finding precise bounds is a great open question. Claim 7.1. If m ≤nk−3, the following inequality holds with probability 1 −negl(n) for all t ≤L where L = poly(n) and k is a constant. [ i:x[i]̸=0 Si > 2 · t where x is t-sparse (6) Proof. We will upper bound the probability of eq. (6) being violated. Let us calculate the proba- bility that there exist t equations which are supported on at most 2t variables. We can choose the equations in m t  ways, choose the variables in n 2t  ways, and the probability of all these equations being supported on these variables is ( 2t k  / n k  )t. Applying the union bound, we now obtain Pr [There exist some t equations supported on at most 2t variables] ≤ m t n 2t   2t k  n k  !t ≤e3t m t t  n 2t 2t 2t n kt = 2k−2e3mtk−3 nk−2 t ≤ 2k−2e3tk−3 n t since m < nk−3 24 The above probability is asymptotically negligible in n whenever t < n1/(k−3) 2e . Taking a union bound over all t less than this value finishes the proof. If the locality pattern of A satisfies the above combinatorial property, we can show that there does not exist a L-sparse x in the kernel of A with high probability. Since L above is polynomial in n, this rules out the sparse vector in kernel attack. Recall that sparse LPN over F2 is broken for m = nk/2 samples due to this attack (see [AOW15, KMOW17] etc). However, our result holds as long as the sample complexity m is less than nk−3, which is a substantial improvement over theorem 7.1. This is one of the ways increasing the modulus from 2 to some p = ω(m) increases security. We can now prove the following result: Theorem 7.2. Let A be a sLWE matrix where the sample complexity m, dimension n and sparsity param- eter k = O(1) satisfy the relation m < nk−3. If the modulus p is ω(m), then there does not exist any vector x in the kernel of A which has L or fewer nonzero entries for some L = poly(n) with probability 1 −o(1). Proof. We use Claim 7.1 to obtain L. If x is at most L-sparse, the probability that Ax = 0 can now be upper bounded by the expression: X t∈[L] m t  pt/p2t The reason for this is that for a fixed non-zero x, Ax is randomly distributed on the variables in the support of S xi̸=0 ai. By this property, the number of such variables is at least 2t. Note that, X t∈[L] m t  pt/p2t < X t∈[L] mt pt . This quantity is subconstant since m/p = o(1). 7.2 Dense Minor Lower-Bound Model We now introduce a lower-bound model to provide an estimate of lattice attacks that exploit the sparsity structure of the equations. We call our attack the Dense-Minor attack. This captures a variety of different attacks as we will describe later and enables us to reason about security. The rough idea is that all attacks that break LWE over dimension n requires at least n + 1 samples or else secrets are not information theoretically defined. The problem, with the low- locality structure of our assumption is that each sample is constant sparse (say k). Thus, it is plausible that exploiting the low locality, one can find L+1 samples supported over L coordinates for some small L, and then use an algorithm that breaks LWE with dimension L and L+1 samples. For example, if the number of samples is at least k n k  + 1, the pigeonhole principle guarantees the existence of some k + 1 columns which are supported on the same set of k variables. If k is a constant, we can solve the resulting k-dimensional LWE problem in constant time; this points to an attack against sparse LWE with constant sparsity and polynomially many samples. We show how to set parameters to avoid this. In particular, setting the number of samples a reasonable polynomial such as m = n2 or n4 for target applications, we will aim to find k such that 25 L turns out to be at least linear in n e.g. 0.9n for the above attack strategy. This roughly states that any meaningful attack exploiting the sparsity must involve Ω(n) variables. Thus, one can appeal to concrete cryptanalysis to make a reasonable conjecture on the security of sparse LWE. Conjecture 7.1. sLWEn,k,m,p,σ is at least as hard as LWEL,f(L),p,σ for L = Θ(n), k = Ω(log n), and f is some small polynomial. We will use the above heuristic for parameter estimation purposes. We show some examples in Section 7.4. Definition 7.1 (Dense-Minor of order r). For any matrix A ∈Zn×m p , we say that it has a dense minor of size L ∈[0, n], if there exists a subset T ⊆[n] of size L such that there are r ·L column vectors supported entirely over indices given by T. Moreover, L is the minimum such number. We will typically be interested in r as 1 + 1/L or some constant (like 2), or even r = log p. Problem with a Small Dense Minor We observe that if for A ∈Zn×m p there is a dense minor of size L and order r, then, this means that we have r · L columns all supported at some L indices. This means that if one is given a sparse LWE sample A, sA + e mod p one can pick out these r · L equations of the form {ai, ⟨ai, s⟩+ ei mod p}i∈S for some set S ⊆[m] of size at least r · L. Here we assume a′ is are column vectors of A. This new system is an LWE type system with r · L samples of dimension L. This can potentially be broken with access to an LWE oracle that solves LWE on dimension L, sample complexity r · L and the same modulus p. Theorem 7.3. Let n be the dimension, k = log n be the sparsity parameter and m = nβ be the sample complexity for some constant β >
1. Let p be the modulus. We have that, with probability 1 −o(1/n) over choice of A ←Dm coeff,n,k,p (sampling each column independently from the distribution Dcoeff,n,k,p specified in definition 4.1), A the minimum L for which A has a dense minor of order 1 + 1/L is L = Ω(n). Proof. Once again we will use a union-bound. There are n t  ways of choosing t variables and  m t+1  ways of choosing t + 1 samples. The probability that each of these t + 1 equations depends on the chosen t variables is  (t k) (n k) t+1 . Thus, the probability of the dense-minor being smaller than some L is: fDENSEMINOR = X t∈[k,L] t k  n k  !t+1 · n t  ·  m t + 1  We now make every term smaller than 1/n2 and this will prove the claim. Since the expression involves Binomial coefficients we will use the naive asymptotics on the Binomial coefficients. t k  ≤ek  t k k n k  ≥ n k k n t  ≤et n t t  m t + 1  ≤et+1  m t + 1 t+1 26 Then each term for t in the claimed expression f becomes: ≤exp (k(t + 1) + 2t + 1) · tk(t+1) nk(t+1) · nt tt ·  m t + 1 t+1 ≤exp ((k + 2)t + k + 1) · tt(k−1) nt(k−1) · nβ(t+1) tt+1 ≤exp ((k + 4)t) · ttk ntk−2tβ−t ≤  exp (k + 4) · tk nk−1−2βt We set the term inside that is raised to the power t to be lesser than 1
4. This yields, the final term denoted by term term ≤exp (k + 4) · tk nk−1−2β ≤1 4 ⇐= tk ≤ nk−1−2β 4 exp (k + 4) Since, k = Ω(log n) and β is a constant, we can enure that term is smaller than 1/4 provided t ≤αn for some constant α > 0. This proves the theorem. Remark 7.1. We remark that most attacks care about L log p samples or cL samples for some c > 1. In the above theorem, we rule out minors with just L + 1 samples. This only makes our model stronger. The expression above is quite loose as we make several approximations regarding Binomial coef- ficients. If one computes the expression fDENSEMINOR = X t∈[k,L] t k  n k  !t+1 · n t  ·  m t + 1  it is possible to find tradeoffs exactly using a computer program. We use it to estimate the exact size of the dense minor. For more discussion on this, see section 7.4. Now we describe how our dense-minor model captures attacks such as Arora-Ge, BKW and Lattice Reductions. Capturing Arora-Ge Style Attacks Recall that for the Arora-Ge attack
[AG11] on LWE, we as- sume that the infinity norm of the error vector is at most B for some B < p/2. Each LWE sample (a, b) gives rise to the following equation on the entries of the secret vector: B Y j=−B n X i=1 aisi −b −j ! = 0 The degree of each equation is 2B +
1. Since there are n variables, the total number of terms is n+2B+1 n  . We treat each unique term as a separate variable, and we can solve the resulting linear 27 system directly as long as the number of equations, m, exceeds the total number of terms. If we have fewer equations, we first multiply each equation by every possible term of degree ≤d. This increases the number of equations to m n+d d  and the total number of terms to n+2B+1+d n  , and we can solve this system as soon as the former exceeds the latter. Let us now consider what happens if we try to apply the same strategy to sparse LWE. The only difference is the additional constraint that each of the original equations are supported on k variables instead of n. Since our dense minor attack already provides an algorithm for solving sLWE when we are given more than k n k  samples, we will assume that m < k n k  < n+1 k+1  below. • If 2B+1 < k, there is virtually no difference between LWE and sparse LWE for this approach. This is because in either case, the original equations do not have terms containing more than 2B + 1 distinct variables. We will therefore focus on the case where k is smaller than 2B + 1. • The total number of terms is bounded above by the number of all degree 2B + 1 monomials supported on at most k out of n variables. This equals n + 1 k + 1 2B + 1 + k k  > n + 1 k + 1  > m Clearly, the number of terms is greater than the number of equations, and trying to linearize the system naively does not work. • We can consider increasing the number of equations by following the exact recipe used by Arora-Ge. For some d, multiply each equation by every possible monomial of degree at most d. The problem is that this breaks the locality pattern that distinguishes sLWE from LWE in the Arora-Ge approach, since each equation can be now supported on many more variables. • We can instead multiply each equation by all the monomials of degree at most d which are supported on the same k variables as the equation. This preserves the locality, but does not suffice since the number of terms continue to exceed the number of equations n + 1 k + 1 2B + d + 1 + k k  > m d + k k  Another natural way to utilize the sparsity is to try to find a large number of samples sup- ported on the same set of t variables for some t < n, and then run the Arora-Ge algorithm on those samples with an effective dimension of t. The dense minor lower bound rules out this ap- proach for any t = o(n). Therefore, the effective dimension in this approach will be linear in n, and we would still require many more samples than what we have available. Capturing BKW Style Attacks The BKW family of attacks ([BKW03, Lyu05, ACF+15]) look for a short vector x such that the product Ax is either 0 or very sparse. They first partition the columns of A into blocks of size B. New samples are then created by finding collisions in these blocks and reducing those blocks to zero by subtraction. Iteratively applying this process for each block, we can find vectors of magnitude 2n/B in the nullspace of A. To execute this attack naively, we need access to a very large number of samples. For LWE, we can generate new samples by taking random linear combinations with small norm. However, new samples generated by combining columns of A destroy sparsity really fast. Therefore, the search step of BKW attack does not advantage sparse LWE in any way over standard LWE. 28 We can try to take advantage of the fact that the columns of sparse LWE are mostly filled with zeros, and hence it will be easier to find collisions in blocks. While this is indeed true for the first few blocks, observe that we subtract columns from each other at every iteration of BKW. Each subtraction operation would increase the number of nonzero entries in the remaining blocks exponentially, and hence the required sample complexity for the attack will at least be the same as that of regular LWE with a constant factor smaller dimension. So a natural way to leverage sparsity is therefore to work with a dense minor of order log p of size L. Our theorem suggests that L = Ω(n), and we would again require more samples than we have available. Capturing Lattice-Style Attacks Typically, lattice attacks are applied by applying lattice reduc- tion to solve either: • Finding a short x so that Ax =
[Pla18] or Albrecht et.al. [APS15, ACD+18] for an excellent survey on concrete running times). Thus if we are able to find dense minor of size (say) n/2 of order log p, that is an exponential improvement in the running time over a dense matrix. Our dense-minor model captures such improvements. In fact, we rule out attacks that makes use of only L + 1 samples in L variables. Typical lattice attacks require at least cL (where c > 1 is some constant) or even L log p samples. 7.3 Open questions We leave some exciting open problems for future work:
1. Are there other ways of leveraging sparsity besides the dense-minor method?
2. Analyze the performance of current lattice reduction algorithms with sparse LWE matrices.
1. Aggarwal, D., Dodis, Y., Kazana, T., Obremski, M.: Non-malleable reductions and applications. In: Servedio, R.A., Rubinfeld, R. (eds.) Proceedings of the 47th Annual ACM Symposium on Theory of Computing, Portland, 14–17 June 2015, ACM Press (2015)
2. Aggarwal, D., Dodis, Y., Lovett, S.: Non-malleable codes from additive combina- torics. SIAM J. Comput. 47(2), 524–546 (2018)
4. Aggarwal, D., Obremski, M.: A constant rate non-malleable code in the split-state model. In: Proceedings of the 61st Annual Symposium on Foundations of Computer Science, Durham, 16–19 November 2020,  IEEE Computer Society Press (2020)
8. Babai, L.: Trading group theory for randomness. In: 17th Annual ACM Symposium on Theory of Computing, Providence, 6–8 May 1985,  ACM Press (1985)
9. Babai, L., Moran, S.: Arthur-merlin games: a randomized proof system, and a hierarchy of complexity classes. J. Comput. Syst. Sci. 36(2), 254–276 (1988) 174 M. Ball et al.
11. Ball, M., Dachman-Soled, D., Guo, S., Malkin, T., Tan, L.-Y.: Non-malleable codes for small-depth circuits. In: Thorup, M. (ed.) Proceedings of the 59th Annual Symposium on Foundations of Computer Science, Paris, 7–9 October 2018,  IEEE Computer Society Press (2018)
15. Ball, M., Dachman-Soled, D., Kulkarni, M., Malkin, T.: Limits to non-malleability. In: Vidick, T. (ed.) Proceedings of the ITCS 2020: 11th Innovations in Theoretical Computer Science Conference, Seattle, 12–14 January 2020, vol. 151, pp. 80:1– 80:32. LIPIcs (2020)
20. Bellare, M., Goldreich, O., Petrank, E.: Uniform generation of NP-witnesses using an NP-oracle. Inf. Comput. 163(2), 510–526 (2000)
21. Bitansky, N., Kalai, Y.T., Paneth, O.: Multi-collision resistance: a paradigm for keyless hash functions. In: Diakonikolas, I., Kempe, D., Henzinger, M. (eds.) Pro- ceedings of the 50th Annual ACM Symposium on Theory of Computing, Los Ange- les, 25–29 June 2018,  ACM Press (2018)
24. Chattopadhyay, E., Li, X.: Non-malleable codes and extractors for small-depth circuits, and aﬃne functions. In: Hatami, H., McKenzie, P., King, V. (eds.) Pro- ceedings of the 49th Annual ACM Symposium on Theory of Computing, Montreal, 19–23 June 2017,  ACM Press (2017)
34. Dziembowski, S., Pietrzak, K., Wichs, D.: Non-malleable codes. In: Yao, A.C.-C. (ed.) ICS 2010: 1st Innovations in Computer Science, Tsinghua University, Beijing, 5–7 January 2010,  Tsinghua University Press (2010)
35. Dziembowski, S., Pietrzak, K., Wichs, D.: Non-malleable codes. J. ACM 65(4), 20:1-20:32 (2018)
39. Feige, U., Lund, C.: On the hardness of computing the permanent of random matrices. Comput. Complex. 6(2), 101–132 (1997)
40. Goldreich, O., Micali, S., Wigderson, A.: Proofs that yield nothing but their validity for all languages in NP have zero-knowledge proof systems. J. ACM 38(3), 691–729 (1991)
42. Goldwasser, S., Sipser, M.: Private coins versus public coins in interactive proof systems. In: 18th Annual ACM Symposium on Theory of Computing, Berkeley, 28–30 May 1986,  ACM Press (1986)
43. Goyal, V., Kumar, A.: Non-malleable secret sharing. In: Diakonikolas, I., Kempe, D., Henzinger, M. (eds.) Proceedings of the 50th Annual ACM Symposium on Theory of Computing, Los Angeles, 25–29 June 2018,  ACM Press (2018)
45. Gutfreund, D., Shaltiel, R., Ta-Shma, A.: Uniform hardness versus randomness tradeoﬀs for Arthur-Merlin games. Comput. Complex. 12(3–4), 85–130 (2003)
46. Impagliazzo, R., Wigderson, A.: P = BPP if E requires exponential circuits: deran- domizing the XOR lemma. In: 29th Annual ACM Symposium on Theory of Com- puting, El Paso, 4–6 May 1997,  ACM Press (1997)
47. Jerrum, M., Valiant, L.G., Vazirani, V.V.: Random generation of combinatorial structures from a uniform distribution. Theor. Comput. Sci. 43, 169–188 (1986)
50. Kinne, J., van Melkebeek, D., Shaltiel, R.: Pseudorandom generators, typically- correct derandomization, and circuit lower bounds. Comput. Complex. 21(1), 3–61 (2012)
51. Klivans, A.R., van Melkebeek, D.: Graph nonisomorphism has subexponential size proofs unless the polynomial-time hierarchy collapses. SIAM J. Comput. 31(5), 1501–1526 (2002)
53. Li, F., Zuckerman, D.: Improved extractors for recognizable and algebraic sources. In: Achlioptas, D., V´egh, L.A. (eds.) Approximation, Randomization, and Com- binatorial Optimization. Algorithms and Techniques, APPROX/RANDOM 2019, 20–22 September 2019, Massachusetts Institute of Technology, Cambridge, volume 145 of LIPIcs, pp. 72:1–72:22. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2019)
54. Li, X.: Improved non-malleable extractors, non-malleable codes and independent source extractors. Electron. Colloq. Comput. Complex. 23, 115 (2016)
55. Li, X.: Improved non-malleable extractors, non-malleable codes and independent source extractors. In Hatami, H., McKenzie, P., King, V. (eds.) Proceedings of the 49th Annual ACM Symposium on Theory of Computing, Montreal, 19–23 June 2017,  ACM Press (2017)
56. Li, X.: Non-malleable extractors and non-malleable codes: partially optimal con- structions. In: Proceedings of the 34th Computational Complexity Conference, CCC 2019, New Brunswick, 18–20 July 2019, pp. 28:1–28:49 (2019)
58. Micali, S.: CS proofs (extended abstracts). In: 35th Annual Symposium on Foun- dations of Computer Science, Santa Fe, 20–22 November 1994,  IEEE Computer Society Press (1994)
59. Miltersen, P.B., Vinodchandran, N.V.: Derandomizing Arthur-Merlin games using hitting sets. Comput. Complex. 14(3), 256–279 (2005)
60. Shaltiel, R.: Weak derandomization of weak algorithms: explicit versions of Vao’s lemma. Comput. Complex. 20(1), 87–143 (2011)
61. Shaltiel, R., Umans, C.: Simple extractors for all min-entropies and a new pseudo- random generator. J. ACM 52(2), 172–216 (2005)
62. Shaltiel, R., Umans, C.: Pseudorandomness for approximate counting and sam- pling. Comput. Complex. 15(4), 298–341 (2006)
63. Shaltiel, R., Umans, C.: Low-end uniform hardness versus randomness tradeoﬀs for AM. SIAM J. Comput. 39(3), 1006–1037 (2009)
64. Trevisan, L., Vadhan, S.P.: Extracting randomness from samplable distributions. In: 41st Annual Symposium on Foundations of Computer Science, Redondo Beach, 12–14 November 2000,  IEEE Computer Society Press (2000)
3. Bos, J.W., Ducas, L., Kiltz, E., Lepoint, T., Lyubashevsky, V., Schanck, J.M., Schwabe, P., Seiler, G., Stehl´e, D.: CRYSTALS - Kyber: A CCA-secure module- lattice-based KEM. In: EuroS&P (2018)
6. Brakerski, Z., Gentry, C., Vaikuntanathan, V.: (Leveled) fully homomorphic en- cryption without bootstrapping. ACM Trans. Comput. Theory (2014)
7. Brakerski, Z., Langlois, A., Peikert, C., Regev, O., Stehl´e, D.: Classical hardness of learning with errors. In: STOC (2013)
8. Chen, H., Dai, W., Kim, M., Song, Y.: Homomorphic conversion between (ring) LWE ciphertexts. In: ACNS (2021)
12. Chillotti, I., Joye, M., Paillier, P.: Programmable bootstrapping enables efficient homomorphic inference of deep neural networks. In: CSCML (2021)
13. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional transformers for language understanding (2018), available at https: //arxiv.org/abs/1810.04805
14. Ding, Y., Guo, H., Guan, Y., Liu, W., Huo, J., Guan, Z., Zhang, X.: East: Effi- cient and accurate secure transformer framework for inference (2023), available at https://arxiv.org/abs/2308.09923
15. Dumas, J.G., Giorgi, P., Pernet, C.: Dense linear algebra over word-size prime fields: the FFLAS and FFPACK packages. ACM Trans. on Mathematical Software (2008)
16. Fan, J., Vercauteren, F.: Somewhat practical fully homomorphic encryption (2012), available at http://eprint.iacr.org/2012/144
17. FFLAS14, T.F.F.G.: FFLAS-FFPACK: Finite Field Linear Algebra Subroutines / Package, v2.0.0 edn. (2014), http://linalg.org/projects/fflas-ffpack
18. Froelicher, D., Cho, H., Edupalli, M., Sousa, J.S., Bossuat, J.P., Pyrgelis, A., Troncoso-Pastoriza, J.R., Berger, B., Hubaux, J.P.: Scalable and privacy-preserving federated principal component analysis (2023), available at https://arxiv.org/ abs/2304.00129
19. Gentry, C., Halevi, S., Peikert, C., Smart, N.P.: Ring switching in BGV-style ho- momorphic encryption. In: SCN (2012)
20. Goldwasser, S., Kalai, Y.T., Peikert, C., Vaikuntanathan, V.: Robustness of the learning with errors assumption. In: ICS (2010) 34 Y. Bae et al.
22. Hao, M., Li, H., Chen, H., Xing, P., Xu, G., Zhang, T.: Iron: Private inference on transformers. Advances in Neural Information Processing Systems (2022)
29. Pang, Q., Zhu, J., Mollering, H., Zheng, W., Schneider, T.: BOLT: Privacy- preserving, accurate and efficient inference for transformers (2023), available at https://eprint.iacr.org/2023/1893
31. Peikert, C., Waters, B.: Lossy trapdoor functions and their applications. In: STOC (2008)
32. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I.: Improving language un- derstanding by generative pre-training (2018), available at https://openai.com/ research/language-unsupervised
34. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozi`ere, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and efficient foundation language models (2023), available at https://arxiv.org/abs/2302.13971
35. Zhang, J., Liu, J., Yang, X., Wang, Y., Chen, K., Hou, X., Ren, K., Yang, X.: Secure transformer inference made non-interactive (2023), available at https:// eprint.iacr.org/2024/136 35 Appendices A On sub-rings and MLWE-RLWE conversions For the sake of completeness, we describe the procedures mentioned in 2.3. Subrings. We define the cyclotomic ring RQ,N′ of order 2N ′ as RQ,N′ = ZQ[Y ]/(Y N′ + 1). The map Y 7→XN/N ′ extends to a ring-homomorphism from RQ,N′ to RQ,N, which embeds RQ,N′ into RQ,N. The ring RQ,N con- tains k copies of RQ,N′: an element a = a0 + a1X + . . . + aN−1XN−1 ∈RQ,N may be viewed as k elements in RQ,N′ by writing a =  a0 + akXk + . . . + ak(N′−1)Xk(N′−1) + X  a1 + ak+1Xk + . . . + ak(N′−1)+1Xk(N′−1) + . . . + Xk−1  ak−1 + a2k−1Xk + . . . + akN ′−1Xk(N′−1) , (14) and identifying Xk with the indeterminate Y of RQ,N′. For an element a ∈ RQ,N, we shall use the notation e∗ i (a) for the coefficient of Xi in the decompo- sition (14) of a over RQ,N′. Ring-switching. The goal is to decompose a ciphertext ct = (a, b) ∈(RQ,N)2 for RLWEQ,N under a key sk ∈RN to a set of ciphertexts (ct′ i = (a′ i, b′ i))0≤i<k ∈ (R2 Q,N′)k for RLWEQ,N′ under a secret key sk′ ∈RN′. This is accomplished by first switching key from sk to sk′ using a switching key swkQ,P,sk→sk′ = (aswk, bswk) = (aswk, −aswk · sk′ + e + P · sk) ∈R2 P Q,N , for which sk′ belongs to the subring RN′, i.e., whose non-zero coefficients as viewed as an element of RN can only correspond to the Xki’s for 0 ≤i < N ′. In fact, the pair (aswk, bswk) may be viewed as k RLWE pairs in the subring RP Q,N ′ that share the same secret. Note that providing this switching key requires the security of RLWE in degree N ′, which in turns requires that PQ should not be too large. Ring-switching is then described as: • RingSwitch. On input ct = (a, b) ∈RQ,N and swkQ,P,sk→sk′, set (ea,eb) ← KeySwitch((a, b), swkQ,P,sk→sk′), and return (ai, bi) = (e∗ i (ea), e∗ i (eb)) for 0 ≤ i < k. From RLWE to MLWE. Let ct = (a, b) ∈R2 Q,N be an RLWEQ,N ciphertext under a secret key sk ∈RN. The identity a · sk + b = m may be rewritten in module form as X 0≤i<k e∗ i (m)Xi = X 0≤j,ℓ<k e∗ ℓ(a)Xℓe∗ j(sk)Xj + X 0≤i<k e∗ i (b)Xi (15) = X 0≤i<k ⟨eai, sk′⟩+ e∗ i (b)  Xi , 36 Y. Bae et al. where sk′ = (e∗ 0(sk), . . . , e∗ k−1(sk)) ∈Rk N ′ and eai = (e∗ i (a), e∗ i−1(a), . . . , e∗ 0(a), Y e∗ k−1(a), . . . , Y e∗ i+1(a)) ∈Rk Q,N′ . This shows that for 0 ≤i < k, the tuple (eai, e∗ i (b)) is an MLWEk Q,N′ encryption of mi under the key sk′. We thus define the RLWE to MLWE decomposition as: • ModDecomp. On input ct = (a, b), return the k ciphertexts (eai , e∗ i (b)) for 0 ≤i < k, defined as above. As a and sk play a symmetric role in Equation (15), we can also write X 0≤i<k e∗ i (m)Xi = X 0≤i<k  ⟨a′, eski⟩+ e∗ i (b)  Xi , where a′ and esk are obtained from a and sk as in the previous case. We then obtain a decomposition in k ciphertexts with common a part, but distinct secret keys; this gives the ShModDecomp algorithm. From MLWE to RLWE. Let ct = (a, b) ∈Rk+1 Q,N′ be an MLWE-ciphertext for sk ∈Rk N ′. We define esk = P 0≤i<k skiXi ∈RN and let swkP,Q,esk→sk′ ∈RP Q,N be an RLWE-switching key from esk to a new key sk′. • ModKeySwitch goes through the following steps:
1. Embed: ea ←a0 + P 1≤i<k aiXiY −1 ∈RQ,N; then (ea, b) is an RLWEQ,N encryption of em ∈RQ,N such that e∗ 0( em) = m.
2. (a′, b′) ←KeySwitch((ea, b), swkQ,P,esk→sk′).
3. Extract: using ModDecomp, recover (ea′ 0, b′ 0) encrypting e∗ 0( em) = m under (e∗ 0(sk′), . . . , e∗ k−1(sk′)). Module packing takes as input (cti)0≤i<k where cti = (ai, bi) encrypts mi under a common MLWE-secret key sk ∈Rk N′. It first combines the various cti’s in polynomial form, turning the k = N/N ′ MLWEk Q,N′ ciphertexts into a single MLWEk Q,N ciphertext, then reduces the MLWE dimension to 1 by switching, sep- arately, all the components of the MLWE secret key vector to sk′. It thus requires switching keys swki = swkQ,P,ski→sk′. It outputs a single RLWEQ,N ciphertext. • ModPack proceeds as follows:
1. ct′ = (A, B) ←(P 0≤i<k a′ iXi, P 0≤i<k b′ iXi) ∈Rk+1 Q,N.
2. For 0 ≤i < k, run (A′ i, βi) ←KeySwitch((Ai, 0), swki).
3. Return (P 0≤i<k A′ i, B + P 0≤i<k βi) ∈R2 Q,N, which encrypts m = P 0≤i<k miXi under sk′. The correctness of the process follows from the identity m−B ≈P 0≤i<k Ai· ski ≈P 0≤i<k(A′ i · sk′ + βi). 37 Algorithm 3 Precomputation-based PC-MM for dimension above the RLWE ring degree N Input: A matrix U ∈Rd×d, with d = kN for some integer k ≥1, coefficients-encoded RLWE ciphertexts (cti)0≤i<d2/N in RQ1,N, each of which encrypts a segment of a row of a matrix M ∈Rd×d. Input: Switching keys fmt-swkQ1,P,sk→{ski}0≤i<k and swkQ0,P,sk′ i→sk for 0 ≤i < k, where U[skT 0 | · · · |skT d−1]T = [sk′ 0 T | · · · |sk′ d−1 T ]T . Output: Coefficients-encoded RLWE ciphertexts in RQ0,N, each of which encrypts a segment of a row of the matrix UM ∈Rd×d. 1: for i ←0 to d do 2: (ai, bi,j) ←FmtSwitch(ctki, · · · , ctk(i+1)−1; fmt-swkQ1,P,sk→{ski}0≤i<k) 3: end for 4: B ←(bi,j)0≤i<d,0≤j<d 5: B′ ←U · B 6: for i ←0 to d and j ←0 to k do 7: ct′ i,j ←(P ℓai,ℓXℓ, P ℓb′ i,jN+ℓXℓ) ∈R2 Q1,N 8: ct′ i,j ←KeySwitch(ct′ i,j; swkQ0,P,sk′ i→sk) 9: ct′ i,j ←Rescale(ct′ i,j; Q1, Q0) 10: end for 11: return all (ct′)i,j’s B Precomputation-based algorithms In this Section, we give a full description of the precomputation-based algorithms outlined in Sections 4.3. Algorithm 3 is to be used when the dimension d is larger than the ring degree N, whereas Algorithm 4 is to be used for d < N. C Reduction of Modular PP-MM to floating-point PP-MM For d < 215, we have implemented our own reduction from one PP-MM between a matrix U with entries bounded by 218 and a matrix modulo q0 ≈258, to three floating-point PC-MM’s using BLAS plus a quadratic (in d) number of integer operations. We shall not undertake a systematic study of this reduction, which is folklore; we restrict ourselves to the parameter values of our implementation. We wish to compute U · M, where M is defined modulo q0 < 260, and the coefficients of U are bounded by ∥U∥∞= 218. For these parameter values, we claim that for d < 215, PP-MM modulo q0 can be reduced to 3 floating-point PP-MM, plus a quadratic (in d) number of operations on integers ≤293 in absolute value. We define δ = 220, and given an integer x ∈[0, q0 −1], we write x = x(2) ·δ2 + x(1) · δ + x(0) the base-δ decomposition of x, where 0 ≤xi < δ, i = 0, 1,
2. Given a d × d matrix M = ( ˜mij)0≤i,j<d over Z/q0Z, and letting mij denote the unique 38 Y. Bae et al. Algorithm 4 Precomputation-based PC-MM for dimension below the RLWE ring degree N Input: A matrix U ∈Rd×d, with N = kd for some integer k ≥1, coefficients-encoded RLWE ciphertexts (cti)0≤i<d2/N in RQ1,N, each of which encrypts a strip of rows of a matrix M ∈Rd×d. Input: Switching keys fmt-swkQ1,P,sk→{ski}0≤i<d2/N , swkQ0,P,sk′ i→sk for 0 ≤i < k, where U[skT 0 | · · · |skT d−1]T = [sk′ 0 T | · · · |sk′ d−1 T ]T , and switching keys for ModPack Output: Coefficients-encoded RLWE ciphertexts in RQ0,N, each of which encrypts a strip of rows of the matrix UM ∈Rd×d. 1: (a, bi) ←FmtSwitch(cti)0≤i<d2/N; fmt-swkQ1,P,sk→{ski}0≤i<d2/N ) 2: for i ←0 to d2/N do 3: ((adi+j, bdi+j))0≤j<k ←ShModDecomp(cti) 4: end for 5: for i ←0 to d do 6: Set the i-th row of B as the coefficients of bi 7: end for 8: B′ ←UB 9: for i ←0 to d do 10: Set the coefficients of b′ i as the i-th row of B′ 11: end for 12: for i ←0 to d2/N do 13: for j ←0 to k do 14: (a′ di+j, b′ di+j) ←KeySwitch((a′ di+j, b′ di+j); swkQ0,P,sk′ i→sk) 15: end for 16: ct′ i ←ModPack((a′ di+j, b′ di+j)0≤j<k) 17: Rescale (ct′ i; Q1, Q0) 18: end for 19: return all ct′ i’s 39 integer congruent to ˜mij modulo q, we extend this notation to the matrix M as M = δ2 · M (2) + δ · M (1) + M (0), where M (k) = (m(k) ij )0≤i,j<d for k = 0, 1, 2. The largest integer occuring in the computation of U · M (i), i = 0, 1, 2, is upper bounded by d∥U∥∞δ < 253 in absolute value. We can thus compute exactly each of the U · M (i), using floating-point arithmetic; the sum δ2 · UM (2) + δ · UM (1) + UM (0), (16) which has quadratic cost (smaller than matrix multiplication for d large enough) is then evaluated using integer arithmetic. Finally, one can check that the integers occuring in this linear combination are < 293 in absolute value, as claimed. D Comparison to [26] We conducted experiments to compare our algorithms with optimization in Sec- tion 5 to the LZ algorithm introduced in [26], under the same parameters in Section 7.2. We note that all parameters achieve 128-bits security. Since [26] does not provide experimental results for PC-MM, in order to provide a fair comparison, we implemented
[26] for d = N by using OpenBLAS
[28] as our algorithms. However, the
[26] algorithm, as described, is restricted to a matrix dimension d equal to, or larger than, the RLWE ring degree N. One trivial modification is to use fewer RLWE slots; that is, in order to encrypt a d × d matrix, we allocate d RLWE ciphertexts with d messages out of N available slots. We have implemented this variant of
[26] algorithm for small matrices, in order to be able to provide a comparison with our algorithms addressing a larger range of dimensions. However, we remark that this modification might incur additional computation and communication costs before and after PC-MM. For all cases, our optimization in Section 5 improves the efficiency a lot, and the cost of format conversions is relatively minor compared to the improvement from our optimization. We remark that our LZ implementation might have larger precision (e.g., ≈19.2 bits) since we did not use the optimization technique in Section 5, while our algorithms also provide reasonable precision (e.g., ≈13.4). Table 7 reports the timings in seconds. log d 8 9 10 11 12 13 14
[26] 0.423 1.05 2.75 8.13 27.4 96.8 786 Ours 0.309 0.684 1.70 5.06 17.1 64.6 347 Table 7. Comparison between our algorithms and our implementation of [26]. All timings are in seconds, for the product of two d × d matrices. E Table of notations 40 Y. Bae et al. PC-MM, PP-MM Sec. 1, p .1 (FP, Mod)-PP-MM Table 1, p. 3 RLWE Sec. 2.1, p. 8 MLWE Sec. 2.1, p. 8 R, RN, Rq, Rq,N Sec. 2, p. 8 ω Sec. 2, p. 8 N RLWE ring-degree d input matrix dimension k MLWE rank ℓS2C Sec. 2.2, p. 11 Qi Sec. 2.2, p. 10 Qtop Sec. 2.2, p. 10 Toep() Sec. 1.1, p. 4 ai,[j,k) Sec. 4.1, p. 17 DFT, iDFT Sec. 2.2, p. 9 S2C, C2S, ModRaise Sec. 2.2, p. 11 Ecdcoeff Sec. 2.2, p. 9 Ecdslot, Dcdslot Sec. 2.2, p. 9 FmtSwitch Sec. 3.2, p. 13 Backward-FmtSwitch Sec. 3.4, p. 15 ModDecomp, ShModDecomp Sec. 2.3, p. 12 ModPack Sec. 2.3, p. 12 EvalMod Sec. 2.2, p. 11 Sh-S2C, Sh-C2S Sec. 6.2, p. 27 KeySwitch Sec. 2.2, p. 9 ModKeySwitch Sec. 2.3, p. 12 HalfBTS Sec. 2.2, p. 11 Rescale Sec. 2.2, p. 10
[BS16] but only in sub-exponential classical time
2. Since HSVP reduces to SVP in the same lattice by Minkowski’s the- orem, we actually only need to prove two reductions, one to free-module-HSVP and one to free-module-CVPcov. We do so in the two subsections below. 4.1 The Case of HSVP (and SVP) In this subsection, we reduce ideal-HSVP to free-module-HSVP in modules of rank
2. The high level idea is to use a two-element representation of the input ideal to transform it into a free rank-2 module, such that any short vector of this free rank-2 module can be transformed back into a short vector of the input 852 G. De Micheli et al. ideal. Similar ideas were used in
[DM22] in order to transform a rank-2 module into a free rank-4 module. More precisely, given an ideal I, we compute a two-element representation I = ⟨a⟩+ ⟨b⟩and construct the free module M with a basis consisting of the columns of the following matrix a b 0 ε  , where ε > 0 is a rational number to be speciﬁed later. Observe that every s ∈M is of the form x yT for x ∈I and y ∈⟨ϵ⟩. Hence, if s is small, then its ﬁrst coordinate x is a small element of I. Here, since the size of s is related to the determinant of M, which depends on the choice of ε, we want to take ε as small as possible. However, M also contains vectors of the form  0 vε T for v ∈OK, so if ε is too small then the short vectors of M are of this form and result in x =
0. To avoid this case, we observe that when 0 vεT is a short vector of M then ε can be upper bounded by a quantity depending only on K, I and a. Thus by choosing ε greater than this quantity, we avoid the case where short vectors of M have their ﬁrst coordinate equal to 0. Proposition 4.1. For any γ ≥1 and γ′ > 2γ2 · Δ1/2d K , there exists a probabilis- tic polynomial-time reduction from solving γ′-ideal-HSVP to solving (γ, 2)-free- module-HSVP in K2. Proof. Let I be a non-zero ideal of K, without loss of generality we can assume that I is integral (otherwise we scale it to an integral ideal, which does not change its geometry). Compute a two-element representation I = ⟨a⟩+ ⟨b⟩with a ̸= 0 using the algorithm of Theorem 2.2 and consider the free module M ⊂K2 generated by the free basis (in columns)  a b 0 ε  , for some ε > 0, rational, to be determined. We want to prove that any solution to γ-HSVP in M is of the form  x y T , with x a solution to γ′-ideal-HSVP in I. Since a free basis of M is eﬃciently computable from I (in probabilistic polynomial time), this will give us a probabilistic polynomial time reduction from γ′-ideal-HSVP to (γ, 2)-free-module-HSVP as desired. Let us ﬁrst prove that if ε is large enough, then all solutions to γ-HSVP in M are of the form  x y T with x non-zero. To do so, assume for a contradiction that  0 vε T is a solution to γ-HSVP in M, then v ∈OK\{0} and there exists u ∈OK such that ua + vb =
0. By deﬁnition of γ-HSVP, we have ε · ∥v∥≤γ · √ 2d · Δ1/2d K · N(M)1/2d = γ · √ 2d · Δ1/2d K · ε1/2 · N(a)1/2d. Next, we want to show that because of the equality ua+vb = 0, then v has to be quite large, and the inequality above cannot be satisﬁed. The equality ua+vb = 0 Reductions from Module Lattices to Free Module Lattices 853 implies that ⟨u⟩⟨a⟩= ⟨v⟩⟨b⟩. Assume for the moment that b ̸=
0. Then, all ideals in the equation above are nonzero (since both a and b are nonzero, and v should also be nonzero). Since I = ⟨a⟩+ ⟨b⟩, there exist nonzero integral ideals J1, J2 such that ⟨a⟩= IJ1, ⟨b⟩= IJ2 and J1, J2 do not have any common factor in their factorization into prime ideals. Since I is invertible (because it is non-zero), the equality ⟨u⟩⟨a⟩= ⟨v⟩⟨b⟩can be rewritten as ⟨u⟩J1 = ⟨v⟩J2. Note that all ideals involved in this equality are integral (because u and v are in OK). Since J1 and J2 are coprime, it must be that J1 divides ⟨v⟩, which implies in particular that N(v) ≥N(J1) = N(a)/N(I), where the last equality comes from the deﬁnition of J1. Finally, recall from Eq. (2) that ∥v∥≥ √ d · N(v)1/d, which gives us ∥v∥≥ √ d · N(a) N(I) 1/d . In the case b = 0, then N(a) = N(I) and thus the inequality still holds, since v ∈OK. Combining this inequality with the one above we obtain √ d · N(a) N(I) 1/d ≤∥v∥≤γ · √ 2d · Δ1/2d K · N(a)1/2d ε1/2 , which results in ε ≤2γ2Δ1/d K · N(I)2/d N(a)1/d . Therefore choosing ε > 2γ2Δ1/d K N(I)2/d/N(a)1/d guarantees that the solution s =  x y T to γ-SVP over M satisﬁes x ̸= 0. Now, we also choose ε such that ε ≤γ′2 2γ2 · N(I)2/d N(a)1/d . Note that γ′ > 2γ2·Δ1/2d K implies the existence of such ε. Calling the free-module- HSVP oracle on input M, let s be the output and x be the ﬁrst coordinate of s. The choice of ε guarantees that x ∈I\{0} and ∥x∥≤∥s∥≤γ · √ 2d · Δ1/2d K · ε1/2 · N(a)1/2d ≤γ′ · √ d · Δ1/2d K · N(I)1/d = γ′ · √ d · det(I)1/d. Hence x is a solution to γ′-ideal-HSVP over I. ⊓⊔ Since (γ, 2)-free-module-HSVP reduces to (γ, 2)-free-module-SVP (by deﬁni- tion and by Minkowski’s bound), Proposition 4.1 implies the following proposi- tion. Proposition 4.2. For any γ ≥1 and γ′ > 2γ2 · Δ1/2d K , there exists a probabilis- tic polynomial-time reduction from solving γ′-ideal-HSVP to solving (γ, 2)-free- module-SVP in K2. 854 G. De Micheli et al. 4.2 The Case of CVPcov Let us now consider the reduction to CVPcov in free-modules of rank
2. The main ideas of the reduction are similar to the SVP/HSVP case, but the analysis is a bit diﬀerent. The idea is again to consider the free rank-2 module M spanned by the columns of the matrix a b 0 ε  , where I = ⟨a⟩+ ⟨b⟩and ε is small. We show that if ε is suﬃciently small, then the covering radius of this lattice is roughly equal to det(I)1/d (up to polynomial factors). Note that, contrary to the SVP/HSVP case, we have no lower bound on ε here. The ideal case would be ε = 0, but this would lead to a (non free) module of rank
1. Ensuring that the module has rank 2 is the only reason we take ε ̸= 0. Then, in order to ﬁnd a short vector in I, we simply solve CVPcov in M with a target vector of the form t = (t0, 0)T , where we choose t0 just slightly above the covering radius of M, so that any solution s = (s0, s1)T has s0 ̸= 0, and s0 ∈I is somewhat short. Proposition 4.3. For any γ ≥1 and γ′ ≥5 · γ · d · λ(∞) d (OK), there exists a probabilistic polynomial-time reduction from solving γ′-ideal-HSVP to solving (γ, 2)-free-module-CVPcov in K2. Proof. Let I be an integral ideal in OK (we can assume that I is integral without loss of generality, if it is not we scale it). Let a, b ∈OK be such that I = ⟨a⟩+⟨b⟩ (with a ̸= 0), and ε > 0 be some rational number. Let M be the rank-2 free module spanned by the basis a b 0 ε  . First, let us prove that cov(M) ≤ε ·  d · λ(∞) d (OK) · Δ1/2d K · ( √ d + ∥a∥)  + d3/2 · λ(∞) d (OK) · det(I)1/d. Let t = (t0, t1)T ∈SpanK(M) = K2. Let w ∈OK be such that ∥wε −t1∥≤ cov(εOK) (i.e., wε is a closest point to t1 in the ideal εOK). If we subtract w · (b, ε)T to t, we obtain a new vector t′ = (t′ 0, t′ 1)T , which is at the same distance to M as t (since w ·(b, ε)T ∈M), but whose second coordinate is small, namely ∥t′ 1∥≤cov(εOK). Let us now reduce the ﬁrst coordinate. Let α ∈I be a closest vector to t′ 0, that is, ∥α −t′ 0∥≤cov(I). Since I is generated by a and b, there exists u0 and v0 in OK such that α = u0a + v0b. We would like to take v0 as small as possible (since adding v0 times the second basis vector will make the second coordinate of our vector increase again). We know that any (u, v) = (u0 + kb, v0 −ka) with k ∈OK also satisﬁes α = ua + vb. Hence, we can always reduce v modulo a and ensure that ∥v∥= ∥v0 −ka∥≤cov(aOK). Reductions from Module Lattices to Free Module Lattices 855 Overall, we obtain (u, v) ∈O2 K with ∥v∥≤cov(aOK) such that ∥ua + vb − t′ 0∥≤cov(I). Taking s = u(a, 0)T + (v + w)(b, ε)T ∈M ﬁnally gives us ∥t −s∥= ∥t′ −u(a, 0)T −v(b, ε)T ∥ = ∥(t′ 0 −α, t′ 1 −εv)T ∥ ≤∥t′ 0 −α∥+ ∥t′ 1∥+ ε∥v∥ ≤cov(I) + cov(εOK) + ε · cov(aOK). To conclude, recall from preliminaries (Eqs. (3) and (4)) that cov(I) ≤d3/2 · λ(∞) d (OK) · det(I)1/d, cov(aOK) ≤d · λ(∞) d (OK) · Δ1/2d K · ∥a∥, cov(εOK) ≤ε · d3/2 · λ(∞) d (OK) · Δ1/2d K , where in the last inequality we used the fact that ε is rational and so ∥ε∥= ε √ d. Combining everything, we obtain the desired upper bound on cov(M). We can now describe our reduction from ideal-HSVP to free-module-CVPcov in modules of rank
2. In both cases, by choice of γ3, it holds that γ2 > 2γ2 3 · Δ1/2d K and so from Proposition 4.1, we have a reduction from γ2-ideal-HSVP to (γ3, 2)-free-module-HSVP. Finally, let εn be as in Proposition 5.2, that is εn = 0 if n is even and εn = 1/(n −1) if n is odd. Note that εn = 0 when n = 2 and εn ≤1/2 when n ≥3. With this in mind, one can check that γ3 ≥γ1+εn 4 · √n1+εn · Δεn/2d K in both cases n = 2 and n ≥3. From Proposition 5.2, this implies the existence of a reduction from (γ3, 2)-free-module-HSVP to (γ4, n)-free-module-HSVP. Com- bining the three reductions provides a reduction from (γ1, n)-module-HSVP to (γ4, n)-free-module-HSVP as required. ⊓⊔ Proof (Proof of Theorem 6.3). Let γ1 = γ′, γ2 = γ · 5 √ 2 · d · Δ1/d K , γ3 = √ 2γ and γ4 = γ. By deﬁnition and from the lower bound on γ′ in the theorem statement, it holds that γ1 ≥γ4 · γ2 · Δ1/d K hence, by Corollary 3.3, we have a reduction from (γ1, n)-module-CVPcov to (γ4, n)-free-module-CVPcov and γ2- ideal-HSVP. Then, by deﬁnition of γ2 and using the fact that λ(∞) d (OK) ≤Δ1/d K (see Lemma 2.1), we have γ2 ≥5γ3 · d · λ(∞) d (OK), so by Proposition 4.3 there is 862 G. De Micheli et al. a reduction from γ2-ideal-HSVP to (γ3, 2)-free-module-CVPcov. Finally, we have γ3 ≥ √ 2 · γ4 and so by Proposition 5.3, there is a reduction from (γ3, 2)-free- module-CVPcov to (γ4, n)-free-module-CVPcov. Combining the three reductions provides a reduction from (γ1, n)-module-CVPcov to (γ4, n)-free-module-CVPcov as required. ⊓⊔ 7 Application: Dequantizing Module-LLL One of the main application of our reductions (and more precisely of the reduc- tion for SVP from Theorem 6.1) is a de-quantized, i.e., classical version of the LLL algorithm for modules lattices from
[LPSW19] (which we refer to as module- LLL). Module-LLL is an oracle-based algorithm which, on input a pseudo-basis of a rank-n module M ⊂Km, outputs a somewhat short vector of the module. The algorithm is heuristic and runs in quantum polynomial time, provided it is given access to an oracle solving the closest vector problem in a ﬁxed (ﬁeld dependent) lattice LK. The authors of
[LPSW19] also showed that module-LLL can be made classical if the input module is free and represented by a basis, but they were unable to de-quantize the algorithm in the generic case. The following theorem was proved in [LPSW19]. Theorem 7.1 (Heuristic [LPSW19, Theorem 5.1]). For any sequence of number ﬁelds K and any η > 0, there exist a sequence of lattices LK of dimension O((log ΔK)2+η), an approximation factor γ = 2 ˜ O(log ΔK)/d and an algorithm A such that (under some heuristics): • Algorithm A solves (γn, n)-free-module-SVP in Kn; • Algorithm A makes a number of queries to an oracle solving the closest vector problem in LK and requires a total number of classical operations that are both polynomial in log ΔK and the input bit-length. Note that our formulation of Theorem 7.1 is slightly diﬀerent from the one of Theorem 5.1 from [LPSW19]. In particular, we state the theorem only for full rank modules and we use the recent result from
[BST+20] to simplify some of the bounds. More precisely, in [LPSW19, Theorem 5.1], both the dimension of the lattice LK and the approximation factor γ involved the quantity d log(cov(OK)). By combining Lemma 2.1 and Eq. (3), we can see that cov(OK) ≤d3/2 · Δ3/(2d) K , which implies that d log(cov(OK)) = ˜O(log ΔK), and leads to our simpliﬁcation. We now show in the following theorem that there exists a classical module- LLL algorithm that solves an approximate version of the module-SVP problem, regardless of the fact that the input module is free or not. The only diﬀerence between Theorem 7.2 below and Theorem 7.1 above is that A now solves module- SVP, instead of free-module-SVP. Theorem 7.2. For any sequence of number ﬁelds K and any η > 0, there exist a sequence of lattices LK of dimension O((log ΔK)2+η), an approximation factor γ′ = 2 ˜ O(log ΔK)/d and an algorithm A such that (under some heuristics): Reductions from Module Lattices to Free Module Lattices 863 • Algorithm A solves ((γ′)n, n)-module-SVP in Kn; • Algorithm A makes a number of queries to an oracle solving the closest vector problem in LK and requires a total number of classical operations that are both polynomial in log ΔK and the input bit-length. Proof. Combine Theorem 7.1 with Theorem 6.1. Note that, due to the reduction, the approximation factor γ′ from Theo- rem 7.2 is a priori slightly worse than the approximation factor γ in Theorem 7.1 (we have, e.g., γ′ = 3·γ3 ·Δ3/2d K ), but the diﬀerence is hidden in the soft O nota- tion that is used in both statements.
20. Boneh, D., Shaw, J.: Collusion-secure ﬁngerprinting for digital data. IEEE Trans. Inf. Theory 44(5), 1897–1905 (1998). https://doi.org/10.1109/18.705568
35. Goyal, R., Koppula, V., Waters, B.: Collusion resistant traitor tracing from learning with errors. In: Diakonikolas, I., Kempe, D., Henzinger, M. (eds.) 50th ACM STOC, ACM Press, Los Angeles, CA, USA, 25–29 June 2018. https://doi. org/10.1145/3188745.3188844
41. Li, R., Li, Y., Wang, Q., Duan, S., Wang, Q., Ryan, M.: Accountable decryption made formal and practical (2023). here
47. Osmosis. link
50. Rondelet, A., Kilbourn, Q.: Threshold encrypted mempools: limitations and con- siderations (2023). here
56. Shutter: Preventing front running and malicious MEV on ethereum. link
58. Tardos, G.: Optimal probabilistic ﬁngerprint codes. J. ACM 55(2) (2008). https:// doi.org/10.1145/1346330.1346335, https://doi.org/10.1145/1346330.1346335
59. de Valence, H.: The Penumbra protocol. link
13. We observe that this corresponds to the case b “ 1 of the V3S-fk game, and implements perfectly the simulators SimProof, SimSecret we previously described. The computation of JvK as a function of R ¨ x ` y and pR ¨ JxKi, JyKiqiPS is equivalent to the one done in Hybrid2 due to the correctness of the sharing of x, and as we only need T points of JvK to recover its full value. Hence, this change does not induce an advantage loss. We also note that the adversary observes outputs computed from exactly T ´ 1 shares of JxK in Hybrid3 and they are thus randomly distributed independently from x. We can sample them directly with no advantage loss. Finally, applying Lemma 1, we have that px, R ¨ x ` yq follows the same distribution as pˆx, R ¨ x ` yq. We conclude that: AdvHybrid3 A pκq “ AdvHybrid2 A pκq. [\ B Security proof of Pelican We define in Figure 15 variants of the key generation from Figure 14 coined LeakyKeygenRB and LeakyKeygenUF. LeakyKeygen allows an adversary to bias the distribution of the key. In this section, we prove stronger unforgeability and 41 robustness results using LeakyKeygen. It will be used to prove the security of our distributed key generation. Pelican.Setupppp, Nq 1: for i P t1, ..., Nu do 2: skSIG i , pkSIG i Ð SIG.Keygenpppq 3: for j P t1, ..., Nu do 4: KiÑj Ð SKE.Keygenpppq 5: sigiÑj “ SIG.Signpski, ti, k, KiÑjuq 6: return ppkSetup i :“ pkSIG i qiPt1,...,Nu, pskSetup i :“ pKjÑk, sigjkqj“i_k“iqiPt1,...,Nu Pelican.Keygenppp, T, Nq 1: ppkSetup i , skSetup i qiPt1,...,Nu Ð Pelican.Setupppp, Nq 2: s Ð D2 σt 3: Sample P P R2 qrXs of degree ă T such that Pp0q “ s 4: salt Ð t0, 1uκ 5: a :“ Hapsaltq 6: b :“ β ´ “ 1 a ‰ ¨ s mod q 7: return vk “ pa, bq, pski :“ pPpiq, ppkSetup j qjPt1,...,Nu, skSetup i qqiPt1,...,Nu Fig. 14: Algorithms for the key generation of Pelican. B.1 Robustness Proof (of Theorem 6). We start by proving a slightly more general variant of Theorem 6, with keys generated with LeakyKeygenRB and allowing the adversary to bias generated keys. This result will be leveraged for the robustness proof of Pelican used with our DKG in
9. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Sponge functions. Ecrypt Hash Workshop 2007, May 2007
11. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: The Keccak reference, Jan- uary 2011
9. Buss, J.F., Frandsen, G.S., Shallit, J.O.: The Computational Complexity of Some Problems of Linear Algebra. BRICS Rep. Ser. 3(33) (1996). https://doi.org/10. 7146/brics.v3i33.20013
80. Springer, New York (2020). https://doi.org/10.1007/978-1-0716-0987-3
12. Faug`ere, J.C.: A new eﬃcient algorithm for computing gr¨obner bases without reduction to zero (F5). In: Proceedings of the 2002 International Symposium on Symbolic and Algebraic Computation,  ISSAC ’02, ACM, New York, NY, USA (2002). https://doi.org/10.1145/780506.780516
13. Faug`ere, J.C., Safey El Din, M., Spaenlehauer, P.J.: Gr¨obner bases of bihomo- geneous ideals generated by polynomials of bidegree (1,1): Algorithms and com- plexity. J. Symbolic Comput. 46(4), 406–437 (2011). https://doi.org/10.1016/j.jsc. 2010.10.014
18. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions. J. ACM 33(4), 792–807 (1986). https://doi.org/10.1145/6490.6503
20. Grover, L.K.: A fast quantum mechanical algorithm for database search. In: 28th ACM STOC,  ACM Press (1996). https://doi.org/10.1145/237814. 237866
23. Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A.: Zero-knowledge from secure multiparty computation. In: Johnson, D.S., Feige, U. (eds.) 39th ACM STOC,  ACM Press (2007). https://doi.org/10.1145/1250790.1250794
24. Johnson, C.R., ˇSmigoc, H., Yang, D.: Solution theory for systems of bilinear equa- tions. Linear Multilinear Algebra 62(12), 1553–1566 (2013). https://doi.org/10. 1080/03081087.2013.839670
25. Joux, A., , Pierrot, C.: Algorithmic aspects of elliptic bases in ﬁnite ﬁeld discrete logarithm algorithms. Adv. Math. Commun. (2022). https://doi.org/10.3934/amc. 2022085
28. Joux, A., Pierrot, C.: Technical history of discrete logarithms in small characteristic ﬁnite ﬁelds - the road from Subexponential to quasi-polynomial complexity. DCC 78(1), 73–85 (2016). https://doi.org/10.1007/s10623-015-0147-6
32. Lang, S.: Algebra. Springer New York (2002). https://doi.org/10.1007/978-1-4613- 0041-0
33. Shor, P.W.: Algorithms for quantum computation: discrete logarithms and factor- ing. In: 35th FOCS,  IEEE Computer Society Press (1994). https:// doi.org/10.1109/SFCS.1994.365700
34. Spaenlehauer, P.J.: Solving multi-homogeneous and determinantal systems: algo- rithms, complexity, applications. Phd thesis, Universit´e Pierre et Marie Curie (Univ. Paris 6) (2012)
2. Biham, E., Shamir, A.: Differential Cryptanalysis of the Data Encryption Standard, Springer 1993.
20. Dobraunig, C., Eichlseder, M., Mendel, F., Schl¨affer, M.: Ascon v1.2. Submission to the CAESAR Competition (2016)
25. Zhang, W., et al.: KNOT: algorithm specifications and supporting document.
30. Canteaut, A., et al.: On the differential-linear connectivity table of vectorial Boolean functions. CoRR, abs/1908.07445 (2019)
6. Barooti, K., Collins, D., Colombo, S., Huguenin-Dumittan, L., Vaudenay, S.: On Active Attack Detection in Messaging with Immediate Decryption. IACR Cryp- tology ePrint Archive (2023)
14. Cohn-Gordon, K., Cremers, C., Dowling, B., Garratt, L., Stebila, D.: A formal security analysis of the signal messaging protocol. In: EuroS&P (2017)
15. Cohn-Gordon, K., Cremers, C., Garratt, L.: On post-compromise security. In: CSF (2016)
19. Dowling, B., Hale, B.: Secure messaging authentication against active man-in-the- middle attacks. In: EuroS&P (2021)
22. Haeberlen, A., Kouznetsov, P., Druschel, P.: PeerReview: practical accountability for distributed systems. SIGOPS 41(6), 175–188 (2007)
24. Jacob, R., Larsen, K.G., Nielsen, J.B.: Lower bounds for oblivious data structures. In: SODA (2019)
28. Marlinspike, M.: Safety number updates (2017). https://signal.org/blog/veriﬁed- safety-number-updates/. Accessed 22 May 2022
29. Naor, M., Rotem, L., Segev, G.: Out-of-band authenticated group key exchange: from strong authentication to immediate key delivery. In: ITC (2020) On Active Attack Detection in Messaging with Immediate Decryption 395
34. Scott-Railton, J., et al.: CatalanGate: Extensive Mercenary Spyware Operation against Catalans Using Pegasus and Candiru (2022). https://citizenlab.ca/2022/ 04/catalangate-extensive-mercenary-spyware-operation-against-catalans-using- pegasus-candiru/. Accessed 22 May 2022
35. Support, S.: Twilio Incident: What Signal Users Need to Know (2022). https:// support.signal.org/hc/en-us/articles/4850133017242. Accessed 03 Oct 2022
1. A public uniform random string rpub is sampled6.
2. The adversary sees rpub and chooses (x, y) ∈X × Y .
3. Alice and Bob get (x, rpub) and (y, rpub) respectively.
4. Alice and Bob send message(s) (optionally using private coins) in order to compute some target function.
5. Optionally: More steps that depend on the communication settings. For instance, in the SM model the referee steps in here. We say that a protocol is ε-secure in this model if for every PPTM adversary Adv with running time poly(λ) the probability that the computation of Alice and Bob will be correct is at least 1 −ε: Pr rpub (x,y)←Adv(rpub) Alice and Bob private coins [Protocol Fails] ≤ε Ampliﬁcation. The usual requirements in communication complexity is for ε = 1/3 and then to argue for ampliﬁcation by repetition. Here we have to be a bit more careful, since the correctness requirement is computational. However, we know that for games of a certain structure we get parallel ampliﬁcation: Bellare et al.
[BIN97] showed that parallel repetition of computationally sound protocols doesn’t always lower the error as one may expect. However, they proved that for three-round protocols the error does go down exponentially fast7 as in the information-theoretic case. A protocol in our model can be evaluated in the following 3 rounds: 6 Can be generalized to a sample from any known eﬃcient distribution. 7 See Canetti et al.
[CHS05] for better parameters. 262 S. P. Cohen and M. Naor
1. The prover chooses the public random string.
2. The adversary chooses the inputs of Alice and Bob.
3. The prover chooses Alice’s and Bob’s private random string. Note 2.8. Alice’s and Bob’s algorithms are public and since they don’t have any secret state or secret input they can be simulated (also by the adversarial participant). It is a core fact when we are using the technique of Babai and Kimmel in computational settings in the proofs of Theorems 3.2 and 3.14 and Theorem 4.1. 2.2 Free Talk Model We consider a variation to the SM model where Alice and Bob are allowed to communicate freely in a preprocessing phase, before the inputs are chosen: Free talk. Free talk is a ‘free’ communication that Alice and Bob can have before the inputs are chosen by the adversary. Alice and Bob can generate states (possibly secret) in the free talk phase. Those states can be used afterward to reduce the communication complexity. However, the adversary is also stronger, in two ways: Free Talk Eavesdropping. The transcript of the free talk phase is known to the adversary and it may choose the inputs depending also on it. Rushing. Rushing adversary decides Bob’s input at the ‘last moment’: Rushing adversary chooses the input of Bob after Alice produces its message. That is, ﬁrst Alice’s input is chosen and Alice sends its message, and afterwards, Bob’s input is chosen depending on Alice’s message and Bob sends its message. Deﬁnition 2.9 (SM Preset Public Coins With Stateful Free Talk and Rushing Adversary). A protocol for a function f in the SM Preset Public Coins With stateful free talk and rushing adversary is deﬁned by the following game: Let Alice and Bob be PPTMs with running time poly(λ).
1. Alice and Bob toss coins and communicate in order to generate their (possibly secret) states τA and τB respectively.
2. The adversary sees their full communication (but not their internal states τA and τB) and sets Alice’s input x ∈X.
3. Alice (that has τA as her internal state) gets x and sends a message mA to the referee.
4. The adversary sees mA and chooses Bob’s input y ∈Y , optionally depending on mA and the free talk’s transcript.
5. Bob (that has τB as his internal state) gets y and sends a message mB to the referee.
[Wee07] who ruled out constructions for statistically hiding commitments with low round complexity that are based only on black-box one-way functions. Distributional Collision Resistant Hash Functions Distributional colli- sion resistant hash functions (dCRH) are functions where it is hard for any adversary to generate collisions that are close to random collisions. We ﬁrst have to deﬁne an ideal collision ﬁnder: Low Communication Complexity Protocols 265 Deﬁnition 2.15 (Ideal Collision Finder COL). The random function COL gets a description of a hash function h and outputs (x, x′) s.t. x is uniformly random and x′ is uniformly random from h−1(x). Note that:
1. The marginal distribution of x and x′ is the same: x and x′ are uniformly random (but not independent).
2. It is possible that x = x′. That notion of distributional collision resistance hash functions is due to Dubrov and Ishai [DI06]. However, Bitansky et al.
[BHKY19] deviated from this deﬁnition and used a stronger deﬁnition8. Since our results hold also for the stronger deﬁnition we will use it: Deﬁnition 2.16 (dCRH). Let a functions family H be a family of functions that (1) compress (2) are computable in polynomial time. H is a family of dis- tributional CRHs if there exists some polynomial p(·) s.t. for every PPTM Adv, and large enough λ, Δ(COL(h), Adv(h)) ≥ 1 p(λ) where h ←H. This deﬁnition is a generalization of distributional one-way functions9 and hence implies it. Furthermore, Bitansky et al. showed that dCRHs can be used for applications that one-way functions aren’t known to achieve (and are black-box separated) [BHKY19]. Although the notion of dCRH is much weaker than CRH, as noted by Dubrov and Ishai [DI06], the black-box separation result of Simon
[Hol06] proved when an (α, β)-secret bit agreement can be ampliﬁed eﬃciently to a secret key agreement: Theorem 2.20 ([Hol06, Corollary 7.5]). Let eﬃciently computable functions α(λ), β(λ), be given such that 1 −α 1 + α < β Let ϕ = max(2, 8 log( β(1+α) 1−α )) and γ = 1 log(1+((1−α)/(1+α))ϕ), and assume that ϕ·24γ α ∈poly(λ). If there exists an (α, β)-secret bit agreement protocol for all but ﬁnitely many k, then there exists a computationally secure key agreement. Note that a secret key agreement is unlikely to be based (only) on one-way permutations and collision resistant hash functions in a black-box manner: It is known that any secret key agreement protocol in the random oracle model11 can be broken using an O(n2) queries attack [IR89,BM09] and this is tight. 10 ∗is a don’t care symbol, see
[BLV18] for a comparison of “total vs. partial predicates”. 11 CRHs exist in this model. Low Communication Complexity Protocols 267 3 Collision Resistance and the Preset Public Coins Model 3.1 CRHs Imply Succinct Protocols We start by noting that the lower bounds shown in Sect. 3.2 (about the necessity of dCRHs) are almost tight, since using a CRH one can break those bounds (Ω(√n) in the SM model (Theorem 3.2) and Ω(log n) in the interactive model (Theorem 3.14)). See the full version for details. Theorem 3.1. If CRHs exist, then given a family of CRHs {h : {0, 1}n → {0, 1}λ}, In the preset public coins SM model: There exist protocols of communica- tion complexity O( √ λ) for the Equality predicate. In the preset public coins interactive model: There exist protocols of com- munication complexity O(log λ) for the Equality predicate. 3.2 Succinct Protocols Imply dCRHs Theorem 3.2. Let c(n) ≤o(√n). Given a protocol for an eﬃciently separable predicate (Deﬁnition 2.2) of complexity c(n) in the preset public coins SM model, then distributional CRH functions exist and it is possible to construct them from the protocol. Proof. Our intuition is that after ﬁxing the public random string rpub, the model is similar to the private coins SM model where the adversary is faced with a problem deﬁned by the random string. We therefore appeal to Babai and Kimmel’s deﬁnitions and techniques. Furthermore, in Lemma 3.5 we will also repeat the proof of [BK97, Lemma 2.3] with a diﬀerent constant and make it constructive. For each multiset of Alice’s messages and one message from Bob we consider the probability of acceptance by the referee: Deﬁnition 3.3 (Referee’s Expected Value for a Multiset). For any rpub, for a multiset T of members from MA and mB ∈MB, let Q(T, mB) = E i∈[t][ρrpub(T[i], mB)] = 1 t  i∈[t] ρrpub(T[i], mB) where t = |T|. Now, we show that for every input of Alice x ∈X, there exists a multiset char- acterizing the behavior of Alice on x. In other words, instead of running Alice, we can approximate the protocol’s result (referee’s output) by a uniform sample from the multiset. Furthermore, we prove that such a multiset can be found (w.h.p.) by some (relatively few) independent samples from the distribution deﬁned by Alice (given x and rpub). 268 S. P. Cohen and M. Naor Deﬁnition 3.4 (Characterizing Multiset). For any rpub, a multiset T of elements from MA characterizes Alice for x ∈X if ∀mB ∈MB, Q(T, mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]  ≤0.1 where Q(Tx, mB) is the referee’s expected value for the multiset Tx and Bob’s possible message mB ∈MB (Deﬁnition 3.3). Lemma 3.5 (Sample a Characterizing Multiset). For any rpub, for x ∈ X, let r′ = (r1 A, ..., rt A) be t independent uniform samples from RA where t = 2 · 200 · ln(2 |MB|). Then, for the multiset Tx = {Arpub(x, ri A) : i ∈[t]} it holds that ∀mB ∈MB, Pr r′ Q(Tx, mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]  ≤0.1  ≥1 − 1 2 |MB| (i.e., Tx characterizes Alice for x) Proof. Let Tx be as deﬁned. ∀i ∈[t], mB ∈MB, E[ρrpub(Tx[i], mB)] = Pr rA [ρrpub(Arpub(x, rA), mB) = 1] =⇒E  ρrpub(Tx[i], mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]  = 0 where the probability is over the random choice Tx[i] ←Arpub(x). Now, for i ∈[i], deﬁne random variables η(i) = ρrpub(Tx[i], mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]. Since the members of Tx are independent random variables, we have that all {η(i) : i ∈[t]} are independent random variables with expectation
0. Hence, we can use a Chernoﬀbound to bound the probability that, for a ﬁxed mB ∈MB,   i∈[t] η(Tx[i])  > 0.1 · t. In other words, the probability that Q(Tx, mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]  > 0.1 is bounded by Pr r′ [|  i∈[t] ρrpub(Tx[i], mB) −E[  i∈[t] ρrpub(Tx[i], mB)]| > 0.1] < 2e−(0.1)2·t 2 (Lemma 2.12) = 2e− t 200 = 2e−2 ln(2|MB|) = 1 2 |MB|2 . Low Communication Complexity Protocols 269 By the union bound (over all mB ∈MB), Pr r′  ∃mB s.t. Q(T, mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]  > 0.1  < |MB| 2 |MB|2 = 1 2 |MB| □ We deﬁne a hash function by following the process of Lemma 3.5 (running Alice t times independently): Construction 3.6. Characterizing Multiset Function Deﬁnition: The function is deﬁned by the public random string rpub and t Alice’s random tapes r1 A, ..., rt A ∈RA. Output: For x ∈X, the value of the function is the multiset as in Lemma 3.5: h(x) = The multiset {Arpub(x, ri A) : i ∈[t]} where the multiset is encoded as a sequence Arpub(x, r1 A), . . . , Arpub(x, rt A), note that every Alice’s message can be encoded using log |MA| = c bits. Observation 3.7. For all x ∈X, the function from Construction 3.6 outputs a multiset that characterizes x w.p. 1 − 1 2|MB| where the probability is over the uniform random choice of r1 A, ..., rt A ∈RA. Observation 3.8. The function from Construction 3.6 is compressing: The domain of the function is of size 2n, but the range is of size at most (2c)t = 2400c·(c+1)·ln 2 = 2Θ(c2) = 2o(n) Next, we prove that any x and x′ which share a characterizing multiset, induce bad inputs for the protocol (since Alice’s behavior on x and x′ is similar). Proposition 3.9. Let x, x′ ∈X and y ∈Y that separates them (Deﬁnition 2.1), if there is a multiset T that is characterizing for both x and x′ then, the sum of the failure probability of π(x, y) and π(x′, y) is at least 0.8. In other words, at least one of them fails. Proof. Since T is a characterizing multiset (Deﬁnition 3.4) of both x and x′, then ∀mB ∈MB Q(T, mB) −Pr rA [ρrpub(Arpub(x, rA), mB) = 1]  ≤0.1 270 S. P. Cohen and M. Naor and the same for x′. This means Pr rA [ρrpub(Arpub(x, rA), mB) = 1] ∈[Q(T, mB) ± 0.1] and Pr rA [ρrpub(Arpub(x′, rA), mB) = 1] ∈[Q(T, mB) ± 0.1] . Putting it together we get that: Pr rA [ρrpub(Arpub(x, rA), mB) = 1] −Pr rA [ρrpub(Arpub(x′, rA), mB) = 1]  ≤0.2. (1) Assume without loss of generality that f(x, y) = 0 and f(x′, y) = 1 Pr[π fails on (x, y)] = Pr rA,rB[ρrpub(Arpub(x, rA), Brpub(y, rB)) = 1] = E rA,rB [ρrpub(Arpub(x, rA), Brpub(y, rB))] = E rB  E rA [ρrpub(Arpub(x, rA), Brpub(y, rB))]  ≥E rB  E rA [ρrpub(Arpub(x′, rA), Brpub(y, rB))] −0.2  (Equation (1)) = E rB  E rA [ρrpub(Arpub(x′, rA), Brpub(y, rB))]  −0.2 = Pr rA,rB[ρrpub(Arpub(x′, rA), Brpub(y, rB)) = 1] −0.2 = Pr[π succeeds on (x′, y)] −0.2 = 1 −Pr[π fails on (x′, y)] −0.2 = 0.8 −Pr[π fails on (x′, y)] Hence, the sum of the failure probability of the protocol on (x, y) and the failure probability of the protocol on (x′, y) is Pr[π(x, y) fails] + Pr[π(x′, y) fails] ≥0.8 □ However, now we deal with the fact that there exist x’s s.t. the multiset h(x) does not characterize x (Observation 3.7). Lemma 3.10. Let π be an SM protocol of complexity c(n) = o(√n) and h(x) be as in Construction 3.6. If we have an eﬃcient adversary Advcollision that breaks the security of h as a distributional CRH for some p ∈poly(λ): Δ (Advcollision(h), COL(h)) ≤ 1 p(λ) Low Communication Complexity Protocols 271 Then, we can construct an adversary Advπ with running time of the same order as Advcollision s.t. Pr[π fails on inputs from Advπ] ≥0.4  1 − 1 p(λ) −negl(λ) Proof. Advπ’s algorithm is: Algorithm 3.11. Near Ideal Collision Finder for h to Bad Inputs for Protocol π
1. Construct h(x) using the public random string of π and as in Construction 3.6.
2. x, x′ ←Advcollision(h).
3. Find y ∈Y which separates x and x′ (promised to be eﬃcient by Deﬁnition 2.2).
4. Pass to Alice and Bob (x, y) w.p. 1/2 or (x′, y) w.p. 1/2. First, we consider COL’s distribution: A pair (x, x′) that was sampled from COL (the ideal collisions ﬁnder, Deﬁnition 2.15) will not be usable for Algo- rithm 3.11 if any of the following conditions hold:
1. x = x′.
0. That is, we start with any preset public coins SM protocol and repeat it nε times to make the error probability negligible. This protocol deﬁnes a family of PPHs and its random coins are ﬁxed when sampling a function from the family. 4 No Ultra Short Interactive Communication The power of the preset public coins model power lies between the public and the private coins models. As noted, the public random coins model is strictly more powerful than the private one: there are protocols of O(1) bits only in this model. We show (unconditionally) that in our model there are no functions with o(log log n) communication complexity: Theorem 4.1. Let c(n) : N →N be s.t. 23c(n) = O(log n) and let f : X × Y → {0, 1} be an eﬃciently separable predicate (satisfying Deﬁnition 2.2, i.e., non redundant s.t. can be proven eﬃciently). In the preset public coins interactive communication model, if the adversary has a running time of poly(λ) (where λ is the security parameter) then, there are no protocols of complexity O(c(n)). Proof. Assume there is such a protocol in the preset public coins interactive model for some non-redundant function f of complexity c(n). In the proof of Theorem 3.14 we adapted Construction 3.6 for interactive protocols. The constructed hash function has the following properties: 274 S. P. Cohen and M. Naor – Random collisions in the function induce (w.h.p.) bad inputs in the protocol (Lemma 3.10). – The range of the function is of size |SA|t = |SA|22·200 ln(2|SB|) Those properties are the key points of the adversary described by Algorithm 4.2 that searches for random collisions in a brute force manner. Algorithm 4.2. Finding Bad Inputs in Ulta-Succinct Protocols
1. Construct a characterizing function h(·) (Construction 3.6).
2. Repeat at most 3 · 223c = poly(λ) times: (a) Choose a pair x ̸= x′ ∈X uniformly at random. (b) If h(x) = h(x′): i. Find y ∈Y that separates x and x′ (can be done eﬃciently, as promised by Deﬁnition 2.2). ii. Output (x, y) w.p. 1/2 or (x′, y) w.p. 1/2 iii. Halt Let h be a characterizing function of the protocol (Construction 3.6). The proof relies on the following two claims: □ Proposition 4.3. There must be a collision in h. Proof. The range of the characterizing function h(x) is of size (number of possible characterizing sets): |SA|22·200 ln(2|SB|) = 22c·2·200 ln(22c+1) < 223c Hence, since 23c = O(log n) = o(n) there must be a collision in the function. □ Proposition 4.4. The adversary described in Algorithm 4.2 ﬁnds a collision w.h.p. Proof. Since the range is small (same order as the running time of the adversary 223c = poly(λ)), the adversary can ﬁnd random collisions easily. The probability for a random pair to collide is at least 1 223c and hence, after 3 · 223c trials, the probability that a collision was not found is at most: Pr x,x′[h(x) ̸= h(x′)]3·223c ≤ ⎛ ⎝  1 − 1 223c223c⎞ ⎠ 3 →e−3 =⇒Pr x,x′[h(x) ̸= h(x′)]3·223c < 0.05 □ Low Communication Complexity Protocols 275 We get that w.h.p. the adversary ﬁnds a collision in the function h. However, not every collision implies bad inputs for the protocol: the construction of the characterizing function implies that there exist also bad collisions: x and x′ s.t. h(x) = h(x′) but h(x) doesn’t characterizes x or x′ (recall Observation 3.7). However, in almost all collisions it is not the case and h(x) characterizes x and x′ (recall Proposition 3.13). Now, since the collision that Algorithm 4.2 ﬁnds is completely random we can conclude, Pr[the adversary ﬁnds a colliding pair] ≥1 −0.05 − 1 |SB| and by Proposition 3.9 Pr[the protocol will fail] ≥1 2 · 8 10  1 −0.05 − 1 |SB| > 1 3. □ 5 Secret Key Agreement from Eﬃcient SM Protocols 5.1 Optimal Protocols from SKA Our ﬁrst observation is that it is possible to obtain an optimal protocol (in terms of the error as a function of the communication) for the equality predicate once given a secret key agreement protocol, following relatively simple principles. The error is 2−c (where c is the communication complexity after the free talk) plus a negligible factor reﬂecting the probability of breaking the secret-key exchange. For details see the full version. Theorem 5.1. In the stateful preset public coins SM with free talk model: Given a secret key agreement protocol there is, for any c(n), a protocol for the equality predicate of complexity c(n), where any adversary can cause an incorrect answer with probability at most 2−c + negl(n), satisfying Deﬁnition 2.10. 5.2 SKA from Near Optimal Protocols Theorem 5.2. An SM protocol with stateful free talk for the equality predicate of complexity c(n) = O(log log n) for c(n) larger from some constant, that is ε-secure (Deﬁnition 2.10) with ε ≤2−0.7c(n), implies the existence of secret key- agreement protocols. Proof. Assume we have such a protocol π for the equality predicate EQ : {0, 1}n ×{0, 1}n →{0, 1}. We will use π for constructing a secret key-agreement protocol. The idea is to construct a weak secret bit agreement (Deﬁnition 2.18) that can be ampliﬁed into a full secret key agreement (α and β according to Theorem 2.20). The construction is based on the following: (α, β)-SBA protocol: 276 S. P. Cohen and M. Naor Algorithm 5.3. Weak Bit Agreement
1. Alice and Bob communicate and toss coins according to the free talk of protocol π to generate their secret states τA and τB respectively.
2. Alice selects at random a bit b ∈{0, 1} and uniformly random inputs x0, x1 ∈ {0, 1}n.
3. Alice evaluates mA = A(xb, τA) (that is, a message of the protocol π for EQ(·, ·)).
4. Alice sends to Bob (mA, x1).
5. Bob evaluates mB = B(x1, τB).
6. Alice outputs b and Bob outputs b′ = ρ(mA, mB). Lemma 5.4. Algorithm 5.3 is a α = 1 −2−c/2−3, β = 2−c/2+1 -SBA protocol. Proof. Let c = c(n). We have to show its agreement and secrecy properties: Agreement. By the properties of protocol π, speciﬁcally that the error ε ≤ 2−0.7c(n): Pr[b = b′] ≥1 − 1 20.7c ≥1 − 1 20.5c−2 = 1 + (1 −2−c/2−3) 2 = 1 + α 2 . Secrecy. We should show that for every PPTM adversary Advsba Pr[Advsba(mA, x1) = b | b = b′] ≤2 −β 2 = 2 −2−c/2+1 2 = 2c/2 −1 2c/2 . Assume towards contradiction that Pr[Advsba(mA, x1) = b | b = b′] > 2c/2−1 2c/2 . We show that given Advsba, we can construct Adveq that ﬁnds bad inputs for the protocol π (with probability higher than ε): Lemma 5.5. Given an adversary Advsba with success probability (guessing b when it is equal to b′) at least 2c/2−1 2c/2 , we can construct an adversary Adveq with running time O(6 · 2c+1) s.t. Pr[π fails on inputs from Adveq] > 2−0.7c ≥ε. Proof. The strategy of the adversary Adveq to ﬁnd bad inputs is: Algorithm 5.6. Adveq – Find Bad Inputs Using Advsba
1. Repeat at most 6 · 2c+1 times: (a) Select uniformly at random x ∈{0, 1}n and set it as Alice’s input. (b) Let Alice’s message (output) be mA ∈MA. (c) Select uniformly at random x′ ∈{0, 1}n. (d) If Advsba(x, mA) = 1 and Advsba(x′, mA) = 1: i. Pass the message mA to the referee and set Bob’s input to be either y = x w.p. 1/2 or y = x′ w.p. 1/2. ii. Halt. (e) Otherwise, continue to the next session. Low Communication Complexity Protocols 277 Recall that the private states of Alice and Bob are τA and τB (unknown to the adversary). The success of the adversary Adveq relies on choosing a colliding x′ (i.e., x′ s.t. A(x, τB) = A(x′, τB)). For x ∈{0, 1}n denote by p0 x and p1 x the probability of a random x′ ∈{0, 1}n to be bad in the following sense:
1. Let p0 x be the probability that for a random x′: x and x′ collide yet are not identiﬁed by Advsba as such. I.e., p0 x = Pr x′,Adv[A(x) = A(x′) ∧Advsba(x′, A(x, τA)) = 0].
[BLV18] proved two general lower bounds for property preserving hash functions using communication complexity12:
1. A lower bound for reconstructing predicates: Boyle et al. proved that for predicates that can be used for reconstructing the original string there cannot exist (compressing) property preserving hash functions. This lower bound is also true for our preset public coins SM model. However, we didn’t necessarily consider reconstructing predicates (for instance, the equality predicate is not a reconstructing predicate).
2. General lower bound from one-way communication: Boyle et al. proved that any property preserving hash function cannot compress better than the one- way communication complexity13. This lower bound is also true in our model, but it is too loose in our context since in our model the inputs and the public random string may be dependent (e.g., the equality predicate complexity is O(1) in the one-way communication complexity model). Multi CRHs (MCRH). For k ≥3, A familty of hash function is k-multi-collision resistant if ﬁnding a collision of size k is hard: no PPTM can succeed in ﬁnding x1, . . . , xk s.t. h(x1) = . . . = h(xk) with non-negligible probability (for k = 2 it is the regular notion of collision resistance); see [KNY18,KY18,RV22] for the relationship between MCRHs, dCRHS and CRHs. One question is whether MCRHs can be constructed from succinct protocols in a black-box manner. Secret Key Agreement. We showed a tight relationship between secret key agree- ment protocols and succinct protocols for the equality predicate in the SM pre- set public coins stateful free talk model. On the one hand, SKA can be used for constructing an equality protocol in this model, and on the other hand, equality protocols with good error in this model can be used for constructing SKA pro- tocols. The open questions are (i) whether the existence of protocols with much worse error probability (e.g., constant error probability for c which O(log log λ)) 12 See also Hardt and Woodruﬀ[HW13] who proved robustness limitations for linear functions. 13 See Fleischhacker and Simkin
[FS21] and Fleischhacker et al.
[AS08] Alon, N., Spencer, J.H.: The Probabilistic Method, 3rd edn. Wiley, Hobo- ken (2008)
[BIN97] Bellare, M., Impagliazzo, R., Naor, M.: Does parallel repetition lower the error in computationally sound protocols? In: Proceedings 38th Symposium on Foundations of Computer Science,  IEEE (1997)
[BK97] Babai, L., Kimmel, P.G.: Randomized simultaneous messages: solution of a problem of YAO in communication complexity. In: Proceedings of Compu- tational Complexity. Twelfth IEEE Conference,  IEEE (1997)
[BLV18] Boyle, E., LaVigne, R., Vaikuntanathan, V.: Adversarially robust property- preserving hash functions. In: ITCS 2019 (2018)
[BM15] Ben-Sasson, E., Maor, G.: Lower bound for communication complexity with no public randomness. Electron. Colloquium Comput. Complex. 22, 139 (2015)
[DI06] Dubrov, B., Ishai, Y.: On the randomness complexity of eﬃcient sampling. In: Proceedings of the Thirty-eighth ACM Symposium on Theory of Com- puting,  (2006)
[Hol05] Holenstein, T.: Key agreement from weak bit agreement. In: Proceedings of the 37th ACM Symposium on Theory of Computing,  (2005)
[Hol06] Holenstein, T.: Strengthening key agreement using hard-core sets. Ph.D thesis, ETH Zurich (2006)
[HW13] Hardt, M., Woodruﬀ, D.: How robust are linear sketches to adaptive inputs? In: Proceedings of the Forty-Fifth ACM Symposium on Theory of Computing,  (2013)
[IR89] Impagliazzo, R., Rudich, S.: Limits on the provable consequences of one- way permutations. In: Proceedings of the 21st ACM symposium on Theory of Computing,  (1989)
[KN96] Kushilevitz, E., Nisan, N.: Communication Complexity. Cambridge Uni- versity Press, Cambridge (1996)
[MNS11] Mironov, I., Naor, M., Segev, G.: Sketching in adversarial environments. SIAM J. Comput. 40(6), 1845–1870 (2011)
[MPSW10] Micali, S., Peikert, C., Sudan, M., Wilson, D.A.: Optimal error correction for computationally bounded noise. IEEE Trans. Inf. Theory 56(11), 5673– 5680 (2010)
[New91] Newman, I.: Private vs common random bits in communication complexity. Inf. Process. Lett. 39(2), 67–71 (1991)
[NR09] Naor, M., Rothblum, G.N.: The complexity of online memory checking. J. ACM 56(1), 1–46 (2009)
[NS96] Newman, I., Szegedy, M.: Public vs. private coin ﬂips in one round commu- nication games. In: Proceedings of the Twenty-Eighth ACM Symposium on Theory of Computing,  (1996)
[RV22] Rothblum, R.D., Vasudevan, P.N.: Collision-resistance from multi- collision-resistance. Electron. Colloquium Comput. Complex. 17 (2022)
[RY20] Rao, A., Yehudayoﬀ, A.: Communication Complexity: and Applications. Cambridge University Press, Cambridge (2020) Low Communication Complexity Protocols 281
[Yao79] Yao, A.C.-C.: Some complexity questions related to distributive comput- ing. In: Proceedings of the 11th ACM Symposium on Theory of Computing, STOC 1979,  (1979)
3. Aguilar Melchor, C., Gama, N., Howe, J., H¨ulsing, A., Joseph, D., Yue, D.: The return of the SDitH,  (2023). https://doi.org/10.1007/978-3-031- 30589-4 20
4. Akavia, A., Bogdanov, A., Guo, S., Kamath, A., Rosen, A.: Candidate weak pseu- dorandom functions in AC0 o MOD2,  (2014).https://doi.org/10.1145/ 2554797.2554821
7. Albrecht, M.R., Davidson, A., Deo, A., Smart, N.P.: Round-optimal veriﬁable oblivious pseudorandom functions from ideal lattices,  (2021). https:// doi.org/10.1007/978-3-030-75248-4 10
8. Albrecht, M.R., et al.: Feistel structures for MPC, and more,  (2019). https://doi.org/10.1007/978-3-030-29962-0 8
9. Albrecht, M.R., Rechberger, C., Schneider, T., Tiessen, T., Zohner, M.: Ciphers for MPC and FHE,  (2015). https://doi.org/10.1007/978-3-662-46800- 5 17
10. Araki, T., Furukawa, J., Lindell, Y., Nof, A., Ohara, K.: High-throughput semi- honest secure three-party computation with an honest majority, (2016). https://doi.org/10.1145/2976749.2978331
11. Badrinarayanan, S., Das, S., Garimella, G., Raghuraman, S., Rindal, P.: Secret- shared joins with multiplicity from aggregation trees,  (2022). https:// doi.org/10.1145/3548606.3560670
15. Becker, A., Coron, J.S., Joux, A.: Improved generic algorithms for hard knapsacks, (2011). https://doi.org/10.1007/978-3-642-20465-4 21
19. Boneh, D., Kogan, D., Woo, K.: Oblivious pseudorandom functions from isogenies, (2020). https://doi.org/10.1007/978-3-030-64834-3 18
20. Bonnetain, X., Bricout, R., Schrottenloher, A., Shen, Y.: Improved classical and quantum algorithms for subset-sum,  (2020). https://doi.org/10.1007/ 978-3-030-64834-3 22
21. Boyle, E., Couteau, G., Gilboa, N., Ishai, Y., Kohl, L., Rindal, P., Scholl, P.: Eﬃcient two-round OT extension and silent non-interactive secure computation, (2019). https://doi.org/10.1145/3319535.3354255
22. Boyle, E., Couteau, G., Gilboa, N., Ishai, Y., Kohl, L., Scholl, P.: Eﬃcient pseudo- random correlation generators: silent OT extension and more,  (2019). https://doi.org/10.1007/978-3-030-26954-8 16
23. Carozza, E., Couteau, G., Joux, A.: Short signatures from regular syndrome decod- ing in the head,  (2023). https://doi.org/10.1007/978-3-031-30589-4 19 306 N. Alamati et al.
24. Chase, M., et al.: Post-quantum zero-knowledge and signatures from symmetric- key primitives,  (2017). https://doi.org/10.1145/3133956.3133997
25. Chaum, D.: Blind signatures for untraceable payments,  (1982)
28. Dobraunig, C., et al.: Rasta: a cipher with low ANDdepth and few ANDs per bit, (2018). https://doi.org/10.1007/978-3-319-96884-1 22
31. Esgin, M.F., Steinfeld, R., Zhao, R.K.: MatRiCT+: more eﬃcient post-quantum private blockchain payments,  (2022). https://doi.org/10.1109/ SP46214.2022.9833655
32. Feneuil, T., Joux, A., Rivain, M.: Syndrome decoding in the head: shorter sig- natures from zero-knowledge proofs,  (2022). https://doi.org/10.1007/ 978-3-031-15979-4 19
33. Freedman, M.J., Ishai, Y., Pinkas, B., Reingold, O.: Keyword search and oblivious pseudorandom functions,  (2005). https://doi.org/10.1007/978-3-540- 30576-7 17
34. Goel, A., Green, M., Hall-Andersen, M., Kaptchuk, G.: Eﬃcient set membership proofs using MPC-in-the-head. 2022(2), 304–324 (2022). https://doi.org/10.2478/ popets-2022-0047
35. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions (extended abstract),  (1984). https://doi.org/10.1109/SFCS.1984. 715949
37. Grassi, L., Rechberger, C., Rotaru, D., Scholl, P., Smart, N.P.: MPC-friendly symmetric key primitives,  (2016). https://doi.org/10.1145/2976749. 2978332
39. H⊕stad, J., Impagliazzo, R., Levin, L.A., Luby, M.: A pseudorandom generator from any one-way function. SIAM J. Comput. 28(4), 1364–1396 (1999)
42. Howgrave-Graham, N., Joux, A.: New generic algorithms for hard knapsacks,  (2010). https://doi.org/10.1007/978-3-642-13190-5 12
45. Ishai, Y., Kilian, J., Nissim, K., Petrank, E.: Extending oblivious transfers eﬃ- ciently,  (2003). https://doi.org/10.1007/978-3-540-45146-4 9
46. Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A.: Zero-knowledge from secure multiparty computation,  (2007). https://doi.org/10.1145/1250790. 1250794
47. Kales, D., Zaverucha, G.: An attack on some signature schemes constructed from ﬁve-pass identiﬁcation schemes,  (2020). https://doi.org/10.1007/978-3- 030-65411-5 1
49. Katz, J., Kolesnikov, V., Wang, X.: Improved non-interactive zero knowledge with applications to post-quantum signatures,  (2018). https://doi.org/10. 1145/3243734.3243805
50. Kim, S., et al.: Aim: symmetric primitive for shorter signatures with stronger security. In: Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security,  (2023)
51. Levin, L.A.: One-way functions and pseudorandom generators,  (1985). https://doi.org/10.1145/22145.22185
54. Micali, S., Rabin, M.O., Vadhan, S.P.: Veriﬁable random functions, (1999). https://doi.org/10.1109/SFFCS.1999.814584
56. Mohassel, P., Rindal, P., Rosulek, M.: Fast database joins and PSI for secret shared data,  (2020). https://doi.org/10.1145/3372297.3423358
57. Naor, M., Reingold, O.: Number-theoretic constructions of eﬃcient pseudo-random functions,  (1997). https://doi.org/10.1109/SFCS.1997.646134 308 N. Alamati et al.
60. Razborov, A.A.: Lower bounds on the size of bounded depth circuits over a com- plete basis with logical addition. Math. Notes Acad. Sci. USSR 41(4), 333–338 (1987)
61. Rivest, R.L., Shamir, A., Tauman, Y.: How to leak a secret,  (2001). https://doi.org/10.1007/3-540-45682-1 32
62. Roy, L.: SoftSpokenOT: quieter OT extension from small-ﬁeld silent VOLE in the minicrypt model,  (2022). https://doi.org/10.1007/978-3-031-15802- 5 23
64. Smolensky, R.: Algebraic methods in the theory of lower bounds for Boolean circuit complexity. In: Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing,  (1987)
65. Yao, A.C.C.: Theory and applications of trapdoor functions (extended abstract), (1982). https://doi.org/10.1109/SFCS.1982.45
4. Beierle, C., et al.: SKINNY-AEAD and SKINNY-hash. IACR Trans. Symm. Cryp- tol. 2020(S1), 88–131 (2020)
10. Bernstein, D.J.: CAESAR competition call for submissions (2014). https:// competitions.cr.yp.to/caesar-call.html 294 J. P. Degabriele and V. Karadˇzi´c
[GGG+14a] to multi-authority FE
[Cha07] to multi-client FE
[CDG+18a] to dynamic decentralized FE
1. Multi-Input FE (MIFE): The primitive of multi-input FE (MIFE)
3. Dynamic Decentralized FE (DDFE): DDFE [CDSG+20], as the name suggests, is a decentralized variant of FE, where not only can ciphertexts be generated locally and independently but so can the keys. In DDFE for some functionality f, the setup step is localized and run independently by users, letting them generate their private and public keys individually. During encryption, the set of users with whom a given input or key object should be combined can be chosen dynamically. In more detail, each party can specify the set of parties with which its input may be combined, a label that controls which values should be considered together and the input zi itself. Similarly, every user can also generate a key object which specifies the set of parties with which the key may be combined, and a key vector ci. For decryption, the ciphertexts and keys from the parties who mutually agree to combine their inputs and keys are put together to compute f({zi}i, {cj}j). Note that DDFE implies MCFE which implies MIFE4. Prior Work. We summarize the state of the art below. The AWS Functionality. For the AWS functionality, even the weakest multi-input notion, namely MIFE is not known to the best of our knowledge. We note Abdalla et al.
[AGW20] did propose a multi-party extension to their FE for AWS. However, this scheme is a much weaker primitive than the standard notion of MCFE (or even MIFE), since this scheme natively only supports a single ciphertext query per slot. To extend it the setting of multiple queries, the authors make use of non-interactive MPC to enable the parties to obtain a random secret sharing of 0. In more detail, while their scheme supports labels, the difference from standard MCFE schemes is that in their scheme each party uses a one-time secret key for each encryption instead of long- term encryption key, and the one-time keys are generated via non-interactive MPC run between the parties. Specifically, their scheme consists of five algorithms (Setup, OTSKGen, Enc, KeyGen, Dec), and Setup, KeyGen, Dec are the same as those in standard MCFE. OTSKGen(1λ) is a non-interactive proto- col where party i obtains one-time secret key otski as the output of the protocol. Enc(otski, xi) takes otski and a message xi and outputs a ciphertext CTi for party i. Correctness holds, i.e., decrypting a set {CTi}i∈[n] of ciphertexts with a secret key for f reveals f(x1, . . . , xn), only when the set of ciphertexts are generated under the one-time secret keys {otski}i∈[n] derived from a single running of OTSKGen(1λ). The one-time secret-key can be used only once for encryption, otherwise security does not hold any more. Thus, this notion is even weaker than the variant of MCFE with one-time labeling restriction
1. The generalization to multi-input predicate encryption additionally allows to hide the attributes yi. In this setting, Agrawal, Yadav and Yamada
[AYY22] recently provided a construction for arbitrary predicates in NC1 from pairings and Learning With Errors. Additionally, Francati et al.
[AYY22] for a conjunction of predicates represented as ABP. Thus, our construction supports the functionality g(y1, . . . , yn) = V(gi(yi) = 0), where each gi is an ABP. In contrast, the MIABE construction of
[AYY22] supports an arbitrary g ∈NC1 but only outputs a fixed message whereas our construction supports the AWS functionality. Additionally, our construction also supports a stronger security model which allows user corruption. In more detail, the MIABE construction of
1. Comparison with Prior Work in MIABE and MIPE. Note that Koala is a non-standard knowledge type assumption on pairings. For
2. Prior state of the art and our results. We do not consider function hiding or MCFE schemes with only one time labels. Above, we denote y = (y1, . . . , yn), z = (z1, . . . , zn) or z = (zi)i∈S. S is some subset of authorized users for a given key. A function fi is a monotone span programs fixed in setup. Functions fi, gi, hi are arithmetic branching programs chosen in key generation. the functionality computes: f ′({i, ki}i∈U′ K, {i, mi}i∈U′ M ) = (P i∈U′ K P j∈[Ni]⟨fi(xi,j), zi,j⟩ if the conditions below are satisfied ⊥ otherwise The conditions are:
1. U′ K = U′ M and ∀i ∈U′ K, UK,i = UM,i = U′ K.
2. ∀i,i′∈U′ K, ¯fi = ¯fi′ and Li = Li′. We summarize prior work in Table
2. Please see
28. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or a com- pleteness theorem for protocols with honest majority. In: Aho, A. (ed.) 19th ACM STOC,  ACM Press (1987). https://doi.org/10.1145/28395.28420 Sometimes You Can’t Distribute Random-Oracle-Based Proofs 357
29. Goldreich, O., Micali, S., Wigderson, A.: Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems. J. ACM 38(3), 691–729 (1991)
30. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interactive proof-systems (extended abstract). In: 17th ACM STOC,  ACM Press (1985). https://doi.org/10.1145/22145.22178
33. Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A.: Zero-knowledge from secure multiparty computation. In: Johnson, D.S., Feige, U. (eds.) 39th ACM STOC,  ACM Press (2007). https://doi.org/10.1145/1250790.1250794
nathanielclizbe@MacBookAir citation-analysis % 
