[2] Algorand. Pairing plus library, 2020. https://github. com/algorand/pairing-plus.
[3] Algorand. Source code for pointproofs, 2020. https: //github.com/algorand/pointproofs.
[4] Arvind Arasu, Ken Eguro, Raghav Kaushik, Donald Kossmann, Pingfan Meng, Vineet Pandey, and Ravi Ra- mamurthy. Concerto: A high concurrency key-value store with integrity. In Semih Salihoglu, Wenchao Zhou, Rada Chirkova, Jun Yang, and Dan Suciu, editors, SIG- MOD 2017, pages 251â€“266. ACM, 2017.
[6] Paulo S. L. M. Barreto, Ben Lynn, and Michael Scott. Constructing elliptic curves with prescribed embed- ding degrees. In Stelvio Cimato, Giuseppe Persiano, and Clemente Galdi, editors, Security in Communica- tion Networks, pages 257â€“267, Berlin, Heidelberg, 2003. Springer Berlin Heidelberg.
[8] Eli Ben-Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers, Eran Tromer, and Madars Virza. Zerocash: Decentralized anonymous payments from bitcoin. In SP 2014, Berkeley, CA, USA, May 18-21, 2014, pages 459â€“474. IEEE Computer Society, 2014.
[10] Manuel Blum, William S. Evans, Peter Gemmell, Sam- path Kannan, and Moni Naor. Checking the correct- ness of memories. In FOCS 1991, San Juan, Puerto Rico, 1-4 October 1991, pages 90â€“99. IEEE Computer Society, 1991. Later appears as [11], which is avail- able at http://citeseerx.ist.psu.edu/viewdoc/ summary?doi=10.1.1.29.2991.
[11] Manuel Blum, William S. Evans, Peter Gemmell, Sam- path Kannan, and Moni Naor. Checking the correct- ness of memories. Algorithmica, 12(2/3):225â€“244, 1994. Available at http://citeseerx.ist.psu.edu/ viewdoc/summary?doi=10.1.1.29.2991.
[15] Vitalik Buterin. The stateless client concept, 2017. https://ethresear.ch/t/the-stateless- client-concept/172.
[16] Vitalik Buterin. An incomplete guide to rollups, 2021. https://vitalik.ca/general/2021/01/05/ rollup.html.
[18] Kyle Croman, Christian Decker, Ittay Eyal, Adem Efe Gencer, Ari Juels, Ahmed Kosba, Andrew Miller, Pra- teek Saxena, Elaine Shi, and Emin GÃ¼n. On scaling decentralized blockchains. In Proc. 3rd Workshop on Bitcoin and Blockchain Research, 2016.
[20] Justin Drake. Accumulators, scalability of UTXO blockchains, and data availability. https:// ethresear.ch/t/accumulators-scalability-of- utxo-blockchains-and-data-availability/176, 2017.
[23] Alex Gluchowski. Introducing zkSync: the missing link to mass adoption of Ethereum. https://medium.com/matter-labs/introducing- zk-sync-the-missing-link-to-mass-adoption- of-ethereum-14c9cea83f58.
[28] Jonathan Lee, Kirill Nikitin, and Srinath T. V. Setty. Replicated state machines without replicated execution. In SP 2020, pages 119â€“134. IEEE, 2020.
[29] Derek Leung, Leonid Reyzin, and Nickolai Zeldovich. Aardvark prototype artifact, 2020. https://github. com/derbear/aardvark-prototype.
[31] Loopring: zkRollup exchange and payment protocol. https://loopring.org/.
[33] Andrew Miller. Storing UTXOs in a balanced Merkle tree (zero-trust nodes with O(1)-storage), 2012. https://bitcointalk.org/index.php? topic=101734.msg1117428.
[34] Andrew Miller, Michael Hicks, Jonathan Katz, and Elaine Shi. Authenticated data structures, generically. In Suresh Jagannathan and Peter Sewell, editors, POPL â€™14, pages 411â€“424. ACM, 2014. Project page and full ver- sion at http://amiller.github.io/lambda-auth/ paper.html.
[36] Babis Papamanthou. Private Communication.
[42] SCIPR-Lab. Zexe, 2020. https://github.com/ scipr-lab/zexe.
[43] Supranational. blst, 2020. https://github.com/ supranational/blst. 15
[44] Roberto Tamassia and Nikos Triandopoulos. Certifi- cation and authentication of data structures. In Al- berto H. F. Laender and Laks V. S. Lakshmanan, editors, AMW 2010, volume 619 of CEUR Workshop Proceed- ings. CEUR-WS.org, 2010.
[45] Peter Todd. Making UTXO set growth irrele- vant with low-latency delayed TXO commitments, 2016. https://petertodd.org/2016/delayed- txo-commitments.
[52] Yupeng Zhang. vector commitment scheme with effi- cient updates, 2019. https://github.com/starzyp/ vcs. A Security Analysis Agrawal and Raghuraman
1. Let (cinit,winit,pp) â†Init(Î»)
2. Set s := sinit, c := cinit, w := winit, i := 0.
1. Let (cinit,winit,pp) â†Init(Î»)
2. Set c := cinit, s := sinit.
3. For some number of iterations polynomial in Î», do the following in a loop: (a) Query A to get (o,x,Ïƒ) â†A(pp,Î») where o âˆˆ O,x = (xs,xd) âˆˆX,Ïƒ âˆˆÎ£. (b) Set (sâ€²,y) := F (s,o,x) and set (câ€², Â¯y) = F(c,o,x,Ïƒ). (c) If Vpp(c,o,xs,Ïƒ) = 1 and y Ì¸= Â¯y, output FAIL and halt. (d) If Vpp(c,o,xs,Ïƒ) = 1, set c := câ€² and s := sâ€².
1. After t operations, the validators hold commit- ments to the past min(t,Ï„) snapshots, as well as min(t,Ï„) most recent operations, with all but negligible probability. Proof. We prove the lemma by induction on t. The base case holds by design, so consider the inductive hypothesis. Any operation Î³ for a key k must come with a context relative to a snapshot Â¯etâ€² with t âˆ’Ï„ â‰¤tâ€² â‰¤t, or else the validator will reject. By the binding property of the vector commitment, the context will contain accurate information on the slot that holds k (and its predecessor in case of deletes) for the snapshot Â¯etâ€², or else the vector commitment verification algorithm (which gets correct inputs by the inductive hypoth- esis, because the validator has correct Â¯ctâ€²) will reject with all but negligible probability. If the validator rejects the operation then neither the snapshot nor the validator state changes, and the inductive case holds. If the validator accepts the operation, it will use CommitUpdate to compute the new commitment for the snap- shot Â¯et+1. Because the validator has the information relevant to the operation from Â¯etâ€² and all the operations that happened since tâ€², the validator can correctly compute the difference between the latest snapshot Â¯et and the new snapshot Â¯et+1 pro- duced by the operation. By the correctness of CommitUpdate, the validator will compute the correct commitment to this new snapshot, and the inductive case holds. A.3.3 Snapshots Encode the Ideal Map The second invariant we must show is that snapshots encode the ideal map in a manner consistent with read and write operations. Since read changes neither the snapshot nor the map, we focus only on write. We define a snapshot Â¯e to be well-formed if the following conditions hold. â€¢ For any k, a triple (k,v1,succ(k)) appears in Â¯e at most once. â€¢ If k Ì¸= âŠ¥and (k,v,kâ€²) âˆˆÂ¯e, v Ì¸= âŠ¥. In other words, all keys (not the sentinel key âŠ¥) which are in a slot are mapped to a value which is not âŠ¥. â€¢ For all (k,v,kâ€²) âˆˆÂ¯e, it is the case that kâ€² = succ(k) (rela- tive to the list of keys in Â¯e). In other words, the successor- references in Â¯e form a valid circularly-linked list of keys. From this definition, it follows that there exists a natural decoding function D from well-formed snapshots to ideal maps m. Namely, since for all slots (k,v,kâ€²) âˆˆÂ¯e, (k,v) appears uniquely, it follows that D defines the map m where m(k) = v if (k,v) appears in Â¯e and m(k) = âŠ¥otherwise. We will now show that the invariant holds by induction. The base case follows by our initialization. The inductive step is given by the following lemma. Lemma
2. Suppose Â¯e is well-formed, D(Â¯e) = m, and Î³ = (write,(k,v),Ïƒ). Let Â¯eâ€² = A(Â¯e,Î³). Let mâ€² be the map given 18 by mâ€²(k) = v and mâ€²(kâ€²) = m(kâ€²) for all kâ€² Ì¸= k. Then Â¯eâ€² is well-formed, and D(Â¯eâ€²) = mâ€². Proof. The lemma follows by inspection of A (for the case of v = âŠ¥and the case of v Ì¸= âŠ¥) as defined in Section A.3.1. 19
[4] Ittai Abraham, Philipp Jovanovic, Mary Maller, Sarah Meiklejohn, Gilad Stern, and Alin Tomescu. Reaching consensus for asynchronous distributed key generation. In ACM PODC, 2021.
[5] Ittai Abraham, Dahlia Malkhi, and Alexander Spiegelman. Asymptot- ically optimal validated asynchronous byzantine agreement. In ACM PODC, 2019.
[7] Joshua Baron, Karim El Defrawy, Joshua Lampkins, and Rafail Ostrovsky. Communication-optimal proactive secret sharing for dynamic groups. In ACNS, 2015.
[9] Donald Beaver, Silvio Micali, and Phillip Rogaway. The round complexity of secure protocols. In ACM STOC, 1990.
[18] Miguel Castro and Barbara Liskov. Practical byzantine fault tolerance and proactive recovery. ACM TOCS, 2002.
[23] Yvo Desmedt and Sushil Jajodia. Redistributing secret shares to new access structures and its applications. Technical report, Citeseer, 1997.
[28] Sanjam Garg, Craig Gentry, Amit Sahai, and Brent Waters. Witness encryption and its applications. In ACM STOC, 2013.
[34] Eleftherios Kokoris-Kogias, Enis Ceyhun Alp, Linus Gasser, Philipp Jo- vanovic, Ewa Syta, and Bryan Ford. Calypso: Private data management for decentralized ledgers. In Proc. VLDB Endow., 2020.
[36] Subramanian Lakshmanan, Mustaque Ahamad, and H Venkateswaran. Responsive security for stored data. IEEE TPDS, 2003.
[37] Yunqi Li. Honeybadgerswap: Making mpc as a sidechain, 2021.
[39] Dahlia Malkhi and Michael Reiter. Byzantine quorum systems. Distributed computing, 1998.
[41] Michael A Marsh and Fred B Schneider. Codex: A robust and secure secret distribution system. IEEE TDSC, 2004.
[42] Ricardo Padilha and Fernando Pedone. Belisarius: Bft storage with confidentiality. In 2011 IEEE 10th International Symposium on Network Computing and Applications. IEEE, 2011.
[43] David A Schultz, Barbara Liskov, and Moses Liskov. Mobile proactive secret sharing. In ACM PODC, 2008.
[44] Adi Shamir. How to share a secret. Communications of the ACM, 1979.
[46] Theodore M Wong, Chenxi Wang, and Jeannette M Wing. Verifiable secret redistribution for archive systems. In IEEE SISW, 2002.
[48] Maofan Yin, Dahlia Malkhi, Michael K Reiter, Guy Golan Gueta, and Ittai Abraham. Hotstuff: Bft consensus with linearity and responsiveness. In ACM PODC, 2019.
[1] Archita Agarwal, Maurice Herlihy, Seny Kamara, and Tarik Moataz. Encrypted databases for differential pri- vacy. PoPETs, 2019(3):170â€“190, July 2019.
[2] Rakesh Agrawal, Jerry Kiernan, Ramakrishnan Srikant, and Yirong Xu. Order preserving encryption for nu- meric data. In Proceedings of the 2004 ACM SIGMOD international conference on Management of data, pages 563â€“574, 2004.
[3] Panagiotis Antonopoulos, Arvind Arasu, Kunal D Singh, Ken Eguro, Nitish Gupta, Rajat Jain, Raghav Kaushik, Hanuma Kodavalla, Donald Kossmann, Nikolas Ogg, et al. Azure sql database always encrypted. In Proceed- ings of the 2020 ACM SIGMOD International Confer- ence on Management of Data, pages 1511â€“1525, 2020.
[4] Alexandre Anzala-Yamajako, Olivier Bernard, Matthieu Giraud, and Pascal Lafourcade. No such thing as a small leak: Leakage-abuse attacks against symmetric searchable encryption. In International Conference on E-Business and Telecommunications, pages 253â€“277. Springer, 2019.
[16] Zhao Chang, Dong Xie, Sheng Wang, and Feifei Li. Towards practical oblivious join. In Proceedings of the 2022 International Conference on Management of Data, pages 803â€“817, 2022.
[21] Craig Gentry. Fully homomorphic encryption using ideal lattices. In Michael Mitzenmacher, editor, 41st ACM STOC, pages 169â€“178. ACM Press, May / June 2009.
[24] Oded Goldreich. Towards a theory of software protec- tion and simulation by oblivious RAMs. In Alfred Aho, editor, 19th ACM STOC, pages 182â€“194. ACM Press, May 1987.
[28] Florian Hahn, Nicolas Loza, and Florian Kerschbaum. Joins over encrypted data with fine granular security. In 2019 IEEE 35th International Conference on Data Engineering (ICDE), pages 674â€“685. IEEE, 2019.
[35] Harold W Kuhn. The hungarian method for the as- signment problem. Naval research logistics quarterly, 2(1-2):83â€“97, 1955.
[41] Raluca Ada Popa, Catherine M. S. Redfield, Nickolai Zeldovich, and Hari Balakrishnan. Cryptdb: A practical encrypted relational dbms. In In Proceedings of the 23rd ACM Symposium on Operating Systems Principles (SOSP), Cascais, Portugal, October 2011. ACM.
[45] Lei Xu, Huayi Duan, Anxin Zhou, Xingliang Yuan, and Cong Wang. Interpreting and mitigating leakage-abuse attacks in searchable symmetric encryption. IEEE Trans- actions on Information Forensics and Security, 16:5310â€“ 5325, 2021.
[46] Lei Xu, Leqian Zheng, Chengzhi Xu, Xingliang Yuan, and Cong Wang. Leakage-abuse attacks against forward and backward private searchable symmetric encryption. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security, pages 3003â€“ 3017, 2023.
[49] Zheguang Zhao, Seny Kamara, Tarik Moataz, and Stan Zdonik. Encrypted databases: From theory to systems. In CIDR, 2021. A Column Equality Theory This section contains theorems and proofs omitted from the main text for brevity. We recall an attack from prior work in Figure
10. The following definition and lemma are useful in proofs below. Definition
2. Let V be an n element set, m â‰¤n be an inte- ger, âƒ—c = (c1,...,cm,u) âˆˆZm+1, and Ï âˆˆDist(V). We call a function f : [m] â†’V non-crossing if for any i, j âˆˆ[m] Ï(f(i)) < Ï(f(j)) =â‡’ci â‰¤cj and ci < cj =â‡’Ï(f(i)) â‰¤Ï(f(j)). Lemma
1. Let V be an n element set, m â‰¤n be an integer,âƒ—c = (c1,...,cm,u) âˆˆZm+1, and Ï âˆˆDist(V). Then, if f maximizes Pr[âƒ—c|f = f,Ï], then f is non-crossing. We defer the proof of Lemma 1 to the full version. Theorem
3. For every n element set V, âƒ—c âˆˆZn Ã— {0} and Ï âˆˆDist(V), and p > 1 Lp(âƒ—c,Ï) outputs a plaintext mapping g such that Pr[âƒ—c|f = g,Ï] = maxf Pr[âƒ—c|f = f,Ï]. We defer the proof of Theorem 3 to the full version. Theorem
4. There exists a 4 element set V,âƒ—c âˆˆZ5, and Ï âˆˆ Dist(V), such that L1(âƒ—c,Ï) may output a plaintext mapping g such that Pr[âƒ—c|f = g,Ï] < maxf Pr[âƒ—c|f = f,Ï]. We defer the proof of Theorem 4 to the full version. Theorem
[1] ï¬x prng key reuse in differential privacy exam- ple by mattjj Â· Pull Request #3646 Â· google/jax â€” github.com. https://github.com/google/jax/ pull/3646. [Accessed 28-Jan-2023].
[3] ALTSCHULER, J. M., AND TALWAR, K. Privacy of noisy stochastic gradient descent: More iterations with- out more privacy loss. arXiv preprint arXiv:2205.13710 (2022).
[4] BALLE, B., CHERUBIN, G., AND HAYES, J. Recon- structing training data with informed adversaries. arXiv preprint arXiv:2201.04845 (2022).
[7] CARLINI, N., IPPOLITO, D., JAGIELSKI, M., LEE, K., TRAMER, F., AND ZHANG, C. Quantifying memo- rization across neural language models. arXiv preprint arXiv:2202.07646 (2022).
[9] DE, S., BERRADA, L., HAYES, J., SMITH, S. L., AND BALLE, B. Unlocking high-accuracy differentially pri- vate image classiï¬cation through scale. arXiv preprint arXiv:2204.13650 (2022).
[10] DING, Z., WANG, Y., WANG, G., ZHANG, D., AND KIFER, D. Detecting violations of differential privacy. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (2018),
[11] DONG, J., ROTH, A., AND SU, W. J. Gaussian differ- ential privacy. arXiv preprint arXiv:1905.02383 (2019).
[13] JAGIELSKI, M., THAKKAR, O., TRAMER, F., IP- POLITO, D., LEE, K., CARLINI, N., WALLACE, E., SONG, S., THAKURTA, A., PAPERNOT, N., ET AL. Measuring forgetting of memorized training examples. arXiv preprint arXiv:2207.00099 (2022).
[14] JAGIELSKI, M., ULLMAN, J., AND OPREA, A. Audit- ing differentially private machine learning: How private is private sgd? Advances in Neural Information Process- ing Systems 33 (2020), 22205â€“22216.
[16] KAIROUZ, P., OH, S., AND VISWANATH, P. The com- position theorem for differential privacy. In Interna- tional conference on machine learning (2015), PMLR,
[17] KATZ, D., BAPTISTA, J., AZEN, S., AND PIKE, M. Obtaining conï¬dence intervals for the risk ratio in cohort studies. Biometrics (1978), 469â€“474.
[19] LU, F., MUNOZ, J., FUCHS, M., LEBLOND, T., ZARESKY-WILLIAMS, E., RAFF, E., FERRARO, F., AND TESTA, B. A general framework for auditing dif- ferentially private machine learning. arXiv preprint arXiv:2210.08643 (2022).
[20] MADDOCK, S., SABLAYROLLES, A., AND STOCK, P. Canife: Crafting canaries for empirical privacy measurement in federated learning. arXiv preprint arXiv:2210.02912 (2022).
[21] MIRONOV, I. RÃ©nyi differential privacy. In 2017 IEEE 30th computer security foundations symposium (CSF) (2017), IEEE,
[22] NASR, M., HAYES, J., STEINKE, T., BALLE, B., TRAMÃˆR, F., JAGIELSKI, M., CARLINI, N., AND TERZIS, A. Tight auditing of differentially private machine learning. arXiv preprint arXiv:2302.07956 (2023).
[26] STEVENS, T., NGONG, I. C., DARAIS, D., HIRSCH, C., SLATER, D., AND NEAR, J. P. Backpropagation clip- ping for deep learning with differential privacy. arXiv preprint arXiv:2202.05089 (2022).
[27] TRAMÃˆR, F., TERZIS, A., STEINKE, T., SONG, S., JAGIELSKI, M., AND CARLINI, N. Debugging differ- ential privacy: A case study for privacy auditing. arXiv preprint arXiv:2202.12219 (2022).
[28] TRAMER, F., TERZIS, A., STEINKE, T., SONG, S., JAGIELSKI, M., AND CARLINI, N. Debugging differ- ential privacy: A case study for privacy auditing. arXiv preprint arXiv:2202.12219 (2022).
[29] WANG, J. T., MAHLOUJIFAR, S., WU, T., JIA, R., AND MITTAL, P. A randomized approach for tight privacy accounting. arXiv preprint arXiv:2304.07927 (2023).
[30] WANG, Y., DING, Z., KIFER, D., AND ZHANG, D. Checkdp: An automated and integrated approach for proving differential privacy or ï¬nding precise counterex- amples. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Secu- rity (2020),
[32] YE, J., AND SHOKRI, R. Differentially private learning needs hidden state (or much faster convergence). arXiv preprint arXiv:2203.05363 (2022).
[33] YEOM, S., GIACOMELLI, I., FREDRIKSON, M., AND JHA, S. Privacy risk in machine learning: Analyzing the connection to overï¬tting. In 2018 IEEE 31st computer security foundations symposium (CSF) (2018), IEEE,
[35] ZANELLA-BÃ‰GUELIN, S., WUTSCHITZ, L., TOPLE, S., SALEM, A., RÃœHLE, V., PAVERD, A., NASERI, M., AND KÃ–PF, B. Bayesian estimation of differential pri- vacy. arXiv preprint arXiv:2206.05199 (2022). A Using PLD to approximate the trade off function PLD does not have a closed-form trade-off function, but we can evaluate empirically a lower bound for a given FPR. We 0.0 0.2 0.4 0.6 0.8 1.0 Type I Error (FPR) 0.0 0.2 0.4 0.6 0.8 1.0 Type II Error (FNR) Optimal bound DP bound PLD approximated bound (n=10) Figure 13: Comparison of the trade-off functions when using an approximation of PLD compared to the optimal curve. approximate the trade-off function using Algorithm 4, which will give us a looser bound for Îµ, however, the difference is in the order of 10âˆ’1. Figure 13 compares the approximation approach in Algorithm 4 to the optimal trade-off function, as we can see, even with 10 approximations we can get a good estimation of the trade-off function. In Section 6, we will present experiments that provide lower bounds for a single step of DP-SGD and multiple steps, they will use the GDP and PLD formulations, respectively. Algorithm 4 Approximating a lower bound on trade-off func- tion using PLD Args: fM privacy analysis function (outputs Îµ for a given Î´), n number of approximation lines, Î´ target delta in pri- vacy analysis âˆ†â†n linearly spaced points between [Î´,1âˆ’Î´] for Î´â€² âˆˆâˆ†do Ë†Îµ â†fM (Î´â€²) lÎ´â€²(x) := max(0,1âˆ’Î´â€² âˆ’(xeË†Îµ),eâˆ’Ë†Îµ(1âˆ’Î´â€²âˆ’x)) end for l(x) := minÎ´â€²âˆˆâˆ†lÎ´â€²(x) return l B Effect Of Auditing Choices B.1 Choosing a Canary Gradient We ï¬rst investigate how the canary gradient affects the es- timated privacy bound. We construct the canary gradient in three ways:
1. Dirac canary: All gradient values are zero except at a single index.
2. Constant canary: All gradient values have the same value.
1. Mislabeled example: We select a random example from the test dataset of the model and we select a random label (that is not equal to the original label).
2. Blank example: We craft an input where all dimensions of the input are equal to zero.
3. Adversarial example: We apply Projected Gradient De- scent (PGD) to generate adversarial example on a ran- dom example from the test dataset. Mislabel Blank Adv Crafted 0.0 0.5 1.0 1.5 Empirical Epsilon Upper bound Figure 15: Comparison of the different canary crafting ap- proaches in input space for CIFAR-10 dataset using WRN architecture.
16. We ï¬nd that indeed, the ï¬rst part of training does leak more information than later in training on the CIFAR-10 dataset. However, when we evaluate the random dataset we do not see the same behavior (please note that, if we only look at a very small number (<100) of the iterations we get a very loose bound on Îµ because we do not have enough observations to have a sufï¬ciently conï¬dent estimation). Understanding why we cannot lower bound from our audit becomes looser in later iterations requires further investigation which we leave for future work. Nevertheless, the results suggest that when we limit the adversary to canaries in the input space then model architecture, underlying dataset and the how well a model has been trained all have an effect on privacy leakage. C.2 Do larger models leak more privacy? Recent work has shown the larger models have a greater capac- ity to memorize training data verbatim [7]. We investigate if the same trend holds when training with DP-SGD by compar- ing lower bounds on a WRN-16 and WRN-40 model. Results are shown in Figure
17. Interestingly, if one was to use a non f-DP auditing method, one would make an incorrect conclu- sion that the WRN-16 leaks more than the WRN-40. Using our f-DP auditing method, we identify that, indeed, the larger WRN-40 model leaks slightly more than the WRN-16 model. C.3 Does augmentation multiplicity affect pri- vacy lower bounds? In De et al. [9], data augmentation was a key ingredient in achieving state-of-the-art results on CIFAR-10. In particu- f-DP (ZB) f-DP (CP) ( , )-DP (ZB) -DP (Katz) ( , )-DP (CP) 0.0 0.5 1.0 1.5 Empirical Epsilon Upper bound WRN-40 WRN-16 Figure 17: Comparison of how model architecture (WRN-16 and -40) affects the Îµ lower bound. 1 2 4 8 16 Augmult 0.0 0.5 1.0 1.5 Empirical Epsilon Upper bound Figure 18: How the value for Augmult
[2] Sebastian Angel, Hao Chen, Kim Laine, and Srinath T. V. Setty. PIR with compressed queries and amortized query processing. In S&P. IEEE, 2018.
[3] Vladimir L. Arlazarov, E. A. Dinic, M. A. Kronrod, and I. A. Faradzev. On economical construction of the transitive closure of an oriented graph. Journal of USSR Academy of Sciences, 1970.
[5] Daniel Augot, FranÃ§oise Levy-Dit-Vehel, and Abdullatif Shikfa. A storage-efï¬cient and robust private informa- tion retrieval scheme allowing few servers. In CANS. Springer, 2014.
[7] Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval Ishai. Lightweight techniques for private heavy hitters. In S&P. IEEE, 2021.
[9] Stefan Brechtken. GPU and CPU acceleration of a class of kinetic lattice group models. Computers and Mathematics with Applications, 2014.
[10] Benny Chor, Oded Goldreich, Eyal Kushilevitz, and Madhu Sudan. Private information retrieval. In FOCS. IEEE, 1995.
[13] Henry Corrigan-Gibbs and Dmitry Kogan. Private infor- mation retrieval with sublinear online time. In EURO- CRYPT. Springer, 2020.
[14] Wei Dai, Yarkin DorÃ¶z, and Berk Sunar. Accelerating SWHE based pirs using GPUs. In FC. Springer, 2015.
[16] Daniel Demmler, Marco Holz, and Thomas Schneider. OnionPIR: Effective protection of sensitive metadata in online communication networks. In ACNS, 2017.
[18] Yarkin DorÃ¶z, Berk Sunar, and Ghaith Hammouri. Band- width efï¬cient PIR from NTRU. In FC. Springer, 2014.
[19] Zeev Dvir and Sivakanth Gopi. 2 Server PIR with sub- polynomial communication. In STOC. ACM, 2015.
[24] Yael Gertner, Yuval Ishai, Eyal Kushilevitz, and Tal Malkin. Protecting data privacy in private information retrieval schemes. In STOC. ACM, 1998.
[25] Ian Goldberg. Improving the robustness of private infor- mation retrieval. In S&P. IEEE, 2007.
[30] Troy Hunt. Have i been pwnd? https:// haveibeenpwned.com/, 2019.
[34] Eyal Kushilevitz and Rafail Ostrovsky. Replication is not needed: Single database, computationally-private information retrieval. In FOCS. IEEE, 1997.
[36] Sunil B. Mane, Sandip B. Bansode, and Pradeep K. Sinha. Optimized private information retrieval us- ing graphics processing unit with reduced accessibility. In International IT Conference & Exhibition (CUBE). ACM, 2012.
[37] Mihai Maruseac, Gabriel Ghinita, Ming Ouyang, and Razvan Rughinis. Hardware acceleration of private information retrieval protocols using gpus. In ASAP. IEEE, 2015.
[38] Carlos Aguilar Melchor, BenoÃ®t Crespin, Philippe Ga- borit, Vincent Jolivet, and Pierre Rousseau. High-speed private information retrieval computation on GPU. In SECURWARE. IEEE, 2008.
[39] Carlos Aguilar Melchor and Philippe Gaborit. A lattice- based computationally-efï¬cient private information re- trieval protocol. In WEWORC. Springer, 2007.
[40] Moni Naor and Benny Pinkas. Oblivious transfer and polynomial evaluation. In STOC. ACM, 1999.
[43] Shane Ryoo, Christopher I. Rodrigues, Sara S. Bagh- sorkhi, Sam S. Stone, David B. Kirk, and Wen Mei W. Hwu. Optimization principles and application perfor- mance evaluation of a multithreaded GPU using CUDA. In PPOPP. ACM, 2008.
[45] Jeff Shiner. Finding pwned passwords with 1password. https://blog.1password.com/finding- pwned-passwords-with-1password/, 2019.
3. (For example by resending the same seeds.) Recall that for a query of the client, the client sends information that is embedded in a ï¬‚ip chunk that is sent to one server. This information is based on the client input and on the seeds received from t âˆ’1 other servers. The ï¬‚ip chunk is computed as the exclusive-or of the expansion of the t âˆ’1 seeds and the query. There are only two possible cases: In the ï¬rst case one of the corrupt servers is the recipient of the ï¬‚ip chunk. In the second case, the recipient of the ï¬‚ip chunk is not corrupt. In the ï¬rst case, it must hold that at least one of the t âˆ’1 seeds that were expanded to strings that were XORed into the ï¬‚ip chunk, was generated by an honest server. This seed is random and unknown to the corrupt servers, and therefore the string that is XORed into the ï¬‚ip chunk looks pseudo-random to them. Therefore, a standard argument can show that if they can distinguish that ï¬‚ip chunk from a random string then they can also break the pseudo-randomness of the pseudo-random generator that was used to expand the seed. The other case is where all t âˆ’1 non-ï¬‚ip chunks affecting the generation of a ï¬‚ip chunk are chosen by corrupt servers. In this case the resulting ï¬‚ip-chunk is sent to another server, which is not part of the corrupt coalition, and therefore the security property required by Deï¬nition 3 is preserved. (We must comment that in this case the corrupt servers might cause the ï¬‚ip chunk to reveal information about the queries. For example, if they repeat using the same seeds for two queries, the exclusive-or of the ï¬‚ip-chunks of the two queries will be equal to the exclusive-or of the queries. But since these ï¬‚ip chunks are sent to an additional server which is not part of the coalition, the requirement of Deï¬nition 3 is preserved.)7 C Complexity Analysis of CIP-PIR In this section we compare the communication, computation and storage complexities of RAID-PIR [15,16] and our new CIP-PIR scheme (cf. Â§3.2). We further show experimental delay times and storage overheads of CIP-PIR. Complexities. Table 2 compares the communication, com- putation and storage complexities of RAID-PIR and CIP- PIR. To minimize the number of variables, we set the block- size b = p |DB|/n which is the optimal blocksize for n servers and database size |DB| (cf. Â§3.3) . The number of blocks is B = |DB|/b = n p |DB| and the number of blocks per chunk is k = B/n = p |DB|. Communication. The total amount of communication is the same in both schemes. In both schemes, a Îº bit seed is uploaded (RAID-PIR) or downloaded (CIP-PIR). The query for both schemes has B/n = p |DB| bits and an answer from one server has size b = p |DB|/n, i.e., all n answers have in total size p |DB|. However, our CIP-PIR scheme needs one additional round-trip to receive the seeds from the servers, which results in slightly higher communication time. Server Computation. The serverâ€™s average online compu- tation in our CIP-PIR protocol is rÃ— smaller than in RAID- PIR. In CIP-PIR, one server processes only one chunk of size kb = |DB|/n whereas a RAID-PIR server processes r chunks, where r is the threshold and k is the number of blocks per chunk. We give the average number of XOR operations as the actual number depends on the number of 1-bits in the clientâ€™s query that is on average k/2 per chunk. Thus, we as- sume that a server only needs to touch k/2 blocks per chunk. Note that the database preprocessing (cf. Â§2.1) that is used by RAID-PIR and in our implementation improves the costly dependence on the clientâ€™s query to a constant number of XOR operations (cf.
3. While the difference between the queue size of a 0.8 GB and 4 GB (5Ã— larger) database is 174 MB, the difference between the 4 GB and 8 GB (only 2Ã— larger) database is just 125 MB. For the largest database of 8 GB, the queue size |Q| =89 427 is equal to the database size. The ofï¬‚ine computation time grows linearly with the database size (cf. Table 2), which we can approximately also see in Table
3. A CIP-PIR server needs â‰ˆ34 minutes to precompute 10 000 pairs (200 ms per pair) in the ofï¬‚ine com- putation for the largest database of 8 GB. Our CIP-PIR implementation processes incoming queries sequentially in a â€œï¬rst-come ï¬rst-serve" manner. Thus, the delay time until a client obtains a block highly depends on the number of simultaneous queries as shown in Table
3. For the 8 GB database, the delay for a single query is just 176 ms, but for 10 simultaneous queries the average delay time is 737 ms and for 100 queries it is 8 500 ms. Hence, the performance of our PIR scheme depends on the database size and the number of active users. Note that our servers just use the computation power of one machine. Thomas et al.
[2] Module-lattice-based key-encapsulation mechanism standard. Technical report, Gaithersburg, MD, 2023.
[4] David Baelde, StÃ©phanie Delaune, Adrien Koutsos, Charlie Jacomme, and SolÃ¨ne Moreau. An interactive prover for protocol verification in the computational model. In 42nd IEEE Symposium on Security and Pri- vacy (S&Pâ€™21),, pages 537â€“554, Los Alamitos, CA, May 2021. IEEE Computer Society Press.
[8] David Basin, Jannik Dreier, Lucca Hirschi, SaÅ¡a Radomirovic, Ralf Sasse, and Vincent Stettler. A for- mal analysis of 5g authentication. In Proceedings of the 2018 ACM SIGSAC conference on computer and communications security, pages 1383â€“1396, 2018.
[14] Bruno Blanchet. Modeling and verifying security pro- tocols with the applied pi calculus and proverif. Foun- dations and TrendsÂ® in Privacy and Security, 1(1-2):1â€“ 135, 2016.
[17] Joppe W. Bos, LÃ©o Ducas, Eike Kiltz, TancrÃ¨de Lepoint, Vadim Lyubashevsky, John M. Schanck, Peter Schwabe, Gregor Seiler, and Damien StehlÃ©. CRYSTALS - Ky- ber: A CCA-Secure Module-Lattice-Based KEM. In EuroS&P, pages 353â€“367. IEEE, 2018.
34. Springer, 2022.
[28] Ehren Kret and Rolfe Schmidt. The pqxdh key agree- ment protocol - diff between rev 1 and 2, September 2023. https://github.com/Inria-Prosecco/pq xdh-analysis/blob/main/revision2/pqxdh-dif f-rev-1-to-2.pdf.
[29] Ehren Kret and Rolfe Schmidt. The pqxdh key agree- ment protocol - revision 1, September 2023. Archive: https://github.com/Inria-Prosecco/pqxdh-a nalysis/blob/main/revision1/pqxdh-rev1.pdf.
[30] Ehren Kret and Rolfe Schmidt. The pqxdh key agree- ment protocol - revision 2, September 2023. Archive: https://github.com/Inria-Prosecco/pqxdh-a nalysis/blob/main/revision2/pqxdh-rev2.pdf.
[32] Moxie Marlinspike and Trevor Perrin. The X3DH Key Agreement Protocol, 2016.
[33] Trevor Perrin and Moxie Marlinspike. The Double Ratchet Algorithm, 2016.
[36] P.W. Shor. Algorithms for quantum computation: dis- crete logarithms and factoring. In Proceedings 35th Annual Symposium on Foundations of Computer Sci- ence, pages 124â€“134, 1994.
[38] Dominique Unruh. Quantum relational hoare logic. Proceedings of the ACM on Programming Languages, 3(POPL):1â€“31, 2019.
1. the exhaustive case disjunction under which the key com- puted by the responder Alex is secret;
2. the exhaustive case disjunction under which the key com- puted by the initiator Blake is secret;
3. the exhaustive case disjunction under which there is authentication. In PROVERIF, the final correct and complete query we were able to prove for the secrecy of the responder key is: query A,B:client, spk:point, pqpk:kempub, sk:symkey, i,j:time; event(AlexOK(A,B,spk,pqpk,ts))@i =â‡’not(attacker(sk)) | (CompromisedIK(B)@j & (j<i | (event(CompromiseSPK(B,spk)) & (event(CompromisePQPK(B,pqpk)) | event(BrokenKEM)) ) ) ) | (event(BrokenDH())@j & (j < i | event(CompromisePQPK(B,pqpk)) | event(BrokenKEM) ) ) This can be translated as a security theorem detailing the possible cases. Theorem 7 (Symbolic Responder Secrecy). The key SKA computed by the responder Alex is secret, unless:
1. IKB was compromised before the completion of the key exchange (this is to be expected, this is essentially a malicious A case).
2. IKB was compromised after the key exchange, as well as some SPKb, and either KEMs are broken or the corre- sponding PQSPKB has been compromised (the attacker just need to send a malicious OPK here to be able to compute all the values).
3. DH was broken before the key exchange (this is similar to case 1).
1. IKA was compromised before the exchange ( allows the impersonation of Alex).
2. Some SPKB was compromised before the exchange (knowing SPKB allows to impersonate A).
3. DH has been broken before the exchange. The second compromise case here is the most interesting one. Indeed, it means that Signal is suceptible to a form of ephemeral key compromise impersonation: compromising the ephemeral SPKB secret of Blake allows to impersonate anybody to Blake. This is natural with the design of Signal, as Alex only authenticates by using a long term DH share combined with the SPKB. Theorem 9 (Symbolic Initiator Secrecy). The key SKB com- puted by the initiator Blake is secret, unless:
1. IKA was compromised before the communication. (this allows a full impersonation of Alex)
2. Some SPKB was compromised before the communica- tion. (more surprisingly, but inevitably, this allows a full impersonation of any Alex)
3. IKB, SPKB and PQSPKB are compromised after the com- munication, and either no OPK was used or it was com- promised. (all secret material of A is leaked here, so this is a very natural case)
4. IKB and SPKB are compromised after the communication, and KEMs are broken, and either no OPK was used or it was compromised. (similar to 3)
5. DH was broken before the exchange (naturally breaks everything)
6. DH was broken after the exchange, and the PQSPKB used by the responder was compromised (similar to 3)
7. DH was broken after the exchange, and KEMs are broken (similar to 5) In contrast, the OPK now plays a role and increases the security, and also need to be compromised in many cases. Summing up the three theorems, we do have the higher level security properties mentioned in Theorem 1:
1. peer-authentication: directly implied by Theorem 8, where authentication holds unless there is a compromise.
2. forward secrecy: implied by Theorems 7 and 9, where we can see that compromising the identity key of any party after the completion of a key exchange is not one of the insecure case, and is thus not enough to break the security.
3. resistance to key compromise impersonation: implied by Theorem 8, as authentication holds even if IKB was compromised.
4. session independence: implied by Theorems 7 and 9, where we can see that one must compromise precisely ephemerals secrets of the target session to break it, and thus that leaking the ephemeral keys of other sessions does not impact security.
[1] A toolbox for zksnarks on ethereum. https://github.com/ Zokrates/ZoKrates, 2022.
[2] Aumasson, J.-P., Kolegov, D., and Stathopoulou, E. Se- curity review of ethereum beacon clients. arXiv preprint arXiv:2109.11677 (2021).
[3] Badertscher, C., GaË‡zi, P., Kiayias, A., Russell, A., and Zikas, V. Ouroboros genesis: Composable proof-of-stake blockchains with dynamic availability. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (2018),
[6] Baldimtsi, F., Madathil, V., Scafuro, A., and Zhou, L. Anony- mous lottery in the proof-of-stake setting. In 2020 IEEE 33rd Computer Security Foundations Symposium (CSF) (2020), IEEE,
[7] Bellare, M. Lectures on nizks: A concrete security treatment.
[9] Bentov, I., Lee, C., Mizrahi, A., and Rosenfeld, M. Proof of activity: Extending bitcoinâ€™s proof of work via proof of stake [ex- tended abstract] y. ACM SIGMETRICS Performance Evaluation Review 42, 3 (2014), 34â€“37.
[12] Bolot, J., Fawaz, N., Muthukrishnan, S., Nikolov, A., and Taft, N. Private decayed predicate sums on streams. In Proceed- ings of the 16th International Conference on Database Theory (2013),
[14] Buchman, E. Tendermint: Byzantine fault tolerance in the age of blockchains. PhD thesis, University of Guelph, 2016.
[16] Chan, H., Shi, E., Song, D., et al. Private and continual re- lease of statistics. In International Colloquium on Automata, Languages, and Programming (2010), Springer,
[17] Chen, J., and Micali, S. Algorand. arXiv preprint arXiv:1607.01341 (2016).
[22] Dodge, Y., and Cox, D. The Oxford dictionary of statistical terms. Oxford University Press, USA, 2003.
[23] Douceur, J. R. The sybil attack. In International workshop on peer-to-peer systems (2002), Springer,
[24] Dwork, C. Differential privacy in new settings. In Proceed- ings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms (2010), SIAM,
[25] Dwork, C., Naor, M., Pitassi, T., and Rothblum, G. N. Differ- ential privacy under continual observation. In Proceedings of the forty-second ACM symposium on Theory of computing (2010),
[26] Dwork, C., Roth, A., et al. The algorithmic foundations of differential privacy. Found. Trends Theor. Comput. Sci. 9, 3-4 (2014), 211â€“407.
[27] Etherum. Etherum 2.0 phse 0 becaon chain. https: //github.com/ethereum/consensus-specs/blob/dev/ specs/phase0/beacon-chain.md, 2021.
[28] Ethscan. Ethscan Statistics. https://ethscan.org/, 2022.
[32] Grinstead, C. M., and Snell, J. L. Introduction to probability. American Mathematical Soc., 1997.
[35] Haney, S., Machanavajjhala, A., Abowd, J. M., Graham, M., Kutzbach, M., and Vilhuber, L. Utility cost of formal privacy for releasing national employer-employee statistics. In Proceed- ings of the 2017 ACM International Conference on Management of Data (2017),
[37] Karp, R. M., and Kleinberg, R. Noisy binary search and its applications. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms (2007),
[45] Mazieres, D. The stellar consensus: A federated model for internet-level consensus. Stellar Development Foundation (2015).
[46] Miller, A., Litton, J., Pachulski, A., Gupta, N., Levin, D., Spring, N., and Bhattacharjee, B. Discovering bitcoinâ€™s public topology and influential nodes. et al (2015).
[47] Nakamoto, S., and Bitcoin, A. A peer-to-peer electronic cash system. Bitcoin.â€“URL: https://bitcoin. org/bitcoin. pdf 4 (2008).
[48] Narayan, A., Feldman, A., Papadimitriou, A., and Hae- berlen, A. Verifiable differential privacy. In Proceedings of the European Conference on Computer Systems (2015),
[50] Ross, S. M. Intro. to probability models. Academic press, 2014.
[52] Shirali, S. A. The bhaskara-aryabhata approximation to the sine function. Mathematics Magazine 84, 2 (2011), 98â€“107.
[53] Tawfik, S. A. Minimax approximation and remez algorithm.
[54] Vujicic, D., Jagodic, D., and Randic, S. Blockchain tech- nology, bitcoin, and ethereum: A brief overview. In 2018 17th international symposium infoteh-jahorina (2018), IEEE,
[55] Wang, C., Bater, J., Nayak, K., and Machanavajjhala, A. Dp-sync: Hiding update patterns in secure outsourced databases with differential privacy. In Proceedings of the 2021 International Conference on Management of Data (2021),
[56] Wang, C., Bater, J., Nayak, K., and Machanavajjhala, A. Incshrink: Architecting efficient outsourced databases us- ing incremental mpc and differential privacy. arXiv preprint arXiv:2203.05084 (2022).
[59] Xu, B., Luthra, D., Cole, Z., and Blakely, N. Eos: An architectural, performance, and economic analysis. Retrieved June 11 (2018), 2019.
10. Given ğ›¿âˆˆ(0,1), with probability at least 1âˆ’ğ›¿, ğ‘SC(...,ğ›¿) outputs correct comparisons. Proof. We first prove that for each round, the probability that Algorithm 1 outputs the wrong comparison between the two biased coins ğ‘( ğ‘“ğ‘£) and ğ‘( ğ‘“cmp) is at most ğ›¿ğ‘–. Without loss of generality, we consider the case where the algorithm outputs ğ‘“ğ‘£> ğ‘“cmp (ğ‘0 > ğ‘1 and |ğ‘0âˆ’ğ‘1| > 2ğœğ‘–). By Hoeffdingâ€™s Inequality
[44] the failure probability that Algorithm 1 outputs the wrong comparison satisfies Pr [wrong cmp] â‰¤Pr [ğ‘( ğ‘“ğ‘£) < ğ‘0âˆ’ğœğ‘–] +Pr  ğ‘( ğ‘“cmp) > ğ‘1 + ğœğ‘–  â‰¤ğ‘’âˆ’2ğ‘’log( 1 ğ›¿ğ‘–) = ğ‘’âˆ’2ğ›¿ğ‘– (4) By union bound, the overall failure probability is bounded by Ã+âˆ ğ‘– ğ›¿ğ‘–< ğ›¿ ğ‘’âˆ’1 < ğ›¿ â–¡ Theorem
11. The expected running time of ğ‘SC is bounded by ğ‘‚  log(1/ğ›¿)+log(1/max (ğœ,ğœc)) max(ğœ,ğœc)2  (sim) coin flips. Proof. We prove the complexity of ğ‘SC by following the same technique used by
[37] for proving Lemma 3.2. Without loss of generality, we consider ğ‘( ğ‘“ğ‘£) > ğ‘( ğ‘“cmp). We start with the case of ğœğ‘> ğœ, and let ğ‘˜= log( 1 ğœğ‘), so for any round â„“> ğ‘˜we have ğœâ„“< ğœğ‘ 2 . By Hoeffdingâ€™s Inequal- ity
[44] the probability such that ğ‘SC keeps running after â„“> ğ‘˜rounds is at most ğ›¿Â·ğ‘’âˆ’( 1 2 ğ‘’2â„“ğœ2 ğ‘+â„“). The running time of round â„“> ğ‘˜grows exponentially in â„“, while the prob- ability that Algorithm 1 to continue running after round â„“> ğ‘˜decreases faster than exponential in â„“. Hence, the expected running time is dominated by the running time of round ğ‘˜, which is ğ‘‚  log(1/ğ›¿)+log(1/ğœğ‘) ğœ2ğ‘  . Next, we con- sider the case where ğœğ‘< ğœ. With the same technique, one can obtain that the expected running time is bounded by the running time of ğ‘˜ğ‘¡â„round where ğ‘˜= log( 1 ğœ), which is ğ‘‚  log(1/ğ›¿)+log(1/ğœ) ğœ2  . Combining both cases, the ex- pected running time of ğ‘SC is bounded by ğ‘‚ log(1/ğ›¿) +log(1/max (ğœ,ğœc)) max(ğœ,ğœc)2  (5) â–¡ B.2 Proof of Theorem 2 Theorem
12. Let ğ‘›= ğ‘† ğœƒ, and ğ›¿= ğ‘‚( 1 logğ‘›), then the run- ning time of RdBin is bounded by ğ‘‚  log(logğ‘›/ğœ) ğœ2 Ã—logğ‘›  Proof. Let ğ›¿= ğ‘ logğ‘›, where ğ‘is considered to be a constant factor and ğ‘>
0. By Equation 5, we can obtain that for each random walk phase of RdBin, the expected running time is bounded by ğ‘‚  log(logğ‘›/ğœ) ğœ2  . As the random walk will terminate within logğ‘›steps, and thus the overall running is bounded by ğ‘‚  log(logğ‘›/ğœ) ğœ2 Ã—logğ‘›  . â–¡ Theorem
14. Given ğ‘›independent and identically dis- tributed (i.i.d.) Laplace random variables ğ‘‹1, ğ‘‹2,..., ğ‘‹ğ‘› drawn from Lap( Î” ğœ–). Let ğ‘‹= Ãğ‘› ğ‘–=1 ğ‘‹ğ‘–, 0 < ğ›¼â‰¤ğ‘›Î” ğœ–, then: Pr [ ğ‘‹â‰¥ğ›¼] â‰¤ğ‘’  âˆ’ğ›¼2Î”2 4ğ‘›ğœ–2  Proof. Please refer to the proof to Lemma 12.2 in
[26] or proof to Theorem 6 in [55] â–¡ Proof. (Theorem 7) When adopting stake distortion, the inference errors consist of two parts: (i) the error due to injected DP noises and (ii) the error caused by the inference algorithm. By Theorem 2, the part (ii) noise is bounded by ğœ‚. By Lemma 14, and let ğ‘’( âˆ’ğ›¼2Î”2 4ğ‘›ğœ–2 ) = ğ›½, and take log on both sides, one can obtain that with probability at least 1âˆ’ğ›½, for any ğ›½>
[AA14] Ange Albertini and Jean-Philippe Aumasson. A binary magic trick, angecryption. International Journal of Proof-of-Concept or GTFO, 0x03:37â€“ 41, 2014. https://archive.org/details/ pocorgtfo03.
[Alb15] Ange Albertini. Abusing ï¬le formats. International Journal of Proof-of-Concept or GTFO, 0x07:18â€“ 41, 2015. https://archive.org/details/ pocorgtfo07.
[CAE14] CAESAR: Competition for Authenticated En- cryption: Security, Applicability, and Robustness, May 2014. http://competitions.cr.yp.to/ caesar.html. Date Accessed: 14 Oct 2020.
[FIM20] Rintaro Fujita, Takanori Isobe, and Kazuhiko Mine- matsu. ACE in chains: How risky is CBC encryp- tion of binary executable ï¬les? In ACNS (1), volume 12146 of Lecture Notes in Computer Science, pages 187â€“207. Springer, 2020.
[ISO09] Information technology â€” Security techniques â€” Authenticated encryption. Standard, Interna- tional Organization for Standardization, Geneva, CH, February 2009.
[JNP15] JÃ©rÃ©my Jean, Ivica NikoliÂ´c, and Thomas Peyrin. Deoxys v1.3. CAESAR submissions, 2015. http://competitions.cr.yp.to/round2/ deoxysv13.pdf.
[KR07] Lars R. Knudsen and Vincent Rijmen. Known- key distinguishers for some block ciphers. In ASI- ACRYPT, volume 4833 of Lecture Notes in Com- puter Science, pages 315â€“324. Springer, 2007.
[RBB03] Phillip Rogaway, Mihir Bellare, and John Black. OCB: A Block-Cipher Mode of Operation for Ef- ï¬cient Authenticated Encryption. ACM Trans. Inf. Syst. Secur., 6(3):365â€“403, 2003.
[4] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthuramakrishnan Venki- tasubramaniam. Ligero. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, 2017.
[15] Sean Bowe, Ariel Gabizon, and Ian Miers. Scalable Multi-party Com- putation for zk-SNARK Parameters in the Random Beacon Model, 2017. https://ia.cr/2017/1050.
[17] Vitalik Buterin. A Theory of Ethereum State Size Management, 2021. https://hackmd.io/@vbuterin/state_size_management.
[22] Thaddeus Dryja. Utreexo: A dynamic hash-based accumulator opti- mized for the Bitcoin UTXO set, 2019. https://ia.cr/2019/611.
[23] Ethereum. Shard chains, 2022. https://ethereum.org/en/ upgrades/shard-chains/.
[25] Filecoin. Trusted Setup Complete!, 2020. https://filecoin.io/ blog/posts/trusted-setup-complete/.
[32] Aniket Kate, Gregory M. Zaverucha, and Ian Goldberg. Constant- Size Commitments to Polynomials and Their Applications. In ASI- ACRYPTâ€™10, 2010.
[33] Jonathan Katz, Rafail Ostrovsky, and Michael O. Rabin. Identity-Based Zero-Knowledge. In Security in Communication Networks, 2005.
[36] John Kuszmaul. Verkle Trees: V(ery short M)erkle Trees. In MIT PRIMES Conference â€™18, 2018.
[41] Andrew Miller. Storing UTXOs in a balanced Merkle tree (zero- trust nodes with O(1)-storage), 2012. https://bitcointalk.org/ index.php?topic=101734.msg1117428.
[43] Nervos Network. How Nervos is Tackling the State Ex- plosion Problem Facing Smart Contract Blockchains, 2021. https://medium.com/nervosnetwork/how-nervos-is- tackling-the-state-explosion-problem-facing-smart- contract-blockchains-a9acc4c5708e.
[44] Alex Ozdemir. bellman-bignat, 2020. https://github.com/alex- ozdemir/bellman-bignat.
[47] Charalampos Papamanthou, Elaine Shi, and Roberto Tamassia. Signa- tures of Correct Computation, 2011. https://ia.cr/2011/587.
[54] Jacob T Schwartz. Probabilistic algorithms for verification of polyno- mial identities. In International Symposium on Symbolic and Algebraic Manipulation, 1979.
[57] Peter Todd. Making UTXO set growth irrelevant with low-latency delayed TXO commitments, 2016. https://petertodd.org/2016/ delayed-txo-commitments.
[58] Alin Tomescu. How to Keep a Secret and Share a Public Key (Using Polynomial Commitments). PhD thesis, Massachusetts Institute of Technology, 2020.
[63] Thomas Walton-Pocock. AZTEC CRS: The Biggest MPC Setup in History has Successfully Finished, 2020. https://medium.com/ aztec-protocol/aztec-crs-the-biggest-mpc-setup-in- history-has-successfully-finished-74c6909cd0c4.
[66] Zcash. What is jubjub?, 2017. https://z.cash/technology/ jubjub/.
[70] Richard Zippel. Probabilistic algorithms for sparse polynomials. In International Symposium on Symbolic and Algebraic Manipulation, 1979. A Assumptions, definitions and primitives We prove Hyperproofs satisfy soundness, as per Def. B.2, under q-Strong Diffie-Hellman (q-SDH) assumption, defined below. Assumption A.1 (q-SDH [11]). For any PPT adversary A, Pr ï£® ï£¯ï£° (p,G1,G2,GT ,e,g1,g2) â†BilGen(1Î»),s âˆˆR Zâˆ— p, pp = ((p,G1,G2,GT ,e,g1,g2),gs 2,gs 1,...,gsq 1 ) : (a,g 1 s+a 1 ) â†A(1Î»,pp) ï£¹ ï£ºï£»â‰¤negl(Î») Inner Product Arguments (IPA). We give the interactive variant of the BÃ¼nz et al.
[19] IPA in Fig.
8. Here, the prover interacts with the verifier over logm rounds. This interactive IPA is knowledge-sound assuming Abe et al. commitments are binding [19, Theorem 1]. It is made non-interactive via the Fiat-Shamir transform
[24] and proved secure in a new algebraic commitment model and in the random oracle model (ROM) [19,
[1] MovieLens Datasets. https://grouplens.org/ datasets/movielens/.
[2] Recommenders. https://github.com/microsoft/ recommenders.
[4] Robert M Bell, Yehuda Koren, and Chris Volinsky. The bellkor 2008 solution to the netflix prize. Statistics Research Department at AT&T Research, 1, 2008.
[5] Leo Breiman. Bagging predictors. Machine learning, 24(2):123â€“140, 1996.
[6] Robin Burke, Bamshad Mobasher, Runa Bhaumik, and Chad Williams. Segment-based injection attacks against collaborative filtering recommender systems. In ICDM, 2005.
[7] Robin Burke, Bamshad Mobasher, Chad Williams, and Runa Bhaumik. Classification features for attack detec- tion in collaborative recommender systems. In KDD, 2006.
[8] Huiyuan Chen and Jing Li. Adversarial tensor factor- ization for context-aware recommendation. In RecSys, 2019.
[9] Konstantina Christakopoulou and Arindam Banerjee. Adversarial attacks on an oblivious recommender. In RecSys, 2019.
[13] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial exam- ples. In ICLR, 2015.
[14] F Maxwell Harper and Joseph A Konstan. The movie- lens datasets: History and context. ACM TIIS, 5(4), 2015.
[19] Jinyuan Jia, Xiaoyu Cao, and Neil Zhenqiang Gong. Intrinsic certified robustness of bagging against data poisoning attacks. In AAAI, 2021.
[20] Jinyuan Jia, Yupei Liu, Xiaoyu Cao, and Neil Zhenqiang Gong. Certified robustness of nearest neighbors against data poisoning and backdoor attacks. In AAAI, 2022.
[21] Yehuda Koren, Robert Bell, and Chris Volinsky. Ma- trix factorization techniques for recommender systems. Computer, 42(8), 2009.
[23] Bo Li, Yining Wang, Aarti Singh, and Yevgeniy Vorob- eychik. Data poisoning attacks on factorization-based collaborative filtering. In NeurIPS, 2016.
[24] Greg Linden, Brent Smith, and Jeremy York. Amazon. com recommendations: Item-to-item collaborative filter- ing. IEEE Internet computing, 7(1), 2003.
[25] Yang Liu, Xianzhuo Xia, Liang Chen, Xiangnan He, Carl Yang, and Zibin Zheng. Certifiable robustness to discrete adversarial perturbations for factorization machines. In SIGIR, 2020.
[26] Bhaskar Mehta, Thomas Hofmann, and Wolfgang Nejdl. Robust collaborative filtering. In RecSys, 2007.
[27] Bamshad Mobasher, Robin Burke, Runa Bhaumik, and Chad Williams. Toward trustworthy recommender sys- tems: An analysis of attack models and algorithm ro- bustness. TOIT, 7(4), 2007.
[29] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback. arXiv:1205.2618, 2012.
[32] Carlos E Seminario and David C Wilson. Attacking item-based recommender systems with power items. In RecSys, 2014.
[34] Jiaxi Tang, Hongyi Wen, and Ke Wang. Revisiting adver- sarially learned injection attacks against recommender systems. In RecSys, 2020.
[35] Jinhui Tang, Xiaoyu Du, Xiangnan He, Fajie Yuan, Qi Tian, and Tat-Seng Chua. Adversarial training to- wards robust multimedia recommender system. TKDE, 32(5), 2019.
[37] Andreas TÃ¶scher, Michael Jahrer, and Robert M Bell. The bigchaos solution to the netflix grand prize. Netflix prize documentation, 2009.
[38] Soumya Wadhwa, Saurabh Agrawal, Harsh Chaudhari, Deepthi Sharma, and Kannan Achan. Data poisoning attacks against differentially private recommender sys- tems. In SIGIR, 2020.
[39] Chenwang Wu, Defu Lian, Yong Ge, Zhihao Zhu, and Enhong Chen. Triple adversarial learning for influence based poisoning attack in recommender systems. In KDD, 2021.
[40] Mingrui Wu. Collaborative filtering via ensembles of matrix factorizations. In KDD Cup and Workshop 2007, 2007.
[41] Zhiang Wu, Junjie Wu, Jie Cao, and Dacheng Tao. Hysad: A semi-supervised hybrid shilling attack detec- tor for trustworthy product recommendation. In KDD, 2012.
[43] Feng Yuan, Lina Yao, and Boualem Benatallah. Ad- versarial collaborative neural network for robust recom- mendation. In SIGIR, 2019.
[44] Fuzhi Zhang and Quanqiang Zhou. Hhtâ€“svm: An on- line method for detecting profile injection attacks in collaborative recommender systems. Knowledge-Based Systems, 2014.
[47] Sheng Zhang, Amit Chakrabarti, James Ford, and Fillia Makedon. Attack detection in time series for recom- mender systems. In KDD, 2006. A Proof of Theorem 3.1 Recall that, given a rating-score matrix M and its poisoned version Mâ€², X and Y are respectively two submatrices with s rows randomly sampled from M and Mâ€² without replacement. We use Î¦ to denote the domain space of Y , i.e., each element in Î¦ is a submatrix with s rows sampled from Mâ€². Note that since M is a submatrix of Mâ€², the domain space of X is a subset of Î¦. For simplicity, we define the following notations. Suppose we have Z âˆˆÎ¦ and another rating-score matrix W , we say Z â‰ºW (or Z âŠ€W ) if Z is (or is not) in the domain space created by sampling s rows from W . We have X â‰ºM and Y â‰ºMâ€² based on our defined notations. Similarly, give a user u and Z âˆˆÎ¦, we say u âŠ¢Z if Z contains rating scores of user u. We say u âŠ¬Z if Z does not contain user uâ€™s rating scores. The following lemma generalizes the Neyman-Pearson Lemma
[28] to multiple functions: Lemma
1. Sim- ilarly, we use gl(0|Z) to denote the probability that gl(Z) = 0. Then, we have the following: (1) If Î¦â€² âŠ†{Z âˆˆÎ¦ : g1(1|Z) = g2(1|Z) = Â·Â·Â· = gÎ³(1|Z) = 0}, O1 = {Z âˆˆÎ¦ \ Î¦â€² : Pr(Y = Z) < Ï Â· Pr(X = Z)} and O2 = {Z âˆˆÎ¦ \ Î¦â€² : Pr(Y = Z) = Ï Â· Pr(X = Z)} for some Ï >
0. Assuming we have O3 âŠ†O2, and O = O1 âˆªO3. Then, if we have âˆ‘Î³ l=1 Pr(gl(X)=1) Î· â‰¥Pr(X âˆˆO), then âˆ‘Î³ l=1 Pr(gl(Y )=1) Î· â‰¥ Pr(Y âˆˆO). A B P Q Figure 14: Illustration of subset P, Q, A, and B. (2) If Î¦â€² âŠ†{Z âˆˆÎ¦ : g1(1|Z) = g2(1|Z) = Â·Â·Â· = gÎ³(1|Z) = 0}, O1 = {Z âˆˆÎ¦ : Pr(Y = Z) > Ï Â· Pr(X = Z)} and O2 = {Z âˆˆÎ¦ : Pr(Y = Z) = Ï Â· Pr(X = Z)} for some Ï >
1. Finally, we let O = O1 âˆªO3 = Ci. We can apply Lemma 1 based on the condition in Equation (36) and we have the following: Pr(gi(Y ) = 1) â‰¥Pr(Y âˆˆCi). (38) Based on the definition of gi, we have the following: Pr(i âˆˆA(Y ,u)) (39) =Pr(gi(Y ) = 1) (40) â‰¥Pr(Y âˆˆCi) (41) =Pr(X âˆˆCi)Â·Ï„ (42) =pâˆ— i Â·Ï„. (43) For simplicity, we denote Dr = {dâ€² 1,dâ€² 2,Â·Â·Â· ,dâ€² z}, where z = k âˆ’r +1. Without loss of generality, we assume pdâ€² 1 â‰¥Â·Â·Â· â‰¥ pdâ€²z. We have the following: max iâˆˆDr Pr(i âˆˆA(Y ,u)) â‰¥max iâˆˆDr pâˆ— i Â·Ï„ = pâˆ— dâ€² 1 Â·Ï„. (44) Then, we have the following: min Dr max iâˆˆDr Pr(i âˆˆA(Y ,u)) = min Dr pâˆ— dâ€² 1 Â·Ï„ (45) Therefore, when Dr = {Âµr,Âµr+1,Â·Â·Â· ,Âµk}, pâˆ— dâ€² 1 Â·Ï„ reaches the minimal value which is pâˆ— Âµr Â·Ï„. In other words, we have the following: min Dr max iâˆˆDr Pr(i âˆˆA(Y ,u)) â‰¥pâˆ— Âµr Â·Ï„. (46) Deriving an upper bound of maxVr min jâˆˆVr Pr(j âˆˆ A(Y ,u)): For âˆ€j âˆˆVr, given Equation (3), we have the fol- lowing: pâˆ— j = âŒˆpj Â· (ï¸n s )ï¸ âŒ‰ (ï¸n s )ï¸ â‰¥pj â‰¥Pr(j âˆˆA(X,u)). (47) Suppose we have Vr = {vâ€² 1,vâ€² 2,Â·Â·Â· ,vâ€² w}, where w = N âˆ’r+1. Without loss of generality, we assume the following: pvâ€² 1 â‰¤pvâ€² 2 â‰¤Â·Â·Â· â‰¤pvâ€²w. (48) We first derive an upper bound of minjâˆˆVr Pr(j âˆˆA(Y ,u)). Given an arbitrary item j âˆˆVr, we have the following inequal- ity based on Equation (47) and our definition of X: Pr(j âˆˆA(X,u)) â‰¤pâˆ— j. (49) Given an item j âˆˆVr, we define the function gj(Z) = I(j âˆˆ A(Z,u)). We have Pr(gj(X) = 1) â‰¤pâˆ— j based on Equa- tion (49) and the definition of gj. Then, we can leverage Lemma 1 to derive an upper bound for Pr(gj(X) = 1). In par- ticular, we can find Câ€² j âŠ†P such that we have the following: Pr(X âˆˆCâ€² j) = pâˆ— j. (50) We let Cj = Câ€² j âˆª(A \ P). Since we have Pr(X âˆˆA \ P) = Pr(X âˆˆA)âˆ’Pr(X âˆˆP) = 0, we have the following: Pr(X âˆˆCj) = Pr(X âˆˆCâ€² j)+Pr(X âˆˆA\P) = pâˆ— j. (51) Based on Pr(g j(X) = 1) â‰¤pâˆ— j, we have the following: Pr(gj(X) = 1) â‰¤Pr(X âˆˆCj). (52) Next, we will apply Lemma 1 to obtain the upper bound of Pr(gj(Y) = 1). In particular, we let Î¦â€² = B since we have gj(Z) = 0 for âˆ€Z âˆˆB. Then, we have A = Î¦\Î¦â€². Based on Equation (24) - (25), we have Pr(Y = Z) = Ï„Â·Pr(X = Z) if Z âˆˆP and Pr(Y = Z) > Ï„ Â· Pr(X = Z) if Z âˆˆA \ P. We let O1 = A\P, O2 = P, O3 = Câ€² j âŠ†O2, Î· = 1, and Î³ =
[1] â€œBankruptcy of ftx,â€ https://en.wikipedia.org/wiki/Bankruptcy_of_FT X/, accessed: 2023-04-19.
[7] â€œBinance proof-of-reserves code,â€ https://github.com/binance/zkmerkl e-proof-of-solvency/.
[8] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer, â€œFrom extractable collision resistance to succinct non-interactive arguments of knowledge, and back again,â€ in Innovations in Theoretical Computer Science, 2012.
[11] G. Botrel, T. Piellard, Y. E. Housni, I. Kubjas, and A. Tabaie, â€œConsensys/gnark: v0.8.0,â€ Feb. 2023. [Online]. Available: https: //doi.org/10.5281/zenodo.5819104
[15] V. Buterin, â€œHaving a safe cex: proof of solvency and beyond,â€ https: //vitalik.ca/general/2022/11/19/proof_of_solvency.html, accessed: 2023-05-10.
[23] K. Chalkias, K. Lewi, P. Mohassel, and V. Nikolaenko, â€œPractical pri- vacy preserving proofs of solvency,â€ Amsterdam ZKProof Community Event, 2019.
[26] M. Chase, A. Healy, A. Lysyanskaya, T. Malkin, and L. Reyzin, â€œMer- curial commitments with applications to zero-knowledge sets.â€ in EU- ROCRYPT, 2005.
[27] P. Chatzigiannis, F. Baldimtsi, and K. Chalkias, â€œSok: auditability and accountability in distributed payment systems,â€ in ACNS, 2021.
[34] E. Ghosh, O. Ohrimenko, D. Papadopoulos, R. Tamassia, and N. Trian- dopoulos, â€œZero-knowledge accumulators and set algebra,â€ in ASI- ACRYPT 2016, 2016.
[35] O. Goldreich and R. Ostrovsky, â€œSoftware protection and simulation on oblivious rams,â€ Journal of the ACM (JACM), vol. 43, no. 3, , 1996.
[39] K. Hu, Z. Zhang, and K. Guo, â€œBreaking the binding: Attacks on the merkle approach to prove liabilities and its applications,â€ Computers & Security, 2019.
[43] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Ham- burg, M. Lipp, S. Mangard, T. Prescher et al., â€œSpectre attacks: Exploit- ing speculative execution,â€ Communications of the ACM, 2020.
[45] J. Li, N. Li, and R. Xue, â€œUniversal accumulators with efficient non- membership proofs,â€ in ACNS, 2007.
[47] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg, â€œMeltdown,â€ arXiv preprint arXiv:1801.01207, 2018.
[48] A. Luthra, J. Cavanaugh, H. R. Olcese, R. M. Hirsch, and X. Fu, â€œZe- roaudit,â€ in Annual Computer Security Applications Conference, 2020,
[49] C. McIvor, M. McLoone, and J. V. McCanny, â€œModified mont- gomery modular multiplication and rsa exponentiation techniques,â€ IEE Proceedings-Computers and Digital Techniques, vol. 151, no. 6, , 2004.
[55] Y. Peng, M. Du, F. Li, R. Cheng, and D. Song, â€œFalcondb: Blockchain- based collaborative database,â€ in Proceedings of the 2020 ACM SIG- MOD international conference on management of data, 2020.
[57] A. M. Rozario and M. A. Vasarhelyi, â€œAuditing with smart contracts.â€ International Journal of Digital Accounting Research, vol. 18, 2018.
[60] I. A. Tomescu Nicolescu, â€œHow to keep a secret and share a public key (using polynomial commitments),â€ Ph.D. dissertation, Massachusetts Institute of Technology, 2020.
[63] E. G. Weyl, P. Ohlhaver, and V. Buterin, â€œDecentralized society: Finding web3â€™s soul,â€ Available at SSRN 4105763, 2022.
[66] C. Yue, T. T. A. Dinh, Z. Xie, M. Zhang, G. Chen, B. C. Ooi, and X. Xiao, â€œGlassdb: An efficient verifiable ledger database system through transparency,â€ Proceedings of the VLDB Endowment, 2023.
0. We denote the non-interactive version as NI-ZKAoP. We denote the protocol as (1) Ï€ â†NI-ZKAoP.Prove(G,g;x) where Ï€ is the proof, x is the witness such that x > 0 and G = gx; (2) 1/0 â†NI-ZKAoP.Verify(G,g,Ï€). Besides, the authors in
[29] also proved its knowledge extractability. A.2 Universal Accumulators We follow the universal accumulator definitions provided by [34]. Definition
2. Division intractable. A function family H is called division intractable (DI) if given security parameter Î», finding H âˆˆH and distinct inputs X1,...,Xm,Y, m < poly(Î») such that Pr[H(Y)|H(X1)...H(Xm)] < negl(Î»). Clearly, all Hash-to-prime hash functions are DI. However, most Hash-to-prime functions are time-consuming. Accord- ing to Lemma 6 in [33], a random oracle with Î»2-bit output is also DI. Informally, random numbers with large bit-length tend to have large prime factors. A large prime factor makes the random number hard to divide from other random num- bers with different large prime factors. In particular, Ozdemir et al.
[1] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthura- makrishnan Venkitasubramaniam. Ligero: Lightweight sublinear arguments without a trusted setup. In Proceed- ings of the 2017 acm sigsac conference on computer and communications security, pages 2087â€“2104, 2017.
[3] Carsten Baum, Lennart Braun, Alexander Munch- Hansen, Benoit Razet, and Peter Scholl. Appenzeller to brie: efficient zero-knowledge proofs for mixed-mode arithmetic and Z2k. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 192â€“211, 2021.
[9] VÃ¡clav E BeneÅ¡. Permutation groups, complexes, and re- arrangeable connecting networks. Bell System Technical Journal, 43(4):1619â€“1640, 1964.
[12] Manuel Blum, Will Evans, Peter Gemmell, Sampath Kannan, and Moni Naor. Checking the correctness of memories. Algorithmica, 12:225â€“244, 1994.
[14] Benjamin Braun, Ariel J Feldman, Zuocheng Ren, Sri- nath Setty, Andrew J Blumberg, and Michael Walfish. Verifying computations with state. In Proceedings of the twenty-fourth ACM Symposium on Operating Systems Principles, pages 341â€“357, 2013.
[21] Richard A. DeMillo and Richard J. Lipton. A probabilis- tic remark on algebraic program testing. Information Processing Letters, 7(4):193â€“195, 1978.
[22] Samuel Dittmer, Yuval Ishai, Steve Lu, and Rafail Os- trovsky. Improving line-point zero knowledge: Two multiplications for the price of one. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, pages 829â€“841, 2022.
[27] Ariel Gabizon and Zachary J. Williamson. plookup: A simplified polynomial protocol for lookup tables. Cryp- tology ePrint Archive, Report 2020/315, 2020. https: //eprint.iacr.org/2020/315.
[40] J. T. Schwartz. Fast probabilistic algorithms for verifi- cation of polynomial identities. J. ACM, 27(4):701â€“717, oct 1980.
[42] Abraham Waksman. A permutation network. J. ACM, 15(1):159â€“163, January 1968.
[43] Xiao Wang, Alex J. Malozemoff, and Jonathan Katz. EMP-toolkit: Efficient MultiParty computation toolkit. https://github.com/emp-toolkit, 2016.
[46] Chenkai Weng, Kang Yang, Zhaomin Yang, Xiang Xie, and Xiao Wang. Antman: Interactive zero-knowledge proofs with sublinear communication. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, pages 2901â€“2914, 2022.
[47] Kang Yang, Pratik Sarkar, Chenkai Weng, and Xiao Wang. Quicksilver: Efficient and affordable zero- knowledge proofs for circuits and polynomials over any field. In Proceedings of the 2021 ACM SIGSAC Confer- ence on Computer and Communications Security, pages 2986â€“3001, 2021.
1. Reverse Engineering Apple and Intel DMPs. We reverse engineer the DMP found on Apple CPUs and dis- cover new activation criteria (Section 4).
1. The x axis corresponds to the test access latency for the pointer at the corresponding index in the aop in case it contains the pointer. Blue bars (No Pointer) are for when the test pointer is not in the aop array, while red bars (Contain Pointer) are for when the pointer is in the array. load and no architectural dereference, as shown in Figure 1 (fourth row). Even though the program only loads one aop index, other pointers in the same cache line are also brought into the cache. Figure 2d shows that with a single load,2 we observe similar results to traversing the entire (N = 8) aop in Figure 2c. We further repeat the experiment but vary the number of pointers in the cache line from 1 to
[47] mentions similar pointer detection heuristic. 0x38 0x39 0x3a 0x3b 0x3c 0x3d 0x3e 0x3f 0x40 0x41 0x42 0x43 0x44 0x45 0x46 0x47 Pointer Position 0x38 0x39 0x3a 0x3b 0x3c 0x3d 0x3e 0x3f 0x40 0x41 0x42 0x43 0x44 0x45 0x46 0x47 Pointer value 0 20 40 60 80 100 Success Rate (%) Figure 5: For various combinations of pointer position and value, when does the DMP dereference the pointer? Here, we sweep within the region between 0x380000000 and 0x480000000. The white diagonal shows the degenerate case when the pointerâ€™s value equals its position, which is invalid. The lower 28 bits of the addresses are omitted for brevity. Top Byte Ignore. The address space standards in ARMv8 direct the processor to ignore the top byte of the virtual ad- dress [2]. To learn whether the DMP follows this specification, we perform a series of experiments flipping different upper bits in a valid pointer. We then perform a test access to check whether, after these bit flips, the DMP still dereferences the original pointer. Figure 7 shows the results. We perform 16 experiments, where each flips a bit in the address starting at bit 48 and ending at bit
[1] Code repository for SinglePass PIR. Available at: https://github.com/SinglePass712/Submission.
[2] Ishtiyaque Ahmad, Yuntian Yang, Divyakant Agrawal, Amr El Abbadi, and Trinabh Gupta. Addra: Metadata- private voice communication over fully untrusted infras- tructure. 2021.
[7] Elette Boyle, Yuval Ishai, Rafael Pass, and Mary Woot- ters. Can We Access a Database Both Locally and Privately? pages 662â€“693, November 2017.
[8] Benny Chor, Niv Gilboa, and Moni Naor. Private Infor- mation Retrieval by Keywords, 1998. Report Number: 003. 5One caveat of the comparison is it is necessary for the updatable version of Checklist to support keyword queries in order to achieve the O(logN) amortized bandwidth. SinglePass is a pure PIR scheme that only supports index queries. However, using cuckoo hashing we can derive a keyword PIR scheme with a 2Ã— overhead [33].
[10] Richard Durstenfeld. Algorithm 235: Random permuta- tion. Communications of the ACM, 7(7):420, July 1964.
[11] Ronald Aylmer Fisher and Frank Yates. Statistical tables for biological, agricultural and medical research, edited by R.A. Fisher and F. Yates. 6th ed. Edinburgh: Oliver and Boyd, 1963. Accepted: 2006-06-27T07:57:52Z.
[13] Oded Goldreich, S. Goldwasser, and S. Micali. How to Construct Random Functions (Extended Abstract). In FOCS, 1984.
[14] Oded Goldreich and Rafail Ostrovsky. Software protec- tion and simulation on oblivious RAMs. Journal of the ACM, 43(3):431â€“473, May 1996.
[16] Syed Mahbub Hafiz and Ryan Henry. A Bit More Than a Bit Is More Than a Bit Better: Faster (essen- tially) optimal-rate many-server PIR. Proceedings on Privacy Enhancing Technologies, 2019(4):112â€“131, Oc- tober 2019.
[17] Laura Hetz, Thomas Schneider, and Christian Weinert. Scaling Mobile Private Contact Discovery to Billions of Users, 2023. Publication info: Published elsewhere. Minor revision. ESORICS 2023.
[18] Viet Tung Hoang, Ben Morris, and Phillip Rogaway. An Enciphering Scheme Based on a Card Shuffle. Tech- nical Report arXiv:1208.1176, arXiv, November 2014. arXiv:1208.1176
[cs] type: article.
[20] Donald E Knuth. The Art of Computer Programming, Volume II: Seminumerical Algorithms. Addison-Wesley, 1969.
[24] Wei-Kai Lin, Ethan Mook, and Daniel Wichs. Doubly Efficient Private Information Retrieval and Fully Ho- momorphic RAM Computation from Ring LWE, 2022. Report Number: 1703.
[26] Rashed Mazumder, Atsuko Miyaji, and Chunhua Su. A simple construction of encryption for a tiny domain message. pages 1â€“6, March 2017.
[27] Samir Menon. SpiralWiki, 2022.
[30] Muhammad Haris Mughees, Sun I, and Ling Ren. Sim- ple and Practical Amortized Sublinear Private Informa- tion Retrieval, 2023. Publication info: Preprint.
1. For t âˆˆ{0,...T âˆ’1} : (a) Adversary outputs xt = (it, jt) âˆˆ ([Q] Ã—[N/Q]). (b) Output (yt 1,...,yt Q) $â†[N/Q]Q. Experiment 1 Public Parameters: N,Q âˆˆN, assume Q|N. Experiment:
1. Sample P1 1 ,...P1 Q $â† PN/Q Q.
2. For t âˆˆ{0,...,T âˆ’1} : (a) Adversary outputs xt = (it, jt) âˆˆ ([Q] Ã—[N/Q]). (b) Find ind s.t. Pt it(ind) = jt. (c) Output S = (vt 1,...,vt Q) where: â€¢ vt i = Pt i (ind) if i Ì¸= it. â€¢ vt i $â†[N/Q] if i = it. (d) Let {ri}iâˆˆQ $â†[N]Q. (e) For i âˆˆQ, let Pt+1 i = Pt i except we swap the values of Pt i (ri) and Pt i (ind) for i Ì¸= it. Figure 9: Experiments Experiment H0 Public Parameters: N,Q âˆˆN, assume Q|N. Experiment:
1. For t âˆˆ{0,...T âˆ’1} : (a) Sample (Pt 1,...,Pt Q) $â†(PN)Q. (b) Adversary outputs xt = (it, jt) âˆˆ ([Q] Ã—[N/Q]). (c) Find ind such that Pt it(ind) = jt. (d) Output (vt 1,...,vt Q) where: â–¶ Experiment H0 (cont) â€¢ vt i = Pt i (ind) if i Ì¸= it. â€¢ vt i $â†[N/Q] if i = it. Experiment 0 and Experiment H0 are indistinguishable: For each step, we sample fresh permutations, so consider each step independently. Now, consider the distribution of vt i for i âˆˆQ, t âˆˆT. Since our permutations are sampled uniformly, and each Pt i for i Ì¸= it is independent from Pit, every Pi(ind) is uniformly distributed over [N/Q], for i âˆˆQ,i Ì¸= it. Then, it follows that for i âˆˆQ,i Ì¸= it, vt i is uniformly distributed. By definition v1 it is also uniformly distributed. Then, for any step t âˆˆ[T], any i âˆˆ[Q], vt i is distributed uniformly. Since the outputs of both experiments have the same distribution at each step, Experiment H0 and Experiment 0 are indistinguishable. Then, consider the following hybrid: Experiment H1 Public Parameters: N,Q âˆˆN, assume Q|N. Experiment:
1. For t âˆˆ{0,...T âˆ’2} : (a) Sample (Pt 1,...,Pt Q) $â†(PN)Q. (b) Adversary outputs xt = (it, jt) âˆˆ ([Q] Ã—[N/Q]). (c) Output (yt 1,...,yt Q) where yt i = Pt i (xt).
2. Sample (rTâˆ’2 1 ,...rTâˆ’2 Q ) $â†([N/Q])Q.
3. Let PTâˆ’1 i = PTâˆ’2 i except we swap the values of PTâˆ’2 i (rTâˆ’2 i ) and PTâˆ’2 i (xTâˆ’2) for each i âˆˆ[Q],i Ì¸= it.
4. Adversary outputs xTâˆ’1 = (iTâˆ’1, jTâˆ’1).
5. Find ind s.t. PT iTâˆ’1(ind) = jTâˆ’1.
1. For t âˆˆ{0,...T âˆ’k âˆ’1} : (a) Sample (Pt 1,...,Pt Q) $â†(PN)Q. (b) Adversary outputs xt = (it, jt) âˆˆ ([Q] Ã—[N/Q]). (c) Output (yt 1,...,yt Q) where yt i = Pt i (xt).
2. For t âˆˆ{T âˆ’k,T âˆ’1} : (a) Sample (rtâˆ’1 1 ,...rtâˆ’1 Q ) $â†([N/Q])Q. (b) Let Pt i = Ptâˆ’1 i except we swap the values of Ptâˆ’1 i (rtâˆ’1 i ) and Ptâˆ’1 i (indtâˆ’1) for each i âˆˆ[Q]. (c) Adversary outputs xt = (it, jt). (d) Find indt s.t. Pt it(indt) = jt. (e) Output (vt 1,...,vt Q) where: â€¢ vt i = Pt i (ind) if i Ì¸= it. â€¢ vt i $â†[N/Q] if i = it. . Notice that for every k, we can show that Hk is indistinguish- able from Hkâˆ’1 by the same argument above. The only differ- ence between Hk and Hkâˆ’1 is the kâˆ’th step, where instead of sampling a fresh random permutation at step T âˆ’k +1, we use a swapped version of the permutation sampled in the last step. Since distinguishing between Hk and Hkâˆ’1 is exactly equivalent to breaking the Show and Shuffle experiment, we can conclude that this holds for every k âˆˆ{1,...,T âˆ’1}. We define HTâˆ’1 explicity below. After T âˆ’1 hybrids (where each Hkâˆ’1 and Hk are indistinguishable by the Show and Shuffle lemma), we only sample a permutation once, and swap at each step thereafter (rearranged for ease of reading): Experiment HTâˆ’1 Public Parameters: N,Q âˆˆN, assume Q|N. Experiment:
1. Sample (P0 1 ,...,P0 Q) $â†(PN)Q.
2. Adversary outputs x1 âˆˆ[N].
3. For t âˆˆ{0,...,T âˆ’1} : (a) Adversary outputs xt = (it, jt) âˆˆ ([Q] Ã—[N/Q]). (b) Find indt s.t. Pt it(indt) = jt. (c) Output (vt 1,...,vt Q) where: â€¢ vt i = Pt i (ind) if i Ì¸= it. â€¢ vt i $â†[N/Q] if i = it. . (d) Sample (rt 1,...rt Q) $â†([N/Q])Q. (e) Let Pt+1 i = Pt i except we swap the values of Pt i (rt i) and Pt i (indt) for each i âˆˆ[Q]. Notice that Experiment HTâˆ’1 and Experiment 1 are the same, except for the reordering of when each P1 i is sampled and therefore they are indistinguishable. We conclude that Experiment 1 and Experiment 0 are perfectly indistinguish- able. â–  B More Benchmarks In this section, we include benchmarks for the same tests as those already performed, however, normalizing by num- ber of operations performed by the server online, or in other words, the number of elements the online server has to read. In this case, for both static and dynamic cases, we will see that SinglePass achieves 50-100x better preprocessing time and approximately 80x better storage across the board, with simi- lar query time. The price we pay is that the query bandwidth with comparison to MIR and Checklist is much increaased. However, with query sizes hovering around 150KB-3MB, we find that it still is not an impediment for usage, since 3MB is the size of an average web page. We provide the charts in Fig- ure 10 and Figure
[2] Proverif codes. https://tinyurl.com/mw3syfmr, 2024.
[3] MartÃ­n Abadi, Bruno Blanchet, and CÃ©dric Fournet. The Applied Pi Calculus: Mobile Values, New Names, and Secure Communication. Journal of the ACM (JACM), 65(1):1 â€“ 103, October 2017.
[4] Michael Backes, Fabian Bendun, and Dominique Unruh. Computational soundness of symbolic zero-knowledge proofs: Weaker assumptions and mechanized verifica- tion. In David Basin and John C. Mitchell, editors, Principles of Security and Trust, pages 206â€“225, Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.
[6] David A. Basin, Jannik Dreier, and Ralf Sasse. Au- tomated symbolic proofs of observational equivalence. In Indrajit Ray, Ninghui Li, and Christopher Kruegel, editors, Proceedings of the 22nd ACM SIGSAC Confer- ence on Computer and Communications Security, Den- ver, CO, USA, October 12-16, 2015, pages 1144â€“1155. ACM, 2015.
[7] David Bernhard, Olivier Pereira, and Bogdan Warinschi. How not to prove yourself: Pitfalls of the fiat-shamir heuristic and applications to helios. pages 626â€“643, 12 2012.
[9] Bruno Blanchet. Automatic Verification of Security Protocols in the Symbolic Model: The Verifier ProVerif. In Alessandro Aldini, Javier Lopez, and Fabio Martinelli, editors, Foundations of Security Analysis and Design VII, volume 8604 of Lecture Notes in Computer Science, pages 54â€“87. Springer, 2014.
[10] David L. Chaum. Untraceable electronic mail, return addresses, and digital pseudonyms. Commun. ACM, 24(2):84â€“90, feb 1981.
[12] Vincent Cheval, RaphaÃ«lle CrubillÃ©, and Steve Kremer. Symbolic protocol verification with dice: process equiv- alences in the presence of probabilities. In 2022 IEEE 35th Computer Security Foundations Symposium (CSF), pages 319â€“334, 2022.
[13] Vincent Cheval, Steve Kremer, and Itsaka Rakotoni- rina. The DEEPSEC prover. In Hana Chockler and Georg Weissenbacher, editors, Computer Aided Verifi- cation - 30th International Conference, CAV 2018, Held as Part of the Federated Logic Conference, FloC 2018, Oxford, UK, July 14-17, 2018, Proceedings, Part II, vol- ume 10982 of Lecture Notes in Computer Science, pages 28â€“36. Springer, 2018.
[14] VÃ©ronique Cortier, Pierrick Gaudry, and StÃ©phane Glondu. Features and usage of Belenios in 2022. In The International Conference for Electronic Voting (E-Vote- ID 2022), Bregenz / Hybrid, Austria, October 2022.
[15] VÃ©ronique Cortier and Ben Smyth. Attacking and fix- ing helios: An analysis of ballot secrecy. Journal of Computer Security, 21:297â€“311, 06 2011.
[18] Chris Culnane, Peter Y. A. Ryan, Steve Schneider, and Vanessa Teague. Vvote: A verifiable voting system. ACM Trans. Inf. Syst. Secur., 18(1), jun 2015.
[20] S. Delaune, S. Kremer, and M. Ryan. Coercion- resistance and receipt-freeness in electronic voting. In 19th IEEE Computer Security Foundations Workshop (CSFWâ€™06), pages 12 pp.â€“42, 2006.
[21] StÃ©phanie Delaune, Steve Kremer, and Mark Ryan. Ver- ifying privacy-type properties of electronic voting pro- tocols. J. Comput. Secur., 17(4):435â€“487, dec 2009.
[27] Rosario Giustolisi, Gabriele Lenzini, and Peter Y. A. Ryan. Remark!: A secure protocol for remote exams. In Security Protocols Workshop, 2014.
[28] Kristian GjÃ¸steen. The norwegian internet voting pro- tocol. In Aggelos Kiayias and Helger Lipmaa, editors, E-Voting and Identity, pages 1â€“18, Berlin, Heidelberg, 2012. Springer Berlin Heidelberg.
[35] Sebastian MÃ¶dersheim. Diffie-hellman without diffi- culty. In Gilles Barthe, Anupam Datta, and Sandro Etalle, editors, Formal Aspects of Security and Trust, pages 214â€“229, Berlin, Heidelberg, 2012. Springer Berlin Heidelberg.
[38] O. Pereira and J.-J. Quisquater. A security analysis of the cliques protocols suites. In Proceedings. 14th IEEE Computer Security Foundations Workshop, 2001., pages 73â€“81, 2001.
[40] Mohammadamin Rakeei, Rosario Giustolisi, and Gabriele Lenzini. Secure internet exams despite coercion. In 17th DPM International Workshop on Data Privacy Management. Springer, 2022.
[41] A. Roscoe. The Theory and Practice of Concurrency. 01 2005.
[43] Efstathios Stathakidis, Steve Schneider, and James Heather. Robustness modelling and verification of a mix net protocol. pages 131â€“150, 12 2014.
[3] Yuriy Arbitman, Moni Naor, and Gil Segev. Backyard cuckoo hashing: Constant worst-case operations with a succinct representation. 2010 IEEE 51st Annual Sympo- sium on Foundations of Computer Science, pages 787â€“ 796, 2010.
[7] Nishanth Chandran, Divya Gupta, and Akash Shah. Circuit-PSI with Linear Complexity via Relaxed Batch OPPRF. In 22nd Privacy Enhancing Technologies Sym- posium (PETS 2022), jun 2022.
[8] Melissa Chase, Hao Chen, Jintai Ding, Shafi Goldwasser, Sergey Gorbunov, Jeffrey Hoffstein, Kristin Lauter, Satya Lokam, Dustin Moody, Travis Morrison, Amit Sahai, and Vinod Vaikuntanathan. Security of homo- morphic encryption. Technical report, Homomorphi- cEncryption.org, Redmond WA, USA, July 2017.
[12] Benny Chor, Niv Gilboa, and Moni Naor. Private infor- mation retrieval by keywords. pages 0â€“18, 1997.
[16] Daniel Demmler, Peter Rindal, Mike Rosulek, and Ni Trieu. PIR-PSI: Scaling Private Contact Discov- ery. Proceedings on Privacy Enhancing Technologies, 2018:159â€“178, 10 2018.
[22] Mihaela Ion, Ben Kreuter, Ahmet Erhan Nergiz, Sar- var Patel, Shobhit Saxena, Karn Seth, Mariana Raykova, David Shanahan, and Moti Yung. On Deploying Secure Computing: Private Intersection-Sum-with-Cardinality. In 2020 IEEE European Symposium on Security and Pri- vacy (EuroS&P), pages 370â€“389, Genoa, Italy, Septem- ber 2020. IEEE.
[25] Adam Kirsch, Michael Mitzenmacher, and Udi Wieder. More robust hashing: Cuckoo hashing with a stash. SIAM Journal on Computing, 39(4):1543â€“1561, 2010.
[31] Rasmus Pagh and Flemming Friche Rodler. Cuckoo hashing. J. Algorithms, 51(2):122â€“144, may 2004.
[36] L. Reichert, M. Pazelt, and B. Scheuermann. Circuit- based psi for covid-19 risk scoring. In 2021 IEEE In- ternational Performance, Computing, and Communica- tions Conference (IPCCC), pages 1â€“8, Los Alamitos, CA, USA, oct 2021. IEEE Computer Society.
[39] Ni Trieu, Kareem Shehata, P. Saxena, R. Shokri, and Dawn Xiaodong Song. Epione: Lightweight contact tracing with strong privacy. ArXiv, abs/2004.13293, 2020.
[40] Alexander Viand, Christian Knabenhans, and Anwar Hithnawi. Verifiable fully homomorphic encryption, 2023.
[41] Udi Wieder. Hashing, load balancing and multiple choice. Foundations and TrendsÂ® in Theoretical Com- puter Science, 12(3â€“4):275â€“379, 2017.
1. When hashing m client elements and n server ele- ments to Î»-bit strings, the probability of failure in the protocol due to collisions is upper bounded by bÎ³Âµ 2Î» , (2) where b, Î³, and Âµ are the number of bins, maximum client bin size, and maximum server bin size, respectively. Proof. Let P[B] denote the probability of failure due to a collision. Let P[Bi] denote the probability of there existing a collision between any two of the elements of bin i, for i âˆˆ{1,2,Â·Â·Â· ,b}. So we have P[B] â‰¤âˆ‘ iâˆˆ[b] P[Bi]. (3) We know that, in a given bin, failure only occurs when two unequal elements, one from the server and the other from the client, have an equal constant-weight mapping. We know that the probability of a collision between two distinct ele- ments from the domain is 2âˆ’Î», where the probability is in expectation over all perfect hash functions. Hence, combining the facts stated above, we have that P[B] â‰¤âˆ‘ iâˆˆ[b] P[Bi] = âˆ‘ iâˆˆ[b] Î³Âµ2âˆ’Î» = bÎ³Âµ2âˆ’Î». (4) Algorithm 6 Client and server data preparation 1: algorithm CLIENTDATAPREP(X) 2: Initialize Tc with b bins. 3: for each element x âˆˆX do 4: Append x to the bins of Tc according to the bin- ning strategy 5: Append dummy elements to fill each bin in Tc to the max 6: for each bin k âˆˆ[b] do 7: for each batch i âˆˆ[Î³] do 8: T â€² c[k][i] = CW-ENCODE(Tc[k][i],â„“,h) 9: for each batch i âˆˆ[Î³] do 10: for each bit j âˆˆ[â„“] do 11: pt[i][j] = [T â€² c[1][i][j],T â€² c[2][i][j],Â·Â·Â· ,T â€² c[b][i][j]] 12: ctc[i][j] = Enc(ptc[i][j],skc) 13: return ctc 14: algorithm SERVERDATAPREP(Y) 15: Initialize Ts with b bins 16: for each server element y âˆˆY do 17: Append y to bins chosen by the binning strategy. 18: Append dummy elements to fill each bin in Ts to Âµ. 19: for each batch k âˆˆ[b] do 20: for each batch i âˆˆ[Âµ] do 21: T â€² s [k][i] = CW-ENCODE(Tc[k][i],â„“,h) 22: for each batch i âˆˆ[Âµ] do 23: for each bit j âˆˆ[â„“] do 24: pts[i][j] = [T â€² s [1][i][j],T â€² s [2][i][j],Â·Â·Â· ,T â€² s [b][i][j]] 25: return pts B Data Preparation The algorithm for server and client data preparation is pro- vided as Algorithm
3. Algorithm 7 is correct, i.e., M is zero at the index of the kth one in I, and non-zero in all the indicies. Proof. Let i1 < i2 < Â·Â·Â· < is be the indicies such that I[i1] = I[i2] = Â·Â·Â· = I[is] = 1 and I[i] = 0 for i Ì¸= i j. If M[i] = kÂ·I[i]âˆ’ 1âˆ’âˆ‘iâ€²â‰¤i I[iâ€²] then M[ik] = k Â·I[ik]âˆ’1âˆ’âˆ‘ iâ€²<ik I[iâ€²] = k âˆ’1âˆ’(k âˆ’1) = 0 Moreover, j Ì¸= k â‡’M[ij] = k Â·I[ij]âˆ’1âˆ’âˆ‘ iâ€²<ij I[iâ€²] = k âˆ’j Ì¸= 0 ij < i < ij+1 â‡’M[i] = k Â·I[i]âˆ’1âˆ’âˆ‘ iâ€²â‰¤i I[iâ€²] = âˆ’1âˆ’j Ì¸= 0 which proves the theorem. The security of this algorithm is proven by showing that M reveals nothing about I other than the position of the kth one in the array. Theorem
[1] Libsodium library. https://libsodium.gitbook.io. [Online; accessed February 2023].
[4] Tyler Akidau, Robert Bradshaw, Craig Chambers, Slava Chernyak, et al. The dataï¬‚ow model: A practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing. Proceedings of the VLDB Endowment, 8(12), 2015.
[5] Amazon AWS. AWS EC2 On Demand Pricing. https://aws.amazon.com/ec2/pricing/on-demand/. [Online; accessed February 2023].
[8] Gilad Asharov, T-H. Hubert Chan, Kartik Nayak, Rafael Pass, Ling Ren, and Elaine Shi. Bucket oblivious sort: An extremely simple oblivious sort, 2021.
[10] Kenneth E. Batcher. Sorting networks and their applications. In AFIPS Spring Joint Computing Conference, volume 32 of AFIPS Conference Proceedings, pages 307â€“314. Thomson Book Company, Washington D.C., 1968.
[12] George EP Box, Gwilym M Jenkins, Gregory C Reinsel, and Greta M Ljung. Time series analysis: forecasting and control. John Wiley & Sons, 2015.
[26] Eli Cortez, Anand Bonde, Alexandre Muzio, Mark Russinovich, Marcus Fontoura, and Ricardo Bianchini. Re- source central: Understanding and predicting workloads for improved resource management in large cloud plat- forms. In SOSP, pages 153â€“167. ACM, 2017.
[27] Anders P. K. Dalskov, Daniel Escudero, and Marcel Keller. Secure evaluation of quantized neural networks. Proc. Priv. Enhancing Technol., 2020(4):355â€“375, 2020.
[33] F. Emekci, D. Agrawal, A. E. Abbadi, and A. Gulbeden. Privacy preserving query processing using third parties. In 22nd International Conference on Data Engineering (ICDEâ€™06), pages 27â€“27, 2006.
[37] Muhammad Faisal, Jerry Zhang, John Liagouris, Vasiliki Kalavri, and Mayank Varia. TVA GitHub repository. https://github.com/CASP-Systems-BU/tva, 2023.
[40] Liyue Fan and Li Xiong. Real-time aggregate monitoring with differential privacy. In CIKM, pages 2169â€“2173. ACM, 2012.
[41] Ferdinando Fioretto and Pascal Van Hentenryck. Optstream: Releasing time series privately. J. Artif. Intell. Res., 65:423â€“456, 2019.
[45] Craig Gentry. Fully homomorphic encryption using ideal lattices. In STOC, pages 169â€“178. ACM, 2009.
[46] Oded Goldreich. Towards a theory of software protection and simulation by oblivious RAMs. In STOC, pages 182â€“194. ACM, 1987.
[47] Oded Goldreich and Rafail Ostrovsky. Software protection and simulation on oblivious RAMs. J. ACM, 43(3):431â€“473, May 1996.
[48] Michael T. Goodrich. Data-oblivious external-memory algorithms for the compaction, selection, and sorting of outsourced data. In SPAA, pages 379â€“388. ACM, 2011.
[54] D. Harris. A taxonomy of parallel preï¬x networks. In The 37th Asilomar Conference on Signals, Systems & Computers, volume 2, pages 2213â€“2217, 2003.
[55] MatÂ´us Harvan, Samuel Kimoto, Thomas Locher, Yvonne-Anne Pignolet, and Johannes Schneider. Processing encrypted and compressed time series data. In ICDCS, pages 1053â€“1062. IEEE Computer Society, 2017.
[58] Marek Jawurek, Florian Kerschbaum, and George Danezis. Privacy technologies for smart grids - a survey of options. Technical Report MSR-TR-2012-119, November 2012.
[59] SÃ¸ren Kejser Jensen, Torben Bach Pedersen, and Christian Thomsen. Time series management systems: A survey. IEEE Trans. Knowl. Data Eng., 29(11):2581â€“2600, 2017.
[61] KristjÂ´an Valur JÂ´onsson, Gunnar Kreitz, and Misbah Uddin. Secure multi-party sorting and applications. In ACNS, June 2011.
[63] Manos Katsomallos, Katerina Tzompanaki, and Dimitris Kotzinos. Landmark privacy: Conï¬gurable differential privacy protection for time series. In CODASPY, pages 179â€“190. ACM, 2022.
[67] Brian Knott, Shobha Venkataraman, Awni Y. Hannun, Shubho Sengupta, Mark Ibrahim, and Laurens van der Maaten. CrypTen: Secure multi-party computation meets machine learning. In NeurIPS, pages 4961â€“4973, 2021.
[68] Simeon Krastnikov, Florian Kerschbaum, and Douglas Stebila. Efï¬cient oblivious database joins. Proc. VLDB Endow., 13(11):2132â€“2145, 2020.
[71] Yehuda Lindell. Secure multiparty computation. Commun. ACM, 64(1):86â€“96, December 2020.
[72] Yasuko Matsubara, Yasushi Sakurai, Willem G. van Panhuis, and Christos Faloutsos. FUNNEL: automatic mining of spatially coevolving epidemics. In KDD, pages 105â€“114. ACM, 2014.
[75] Muhammad Naveed, Seny Kamara, and Charles V. Wright. Inference attacks on property-preserving encrypted databases. In ACM Conference on Computer and Communications Security, pages 644â€“655. ACM, 2015.
[76] Spiros Papadimitriou and Philip S. Yu. Optimal multi-scale patterns in time series streams. In SIGMOD Confer- ence, pages 647â€“658. ACM, 2006.
[78] Rishabh Poddar, Tobias Boelter, and Raluca Ada Popa. Arx: An encrypted database using semantically secure encryption. Proc. VLDB Endow., 12(11):1664â€“1678, July 2019.
[80] Vibhor Rastogi and Suman Nath. Differentially private aggregation of distributed time-series with transformation and encryption. In SIGMOD Conference, pages 735â€“746. ACM, 2010.
[81] Yasushi Sakurai, Yasuko Matsubara, and Christos Faloutsos. Mining and forecasting of big time-series data. In SIGMOD Conference, pages 919â€“922. ACM, 2015.
[82] Hossein Shafagh, Anwar Hithnawi, Lukas Burkhalter, Pascal Fischli, and Simon Duquennoy. Secure sharing of partially homomorphic encrypted iot data. In SenSys, pages 29:1â€“29:14. ACM, 2017.
[83] Hossein Shafagh, Anwar Hithnawi, Andreas Droescher, Simon Duquennoy, and Wen Hu. Talos: Encrypted query processing for the internet of things. In SenSys, pages 197â€“210. ACM, 2015.
[85] Jonas Traub, Philipp M Grulich, Alejandro RodrÂ´Ä±guez CuÂ´ellar, Sebastian BreÃŸ, Asterios Katsifodimos, Tilmann Rabl, and Volker Markl. Efï¬cient window aggregation with general stream slicing. In EDBT, volume 19, pages 97â€“108, 2019.
[86] Maria Lorena Tuballa and Michael Lochinvar Abundo. A review of the development of smart grid technologies. Renewable and Sustainable Energy Reviews, 59:710â€“725, 2016.
[87] Abhishek Verma, Luis Pedrosa, Madhukar R. Korupolu, David Oppenheimer, Eric Tune, and John Wilkes. Large- scale cluster management at Google with Borg. In EuroSys, pages 18:1â€“18:17. ACM, 2015.
[88] Thijs Veugen and Mark Abspoel. Secure integer division with a private divisor. Proc. Priv. Enhancing Technol., 2021(4):339â€“349, 2021.
[89] Nikolaj Volgushev, Malte Schwarzkopf, Ben Getchell, Mayank Varia, Andrei Lapets, and Azer Bestavros. Con- clave: secure multi-party computation on big data. In EuroSys, pages 3:1â€“3:18. ACM, 2019.
[91] Hao Wang and Zhengquan Xu. CTS-DP: publishing correlated time-series data via differential privacy. Knowl. Based Syst., 122:167â€“179, 2017.
[92] Wanli Xue, Chengwen Luo, Guohao Lan, Rajib Kumar Rana, Wen Hu, and Aruna Seneviratne. Kryptein: a compressive-sensing-based encryption scheme for the internet of things. In IPSN, pages 169â€“180. ACM, 2017.
[93] Zheguang Zhao, Seny Kamara, Tarik Moataz, and Zdonik Stan. Encrypted databases: From theory to systems. In Proceedings of the 11th Annual Conference on Innovative Data Systems Research, 2021. 25
[97] Yunyue Zhu and Dennis E. Shasha. StatStream: Statistical monitoring of thousands of data streams in real time. In VLDB, pages 358â€“369. Morgan Kaufmann, 2002. 26 Functionality Fabb input: Invoked upon receiving (input, Pi, type, id, â„“x, x) from party Pi and (input, Pi, type, id, â„“x) from all other parties. Veriï¬es that id is a fresh identiï¬er and type âˆˆ{arithmetic, boolean}. Stores (type, id, â„“x, x) into memory. shared input: This is an optional method. It is invoked upon receiving (INP, Pi, Pj, type, id, â„“x, x) from party Pi, (INP, Pi, Pj, type, id, â„“x, xâ€²) from party Pj, and (input, Pi, Pj, type, id, â„“x) from all other parties. Veriï¬es that x = xâ€², id is a fresh identiï¬er, and type âˆˆ{arithmetic, boolean}. Stores (type, id, â„“x, x) into memory. add: Invoked upon receiving (add, type, id1, id2, idnew) from all parties. Retrieves from memory the values x1, x2 corresponding to identiï¬ers id1, id2. Veriï¬es that both of them are of the stated type and have the same length â„“x, and that idnew is a fresh identiï¬er. If type = arithmetic, then set x = x1 + x2 mod 2â„“x. If type = boolean, then set x = x1 âŠ•x2. Stores (type, idnew, â„“x, x) into memory. mult: Invoked upon receiving (mult, type, id1, id2, idnew) from all parties. Retrieves from memory the values x1, x2 corresponding to identiï¬ers id1, id2. Veriï¬es that both of them are of the stated type and have the same length â„“x, and that idnew is a fresh identiï¬er. If type = arithmetic, then set x = x1 â‹…x2 mod 2â„“x. If type = boolean, then set x = x1 âˆ§x2. Stores (type, idnew, â„“x, x) into memory. A2B: Invoked upon receiving (A2B, id, idnew) from all parties. Retrieves from memory the tuple (type, id, â„“x, x) with identiï¬er id. Veriï¬es that type = arithmetic and idnew is a fresh identiï¬er. Stores (boolean, idnew, â„“x, x) into memory. B2A: Invoked upon receiving (B2A, id, idnew) from all parties. Retrieves from memory the tuple (type, id, â„“x, x) corresponding to identiï¬er id. Veriï¬es that type = boolean and idnew is a fresh identiï¬er. Stores (arithmetic, idnew, â„“x, x) into memory. b2A: Invoked upon receiving (B2A, id, idnew, Ëœâ„“x) from all parties. Retrieves from memory the tuple (type, id, â„“x, x) corresponding to identiï¬er id. Veriï¬es that type = boolean, idnew is a fresh identiï¬er, and â„“x =
1. Stores (arithmetic, idnew, Ëœâ„“x, x) into memory. output: Invoked upon receiving (output, Pi, type, id) from all parties. Retrieves from memory the value x corresponding to identiï¬er id, and sends it to party Pi. Figure 5: Arithmetic black-box functionality Fabb that supports mixed-mode operations and conversions. Based upon Escudero et al. [35, Figure 1], with a few modiï¬cations described in
1. Zero-knowledge: The proof reveals no information to V beyond the fact that P knows a satisfying witness.
2. Succinct: The size of the proof and its verification is sub- linear in the size of the satisfiability instance.
3. Non-interactive: No interaction between P and V besides the transferring of the computationâ€™s output and proof.
[12] fails to meet Reefâ€™s expressive- ness goals. The most recent works in this area lack support for several common regex features. For example, Zombie
[79] lacks support for lookarounds. ZK-Regex
[56] does not handle lookarounds, negations in character classes such as â€œa[^[:space:]bâ€, or nega- tions of entire matches (i.e., proving a non-match). Finally, zkreg [64], which is based on AC-DFA, only supports matching on a fixed set of strings. Unbounded repetition such as â€œab*câ€ is unsupported, and negation of character classes, negation of entire matches, or wildcard ranges such as â€œa.{100}bâ€ lead to an exponential number of states (2100). Poor scalability. The number of R1CS constraints produced by the standard approach for proving that a document D matches is O(|D|Â·|QDFA|Â·|Î£|), where |QDFA| is the number of states of the corresponding DFA. Zombie
[79] improves this to O(|D|Â·|QTNFA|). But for applications where the document is millions of characters this still results in billions of constraints, even when the regex is small. In contrast, Reefâ€™s NP checkerâ€” based on SAFA (Â§5)â€”has O(Î± log(|D| + |QSAFA| Â· |Î£|)) con- straints, where |QSAFA| â‰¤|QTNFA|. As we discuss in Sec- tion 6.2, in the worst case Î± = O(|D| Â· L), where L is the number of lookarounds in the regex; but in practice Î± is small (under 100 for even our largest document). 4 Improving the standard approach One way to improve on the standard approach is to observe that the match function is well suited for a recursive proof system (this observation has been made many times in the context of other state machines such as blockchain rollups). In a recursive zkSNARK [18â€“20, 24â€“26, 50, 51], instead of arithmetizing the entire match function, we arithmetize one step of it. The result is: field[3] match_step(field[] commit, field[] blind, field state, field cursor) { field cur_char = open_at(commit, blind, cursor); // accepting state and end of document (EOD) if (cur_char == EOD && state == 2) { return {0, 0, 1}; // match } state = delta(state, cur_char); return {state, cursor + 1, 0}; // not yet } The above match_step function takes as input a public polynomial [13, 23, 37, 47, 54, 76, 80] or vector
[27] are finite automata that generalize NFA by labeling states with an existential (âˆƒ) or a universal (âˆ€) quantifier. An âˆƒstate is identical to a state in an NFA; the AFA merely reads the character at the current cursor, advances the cursor, and then transitions to any one of its possible next states. A âˆ€ state is very different. First, the AFA creates a copy of the remaining characters in the input string (starting at the current cursor until the end of the string) for each of its transitions (i.e., if there are 10 transitions it will create 10 copies of the input string). Then, in parallel, it transitions to every next state, and feeds each of those states their own independent copy of the input. For the AFA to accept an input string, all of the parallel branches need to end in accepting states. Intuitively, âˆ€states capture the conjunction of multiple sub-automata, each of which operates independently on the provided input. Formally, an AFA
[27] is a 6-tuple (Q, Î£, q0, Î»q, Î´, F), where Q is the set of all states; Î£ is the alphabet; q0 âˆˆQ is the initial state; Î»q : Q â†’{âˆ€, âˆƒ} is a labeling that assigns each state q either âˆ€or âˆƒ; Î´ âŠ†Q Ã— Î£ Ã— Q is a transition relation that defines final states with respect to initial states and input characters; F âŠ†Q is the set of accepting states. Example. Suppose we want to match documents of length between 2â€“6 that contain â€œaâ€ and â€œbâ€ defined over Î£ = {a, b, c}. This is given by the regex R = â€œ^(?=.*a)(?=.*b).{2,6}$â€. Representing R as an NFA requires creating an automaton that accepts the alter- nation of all strings that contain both â€œaâ€ and â€œbâ€ and have length between 2 to 6 (â€œabâ€, â€œ.abâ€, â€œa..bâ€, â€œ.a.b.â€, etc.). The minimal NFA for this has 17 states (the 16 shown here
[54] has smaller commitments but its ProveEval algorithm results in larger proofs and is more expensive). Let the Pedersen commitment for a vector x âˆˆF n be: Pedersen(x, b) = hb Â· n Y i=1 gxi i where g1, . . . , gn and h are public random generators of the group over which the zkSNARK is defined (Pallas elliptic curve
[42] in our case) and b âˆˆF is a secret random blind. Hyrax-PC treats T as the column-major order of a âˆšn-by-âˆšn matrix M, and commits to each row of M using a Perdersen vector commitment. This means that the commitment in Reef is âˆšn group elements, and there are âˆšn random blinds. Making nlookup zero-knowledge. nlookup
1. For this example, it follows that for all qr âˆˆF â„“â€² eTâ€²(qr) = eT(s, qr), where s = 01 âˆˆ{0, 1}2 = {0, 1}â„“âˆ’â„“â€². In the context of nlookup, to check that eTâ€²(qr) = vr, the verifier can instead check eT(s, qr) = vr, where s =
01. A key take-away here is that for 0 â‰¤â„“â€² â‰¤â„“, observe that a specified prefix s âˆˆ{0, 1}â„“âˆ’â„“â€² â€œselectsâ€ a unique chunk of T and specifies a particular projection of size 2â„“â€². Note that this approach generalizes to project non- contiguous chunks of T. For simplicity, suppose that we want to project two chunks of T, specified with two selectors s1 âˆˆ{0, 1}â„“â€² and s2 âˆˆ{0, 1}â„“â€², where 0 â‰¤â„“â€² â‰¤â„“. The pro- jected table Tâ€² = (L, R) is a vector of size 2â„“âˆ’â„“â€²+1 and L and R are vectors of size 2â„“âˆ’â„“â€², so eTâ€² is a multilinear polynomial in â„“âˆ’â„“â€²+1 variables. When we run nlookup with the projected table Tâ€², the verifier ends up with a claim about the projected table of the form eTâ€²(qr) = vr, where qr âˆˆF â„“âˆ’â„“â€²+1. Again, derived from the properties of multilinear polynomials, eTâ€²(qr) = (1 âˆ’qr[0]) Â· eL(qr[1..]) + qr[0] Â· eR(qr[1..]) = (1 âˆ’qr[0]) Â· eT(s1, qr[1..]) + qr[0] Â· eT(s2, qr[1..]) Thus to check if eTâ€²(qr) = vr, the verifier can instead check if (1 âˆ’qr[0]) Â· eT(s1, qr[1..]) + qr[0] Â· eT(s2, qr[1..]) = vr, which makes two evaluation queries to eT. Note that this idea gener- alizes to projecting k > 2 non-contiguous chunks of T. Low-cost padding to hide document size. In many settings, one would like to hide not just the content of D, but also its size. For example, if D is a password, revealing its size reveals the passwordâ€™s length. Projections allow the commit- ment generator G to pad the document to some upper bound (essentially for free) while allowing P to perform operations proportional to the unpadded document and without having to reveal the selector s to V. Our tech report
[65] zero-knowledge proof of equality Ï€eq. Security. When the verifier computes the commitment CL, it does not learn any additional information about vd as the operations are done using Cvd (Cvd is a commitment that hides the underlying value vd). Furthermore, Ï€eq proves that the values under the commitments CL and Cvr are the same without revealing any additional information. 7 Implementation Reef is implemented in 14K lines of Rust and is open source [8]. We discuss the main components here and op- timizations in our tech report [15]. 7.1 Compilation: from regex to R1CS Reef has two levels of compilation. First, Reef compiles regexes written in standard PCRE syntax
[7] (Figure 1) and produces a SAFA. From this SAFA, Reef generates the SAFAâ€™s transition lookup table and the match_step func- tion discussed in Section 5.3. Since the match_step function uses lookups it also contains the checks that the nlookup verifier
[51] must perform in each step. In particular, it con- tains a series of Fiat-Shamir challenges that we generate with the Poseidon hash function
[39] using the Neptune library [3]. Finally, Reef uses the CirC
[61] compiler to output R1CS instances that we convert to Bellman
[1] instances. 7.2 Solving: finding the satisfying witness Reef, given a document D, finds the witness to the R1CS instance representing match_step in two parts. First, Reef derives which paths in the SAFA to take, the skip values, the entries in D to read, and the rows in the transition table to look up. Reefâ€™s solver might be of independent interest and we discuss it in our tech report [15]. This solver only needs to run once and tells P how many steps to prove. Second, for each step, Reef runs the nlookup prover, which we implement as there was no prior implementation, to generate the values that will satisfy the nlookup checks that were inserted in the corresponding match_step. The result of this and the SAFA solver are sufficient to construct the entire solution vector zi = (yi, 1, wi) where wi is the witness and yi is the output of step i. 7.3 Proving knowledge of the witness For the proving and verifying, we use Nova [4], which we modify to make it zero-knowledge (the existing implementa- tion was only succinct). This required changing 1.6K lines of Rust to hide the number of steps executed, and making the commitments hiding, and the folding scheme, sumcheck pro- tocol, inner product argument, and SNARK zero-knowledge. Our modified version of Nova is open source [5]. 8 Costs and Complexity analysis In this section we discuss the asymptotic costs of all of the components of Reef. The analysis below considers the case where Nova
[52] uses Pedersen commitments to commit to vectors, and Spartan
[66] uses an IPA-based polynomial com- mitment scheme to compress incrementally generated proofs. Furthermore, for nlookup [51], the analysis considers the case where documents are committed with Hyraxâ€™s poly- nomial commitment scheme [76]. Finally, one of the basic operations of the above proof systems are multiexponentia- tions: given generators g1, . . . , gn, and exponents e1, . . . , en, compute ge1 1 Â· ge2 2 Â· Â· Â· gen n . These are also called multi-scalar multiplications (MSM). These proof systems typically use Pippengerâ€™s algorithm
[63] which can compute a size-n MSM in O(nÎ»/ log(nÎ»)) group operations. We will ignore the secu- rity parameter Î» and just treat a size-n MSM as O(n/ log n) group operations. For simplicity, let T = |D| + |QSAFA| be the sum of the size of both the document and the SAFA lookup tables. Committerâ€™s costs. Committing to a document D with Hyraxâ€™s polynomial commitment
[15] we discuss how Reef often batches many character and skip transitions into one step (leading to a larger step function but fewer total steps). Reef generally performs worse on regexes where the regex is similar to the document, as it gives Reefâ€™s prover fewer opportunities to skip and stop early. For example, the email redaction regexes are very similar to the original doc- ument, and hence result in more proving steps than some of the other regexes, and consequently larger proving time. Reefâ€™s benefits are best exemplified with the DNA match- ing application, in which the document has over 32 million characters. Reef is able to generate succinct proofs for DNA in under 30 seconds (including both solving and proving) because it can avoid processing most of the document, thanks to its use of skips and projections. Verification. The verifierâ€™s costs depend on the number of R1CS constraints for a single step (since Nova folds all steps into one), as well as the cost to evaluate the SAFA polynomial at a random point, and check the consistency polynomial eval- uation, and the equality proof. Novaâ€™s current implementation uses Bulletproofsâ€™s
[2] to com- pile the match function and solve the corresponding R1CS instance since CirC
[61] is not presently capable of com- piling such large statements due to memory issues. â€¢ DFA + recursion. This is the approach described in Sec- tion 4, which adds recursion and processes one character at a time. It uses a hash-chain as a vector commitment, which we believe is optimal (exactly one hash invocation) when accessing entries in the committed document sequentially. We use Circom and NovaScotia
[6] to compile the step function and connect it with our zero-knowledge version of Nova (Â§7.3). Again, we are unable to compile these R1CS instances with CirC since they require expressing the (large) DFA delta function in constraints. â€¢ SAFA + lookup. This is our implementation of Reef (Â§7) with SAFA and nlookup, but without projections (Â§6.4) or the hybrid table optimization (Â§6.5). The metrics that we will consider in this section are mem- ory usage and end-to-end completion time for the Prover, which includes both the time to solve and generate all wit- ness values, and prove the satisfiability of the R1CS instance. Our tech report
[15] has additional graphs for these same experiments but separates the time for solving and proving for readers interested in understanding the contribution of each component towards the end-to-end time. One thing to consider is that Reef pipelines the generation of a proof for step i with the generation of the witness for step i + 1 in parallel, as we discuss in our tech report [15]. As a result, the end-to-end time can sometimes be lower than the sum of the corresponding proving and solving times. Results. Figure 7 shows the maximum memory use of Reef and the baselines for the same documents and regexes found in Figure
[79] excel in the opposite regime (small documents or when the document closely matches the regex). We think there are opportunities to combine the techniques in these two approaches to obtain the best of both worlds. Reef has the ability to prove regex matches (and non- matches), but an interesting extension is to support â€œsearch and replaceâ€. In such a setting, the prover would prove not whether there is a match for some regex but rather that some committed document is the result of performing a regex search and replace transformation on some other commit- ted document. Another extension to Reef is to support context free grammars. We think a similar approach of developing a custom automata would work there, and Reef already uses a stack for SAFA, which we show is quite efficient. Source Code Our code is available at: https://github.com/eniac/Reef.
[14] Katharina Boudgoust, Corentin Jeudy, Adeline Roux- Langlois, and Weiqiang Wen. On the hardness of module-lwe with binary secret. In CT-RSA, volume 12704 of Lecture Notes in Computer Science, pages 503â€“ 526. Springer, 2021.
[15] Zvika Brakerski, Adeline Langlois, Chris Peikert, Oded Regev, and Damien StehlÃ©. Classical hardness of learn- ing with errors. CoRR, abs/1306.0281, 2013.
34. Springer, 2022.
[17] Jacqueline Brendel, Marc Fischlin, Felix GÃ¼nther, Chris- tian Janson, and Douglas Stebila. Towards post-quantum security for signalâ€™s X3DH handshake. In SAC, volume 12804 of Lecture Notes in Computer Science, pages 404â€“ 430. Springer, 2020.
[24] Daniel Collins, Simone Colombo, and LoÃ¯s Huguenin- Dumittan. Real world deniability in messaging. Cryp- tology ePrint Archive, 2023.
[33] Cynthia Dwork, Moni Naor, and Amit Sahai. Concur- rent zero-knowledge. Journal of the ACM (JACM), 51(6):851â€“898, 2004.
[42] Brian LaMacchia, Kristin Lauter, and Anton Mitya- gin. Stronger security of authenticated key exchange. In Provable Security: First International Conference, ProvSec 2007, Wollongong, Australia, November 1-2, 2007. Proceedings 1, pages 1â€“16. Springer, 2007.
[44] Xingye Lu, Man Ho Au, and Zhenfei Zhang. Raptor: A practical lattice-based (linkable) ring signature. In ACNS, volume 11464 of Lecture Notes in Computer Science, pages 110â€“130. Springer, 2019.
[47] Vadim Lyubashevsky. Fiat-shamir with aborts: Applica- tions to lattice and factoring-based signatures. In ASI- ACRYPT, volume 5912 of Lecture Notes in Computer Science, pages 598â€“616. Springer, 2009.
[50] Moxie Marlinspike and Trevor Perrin. The x3dh key agreement protocol. Open Whisper Systems, 283, 2016.
[54] Trevor Perrin and Moxie Marlinspike. The double ratchet algorithm. GitHub wiki, 2016.
[58] Peter W. Shor. Polynominal time algorithms for dis- crete logarithms and factoring on a quantum computer. In Leonard M. Adleman and Ming-Deh A. Huang, ed- itors, Algorithmic Number Theory, First International Symposium, ANTS-I, Ithaca, NY, USA, May 6-9, 1994, Proceedings, volume 877 of Lecture Notes in Computer Science, page 289. Springer, 1994.
[60] Nik Unger and Ian Goldberg. Deniable key exchanges for secure messaging. In Indrajit Ray, Ninghui Li, and Christopher Kruegel, editors, Proceedings of the 22nd ACM SIGSAC Conference on Computer and Commu- nications Security, Denver, CO, USA, October 12-16, 2015, pages 1211â€“1223. ACM, 2015.
[61] Nik Unger and Ian Goldberg. Improved strongly deni- able authenticated key exchanges for secure messaging. Proc. Priv. Enhancing Technol., 2018(1):21â€“66, 2018.
[33] on our Android phone and fetching the ï¬le via adb [45]. While the SDK is compiled into the mes- saging application, it is also available separately in a public Maven repository
[15] as an AAR ï¬le. Static Analysis. We decompiled Bridgefy to reconstruct Java source code for better readability. The APK ï¬le was directly decompiled using Jadx [54], but also converted into a JAR ï¬le using enjarify
[34] for further processing. The AAR ï¬le was extracted to retrieve a JAR ï¬le. Both JAR ï¬les were then decompiled to Java source, leveraging multiple Java decompilers: CFR [5], Fernï¬‚ower [39], Krakatau [35], and Procyon [55]. While the output was obfuscated, Bridgefyâ€™s code sometimes references class and method names in debug messages. Dynamic Analysis. After manually inspecting the Java code, we instrumented the Bridgefy messenger with Frida
[1] AGER, B., CHATZIS, N., FELDMANN, A., SARRAR, N., UHLIG, S., AND WILLINGER, W. Anatomy of a large European IXP. In SIG- COMM (2012).
[6] BANIK, S., BAROOTI, K., VAUDENAY, S., AND YAN, H. New attacks on LowMC instances with a single plaintext/ciphertext pair.
[7] BAR, J. The floodgates are open â€“ increased network bandwidth for EC2 instances. https://aws.amazon.com/blogs/aws/the-flood gates-are-open-increased-network-bandwidth-for-ec2-i nstances/, 2018.
[8] BEAVER, D., MICALI, S., AND ROGAWAY, P. The round complexity of secure protocols. In STOC (1990),
[9] BOGDANOV, D., KAMM, L., KUBO, B., REBANE, R., SOKK, V., AND TALVISTE, R. Students and taxes: a privacy-preserving study using secure computation. Proc. Priv. Enhancing Technol. 2016, 3 (2016), 117â€“135.
[11] BUNN, P., KATZ, J., KUSHILEVITZ, E., AND OSTROVSKY, R. Effi- cient 3-party distributed ORAM. In SCN (2020).
[13] CHAUM, D., CRÃ‰PEAU, C., AND DAMGÃ…RD, I. Multiparty Uncondi- tionally Secure Protocols. In STOC (1988).
[18] FALK, B. H., NOBLE, D., AND OSTROVSKY, R. 3-party distributed ORAM from oblivious set membership. In SCN (2022), Springer,
[21] GOLDREICH, O., AND OSTROVSKY, R. Software protection and simulation on oblivious RAMs. JACM 43, 3 (1996).
[22] GOODRICH, M. T., MITZENMACHER, M., OHRIMENKO, O., AND TAMASSIA, R. Privacy-preserving group data access via stateless oblivious RAM simulation. In SODA (2012).
[25] JARECKI, S., AND WEI, B. 3PC ORAM with low latency, low band- width, and fast batch retrieval. In ACNS (2018).
[27] KIRSCH, A., MITZENMACHER, M., AND WIEDER, U. More robust hashing: Cuckoo hashing with a stash. SIAM Journal on Computing (2009).
[28] KUSHILEVITZ, E., LU, S., AND OSTROVSKY, R. On the (in) security of hash-based oblivious RAM and a new balancing scheme. In SODA (2012).
[29] LAUD, P. Privacy-preserving minimum spanning trees through obliv- ious parallel RAM for secure multiparty computation. IACR ePrint Archive 2014/630, 2014.
[30] LAUR, S., WILLEMSON, J., AND ZHANG, B. Round-efficient oblivi- ous database manipulation. In ISC (2011).
[34] NAVEED, M. The fallacy of composition of oblivious RAM and search- able encryption. IACR ePrint 2015/688, 2015.
[36] NOBLE, D. An intimate analysis of cuckoo hashing with a stash. IACR ePrint 2021/447, 2021.
[37] OSTROVSKY, R. Efficient computation on oblivious RAMs. In STOC (1990).
[38] OSTROVSKY, R. Software Protection and Simulation On Oblivious RAMs. PhD thesis, Massachusetts Institute of Technology, 1992.
[39] OSTROVSKY, R., AND SHOUP, V. Private information storage. In STOC (1997), vol. 97.
[40] PAGH, R., AND RODLER, F. F. Cuckoo hashing. In ESA (2001).
[41] PATEL, S., PERSIANO, G., RAYKOVA, M., AND YEO, K. PanORAMa: Oblivious RAM with logarithmic overhead. In FOCS (2018).
[42] RINDAL, P. The ABY3 Framework for Machine Learning and Database Operations. https://github.com/ladnir/aby3.
[44] SMITH, P. Internet exchange point design. https://nsrc.org/wor kshops/2021/marwan-cnrst-ixp/networking/peering-ixp/e n/presentations/IXP-Design.pdf, 2021.
[45] VADAPALLI, A., HENRY, R., AND GOLDBERG, I. DuORAM: A bandwidth-efficient distributed ORAM for 2- and 3-party computation. IACR ePrint 2022/1747, 2022.
[50] YAO, A. Protocols for secure computations (extended abstract). In FOCS (1982).
[51] YAO, A. How to generate and exchange secrets. In FOCS (1986).
[52] ZAHUR, S., AND EVANS, D. Obliv-C: A language for extensible data-oblivious computation. IACR ePrint 2015/1153, 2015.
[53] ZAHUR, S., WANG, X., RAYKOVA, M., GASCÃ“N, A., DOERNER, J., EVANS, D., AND KATZ, J. Revisiting square-root ORAM: efficient random access in multi-party computation. In S & P (2016). A ABB Functionalities The basic ABB operations we use are described in Figure 7. B The naÃ¯ve cache protocol The naÃ¯ve cache protocol works as follows r â†âŠ¥ for i = 1,...,t do if x = xi then r â†yi end if end for Return: r This protocol has multiplicative depth, t, thus implement- ing this under the MPC of
[3] leads to a protocol with numRoundsCache = |L0|. It is possible to implement this with a garbled-circuit-based approach, (e.g. 3-party garbled circuits
[33] or BMR [8]). This results in a constant-round MPC protocol, but the communication complexity is large â€“ too inefficient for our application. Î SpeedCache, (described in Figure 3), parallelizes the equal- ity tests of the naÃ¯ve protocol leading to a low-depth circuit, that we implement using the 3-party MPC of [3]. C LowMC In this section, we discuss LowMC, an MPC-friendly block- cipher we use to instantiate FABB.PRFEval. LowMC. LowMC (Low Multiplicative Complexity)
[45] via their convenient Docker setup on a single c5n.metal machine. We use the set-networking.sh script they provide to set .229ms latency and 25Gbit band- width simulated network between Docker containers. We do not restrict the number of cores their process can use, and DuORAM used all 96 vCPUs during preprocessing. We benchmark FLORAM, FLORAM-CPRG, Circuit ORAM, and Square Root ORAM [16,46,53] via the obliv- c
[52] based setup given by [16].20 We benchmark the above 2-party constructions between two cluster-placed c5n.metal machines. For backwards compatibility with obliv-c, we run tests on Ubuntu 18.04.6 LTS. We do not restrict the network via the tc command as was done in [16]. Bingsheng Zhang kindly benchmarked the proprietary PFE- DORAM
[26] on a comparable network to ours. Zhang exe- cuted the protocol via separate processes on the same Intel(R) Core i7 8700 CPU 3.2 GHz, 6 CPUs, 32 GB Memory, 1TB SSD machine.Bandwidth between the processes was not lim- ited and latency was restricted to 0.05ms. We benchmark 3PC-ORAM
[25] via the dockerization graciously provided by the DuORAM
[45] team21. Like other constructions, we ran 3PC-ORAM with 0.229ms latency and 25Gbit bandwidth. F The cost of running GigaDORAM The c5n.metal machines we rent cost $3.888 per hour, and running DORAM requires 3 different machines. GigaDO- RAM. Given that we get â‰ˆ800 queries per second, (Figure 5), we get 800Â·3600/(3.888Â·3) = 246914 queries per USD. If we benchmark in the same region, all communication is free. If we benchmark in different regions, according to AWS the charge per Gigabyte in and out of AWS is $0.01.22 Accord- ing to Table 8 it is reasonable to conservatively estimate that GigaDORAMrequires 3 Â· 7 Â· 109/100,000 = 210,000 bytes per query = 210,000/230 = 2 Â· 10âˆ’4 Gigabytes per query. Multiplying by the dollar cost, we get that GigaDORAM requires 2Â·10âˆ’4 Â·.02 = 4Â·10âˆ’6 USD per query. Summing up communication and computation, we get that we have 1/246914 + 4 Â· 10âˆ’6 = 8.05 Â· 10âˆ’6 which gives ap- proximately 120,000 queries per dollar. By comparison, DuORAM
[5] Fabian Boemer, Yixing Lao, Rosario Cammarota, and Casimir Wierzynski. ngraph-he: a graph compiler for deep learning on homomorphically encrypted data. In Proceedings of the 16th ACM International Conference on Computing Frontiers, pages 3â€“13, 2019.
[6] Zvika Brakerski and Vinod Vaikuntanathan. Efficient fully homomorphic encryption from (standard) LWE. In Rafail Ostrovsky, editor, 52nd Annual Symposium on Foundations of Computer Science, pages 97â€“106, Palm Springs, CA, USA, October 22â€“25, 2011. IEEE Computer Society Press.
[14] Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter, Saeed Maleki, Madanlal Musuvathi, and Todd Mytkowicz. Chet: an optimizing compiler for fully-homomorphic neural-network inferencing. In Pro- ceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 142â€“156, 2019.
[16] EPFL-LDS. Lattigo 2.2.0. https://github.com/ tuneinsight/lattigo.
[18] Craig Gentry. Fully homomorphic encryption using ideal lattices. In Michael Mitzenmacher, editor, 41st Annual ACM Symposium on Theory of Computing, pages 169â€“178, Bethesda, MD, USA, May 31 â€“ June 2, 2009. ACM Press.
[21] IBM. Helib. https://github.com/homenc/HElib.
[26] WA Microsoft Research, Redmond. Microsoft seal. https://github.com/microsoft/SEAL.
[27] Saerom Park, Jaewook Lee, Jung Hee Cheon, Juhee Lee, Jaeyun Kim, and Junyoung Byun. Security-preserving support vector machine with fully homomorphic encryp- tion. SafeAI@ AAAI, 2301, 2019.
[2] Borja Balle and Yu-Xiang Wang. Improving the gaus- sian mechanism for differential privacy: Analytical cal- ibration and optimal denoising. In International Con- ference on Machine Learning, pages 394â€“403. PMLR, 2018.
[3] Wenxuan Bao, Luke A Bauer, and Vincent Bind- schaedler. On the importance of architecture and fea- ture selection in differentially private machine learning. arXiv preprint arXiv:2205.06720, 2022.
[4] SS Barsov and Vladimir V Ulâ€™yanov. Estimates of the proximity of Gaussian measures. Sov. Math., Dokl, 34: 462â€“466, 1987.
[6] K. Chatzikokolakis, G. Cherubin, C. Palamidessi, and C. Troncoso. Bayes security: A not so average metric. In 2023 2023 IEEE 36th Computer Security Founda- tions Symposium (CSF) (CSF), pages 159â€“177. IEEE Computer Society, jul 2023. doi: 10.1109/CSF57540. 2023.00011.
[7] Giovanni Cherubin. Bayes, not naÃ¯ve: Security bounds on website ï¬ngerprinting defenses. Proceedings on Privacy Enhancing Technologies, 2017.
[8] Giovanni Cherubin. Black-box security: measuring black-box information leakage via machine learning. PhD thesis, Royal Holloway, University of London, 2019.
[10] R Dennis Cook and Sanford Weisberg. Characteriza- tions of an empirical inï¬‚uence function for detecting inï¬‚uential cases in regression. Technometrics, 22(4): 495â€“508, 1980.
[11] Thomas M Cover. Elements of information theory. John Wiley & Sons, 1999.
[12] Luc Devroye, Abbas Mehrabian, and Tommy Reddad. The total variation distance between high-dimensional Gaussians with the same mean. arXiv preprint arXiv:1810.08693 [math.ST], 2018. doi: 10.48550/ ARXIV.1810.08693.
[13] Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy, 2019. URL https://arxiv.org/ abs/1905.02383.
[14] Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Connect the dots: Tighter discrete approximations of privacy loss distributions, 2022. URL https://arxiv.org/abs/2207.04380.
[15] Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Connect the dots: Tighter discrete approximations of privacy loss distributions. arXiv preprint arXiv:2207.04380, 2022.
[17] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Nu- merical composition of differential privacy. Advances in Neural Information Processing Systems, 34:11631â€“ 11642, 2021.
[19] John R Hershey and Peder A Olsen. Approximating the kullback leibler divergence between gaussian mixture models. In 2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSPâ€™07, volume 4, pages IVâ€“317. IEEE, 2007.
[20] Thomas Humphries, Simon Oya, Lindsey Tulloch, Matthew Rafuse, Ian Goldberg, Urs Hengartner, and Florian Kerschbaum. Investigating membership in- ference attacks under data dependencies. CoRR, abs/2010.12112v3, 2021.
[21] Mahdi Imanparast, Seyed Naser Hashemi, and Ali Mo- hades. Efï¬cient approximation algorithms for point-set diameter in higher dimensions. Journal of Algorithms and Computation, 51(2):47â€“61, 2019.
[23] Pang Wei Koh and Percy Liang. Understanding black- box predictions via inï¬‚uence functions. In Interna- tional conference on machine learning, pages 1885â€“ 1894. PMLR, 2017.
[24] Antti Koskela and Antti Honkela. Computing differen- tial privacy guarantees for heterogeneous compositions using fft, 2021. URL https://arxiv.org/abs/2102. 12412.
[25] Antti Koskela, Joonas JÃ¤lkÃ¶, Lukas Prediger, and Antti Honkela. Tight differential privacy for discrete-valued mechanisms and for the subsampled gaussian mecha- nism using fft. 2020. doi: 10.48550/ARXIV.2006.07134. URL https://arxiv.org/abs/2006.07134.
[27] Saeed Mahloujifar, Alexandre Sablayrolles, Graham Cormode, and Somesh Jha. Optimal membership in- ference bounds for adaptive composition of sampled gaussian mechanisms. arXiv preprint arXiv:2204.06106, 2022.
[28] Ilya Mironov, Kunal Talwar, and Li Zhang. R\â€™enyi differential privacy of the sampled gaussian mechanism. arXiv preprint arXiv:1908.10530, 2019.
[30] Geoffrey Smith. On the foundations of quantitative in- formation ï¬‚ow. In International Conference on Founda- tions of Software Science and Computational Structures, pages 288â€“302. Springer, 2009.
[33] Andrew Chi-Chih Yao. On constructing minimum span- ning trees in k-dimensional spaces and related problems. SIAM Journal on Computing, 11(4):721â€“736, 1982.
[34] Samuel Yeom, Irene Giacomelli, Alan Menaged, Matt Fredrikson, and Somesh Jha. Overï¬tting, robustness, and malicious algorithms: A study of potential causes of privacy risk in machine learning. Journal of Computer Security, 28(1):35â€“70, 2020. doi: 10.3233/JCS-191362.
[35] Ashkan Yousefpour, Igor Shilov, Alexandre Sablay- rolles, Davide Testuggine, Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode, and Ilya Mironov. Opacus: User-friendly differential privacy library in PyTorch. arXiv preprint arXiv:2109.12298, 2021.
[36] Santiago Zanella-BÃ©guelin, Lukas Wutschitz, Shruti Tople, Ahmed Salem, Victor RÃ¼hle, Andrew Paverd, Mo- hammad Naseri, and Boris KÃ¶pf. Bayesian estimation of differential privacy. arXiv preprint arXiv:2206.05199, 2022.
[37] Wanrong Zhang, Olga Ohrimenko, and Rachel Cum- mings. Attribute privacy: Framework and mechanisms. In Proceedings of the 2022 ACM Conference on Fair- ness, Accountability, and Transparency, pages 757â€“766, 2022. A Proofs Proposition
4. Let fM be a Gaussian mixture deï¬ned as follows. For a mean vector Âµ = (Âµ1,...,ÂµT) and co- variance matrix Ïƒ2C2IT, and C = maxT j=1 Âµj, let fM (x) = âˆ‘bâˆˆ{0,1}T Ï€b fN (Âµb,Ïƒ2C2)(x). The i-th component takes values from fN (Âµi,Ïƒ2C2) with probability p âˆˆ[0,1], or from fN (0,Ïƒ2C2) otherwise. Here, Ï€b = p|b|(1âˆ’p)Tâˆ’|b|. The error committed in approximating fM with fN (pÂµ,Ïƒ2C2) is: tv(fM , fN (pÂµ,Ïƒ2C2)) = O âˆšpT Ïƒ  Proof. First, observe that the total variation distance is re- lated to the KL divergence DKL as follows: tv(pS,qS) â‰¤ q 1 2DKL(pS,qS). We use the following bound on the KL divergence between two Gaussian mixtures (see Cover
0. From the above, we obtain: DKL(fM ,fN (pÂµ,Ïƒ2C2)) â‰¤ âˆ‘ bâˆˆ{0,1}T Ï€b 2Ïƒ2C2 T âˆ‘ i=1 Âµ2 i (bi âˆ’p)2 ! â‰¤ âˆ‘ bâˆˆ{0,1}T Ï€b 2Ïƒ2C2 T âˆ‘ i=1 T max j=1 Âµ2 j(bi âˆ’p)2 ! = âˆ‘ bâˆˆ{0,1}T Ï€b 2Ïƒ2 T âˆ‘ i=1 b2 i + p2T âˆ’2p T âˆ‘ i=1 bi ! = âˆ‘ bâˆˆ{0,1}T Ï€b 2Ïƒ2 p2T +(1âˆ’2p) T âˆ‘ i=1 bi ! = 1 2Ïƒ2 ï£« ï£­p2T âˆ‘ bâˆˆ{0,1}T Ï€b +(1âˆ’2p) âˆ‘ bâˆˆ{0,1}T Ï€b|b| ï£¶ ï£¸ = 1 2Ïƒ2 pT âˆ’p2T  We used the fact that b2 i = bi. For a ï¬xed T, the goodness of this approximation depends on the choices of Ïƒ and of the sampling rate p. In our main result, T is the number of DP-SGD steps. The result matches expectations: if one wants to run DP-SGD for longer and retain strong security, one either needs to increase the noise multiplier or reduce the sampling rate. In Figure 2, we compare the approximation error between the two distributions for a varying ratio between noise and sampling rate parameters. We observe that Proposition 4 holds when the ratio is small. In particular, for realistic regimes with p/Ïƒ < 10âˆ’3, we observe a negligible approximation error (< 10âˆ’4). In Section 4, we observe that these values for the parameters are not only practical; they are recommended to achieve stronger levels of security against MIA threats. Theorem
6. Assume that f is a bijection, and let âˆ†f be de- ï¬ned as in Equation (3). The Bayes security of DP-SGD with respect to the record-level property inference threat described in Section 3 is: Î²âˆ—(PO|S) â‰¥1âˆ’erf  p âˆ†f 2 âˆš 2ÏƒC  âˆ’O âˆšpT Ïƒ  . Proof. By Corollary 2, the relation between Bayes security and the total variation Proposition 3, and Theorem 1: Î²âˆ—(PO|S) â‰¥Î²âˆ—(PG|S) â‰¥1âˆ’ max s0,s1âˆˆdom(S)tv(PG|S=s0,PG|S=s1) We now determine the total variation term. Observe the following basic consequence of the triangle inequality. Let Î½a and Î¾a be two distributions parameterized by a âˆˆ{0,1}. Then: tv(Î½0,Î½1) â‰¤tv(Î¾0,Î¾1)+tv(Î½0,Î¾0)+tv(Î½1,Î¾1). We use this to replace the Gaussians mixture PG|S with a Gaus- sian, replacing the two pairwise distances tv(Î½0,Î¾0),tv(Î½1,Î¾1) with an error term as deï¬ned in Proposition 4. For any two s0,s1 âˆˆdom(S), we have: tv(PG|S=s0,PG|S=s1) =tv( âˆ‘ bâˆˆ{0,1}T cbPG|B=b,S=s0, âˆ‘ bâˆˆ{0,1}T cbPG|B=b,S=s1) â‰¤tv(N (pÂ¯g(f âˆ’1(s0)),Ïƒ2C2),N (pÂ¯g(f âˆ’1(s1)),Ïƒ2C2)) +O âˆšpT Ïƒ  =erf  pâˆ¥Â¯g(f âˆ’1(s0))âˆ’Â¯g(f âˆ’1(s1))âˆ¥F 2 âˆš 2ÏƒC  +O âˆšpT Ïƒ  In the ï¬rst step, we used the above consequence of the triangle inequality. In the second step, we used the fact that PG|B=b,S is a Gaussian distribution and applied Corollary 5. Proposition
9. Consider a randomized mechanism M : S â†’ O with S = {0,1}, and let S be a random variable on S with Ï€ = Pr[S = 1]. Let sâ€² = Attacker(Ï€,M (S)) be the guess that Attacker makes for S given the output of the mechanism. Let the true positive rate (TPR) be the probability that attacker Attacker guesses correctly when S = 1, and the false positive rate (FPR) be the probability that they guess incorrectly when S =
0. If the mechanism is Î²âˆ—-secure then for every attacker: TPR â‰¤1+FPRâˆ’Î²âˆ— if Ï€ â‰¤1/2 TPR â‰¤ Ï€ 1âˆ’Ï€ (1+FPRâˆ’Î²âˆ—) otherwise. We have equality for a uniform prior, Ï€ = 1/2. Proof. Chatzikokolakis et al.
11. Let A be an mÃ—n matrix; let Ai,j be the ele- ment at row i and column j, and let Ai indicate the i-th row vector. The Frobenius matrix of A is: âˆ¥Aâˆ¥F = s m âˆ‘ i=1 n âˆ‘ j=1 |Ai,j|2 = s m âˆ‘ i=1 âˆ¥Aiâˆ¥2 , where âˆ¥vâˆ¥is the L2 norm of a vector v. Corollary
7. The Bayes security of DP-SGD against record- level MIA (Game 2) is: Î²âˆ—â‰¥1âˆ’erf p âˆš T âˆš 2Ïƒ ! âˆ’O âˆšpT Ïƒ  . Proof. Observe that in the MIA threat model (Game 2) f(zâˆ— s) = s is a bijection. Then: âˆ†f = max zâˆ— 0,zâˆ— 1âˆˆDâˆ¥Â¯g(zâˆ— 0)âˆ’Â¯g(zâˆ— 1)âˆ¥F = max zâˆ— 0,zâˆ— 1âˆˆD s T âˆ‘ t=1 âˆ¥Â¯gt(zâˆ— 0)âˆ’Â¯gt(zâˆ— 1)âˆ¥2 â‰¤2C âˆš T . Applying Theorem 6 concludes the proof. Corollary
10. The Bayes security of DP-SGD against AI is: Î²âˆ—(PO|S) â‰¥1âˆ’erf  p âˆ¥Râˆ¥ 2 âˆš 2ÏƒC  âˆ’O âˆšpT Ïƒ  , where R = (R1,...,RT) with Rt = max zâˆ—âˆˆLt max s0,s1âˆˆA âˆ¥Â¯gt((Ï•(zâˆ—),s0))âˆ’Â¯gt((Ï•(zâˆ—),s1))âˆ¥, where Lt is the batch sampled at step t. Proof. Observe that f is a bijection: as per Game 3, for every zâˆ—, there is exactly one value s âˆˆA such that f(zâˆ—) = s. We bound âˆ†f as deï¬ned in Equation (3): âˆ†f â‰¤ max s0,s1âˆˆA,zâˆ—âˆˆDâˆ¥Â¯g(Ï•(zâˆ—) | s0)âˆ’Â¯g(Ï•(zâˆ—) | s1)âˆ¥F = max s0,s1âˆˆA,zâˆ—âˆˆD s T âˆ‘ t=1 âˆ¥Â¯gt(Ï•(zâˆ—) | s0)âˆ’Â¯gt(Ï•(zâˆ—) | s1)âˆ¥2 â‰¤ T âˆ‘ t=1 max s0,s1âˆˆA,zâˆ—âˆˆDâˆ¥Â¯gt(Ï•(zâˆ—) | s0)âˆ’Â¯gt(Ï•(zâˆ—) | s1)âˆ¥ We then apply Theorem
6. Note that in this corollaryâ€™s state- ment, we range zâˆ—âˆˆLt, where Lt is the batch sampled at time t. This is allowed by observing that, if zâˆ—is not included in the batch at step t, it cannot inï¬‚uence the model weights (and gradients) at that step. B Tightness of MIA bound (Corollary 7) We report results for further sample rates in Figure
1. It is infeasible for S to produce two databases D and Dâ€² such that Digest(pp,D) = Digest(pp,Dâ€²). 16
2. Suppose S can output aÏ€ such that PrRec(pp,d,qÏ€,stÏ€, aÏ€) Ì¸= âŠ¥for qÏ€,stÏ€ â†PrQry(d) with non-negligible probability, where the probability is over the random- ness of PrQry and S. Then, there exists an efï¬cient extractor E that extracts some database D such that Digest(pp,D) = d by rewinding S, with probability at least 1âˆ’2âˆ’Î». Deï¬nition A.3 (Veriï¬cation Soundness). For a security parameter Î», let S be a computationally bounded server. For an honestly-generated public parameter pp, let d â† Digest(pp,D) for some D. Furthermore, let Ï€ Ì¸= âŠ¥be the auxiliary information computed in the preprocessing phase described in ï¬g.
3. Let a be a response computed by S for a query q. We say a vPIR scheme satisï¬es veriï¬cation sound- ness if the following holds with probability at least 1âˆ’2âˆ’Î»: Verify(pp,d,Ï€,q,a) = Accept =â‡’ a = Answer(D,q). Deï¬nition A.4 (Query Hiding Against a Malicious Server). For a security parameter Î», let pp be an honestly-generated public parameter. We say a vPIR scheme that satisï¬es veriï¬- cation completeness (deï¬nition A.1), digest binding (deï¬ni- tion A.2), and veriï¬cation soundness (deï¬nition A.3), is also query hiding against a malicious server if the following holds. For every computationally bounded adversary A let d,stA â†A(pp) be the digest produced by A such that Accept â†DigVer(pp,d). Let D be the database the adver- sary used to produce d; the existence and uniqueness of D is guaranteed by deï¬nition A.2. For every index sequence âƒ—i = {i1,...,iL} âˆˆ[N]L, deï¬ne the distribution REALA,âƒ—i := ï£± ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£³ Î² : qÏ€,stÏ€ â†PrQry(pp,d) aÏ€,stA â†A(stA,qÏ€) Ï€ â†PrRec(pp,d,qÏ€,stÏ€,aÏ€) Î² â†A(stA) if Ï€ = âŠ¥ While Ï€ Ì¸= âŠ¥ ï£± ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£³ q,st â†Query(pp,ik) a,stA â†A(stA,q) b â†Verify(pp,d,Ï€,q,a) stA â†A(stA,b) If b = Reject, set Ï€ â†âŠ¥ Otherwise r â†Recover(pp,st,a,d) bâ€² â†1[r = D[ik]] stA â†A(stA,bâ€²) ï£¼ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£½ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£¾ L k=1 Î² â†A(stA), ï£¼ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£½ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£¾ where the L iterations are run sequentially. Similarly, for a computationally bounded simulator X , deï¬ne the distribution IDEALA,X := ï£± ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£³ Î² : qÏ€,stÏ€ â†PrQry(pp,d) aÏ€,stA â†A(stA,qÏ€) Ï€,stX â†X (pp,d,qÏ€,stÏ€,aÏ€) Î² â†A(stA) if Ï€ = âŠ¥ While Ï€ Ì¸= âŠ¥ ï£± ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£³ q,stX â†X (pp,stA) a,stA â†A(stA,q) b,bâ€² â†X (pp,d,Ï€,q,a,stA) stA â†A(stA,bk) If b = Reject, set Ï€ â†âŠ¥ Otherwise stA â†A(stA,bâ€²) ï£¼ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£½ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£¾ L k=1 Î² â†A(stA), ï£¼ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£½ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£¾ where the L iterations are run sequentially as in REAL. We say that a vPIR scheme is query hiding against a malicious server if the following holds: |Pr[REALA,âƒ—i = 1]âˆ’Pr[IDEALA,X = 1]| â‰¤negl(Î»). B Security Proofs for Reusable VLHE Here, we give the security proofs for the VLHE scheme with preprocessed proofs presented in section 4.2. Lemma B.1 (Semi-honest Preprocessed Protocol). Let S be a computationally bounded server that correctly runs the pro- tocol described in ï¬g.
6. Let bF âˆˆ{0,1} indicate if the client aborts on the function commitment phase and let bP âˆˆ{0,1} indicate if the client aborts on the proof preprocessing phase. Let U be the clientâ€™s message in the proof preprocessing phase, as in ï¬g.
6. The view of S at the end of the preprocessing phase is (bF,U,bP). For q that satisï¬es eq. (6), assume the hardness of (n,â„“,q)- LWE. The view of S is computationally indistinguishable from (0,R,0), where R is a uniformly random element of Zâ„“Ã—Î» q . Proof. This follows directly from the semantic security of the Regev encryption scheme and the perfect completeness of the veriï¬cation algorithms VerCom and BatchVerify. Lemma B.2 (Correct Encryption of Z). Let S be a com- putationally bounded adversary acting as the server in the protocol described in ï¬g.
6. Deï¬ne the view of S at the end of the proof preprocessing phase (bF,U,bP) as in lemma B.1. Let q, â„“, p, and m satisfy eq. (6). Assume the hardness of SISn,m,q,Î²1 for Î²1 = 4â„“p and SISn,â„“,q,Î²2 for Î²2 = 4mp. As in lemma B.1, assume the hardness of (n,â„“,q)-LWE. Consider the commitment deï¬ned by (A1,H1) and the ex- tractor E guaranteed by lemma 2.2 running on S in the func- tion commitment phase. Let D âˆˆZâ„“Ã—m be the unique matrix that can be extracted from E on the commitment (A1,H1) (i.e. H1 = DA1), under hardness assumption of SISn,m,q,Î²1 17 (lemma 2.3). Deï¬ne Dâ€² âˆˆZmÃ—â„“similarly on the commitment (A2,H2) (i.e. H2 = Dâ€²A2), under hardness assumption of SISn,m,q,Î²2. If a client running the prescribed protocol completes the proof preprocessing without aborting, then with probability at least 1âˆ’2âˆ’Î» the Z value held by the client equals CD for the client-sampled C. Furthermore, the view of S is indistin- guishable from the semi-honest view in lemma B.1 of with probability at least 1âˆ’2âˆ’Î». Proof. To see that the clientâ€™s Z value will equal CD, ob- serve that since the ciphertext modulus q satisï¬es eq. (6), applying the linear function Dâ€² âˆˆZmÃ—â„“to the ciphertexts com- prising the columns of U will result in correctly decrypting ciphertexts V. Since BatchVerify accepts, then by lemma 4.1 and the hardness of SISn,â„“,q,Î²2 for Î²2 = 4mp it must be that V = Dâ€²U. Therefore, by the correctness of the VLHE scheme, it must be that the plaintext encrypted in the columns of V is ZT = Dâ€²CT. Meanwhile, the check ZÂ·A1 = CÂ·H1 = C(Dâ€²)TA1 passes, and thus we have C((Dâ€²)TA1 âˆ’H1) =
6. Deï¬ne the view of S at the end of the proof preprocessing phase (bF,U,bP) as in lemma B.1. Let q, â„“, p, and m satisfy eq. (6). Assume the hardness of SISn,m,q,Î²1 for Î²1 = 4â„“p and SISn,â„“,q,Î²2 for Î²2 = 4mp. As in lemma B.1, assume the hardness of (n,â„“,q)- LWE. Consider the commitment deï¬ned by (A1,H1) and the ex- tractor E guaranteed by lemma 2.2 running on S in the func- tion commitment phase. Let D âˆˆZâ„“Ã—m 2pâ„“be the unique matrix that can be extracted from E on the commitment (A1,H1) (i.e. H1 = DA1), under hardness assumption of SISn,m,q,Î²1 (lemma 2.3). If the client has completed the proof preprocessing phase without aborting, then Accept â†PreVerify(u,v,C,Z) im- plies that v = Du with probability at least 1âˆ’2âˆ’Î». Further- more, this guarantee is maintained across any number of homomorphic evaluation protocols as long as PreVerify does not output Reject. Proof. The security of a single instance of the homomorphic evaluation phase follows directly from lemma B.2, since the server has no information about the challenge C used to verify the response. The uniqueness of the ciphertext v then follows from lemma 4.1. The second claim follows from the simulatability of the client accepting the correct transcript. Strong uniqueness of the response ciphertext v guarantees that the only way the server will pass veriï¬cation with probability better than 2âˆ’Î» is if v = Du. If the server returns the correct ciphertext, then clearly there is no additional information about C that is learned, since the fact that the client accepts this transcript fol- lows directly from the perfect completeness of the PreVerify algorithm. Therefore, with probability at least 1 âˆ’2âˆ’Î», no information about C is leaked if PreVerify outputs Accept. This means that the challenge C and the corresponding Z can be safely reused as long as PreVerify outputs Accept. C VeriSimplePIR Security Proofs We give the security proofs of the VeriSimplePIR construction in section 5. Lemma C.1 (VeriSimplePIR Completeness). Construction 5.1 satisï¬es deï¬nition A.1. Proof. This proof follows directly from the perfect complete- ness of the VLHE veriï¬cation in section
4. In particular, the bound on Z will never be exceeded as long as the database D is within the honest bound ||D||âˆâ‰¤p. The perfect complete- ness of the check ZA = CH follows immediately from the honest values of H and Z. Lemma C.2 (VeriSimplePIR Digest Binding). Construction 5.1 satisï¬es deï¬nition A.2. Proof. This follows directly from the SIS hardness assump- tions given in construction 5.1. This SIS assumption imme- diately implies computational binding for the digest from lemma 2.3. Lemma C.3 (VeriSimplePIR Veriï¬cation Soundness). Con- struction 5.1 satisï¬es deï¬nition A.3. Proof. This follows directly from lemma B.3. Lemma C.4 (VeriSimplePIR Query Hiding). Construction 5.1 satisï¬es deï¬nition A.4. Proof. This follows from lemma B.3 along with the correct- ness of the VLHE parameters. Lemma B.3 guarantees that the only ciphertexts that pass veriï¬cation with probability better than 2âˆ’Î» are the honest ciphertexts. Decryption of the honest ciphertext will yield the correct result with probability at least 1 âˆ’2âˆ’Î» by lemma 2.5. Therefore, the second bit bâ€² in the distributions in deï¬nition A.4 are also simulatable. 18
[1] Guillermo Angeris, Alex Evans, and Tarun Chitra. A note on bundle profit maximization. Stanford University, 2021.
[2] arkworks contributors. arkworks zksnark ecosystem. https://arkworks.rs, 2022.
45. Springer, Heidelberg, August 1998.
[14] Agostino Capponi, Ruizhe Jia, and Ye Wang. The evo- lution of blockchain: from lit to dark. arXiv preprint, 2022.
[20] Isaac David, Liyi Zhou, Kaihua Qin, Dawn Song, Lorenzo Cavallaro, and Arthur Gervais. Do you still need a manual smart contract audit?, 2023.
[21] Alfredo De Santis, Yvo Desmedt, Yair Frankel, and Moti Yung. How to share a function securely. In 26th ACM STOC, pages 522â€“533. ACM Press, May 1994.
[22] Christian Decker and Roger Wattenhofer. Information propagation in the bitcoin network. In IEEE P2P 2013 Proceedings, pages 1â€“10, 2013.
[30] Sanjam Garg, Craig Gentry, Amit Sahai, and Brent Wa- ters. Witness encryption and its applications. In Dan Boneh, Tim Roughgarden, and Joan Feigenbaum, edi- tors, 45th ACM STOC, pages 467â€“476. ACM Press, June 2013.
[32] Arthur Gervais, Ghassan O Karame, Karl WÃ¼st, Vasileios Glykantzis, Hubert Ritzdorf, and Srdjan Cap- kun. On the security and performance of proof of work blockchains. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, 2016.
[36] Lioba Heimbach and Roger Wattenhofer. Eliminating sandwich attacks with the help of game theory. arXiv preprint, 2022.
[40] Alireza Kavousi, Duc V. Le, Philipp Jovanovic, and George Danezis. Blindperm: Efficient mev mitigation with an encrypted mempool and permutation. Cryp- tology ePrint Archive, Paper 2023/1061, 2023. https: //eprint.iacr.org/2023/1061.
[44] Tom CW Lin. The new market manipulation. Emory LJ, 66:1253, 2016.
[46] Dahlia Malkhi and Pawel Szalachowski. Maximal ex- tractable value (mev) protection on a dag, 2022.
[47] Conor McMenamin, Vanesa Daza, and Matthias Fitzi. Fairtradex: A decentralised exchange preventing value extraction. arXiv preprint, 2022.
[48] Julien Piet, Jaiden Fairoze, and Nicholas Weaver. Ex- tracting godl
[sic] from the salt mines: Ethereum miners extracting value, 2022.
[49] Julien Piet, Vivek Nair, and Sanjay Subramanian. Mevade: An mev-resistant blockchain design. In 2023 IEEE International Conference on Blockchain and Cryp- tocurrency (ICBC), pages 1â€“9. IEEE, 2023.
[51] Kaihua Qin, Liyi Zhou, and Arthur Gervais. Quantifying blockchain extractable value: How dark is the forest? arXiv preprint, 2021.
[53] Antoine Rondelet and Quintus Kilbourn. Threshold encrypted mempools: Limitations and considerations, 2023.
[54] samczsun. Escaping the dark forest. https: //samczsun.com/escaping-the-dark-forest/, 2020. Accessed: 2022-02-16.
[58] Shutter Network contributors. The shutter network. https://shutter.network, 2021.
[59] Shutter Network contributors. Rolling shutter: Mev protection built into layer
2. https://blog.shutter. network/announcing-rolling-shutter/, 2022.
[61] Ye Wang, Yan Chen, Shuiguang Deng, and Roger Wat- tenhofer. Cyclic arbitrage in decentralized exchange markets. Available at SSRN 3834535, 2021.
[62] Lloyd R Welch and Elwyn R Berlekamp. Error correc- tion for algebraic block codes, December 30 1986. US Patent 4,633,470.
[8] proof systems. Although this would make the decryption procedure more expensive, one can always op- timistically decrypt without proofs and if it fails, then demand proofs. By introducing appropriate penalities such as slashing of stake, we can ensure that incorrect partial decryptions are rarely sent â€“ similar to validators on Ethereum attesting to incorrect state transitions. In order to highlight the core technical ideas without dis- tractions, we focus on the t = n/3 case. In the process, we introduce a new assumption that is closely related to the as- sumption introduced in [39]. We call this the q-strong Bilinear Diffie Hellman Triple Assumption to indicate that there are additional triples given to the adversary beyond that in q-SDH and â€œBilinearâ€ to indicate that the Adversary needs to output a value in the target group. Definition 4 (q-SBDHT Assumption). Let a, b,c and d be sampled uniformly at random from F. Given as input a tuple (g,ga,ga2,...,gan,gb,gd,hd,hac,hcd), for every probabilistic polynomial time algorithm A, Pr[A(g,ga,ga2,...,gan,gb,gd,ha,hd,hac,hcd) â†’e(g,h)bc] â‰¤negl(Î»). We briefly discuss the need for the new assumption, and discuss why the â€˜KZG assumptionâ€™, i.e. the q-strong Diffie Hellman (q-SDH) assumption does not suffice for our setting. Specifically, in the KZG polynomial commitment scheme, the q-SDH is used to argue evaluation binding, which states that even for a (potentially adversarially) chosen polynomial commitment, the adversary cannot produce two accepting evaluation proofs for two distinct evaluations at the same evaluation point, i.e. adversary cannot find a commitment c, a tuple x,y,yâ€²,Ï€,Ï€â€² with y Ì¸= yâ€² such that: (i) Ï€ attests that y is a valid evaluation of x with respect to c; and (ii) Ï€â€² attests that yâ€² is a valid evaluation of x with respect to c. Whereas we require that for an honestly generated commitment, if the adversary does not know the polynomial used in the commitment, it cannot generate a valid proof for any pair (x,y), even if y was such that p(x) = y, where p was the polynomial that was committed. We thus view the above assumption as a strengthening of q-SDH), necessary for our construction Theorem
5. The protocol in Fig. 2 securely emulates the FbTPKE ideal functionality (Fig. 1) in the dealer model against any static PPT adversary A corrupting < n/3 parties, given any weakly simulation-extractable NIZK, and provided the q-SBDHT assumption holds in the programmable random oracle model. Remark
[2] Dan Boneh, David Mazieres, and Raluca Popa. Remote Oblivious Storage: Making Oblivious RAM Practical. Technical report, MIT, 2011. https://dspace.mit. edu/handle/1721.1/62006.
[11] Craig Gentry, Kenny Goldman, Shai Halevi, Charanjit Julta, Mariana Raykova, and Daniel Wichs. Optimizing ORAM and Using it Efï¬ciently for Secure Computation. In Privacy Enhancing Technologies Symposium, pages 1â€“18, 2013.
[13] Oded Goldreich, Shaï¬Goldwasser, and Silvio Micali. How to Construct Random Functions. J. ACM, 33(4):792â€“807, 1986.
[14] Oded Goldreich and Rafail Ostrovsky. Software Pro- tection and Simulation on Oblivious RAMs. J. ACM, 43(3):431â€“473, 1996.
[15] Michael T. Goodrich and Michael Mitzenmacher. MapReduce Parallel Cuckoo Hashing and Oblivious RAM Simulations. CoRR, abs/1007.1259, 2010. http: //arxiv.org/abs/1007.1259.
[16] Michael T. Goodrich, Michael Mitzenmacher, Olga Ohrimenko, and Roberto Tamassia. Oblivious Ram Simulation with Efï¬cient Worst-Case Access Overhead. In ACM Cloud Computing Security Workshop, pages 95â€“100, 2011.
[20] Eyal Kushilevitz, Steve Lu, and Rafail Ostrovsky. On the (in)Security of Hash-Based Oblivious RAM and a New Balancing Scheme. In SODA, pages 143â€“156, 2012.
[24] Moni Naor and Benny Pinkas. Oblivious Transfer and Polynomial Evaluation. In STOC, pages 245â€“254, 1999.
[26] Emil Stefanov, Marten Van Dijk, Elaine Shi, T.-H. Hu- bert Chan, Christopher Fletcher, Ling Ren, Xiangyao Yu, and Srinivas Devadas. Path ORAM: An Extremely Simple Oblivious RAM Protocol. J. ACM, 65(4), 2018.
[28] Adithya Vadapalli, Ryan Henry, and Ian Goldberg. Duo- ram: A Bandwidth-Efï¬cient Distributed ORAM for 2- and 3-Party Computation. https://eprint.iacr. org/2022/1747, 2023.
1. P0 picks (X0,Y0) at random from {0,1}w and P1 picks (X1,Y1) at random from {0,1}w.
2. P0 and P1 pick random words T0 âˆˆ{0,1}w and T1 âˆˆ {0,1}w respectively. Let T = T0 âŠ•T1.
3. P0 acts as the sender in w parallel 1-of-2 oblivious trans- fers with the ith bits of (T0,X0 âŠ•T0) as the input. P1 uses the bits of Y1 as the selection bits. Therefore, P1 learns (X0 âˆ§Y1)âŠ•T0 and computes (X0 âˆ§Y1)âŠ•T0 âŠ•T1 = (X0 âˆ§Y1)âŠ•T.
1. For b âˆˆ{0,1}, Pb uses the PRG to construct the labels on the children of each node in this level. The left and right children of node i at this layer are denoted as (v (iâˆ¥L) b,â„“,v (iâˆ¥R) b,â„“). Therefore, we have vb,â„“+1[2Â·i] = v (iâˆ¥L) b,â„“and vb,â„“+1[2Â·i + 1] = v (iâˆ¥R) b,â„“.
2. For b âˆˆ{0,1}, Pb computes Lb â†L2â„“âˆ’1 j=0 v (jâˆ¥L) b,â„“and Rb â† L2â„“âˆ’1 j=0 v (jâˆ¥R) b,â„“.
3. P0 and P1 use an MPC AND protocol (using the AND triple generation described in Ap- pendix A) to compute the correction word cw (â„“+1) â†  âƒ—iâˆ— 0[â„“]âŠ•âƒ—iâˆ— 1[â„“]  âˆ§(L0 âŠ•L1)  âŠ•  1âŠ•âƒ—iâˆ— 0[â„“]âŠ•âƒ—iâˆ— 1[â„“]  âˆ§(R0 âŠ•R1)  .
4. Pb computes cwtb L â†lsb(Lb) âŠ•âƒ—iâˆ— b[â„“] and cwtb R â† lsb(Rb) âŠ•âƒ—iâˆ— b[â„“], and exchanges those values with the other party; the parties then both compute cwtL â† cwt0 L âŠ•cwt1 L âŠ•1 and cwtR â†cwt0 R âŠ•cwt1 R.
5. Pb computes tb,â„“+1[2 Â· i] â†lsb(vb,â„“+1[2 Â· i]) âŠ•(tb,â„“[i] Â· cwtL) and tb,â„“+1[2 Â· i + 1] â†lsb(vb,â„“+1[2 Â· i + 1]) âŠ• (tb,â„“[i]Â· cwtR), for all i âˆˆ[0,2â„“).
6. Pb updates vb,â„“+1[2Â·i] â†vb,â„“+1[2Â·i]âŠ•(tb,â„“[i]Â·cw (â„“+1)) and vb,â„“+1[2Â·i+1] â†vb,â„“+1[2Â·i+1]âŠ•(tb,â„“[i]Â·cw (â„“+1)), for all i âˆˆ[0,2â„“). D Converting an XOR-shared standard basis vector to additive shares In this section, we elaborate upon the informal description of the share conversion algorithm described in Section 4.1.1. Recall that P0 and P1 hold DPFs without the ï¬nal correction word; that is, P0 holds (v0,Ëšt0,F0) and P1 holds (v1,Ëšt1,F1) such that Ëšt0 âŠ•Ëšt1 = eri and v0 +v1 = âˆ’(F0 +F1)Â·eri. Their goal is to end up with vectors t0 and t1 such that t0 +t1 = eri. An important point to note is that, in this case, Ëštb and the pair (vb,Fb) are not of the same DPF (but have the same target index). In other words, we use an additional DPF to perform the share conversion.
1. P0 interprets its ï¬‚ag vector as a word vector. P1 also interprets its ï¬‚ag vector as a word vector and multiplies it by âˆ’1. In other words, P0 computes bt0[i] â†(Ëšt0[i]) for all i, and P1 computesbt1[i] â†âˆ’(Ëšt1[i]) for all i.
2. For b âˆˆ{0,1}, Pb computes pmb â†âˆ‘ibtb[i].
3. For b âˆˆ{0,1}, Pb selects a random word rb to blind pmb, and the Pb exchange pmb +rb.
4. For b âˆˆ{0,1}, Pb updates btâ€² b â†btb Â· ((pm1âˆ’b + r1âˆ’b) + pmb +rb).
5. The parties use MPC to compute shares eF0 and eF1 of (F0 +F1)Â·(pm0 +pm1).
6. The parties then compute F â€² 0 â†eF0 +r0 and F â€² 1 â†eF1 + r1 respectively, and exchange them to reconstruct F â€² â† F â€² 0 +F â€² 1.
7. For b âˆˆ{0,1}, Pb updates tb â†btâ€² b âˆ’vb âˆ’(btb Â·F â€²). Lemma
[2] F. Alharbi, J. Chang, Y. Zhou, F. Qian, Z. Qian, and N. Abu-Ghazaleh. Collaborative client-side dns cache poisoning attack. In IEEE INFOCOM 2019 - IEEE Conference on Computer Communications, 2019.
[3] Dan J. Bernstein. DNS Forgery. http://cr.yp.to/ djbdns/forgery.html, November 2002.
[5] Markus Brandt, Tianxiang Dai, Amit Klein, Haya Shul- man, and Michael Waidner. Domain Validation++ For MitM-Resilient PKI. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 2060â€“2076. ACM, 2018.
[7] Taejoong Chung, Roland van Rijswijk-Deij, David Choffnes, Dave Levin, Bruce M Maggs, Alan Mislove, and Christo Wilson. Understanding the role of registrars in dnssec deployment. In Proceedings of the 2017 Inter- net Measurement Conference, pages 369â€“383, 2017.
[8] Tianxiang Dai, Haya Shulman, and Michael Waidner. Letâ€™s downgrade letâ€™s encrypt. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Com- munications Security, pages 1421â€“1440, 2021.
[10] Amir Herzberg and Haya Shulman. Security of Patched DNS. In Computer Security - ESORICS 2012 - 17th European Symposium on Research in Computer Security, Pisa, Italy, September 10-12, 2012. Proceedings, pages 271â€“288, 2012.
[11] Amir Herzberg and Haya Shulman. Fragmentation Con- sidered Poisonous: or one-domain-to-rule-them-all.org. In IEEE CNS 2013. The Conference on Communications and Network Security, Washington, D.C., U.S. IEEE, Oc- tober 2013.
[15] Geoff Huston. Measuring the end user, 2015.
[16] Dan Kaminsky. Itâ€™s the End of the Cache As We Know It. Presentation at Blackhat Briefings, 2008.
[17] Amit Klein. Bind 9 dns cache poisoning. Report, Trusteer, Ltd, 3, 2007.
[18] Amit Klein. Windows dns server cache poisoning, 2007.
[20] Amit Klein, Haya Shulman, and Michael Waidner. Internet-wide study of dns cache injections. In IEEE INFOCOM 2017-IEEE Conference on Computer Com- munications, pages 1â€“9. IEEE, 2017.
[21] Amit Klein, Haya Shulman, and Michael Waidner. Internet-Wide Study of DNS Cache Injections. In IN- FOCOM, 2017.
[24] Thomson M. and Schinazi D. Maintaining Robust Pro- tocols, June 2023.
[25] Keyu Man, Zhiyun Qian, Zhongjie Wang, Xiaofeng Zheng, Youjun Huang, and Haixin Duan. DNS Cache Poisoning Attack Reloaded: Revolutions with Side Channels. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, 2020.
[26] Keyu Man, Xinâ€™an Zhou, and Zhiyun Qian. Dns cache poisoning attack: Resurrections with side channels. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 3400â€“ 3414, 2021.
[27] Matthijs Mekking. A Story of Unsupported DNSSEC Algorithms, June 2019.
[29] Moritz MÃ¼ller, Willem Toorop, Taejoong Chung, Jelte Jansen, and Roland van Rijswijk-Deij. The reality of algorithm agility: Studying the dnssec algorithm life- cycle. In Proceedings of the ACM Internet Measurement Conference, pages 295â€“308, 2020.
[30] CZ NIC. Itâ€™s knot dns. 2011.
[32] Eric Osterweil, Pouyan Fotouhi Tehrani, Thomas C. Schmidt, and Matthias WÃ¤hlisch. From the beginning: Key transitions in the first 15 years of dnssec, 2021.
[33] Ebersman P., Kumari W., Griffiths C., Livingood J., and Weber R. RFC7646: Definition and Use of DNSSEC Negative Trust Anchors, September 2015.
[34] Craig Partridge and Mark Allman. Ethical considera- tions in network measurement papers. Communications of the ACM, 59(10):58â€“64, 2016.
[35] Haya Shulman and Michael Waidner. Towards security of internet naming infrastructure. In European Sympo- sium on Research in Computer Security, pages 3â€“22. Springer, 2015.
[41] Wouter CA Wijngaards and Benno J Overeinder. Secur- ing dns: Extending dns servers with a dnssec validator. IEEE Security & Privacy, 7(5):36â€“43, 2009.
[1] Drand - a distributed randomness beacon daemon, 2020. https://github.com/drand/drand.
[4] Ittai Abraham, Dahlia Malkhi, and Alexander Spiegel- man. Asymptotically optimal validated asynchronous byzantine agreement. In Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing, pages 337â€“346, 2019.
[7] Michael Ben-Or, Ran Canetti, and Oded Goldreich. Asynchronous secure computation. In Proceedings of the twenty-fifth annual ACM symposium on Theory of computing, pages 52â€“61, 1993.
[17] Tyler Crain. A simple and efficient asynchronous ran- domized binary byzantine consensus algorithm. arXiv preprint arXiv:2002.04393, 2020.
[18] Tyler Crain. Two more algorithms for randomized signature-free asynchronous binary byzantine consen- sus with t < n/3 and o(n2) messages and o(1) round expected termination. arXiv preprint arXiv:2002.08765, 2020.
[21] Sourav Das, Zhuolun Xiang, and Ling Ren. Asyn- chronous data dissemination and its applications. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, 2021.
[25] Michael J Fischer, Nancy A Lynch, and Michael S Pa- terson. Impossibility of distributed consensus with one faulty process. Journal of the ACM (JACM), 32(2):374â€“ 382, 1985.
[33] Bingyong Guo, Zhenliang Lu, Qiang Tang, Jing Xu, and Zhenfeng Zhang. Dumbo: Faster asynchronous bft protocols. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, pages 803â€“818, 2020.
[35] Timo Hanke, Mahnush Movahedi, and Dominic Williams. Dfinity technology overview series, con- sensus system. arXiv preprint arXiv:1805.04548, 2018.
[36] Aniket Kate and Ian Goldberg. Distributed key genera- tion for the internet. In 2009 29th IEEE International Conference on Distributed Computing Systems, pages 119â€“128. IEEE, 2009.
[38] Eleftherios Kokoris-Kogias, Enis Ceyhun Alp, Linus Gasser, Philipp Jovanovic, Ewa Syta, and Bryan Ford. Calypso: private data management for decentralized ledgers. Proceedings of the VLDB Endowment, 14(4):586â€“599, 2020.
[39] Eleftherios Kokoris Kogias, Dahlia Malkhi, and Alexan- der Spiegelman. Asynchronous distributed key genera- tion for computationally-secure randomness, consensus, and threshold signatures. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communi- cations Security, pages 1751â€“1767, 2020.
[40] Donghang Lu, Thomas Yurek, Samarth Kulshreshtha, Rahul Govind, Aniket Kate, and Andrew Miller. Hon- eybadgermpc and asynchromix: Practical asynchronous mpc and its application to anonymous communication. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pages 887â€“ 903, 2019.
[41] Yuan Lu, Zhenliang Lu, Qiang Tang, and Guiling Wang. Dumbo-mvba: Optimal multi-valued validated asyn- chronous byzantine agreement, revisited. In Proceed- ings of the 39th Symposium on Principles of Distributed Computing, pages 129â€“138, 2020.
[42] Sai Krishna Deepak Maram, Fan Zhang, Lun Wang, Andrew Low, Yupeng Zhang, Ari Juels, and Dawn Song. Churp: dynamic-committee proactive secret sharing. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pages 2369â€“ 2386, 2019.
[44] Wafa Neji, Kaouther Blibech, and Narjes Ben Rajeb. Distributed key generation protocol with a new com- plaint management strategy. Security and communica- tion networks, 9(17):4585â€“4595, 2016.
[45] Orbs Network. Dkg for bls threshold signature scheme on the evm using solidity, 2018. https://github. com/orbs-network/dkg-on-evm.
[48] Philipp Schindler. Ethereum-based distributed key generation protocol, 2020. https://github.com/ PhilippSchindler/ethdkg.
[51] Adi Shamir. How to share a secret. Communications of the ACM, 22(11):612â€“613, 1979.
[53] Heiko Stamer. Distributed privacy guard, 2018. https: //github.com/gnosis/dkg.
[57] Maofan Yin, Dahlia Malkhi, Michael K Reiter, Guy Golan Gueta, and Ittai Abraham. Hotstuff: Bft consensus with linearity and responsiveness. In Pro- ceedings of the 2019 ACM Symposium on Principles of Distributed Computing, pages 347â€“356. ACM, 2019.
[58] Thomas Yurek, Licheng Luo, Jaiden Fairoze, Aniket Kate, and Andrew Miller. hbacss: How to robustly share many secrets. In Proceedings of the 29th Annual Net- work and Distributed System Security Symposium, 2022.
[7] D. R. L. Brown. Generic groups, collision resistance, and ECDSA. Contributions to IEEE P1363a, Feb. 2002. Updated version for â€œThe Exact Security of ECDSA.â€ Available from http://grouper.ieee.org/ groups/1363/.
[9] M. Cooper. Improving Git protocol secu- rity on GitHub, 2021. https://github.blog/ 2021-09-01-improving-git-protocol-security-github/.
[10] B. Cox. Auditing GitHub usersâ€™ SSH key qual- ity. Blog post. https://blog.benjojo.co.uk/post/ auditing-github-users-keys, 2015.
[15] DMR. GitHub Statistics, User Counts, Facts & News (2022), 2022. https://expandedramblings. com/index.php/github-statistics/.
[17] D. Dolev, C. Dwork, and M. Naor. Non-malleable cryp- tography (extended abstract). In 23rd ACM STOC, pages 542â€“552. ACM Press, May 1991.
[18] C. Dwork, M. Naor, and A. Sahai. Concurrent zero- knowledge. In 30th ACM STOC, pages 409â€“418. ACM Press, May 1998.
[31] Mobatek. MobaXterm, 2022. https://mobaxterm. mobatek.net/.
[40] OpenSSH. OpenSSH-Portable, 2022. https: //github.com/openssh/openssh-portable/blob/ master/auth2-pubkey.c#L280-L286.
[46] F. Valsorda. SSH whoami.filippo.io. Blog post. https: //blog.filippo.io/ssh-whoami-filippo-io/, 2015.
[47] F. Valsorda. whoami.filippo.io: an ssh server that knows who you are. Github repository. https://github.com/ FiloSottile/whoami.filippo.io, 2015.
[48] WonderNetwork. Global Ping Statistics, 2022. https: //wondernetwork.com/pings.
[49] Y. Zhao and S. S. M. Chow. Are you the one to share? Secret transfer with access structure. PoPETs, 2017(1):149â€“169, Jan. 2017.
[2] alex ozdemir. collaborative-zksnark. https://github.com/alex-ozdemir/ collaborative-zksnark, 2022.
[3] arkworks contributors. arkworks zksnark ecosys- tem. https://arkworks.rs, 2022.
[11] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer. Recursive composition and boot- strapping for SNARKS and proof-carrying data. In Dan Boneh, Tim Roughgarden, and Joan Feigen- baum, editors, 45th ACM STOC, pages 111â€“120. ACM Press, June 2013.
[25] Vitalik Buterin. Some ways to use zk-snarks for privacy.
[32] Graham Cormode, Michael Mitzenmacher, and Justin Thaler. Practical verified computation with streaming interactive proofs. In Shafi Goldwasser, editor, ITCS 2012, pages 90â€“112. ACM, January 2012.
[36] Matthew K. Franklin and Moti Yung. Communi- cation complexity of secure computation (extended abstract). In 24th ACM STOC, pages 699â€“710. ACM Press, May 1992.
[40] Daniel Genkin, Yuval Ishai, Manoj Prabhakaran, Amit Sahai, and Eran Tromer. Circuits resilient to additive attacks with applications to secure com- putation. In David B. Shmoys, editor, 46th ACM STOC, pages 495â€“504. ACM Press, May / June 2014.
[41] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. Delegating computation: interactive proofs for muggles. In Richard E. Ladner and Cyn- thia Dwork, editors, 40th ACM STOC, pages 113â€“ 122. ACM Press, May 2008.
[47] Matthew Green, Mathias Hall-Andersen, Eric Hen- nenfent, Gabriel Kaptchuk, Benjamin Perez, and Gijs Van Laer. Efficient proofs of software ex- ploitability for real-world processors. Proc. Priv. Enhancing Technol., 2023(1):627â€“640, 2023.
[51] Justin Holmgren and Ron Rothblum. Delegating computations with (almost) minimal time and space overhead. In Mikkel Thorup, editor, 59th FOCS, pages 124â€“135. IEEE Computer Society Press, Oc- tober 2018.
[62] Bryan Parno, Jon Howell, Craig Gentry, and Mar- iana Raykova. Pinocchio: Nearly practical verifi- able computation. In 2013 IEEE Symposium on Se- curity and Privacy, SP 2013, Berkeley, CA, USA, May 19-22, 2013, pages 238â€“252. IEEE Computer Society, 2013.
[63] Alexey Pertsev, Roman Semenov, and Roman Storm. Tornado cash privacy solution version 1.4. 2019.
[64] Nicholas Pippenger. On the evaluation of powers and monomials. SIAM J. Comput., 9(2):230â€“250, 1980.
[75] Michael Walfish and Andrew J Blumberg. Verify- ing computations without reexecuting them. Com- munications of the ACM, 58(2):74â€“84, 2015.
[2] Toshinori Araki, Jun Furukawa, Yehuda Lindell, Ariel Nof, and Kazuma Ohara. High-throughput semi-honest secure three-party computation with an honest majority. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, Vienna, Aus- tria, October 24-28, 2016, pages 805â€“817. ACM, 2016.
[3] Gilad Asharov, Tucker Balch, Hans Buehler, Richard Hua, Antigoni Polychroniadou, and Manuela Veloso. Systems and methods for privacy-preserving inventory matching, filed Dec. 6, 2019.
[4] Gilad Asharov, Tucker Hybinette Balch, Antigoni Poly- chroniadou, and Manuela Veloso. PPDPs: Privacy- preserving dark pools. In 19th International Confer- ence on Autonomous Agents and Multi-Agent Systems (AAMAS 2020), 2020. Extended abstract.
[11] Octavian Catrina and Sebastiaan de Hoogh. Improved primitives for secure multiparty integer computation. In SCN, 2010.
[17] Benjamin Diamond and Antigoni Polychroniadou. Privacy-preserving inventory matching with security against malicious adversaries, filed Jan. 28, 2021.
[18] Marc Fischlin. A cost-effective pay-per-multiplication comparison method for millionaires. In CT-RSA 2001, volume 2020, pages 457â€“472. Springer, 2001.
[27] Takashi Nishide and Kazuo Ohta. Constant-round mul- tiparty computation for interval test, equality test, and comparison. IEICE Trans. Fundam. Electron. Commun. Comput. Sci., 90-A(5):960â€“968, 2007.
[28] Sameer Wagh, Divya Gupta, and Nishanth Chandran. SecureNN: 3-party secure computation for neural net- work training. In Proceedings on Privacy Enhancing Technologies, volume 2019, pages 26â€“49, 2019.
1. P0 proceeds as follows: (Encryption): (a) Commit V0 â†Com(v0;r0), and send V0 to P1. (b) Compute the bit decomposition v0 = âˆ‘jâˆˆN 2nâˆ’1âˆ’j Â·v0,j, for bits v0,j âˆˆ{0,1}. (c) For each j âˆˆN: compute additive homomorphic encryptions A j = Encpk(v0,j). (d) Send the full array (A j)Nâˆ’1 j=0 to P1. (e) Compute: i. Ï€ â†ComEq.Prove  V0,âˆNâˆ’1 j=0 (A j)2 j , ii. Ï€j â†BitProof.Prove(A j), for all j âˆˆN, P0 sends Ï€, and (Ï€j)Nâˆ’1 j=0 to P1.
2. P1 proceeds as follows: (Computing the mini- mum): Receive (Ï€,(Ï€ j)Nâˆ’1 j=0 ) and verify the following: (a) ComEq.Verify  Ï€,V0,âˆNâˆ’1 j=0 (A j)2 j , (b) BitProof.Verify(Ï€j,A j) for each j âˆˆN. If any of these checks fail, P1 aborts. (c) Run Algorithm 1, in parallel, on the ciphertexts A j and on its own secret inputs. That is, P1 runs:  (D0,j)N j=0 ,(D1,j)N j=0  â† ComparisonInitial  (A j)Nâˆ’1 j=0 ,(v1,j)Nâˆ’1 j=0  recall that the algorithm shuffles the two result vectors inside. (d) P1 sends  (D0,j)N j=0 ,(D1,j)N j=0  to P0.
3. Party P0 (Output reconstruction): (a) Decrypt di,j = decsk(Di,j) for each i = {0,1} and j = {0,...,nâˆ’1} (b) Execute Algorithm 2, that is: (b0,b1) := ComparisonFinal  (d0,j)N j=0 ,(d1,j)N j=0  . (c) Write u for the index such that bu is true and sets u := 0 if both are. (d) Compute Ï€â€² â†OneMany.Prove  (Du,j)nâˆ’1 j=0  , and sends Ï€â€² and u to P1. If u = 1 then send also v1.
4. Party P1 (output reconstruction): (a) P1 verifies OneMany.Verify  Ï€â€²,(Du,j)Nâˆ’1 j=0  . If verification passes, then P1 outputs vu. Theorem A.3. Protocol A.2 securely computes Functional- ity A.1 in the presence of a malicious P0 or a semi-honest P1, assuming secure commitments and zero-knowledge function- alities. Concrete instantiation. We implement Protocol A.2 using the ElGammal encryption scheme, where the message m is part of the exponent (thereby we get additive homomorphism). I.e., for a public key h âˆˆG, Encpk(m) = (gr,hrgm). Note that P1 does not have to decrypt the ciphertexts, but just identify an encryption of
0. Given a secret key x such that h = gx and a ciphertext c = (c1,c2), this is done by simply comparing c2/cx 1 to g0. Implementing Functionality 3.1. To implement the bank- to-client functionality, the parties invoke 2|U| times the two- party minimum functionality. For each possible symbol in U, the parties invoke the minimum functionality where once the bank inputs its interest in symbols to buy and the client in sell, and one time where the bank inputs whether it wishes to sell and the client inputs whether it wishes to buy. If a party is not interested in some symbol or in a particular side, it simply inputs
[9] M. Burkhart and Xenofontas Dimitropoulos fontas. Fast private set operations with sepia. 2012.
[12] Alex Davidson and Carlos Cid. An efficient toolkit for computing private set operations. In ACISP 2017, 2017.
[15] Michael J. Freedman, Kobbi Nissim, and Benny Pinkas. Efficient private matching and set intersection. In EU- ROCRYPT 2004, 2004.
[16] Keith B. Frikken. Privacy-preserving set union. In ACNS 2007, 2007.
[22] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any mental game or A completeness theorem for protocols with honest majority. In STOC 1987, 1987.
[24] Kyle Hogan, Noah Luther, Nabil Schear, Emily Shen, David Stott, Sophia Yakoubov, and Arkady Yerukhi- movich. Secure multiparty computation for cooperative cyber risk assessment. In SecDev 2016, 2016.
[33] Arjen K. Lenstra and Tim Voss. Information security risk assessment, aggregation, and mitigation. In ACISP 2004, 2004.
[36] Moni Naor and Benny Pinkas. Efficient oblivious trans- fer protocols. In Proceedings of the Twelfth Annual Symposium on Discrete Algorithms, 2001.
[41] Benny Pinkas, Thomas Schneider, and Michael Zohner. Scalable private set intersection based on OT extension. ACM Trans. Priv. Secur., 21(2):7:1â€“7:35, 2018.
[46] Katsunari Shishido and Atsuko Miyaji. Efficient and quasi-accurate multiparty private set union. In SMART- COMP 2018, 2018.
[47] Xiao Wang, Alex J. Malozemoff, and Jonathan Katz. EMP-toolkit: Efficient MultiParty computation toolkit. https://github.com/emp-toolkit, 2016.
[49] Andrew Chi-Chih Yao. How to generate and exchange secrets (extended abstract). In FOCS, 1986.
[1] S. Addanki, K. Garbe, E. Jaffe, R. Ostrovsky, and A. Polychroniadou. Prio+: Privacy preserving aggregate statistics via boolean shares, 2021. https://ia.cr/2021/576.
[5] Z. Bar-Yossef, T. S. Jayram, R. Kumar, and D. Sivakumar. An informa- tion statistics approach to data stream and communication complexity. Journal of Computer and System Sciences, 68(4):702â€“732, 2004.
[6] M. Barnett, B.-Y. E. Chang, R. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A modular reusable verifier for object-oriented programs. In International Symposium on Formal Methods for Components and Objects, 2005.
[7] C. Baum, I. DamgÃ¥rd, and C. Orlandi. Publicly auditable secure multi-party computation. In SCN, 2014.
[8] C. Baum, D. Escudero, A. Pedrouzo-Ulloa, P. Scholl, and J. R. Troncoso-Pastoriza. Efficient protocols for oblivious linear function evaluation from ring-LWE. In SCN, 2020.
[11] A. Beimel. Secure schemes for secret sharing and key distribution, 1996. PhD Thesis.
[21] E. Ben-Sasson, L. Goldberg, S. Kopparty, and S. Saraf. DEEP-FRI: Sampling outside the box improves soundness. In ITCS, 2020.
[25] A. J. Blumberg, J. Thaler, V. Vu, and M. Walfish. Verifiable compu- tation using multiple provers, 2014. https://eprint.iacr.org/ 2014/846.
[26] P. Bogetoft, D. L. Christensen, I. DamgÃ¥rd, M. Geisler, T. Jakobsen, M. KrÃ¸igaard, J. D. Nielsen, J. B. Nielsen, K. Nielsen, J. Pagter, M. I. Schwartzbach, and T. Toft. Secure multiparty computation goes live. In FC, 2009.
[29] S. Bowe, A. Gabizon, and M. D. Green. A multi-party protocol for constructing the public parameters of the pinocchio zk-SNARK. In FC Workshops, 2019.
[32] B. Braun. Compiling computations to constraints for verified compu- tation. UT Austin Honors Thesis HR-12-10, 2012.
[33] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and M. Wal- fish. Verifying computations with state. In Proceedings of the twenty- fourth ACM Symposium on Operating Systems Principles, 2013.
[38] B. BÃ¼nz, M. Maller, P. Mishra, N. Tyagi, and P. Vesely. Proofs for inner pairing products and applications, 2019. https://eprint. iacr.org/2019/1177.
[42] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical verified computation with streaming interactive proofs. In ITCS, 2012.
[47] N. Daswani and M. Elbayadi. Big Breaches: Cybersecurity Lessons for Everyone. Apress, 2021.
[48] A. Developers. Arkworks, 2020. https://github.com/arkworks- rs.
[49] D. Evans, V. Kolesnikov, and M. Rosulek. A pragmatic introduction to secure multi-party computation. 2017.
[53] A. Gabizon, Z. J. Williamson, and O. Ciobotaru. PLONK: Permuta- tions over lagrange-bases for oecumenical noninteractive arguments of knowledge, 2019. https://eprint.iacr.org/2019/953.
[55] D. Genkin, Y. Ishai, M. Prabhakaran, A. Sahai, and E. Tromer. Circuits resilient to additive attacks with applications to secure computation. In ACM STOC, 2014.
[58] O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game or A completeness theorem for protocols with honest majority. In ACM STOC, 1987.
[59] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating compu- tation: interactive proofs for muggles. In ACM STOC, 2008.
[60] S. Goldwasser, J. Killian, M. Ben-Or, and A. Wigderson. Multi-prover interactive proofs: how to remove intractability assumptions. In STOC, 1988.
[63] V. Goyal and Y. Song. Malicious security comes free in honest- majority MPC, 2020. https://eprint.iacr.org/2020/134.
[65] L. Grassi, D. Kales, D. Khovratovich, A. Roy, C. Rechberger, and M. Schofnegger. Starkad and Poseidon: New hash functions for zero knowledge proof systems, 2019. https://eprint.iacr.org/ 2019/458.
[68] J. Y. Halpern and Y. Moses. Knowledge and common knowledge in a distributed environment. J. ACM, 37(3):549â€“587, 1990.
[69] J. HÃ¥stad and A. Wigderson. The randomized communication com- plexity of set disjointness. Theory of Computing, 3(1):211â€“219, 2007.
[71] D. Heath and V. Kolesnikov. LogStack: Stacked garbling with O(blogb) computation. 2021.
[72] D. Heath, V. Kolesnikov, and S. Peceny. Masked triples - amortizing multiplication triples across conditionals. 2021.
[74] W. jie Lu and J. Sakuma. Faster multiplication triplet generation from homomorphic encryption for practical privacy-preserving machine learning under a narrow bandwidth, 2018. https://eprint.iacr. org/2018/139.
[77] M. Kohlweiss, M. Maller, J. Siim, and M. Volkhov. Snarky ceremonies, 2021. https://ia.cr/2021/219.
[79] K. R. M. Leino. This is boogie
2. manuscript KRML, 178(131):9, 2008.
[81] Y. Lindell. How to simulate it - A tutorial on the simulation proof technique, 2016. https://eprint.iacr.org/2016/046.
[84] Y. Lindell and B. Pinkas. An efficient protocol for secure two-party computation in the presence of malicious adversaries. In EURO- CRYPT, 2007.
[89] P. S. Nordholt and M. Veeningen. Minimising communication in honest-majority MPC by batchwise multiplication verification. In ACNS, 2018.
[90] A. Ozdemir, F. Brown, and R. S. Wahby. Unifying compilers for SNARKs, SMT, and more, 2020. https://eprint.iacr.org/ 2020/1586.
[92] G. C. Platform. All networking pricing. https://cloud.google. com/vpc/network-pricing.
[93] G. C. Platform. Pricing, compute engine. https://cloud.google. com/compute/all-pricing.
[94] T. Rabin and M. Ben-Or. Verifiable secret sharing and multiparty protocols with honest majority (extended abstract). In ACM STOC, 1989.
[95] D. Rathee, T. Schneider, and K. K. Shukla. Improved multiplication triple generation over rings via RLWE-based AHE. In CANS 19, 2019.
[96] A. Sangers, M. van Heesch, T. Attema, T. Veugen, M. Wiggerman, J. Veldsink, O. Bloemen, and D. Worm. Secure multiparty PageRank algorithm for collaborative fraud detection. In FC, 2019.
[97] B. Schoenmakers, M. Veeningen, and N. de Vreede. Trinocchio: Privacy-preserving outsourcing by distributed verifiable computation. In ACNS, 2016.
[98] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Walfish. Resolving the conflict between generality and plausibility in verified computation. 2013.
2. A proof (Setup,Prove,Verify) is honestly sound if for all (x,w) /âˆˆR, Pr  Verify(pp,x,Ï€) = 1 : pp â†Setup(1Î»,R) Ï€ â†Prove(pp,x,w)  = negl(Î») Surprisingly, knowledge soundness does not imply honest soundness. While the former guarantees that a verifier can extract a valid witness from an acceptable proof, it makes no guarantees about the witness that the prover used. As an example, consider the (trivial) relation R= = {(x âˆˆF,w âˆˆF) : x = w} For this relation, define the proof system (Setup,Prove, Verify) where Setup is a no-op, Prove always returns a null proof Ï€ = âŠ¥, and Verify always return
1. This proof system is knowledge-sound, but not honestly sound. Regardless, itâ€™s easy to show that the SNARKs we study are honestly sound. It suffices to show a â„¦(n) communication bound for checking a shared R1CS witness. If there were a low- communication protocol for generating a proof, parties could just check a shared witness by constructing and checking the proof. Per completeness and honest soundness, the proof is valid if and only if the witness was valid, except with negligi- ble probability. Unfortunately, the communication-hard problem DISJn reduces to checking additively shared R1CS witnesses. DISJn asks whether the two length-n bit-strings do not share a one at any index; i.e., DISJn(a,b) = Vn i=1 Â¬(ai âˆ§bi). DISJn has been shown to have â„¦(n) randomized 2-party communication complexity [5, 69]. DISJn(a,b) reduces to R1CS checking as follows. P1, who has a, interprets it as a zero-one vector in Fn and sets x0 â†a;y0 â†âƒ—0;z0 â†âƒ—0. Simultaneously,P2, interprets b as a zero-one vector in Fn and sets x1 â†âƒ—0;y1 â†b;z1 â†âƒ—0. With this reduction, a and b are disjoint if and only if (x0,x1), (y0,y1), and (z0,z1) are sharings of x,y,z such that xâ—¦y = z, an R1CS relation. Note that this is only a limited bound. First, it requires â„¦(n)â€”not â„¦(nlog|F|)â€”communication. We suspect the stronger bound holds as well, but do not know of an existing communication complexity result that it immediately follows from. Second, the bound applies only to additively shared witnesses. C KZG for Shared Polynomials This
[1] Bulletproofs implementation. https://github.com/ ing-bank/zkrp.
[3] IntegriDB implementation. https://github.com/ integridb/Code.
[4] Merkle2 implementation. https://github.com/ ucbrise/MerkleSquare.
[5] Sixads. https://sixads.net/.
[11] J. Camenisch, R. Chaabouni, and a. shelat. Efï¬cient protocols for set membership and range proofs. In ASIA- CRYPT. Springer, 2008.
[12] H. Chen, X. Ma, W. Hsu, N. Li, and Q. Wang. Access control friendly query veriï¬cation for outsourced data publishing. In ESORICS, pages 177â€“191, 2008.
[14] C. Dwork. Differential privacy: A survey of results. In TAMC, pages 1â€“19. Springer, 2008.
[16] A. Eijdenberg, B. Laurie, and A. Cutter. Veriï¬able data structures. Google Research, Tech. Rep, 2015.
[17] N. Holohan, S. Antonatos, S. Braghin, and P. Mac Aonghusa. The bounded Laplace mecha- nism in differential privacy. Journal of Privacy and Conï¬dentiality, 10(1), 2020.
[20] B. Laurie. Certiï¬cate transparency. Communications of the ACM, 57(10):40â€“46, 2014.
[21] B. Laurie and E. Kasper. Revocation transparency. Google Research, 2012.
[22] F. Li, M. Hadjieleftheriou, G. Kollios, and L. Reyzin. Authenticated index structures for aggregation queries. ACM TISSEC, 13(4):1â€“35, 2010.
[24] F. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In ACM SIGMOD, pages 19â€“30, 2009.
[26] E. Morais, T. Koens, C. van Wijk, and A. Koren. A survey on zero knowledge range proofs and applications. SN Applied Sciences, 1(8):946, 2019.
[28] Y. Peng, M. Du, F. Li, R. Cheng, and D. Song. Fal- conDB: Blockchain-based collaborative database. In ACM SIGMOD, pages 637â€“652, 2020.
[29] R. Poddar, T. Boelter, and R. A. Popa. Arx: A strongly encrypted database system. Proceedings of the VLDB endowment, 12:1664â€“1678, 2019.
[30] D. Reijsbergen, Z. Yang, A. Maw, T. T. A. Dinh, and J. Zhou. Transparent electricity pricing with privacy. In ESORICS, pages 439â€“460, 2021.
[33] R. Tamassia. Authenticated data structures. In European Symposium on Algorithms, pages 2â€“5. Springer, 2003.
[15] states that returning a result R such that R(D) = Râˆ—(D)+Z, where Z is a Laplace-distributed random variable with scale parameter Ïƒ, guarantees Îµâ€²-differential privacy with Îµâ€² = âˆ†/Ïƒ. In particular, Ïƒ = âˆ†guarantees Îµ- differential privacy. A challenge in our context is that the Laplace distribution has positive density on the entire interval [âˆ’âˆ,âˆ]. This is acceptable in cases where the threat model assumes that the server is always honest. However, in our case it would allow a malicious server to add arbitrarily large noise to the true result, and therefore convince the user to accept any value desired by the malicious server. To limit the scope for server misbehavior, noise should instead be drawn from a bounded interval. Prior results in this area for truncated Gaussian [23] and Laplace
[17] noise indicate that although Îµ-differential pri- vacy cannot be achieved in this case, (Îµ,Î´)-differential privacy is possible. As such, we focus in the following on a generic ap- proach for noise on the bounded interval {âˆ’b,âˆ’b+1,...,b} for a constant b. In particular, let g : [0,b] â†’[0,âˆ) and G(z) = âˆ‘z x=0 g(x) such that g(0) + 2G(b âˆ’1) =
[1] S. Adeshina. Detecting Fraud in Heterogeneous Net- works using Amazon SageMaker and Deep Graph Li- brary. https://aws.amazon.com/blogs/machine-learning /detecting-fraud-in-heterogeneous-networks-using-am azon-sagemaker-and-deep-graph-library/, 2020.
[2] L. A. Alves et al. Graph Neural Networks as a Po- tential Tool in Improving Virtual Screening Programs. Frontiers in Chemistry, 9:787194, 2021.
[3] M. J. Atallah, M. Bykova, J. Li, K. B. Frikken, and M. Topkara. Private Collaborative Forecasting and Benchmarking. In ACM WPES, 2004.
[4] B. Balakreshnan. Graph Neural Network in Azure Machine Learning â€” Classification. https://balabala76. medium.com/graph-neural-network-in-azure-machine- learning-classification-df7978d7bd45, 2021.
[8] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral Networks and Locally Connected Networks on Graphs. In ICLR, 2014.
[10] H. Dai, Z. Kozareva, B. Dai, A. J. Smola, and L. Song. Learning Steady-States of Iterative Algorithms over Graphs. In ICML, 2018.
[11] M. Defferrard, X. Bresson, and P. Vandergheynst. Con- volutional Neural Networks on Graphs with Fast Local- ized Spectral Filtering. In NIPS, 2016.
[12] V. Duddu, A. Boutet, and V. Shejwalkar. Quantifying Privacy Leakage in Graph Embedding. In ACM MobiQ- uitous, 2020.
[14] H. Peng et al. LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference. In NeurIPS, 2023.
[15] Kai et al. Defense Sgainst Membership Inference At- tack in Graph Neural Networks Through Graph Pertur- bation. International Journal of Information Security, 22(2):497â€“509, 2023.
[17] R. Ying et al. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In ACM KDD, 2018.
[19] S. Wagh et al. Falcon: Honest-Majority Maliciously Se- cure Framework for Private Deep Learning. In PoPETs, 2021.
[20] W. Chiang et al. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Net- works. In ACM KDD, 2019.
[21] F. Falzon and K. G. Paterson. An Efficient Query Re- covery Attack Against a Graph Encryption Scheme. In ESORICS, 2022.
[23] C. Gentry. Fully Homomorphic Encryption Using Ideal Lattices. In ACM STOC, 2009.
[25] W. L. Hamilton, Z. Ying, and J. Leskovec. Inductive Representation Learning on Large Graphs. In NIPS, 2017.
[31] M. Keller and K. Sun. Effectiveness of MPC-friendly Softmax Replacement. In NeurIPS PPML Workshop, 2020.
[32] M. Keller and K. Sun. Secure Quantized Training for Deep Learning. In ICML, 2022.
[33] T. N. Kipf and M. Welling. Semi-Supervised Classifi- cation with Graph Convolutional Networks. In ICLR (Poster), 2017.
[35] B. Lackey. Use Graphs for Smarter AI with Neo4j and Google Cloud Vertex AI. https://cloud.google.com/blog /products/ai-machine-learning/analyze-graph-data-on- google-cloud-with-neo4j-and-vertex-ai, 2022.
[36] Y. Li, D. Tarlow, M. Brockschmidt, and R. S. Zemel. Gated Graph Sequence Neural Networks. In ICLR (Poster), 2016.
[42] Google LLC. Google Cloud Inter-Region Latency and Throughput. http://lookerstudio.google.com/u/0/report ing/fc733b10-9744-4a72-a502-92290f608571/page/70 YCB, 2023.
[52] T. Ryffel, P. Tholoniat, D. Pointcheval, and F. R. Bach. AriaNN: Low-Interaction Privacy-Preserving Deep Learning via Function Secret Sharing. In PoPETs, 2022.
[55] A. Sherstinsky. Fundamentals of Recurrent Neu- ral Network (RNN) and Long Short-Term Memory (LSTM) Network. Physica D: Nonlinear Phenomena, 404:132306, 2020.
[57] P. Velickovic et al. Graph Attention Networks. In ICLR (Poster), 2018.
[58] S. Wagh, D. Gupta, and N. Chandran. SecureNN: 3- Party Secure Computation for Neural Network Training. In PoPETs, 2019.
[60] B. Wu, X Yang., S. Pan, and X. Yuan. Adapting Member- ship Inference Attacks to GNN for Graph Classification: Approaches and Implications. In IEEE ICDM, 2021.
[63] J. Xu, S. Koffas, O. Ersoy, and S. Picek. Watermarking Graph Neural Networks based on Backdoor Attacks. In IEEE EuroS&P, 2023.
[64] K. Xu, W. Hu, J. Leskovec, and S. Jegelka. How Power- ful are Graph Neural Networks? In ICLR, 2019.
[65] W. Xu et al. MDP: Privacy-Preserving GNN Based on Matrix Decomposition and Differential Privacy. In IEEE JCC, 2023.
[66] H. Zhang et al. Trustworthy Graph Neural Networks: Aspects, Methods and Trends. Proceedings of the IEEE, pages 1â€“43, 2024.
[67] J. Zhang, H. Wang, and M. Zhu. Build a GNN-based Real-Time Fraud Detection Solution using Amazon SageMaker, Amazon Neptune, and the Deep Graph Li- brary. https://aws.amazon.com/blogs/machine-learning/ build-a-gnn-based-real-time-fraud-detection-solution- using-amazon-sagemaker-amazon-neptune-and-the- deep-graph-library/, 2022.
[68] X. Zhang, L. Liang, L. Liu, and M. Tang. Graph Neural Networks and Their Current Applications in Bioinfor- matics. Frontiers in Genetics, 12:690049, 2021. A Security Analysis A.1 Security Definition Definition A.1 (FSS Security). We say that the (KeyGen=, KeyGen<, Eval=, Eval<) as defines above, is a FSS scheme if it satisfies the following requirements: Security: For each b âˆˆ{0,1}, there is a Probabilis- tic Polynomial Time (PPT) algorithm Simulator Sb, such that for polynomial-size all-prefix function with sequence ((Î±, Â¯Î²)Î»)Î»âˆˆN and polynomial size input sequence Î±Î», the out- puts of the following experiments Real and Ideal are indistin- guishable: â€¢ RealÎ» : (k0,k1) â†KeyGen(1Î»,(Î±, Â¯Î²)Î»); Output kb. â€¢ IdealÎ» : Output Sb. A.2 Security Proof We employ a simulation framework
0. We initiate the hybrid with the real world. Hybrid
1. Simulator S replaces the FSS kÃ—, k+, DPF keys k= and DCF keys k< with the output from the above-defined FSS, DPF and DCF simulators SFSS, SDPF and SDCF from model owner. Based on the security analysis of FSS, DPF and DCF schemes, it implies that the probability of A can distinguish between H 0 and H 1 is negl(Î»). Hybrid
2. Simulator S replaces the DPF keys kA, kF and kQ with the generated DPF keys based on real graph matrices for OblivUpdate, client inquiry from client. Based on the security analysis of DPF schemes, the probability of A can distinguish between H 1 and H 2 is negl(Î»). Hybrid
[1] Anderson, R., Needham, R., Shamir, A.: The steganographic file system. In: Information Hiding (1998)
[2] Ateniese, G., Magri, B., Venturi, D.: Subversion-resilient sig- nature schemes. In: ACM Conference on Computer and Com- munications Security.  (2015)
[3] Bellare, M., Jaeger, J., Kane, D.: Mass-surveillance without the state: Strongly undetectable algorithm-substitution attacks. In: ACM Conference on Computer and Communications Security. (2015)
[5] Berndt, S., LiÂ´skiewicz, M.: Algorithm substitution attacks from a steganographic perspective. In: ACM Conference on Com- puter and Communications Security.  (2017)
[6] Blass, E.O., Mayberry, T., Noubir, G., Onarlioglu, K.: Toward robust hidden volumes using write-only oblivious ram. In: ACM Conference on Computer and Communications Security. (2014)
[7] Borisov, N., Goldberg, I., Brewer, E.: Off-the-record commu- nication, or, why not to use pgp. In: Workshop on Privacy in the Electronic Society (2004)
[8] Briar. https://briarproject.org
[9] Byrant, F.: 7 best keyloggers for android without root. Spy Drill (2021)
[13] Chakraborti, A., Chen, C., Sion, R.: DataLair: Efficient block storage with plausible deniability against multi-snapshot ad- versaries. In: Privacy Enhancing Technologies Symposium.  (2017)
[16] Chen, C., Chakraborti, A., Sion, R.: INFUSE: Invisible plausibly-deniable file system for NAND flash. In: Privacy Enhancing Technologies Symposium.  (2020)
[17] Cho, H., Zhang, P., Kim, D., Park, J., Lee, C.H., Zhao, Z., DoupÃ©, A., Ahn, G.J.: Prime+count: Novel cross-world covert channels on arm trustzone. In: Annual Computer Security Ap- plications Conference. p. 441â€“452 (2018)
[18] Coynash, H.: Russian fsb terrorizes another ukrainian activist in occupied crimea. http://khpg.org/en/index.php?id= 1549897598
[19] Cui, Y.: Elevation of privilege vulnerability in the ker- nel (cve-2015-6640) ). https://cve.mitre.org/cgi-bin/ cvename.cgi?name=CVE-2015-6640
[22] Di Raimondo, M., Gennaro, R., Krawczyk, H.: Deniable au- thentication and key exchange. In: ACM Conference on Com- puter and Communications Security. p. 400â€“409 (2006)
[23] Google: Hardware-backed keystore. https://source. android.com/security/keystore (2019)
[26] Helms, K.: Us senators introduce â€™lawful access to encrypted data actâ€™ â€” with backdoor mandate. https://tinyurl.com/ lawful-access-backdoor
[28] Jia, S., Xia, L., Chen, B., Liu, P.: Deftl: Implementing plausibly deniable encryption in flash translation layer. In: ACM Confer- ence on Computer and Communications Security (2017)
[31] laginimaineb: Android linux kernel privilege escalation (cve- 2014-4322). http://bits-please.blogspot.com/2015/ 08/android-linux-kernel-privilege.html
[32] laginimaineb: Android linux kernel privilege escalation (cve- 2014-4323). http://bits-please.blogspot.com/2015/ 08/android-linux-kernel-privilege_26.html
[35] Liu, D., Cox, L.P.: VeriUI. In: Workshop on Mobile Computing Systems and Applications (2014)
[36] Liu, F., Ge, Q., Yarom, Y., Mckeen, F., Rozas, C., Heiser, G., Lee, R.B.: Catalyst: Defeating last-level cache side channel attacks in cloud computing. In: IEEE International Symposium on High Performance Computer Architecture. (2016)
[37] Liu, H., Vasserman, E., Hopper, N.: Improved group off-the- record messaging. In: ACM Conference on Computer and Communications Security (2013)
[38] Liu, N., Yu, M., Zang, W., Sandhu, R.S.: Cost and effectiveness of trustzone defense and side-channel attack on arm platform. In: Journal of Wireless Mobile Networks, Ubiquitous Comput- ing, and Dependable Applications. vol. 11,  (2020)
[40] Mull, J.: Aes ige encryption. https://mgp25.com/AESIGE/
[43] Owen, M.: Invisible kismet imessage exploit used to hack jour- nalistsâ€™ iphones. https://appleinsider.com/articles/ 20/12/21/invisible-kismet-imessage-exploit-\ used-to-hack-journalists-iphones
[44] Pang, H., Tan, K.L., Zhou, X.: Stegfs: a steganographic file sys- tem. In: IEEE International Conference on Data Engineering. (2003)
[46] Peters, T., Gondree, M., Peterson, Z.N.J.: DEFY: A deniable, encrypted file system for log-structured storage. In: ISOC Net- work and Distributed System Security Symposium (2015)
[47] Raja, A.: 10 best free hidden spy apps for android. Tech Times (2019)
[48] Sahai, A., Waters, B.: How to use indistinguishability obfusca- tion: Deniable encryption, and more. In: ACM Symposium on Theory of Computing. p. 475â€“484 (2014)
[49] Signal. https://signal.org/en/
[50] Technology preview: Sealed sender for signal. https:// signal.org/blog/sealed-sender/
[51] Sun, H., Sun, K., Wang, Y., Jing, J.: TrustOTP. In: ACM Con- ference on Computer and Communications Security (2015)
[52] Sun, H., Sun, K., Wang, Y., Jing, J., Jajodia, S.: TrustDump: Reliable memory acquisition on smartphones. In: European Symposium on Research in Computer Security. (2014)
[53] Telegram messenger. https://telegram.org
[55] TrustedFirmware.org: Op-tee documentation. https:// optee.readthedocs.io/en/latest/ (2019)
[56] Unger, N., Goldberg, I.: Improved strongly deniable authenti- cated key exchanges for secure messaging. In: Privacy Enhanc- ing Technologies Symposium.  (2018)
[59] Zhao, S., Zhang, Q., Qin, Y., Feng, W., Feng, D.: Sectee: A software-based approach to secure enclave architecture using tee. In: ACM Conference on Computer and Communications Security. p. 1723â€“1740 (2019)
[60] Zheng, X., Yang, L., Ma, J., Shi, G., Meng, D.: TrustPAY: Trusted mobile payment on security enhanced ARM TrustZone platforms. In: IEEE Symposium on Computers and Communi- cation (2016)
[1] CVE-2013-0864. https://cve.mitre.org/ cgi-bin/cvename.cgi?name=CVE-2013-0864. Accessed: 2022-10-10.
[2] FFmpeg. https://ffmpeg.org/. Accessed: 2022-09- 01.
[4] Picolibc: C libraries for smaller embedded systems. https://keithp.com/picolibc/. Accessed: 2022- 10-10.
[5] The Heartbleed Bug. https://heartbleed.com/. Ac- cessed: 2022-09-05.
[6] zkInterface: SIEVE intermediate representation (IR) proposal. https://hackmd.io/@danib31/ BkP9HBp2L. Accessed: 2022-10-10.
[7] Alfred V Aho, Monica S Lam, Ravi Sethi, and Jeffrey D Ullman. Compilers: principles, techniques, & tools. Pearson Education India, 2007.
[9] Carsten Baum, Alex J. Malozemoff, Marc B. Rosen, and Peter Scholl. Macâ€™nâ€™cheese: Zero-knowledge proofs for boolean and arithmetic circuits with nested disjunctions. In Malkin and Peikert [38], pages 92â€“122.
[13] Nick Benton. Simple relational correctness proofs for static analyses and program transformations. ACM SIG- PLAN Notices, 39(1):14â€“25, 2004.
[15] Alexander R. Block, Justin Holmgren, Alon Rosen, Ron D. Rothblum, and Pratik Soni. Time- and space- efficient arguments from groups of unknown order. In Malkin and Peikert [38], pages 123â€“152.
[17] Benjamin Braun, Ariel J Feldman, Zuocheng Ren, Sri- nath Setty, Andrew J Blumberg, and Michael Walfish. Verifying computations with state. In Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles, pages 341â€“357, 2013.
[18] Michael R Clarkson and Fred B Schneider. Hyperprop- erties. Journal of Computer Security, 18(6):1157â€“1210, 2010.
[19] Dorothy E Denning. A lattice model of secure informa- tion flow. Communications of the ACM, 19(5):236â€“243, 1976.
[21] Zhiyong Fang, David Darais, Joseph P Near, and Yupeng Zhang. Zero knowledge static program analysis. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2951â€“ 2967, 2021.
[23] Galois, Inc. swanky: A suite of rust libraries for secure computation. https://github.com/GaloisInc/ swanky, 2019.
[26] Oded Goldreich, Silvio Micali, and Avi Wigderson. Proofs that yield nothing but their validity or all lan- guages in np have zero-knowledge proof systems. Jour- nal of the ACM (JACM), 38(3):690â€“728, 1991.
[29] David Heath and Vladimir Kolesnikov. A 2.1 khz zero- knowledge processor with bubbleram. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, pages 2055â€“2074, 2020.
[32] Allen D Householder, Garret Wassermann, Art Manion, and Chris King. The CERT guide to coordinated vulner- ability disclosure. Technical report, Carnegie-Mellon Univ, Pittsburgh, PA, United States, 2017.
[34] Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky, and Amit Sahai. Zero-knowledge from secure multiparty computation. In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, pages 21â€“30, 2007.
[35] Jasper Vijn. GRIT: Gba raster image transmogrifier. https://github.com/devkitPro/grit, 2022.
[36] Neil D Jones, Carsten K Gomard, and Peter Sestoft. Par- tial evaluation and automatic program generation. Peter Sestoft, 1993.
[37] Jonathan Katz, Vladimir Kolesnikov, and Xiao Wang. Improved non-interactive zero knowledge with appli- cations to post-quantum signatures. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 525â€“537, 2018.
[40] Andrew C Myers. Jflow: Practical mostly-static in- formation flow control. In Proceedings of the 26th ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 228â€“241, 1999.
[41] Andrew C Myers and Barbara Liskov. A decentralized model for information flow control. ACM SIGOPS Op- erating Systems Review, 31(5):129â€“142, 1997.
[43] James Parker, Niki Vazou, and Michael Hicks. Lweb: Information flow security for multi-tier web applications. Proc. ACM Program. Lang., 3(POPL), jan 2019.
[45] John C Reynolds. Separation logic: A logic for shared mutable data structures. In Proceedings 17th Annual IEEE Symposium on Logic in Computer Science, pages 55â€“74. IEEE, 2002.
[46] Andrei Sabelfeld and Andrew C Myers. Language- based information-flow security. IEEE Journal on se- lected areas in communications, 21(1):5â€“19, 2003.
[48] Marc Shapiro and Susan Horwitz. Fast and accurate flow-insensitive points-to analysis. In Proceedings of the 24th ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 1â€“14, 1997.
[49] Bjarne Steensgaard. Points-to analysis in almost lin- ear time. In Proceedings of the 23rd ACM SIGPLAN- SIGACT symposium on Principles of programming lan- guages, pages 32â€“41, 1996.
[50] Deian Stefan, Alejandro Russo, John C Mitchell, and David MaziÃ¨res. Flexible dynamic information flow control in haskell. In Proceedings of the 4th ACM Sym- posium on Haskell, pages 95â€“106, 2011.
[51] G Edward Suh, Jae W Lee, David Zhang, and Srinivas Devadas. Secure program execution via dynamic infor- mation flow tracking. ACM Sigplan Notices, 39(11):85â€“ 96, 2004.
[2] Zeromq: An open-source universal messaging library. https: //github.com/zeromq/libzmq.
[5] Ghous Amjad, Sarvar Patel, Giuseppe Persiano, Kevin Yeo, and Moti Yung. Dynamic volume-hiding encrypted multi- maps with applications to searchable encryption. Proc. Priv. Enhancing Technol., 2023(1):417â€“436, 2023.
[9] Burton H Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 13(7):422â€“426, 1970.
[25] Victor Costan and Srinivas Devadas. Intel sgx explained. Cryp- tology ePrint Archive, 2016.
[29] Ioannis Demertzis, Javad Ghareh Chamani, Dimitrios Pa- padopoulos, and Charalampos Papamanthou. Dynamic search- able encryption with small client storage. 01 2020.
[32] Nabeil Eltayieb, Rashad Elhabob, Alzubair Hassan, and Fagen Li. An efficient attribute-based online/offline searchable en- cryption and its application in cloud-based reliable smart grid. Journal of Systems Architecture, 98:165â€“172, 2019.
[34] Saba Eskandarian and Matei Zaharia. Oblidb: Oblivious query processing for secure databases. Proceedings of the VLDB Endowment, 13(2), 2019.
[36] Benny Fuhry, Jayanth Jain H. A, and Florian Kerschbaum. Encdbdb: Searchable encrypted, fast, compressed, in-memory database using enclaves. In 51st Annual IEEE/IFIP Interna- tional Conference on Dependable Systems and Networks, DSN 2021, Taipei, Taiwan, June 21-24, 2021, pages 438â€“450. IEEE, 2021.
[44] Thang Hoang, Muslum Ozgur Ozmen, Yeongjin Jang, and Attila A Yavuz. Hardware-supported oram in effect: Practical oblivious search and update on very large dataset. Proceedings on Privacy Enhancing Technologies, 2019(1), 2019.
[45] Thang Hoang, Attila Yavuz, F. Durak, and Jorge Guajardo. A multi-server oblivious dynamic searchable encryption frame- work. Journal of Computer Security, 27:1â€“28, 09 2019.
[49] Seny Kamara, Charalampos Papamanthou, and Tom Roeder. Dynamic searchable symmetric encryption. In Proceedings of the 2012 ACM conference on Computer and communications security, pages 965â€“976, 2012.
[52] Florian Kerschbaum and Anselme Tueno. An efficiently search- able encrypted data structure for range queries. In European Symposium on Research in Computer Security, 2017.
[53] Aggelos Kiayias, Ozgur Oksuz, Alexander Russell, Qiang Tang, and Bing Wang. Efficient encrypted keyword search for multi- user data sharing. In European symposium on research in computer security, pages 173â€“195. Springer, 2016.
[56] Steven Lambregts, Huanhuan Chen, Jianting Ning, and Kaitai Liang. Val: Volume and access pattern leakage-abuse attack with leaked documents. In European Symposium on Research in Computer Security, pages 653â€“676. Springer, 2022.
[59] Chang Liu, Liehuang Zhu, Mingzhong Wang, and Yu-An Tan. Search pattern leakage in searchable encryption: Attacks and new construction. Inf. Sci., 265:176â€“188, may 2014.
[70] Emil Stefanov, Marten Van Dijk, Elaine Shi, T.-H. Hubert Chan, Christopher Fletcher, Ling Ren, Xiangyao Yu, and Srinivas De- vadas. Path oram: An extremely simple oblivious ram protocol. J. ACM, 65(4), apr 2018.
[73] Shi-Feng Sun, Xingliang Yuan, Joseph K Liu, Ron Steinfeld, Amin Sakzad, Viet Vo, and Surya Nepal. Practical backward- secure searchable encryption from symmetric puncturable en- cryption. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 763â€“780, 2018.
[75] Jiafan Wang and Sherman Chow. Forward and backward- secure range-searchable symmetric encryption. Proceedings on Privacy Enhancing Technologies, 2022:28â€“48, 01 2022.
[78] Xiao Wang, Alex J. Malozemoff, and Jonathan Katz. EMP- toolkit: Efficient MultiParty computation toolkit. https:// github.com/emp-toolkit, 2016.
[80] Pieter Wuille. libsecp256k1. https://github.com/ bitcoin-core/secp256k1.
