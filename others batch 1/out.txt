nathanielclizbe@MacBookAir citation-analysis % python3 ref_analysis.py
Loaded 10 paper titles from google sheets.
Found 936 PDFs in Zotero storage
9 PDFs match titles in papers_list.txt
Leakage-Abuse Attacks Against Structured Encryption for SQL.
[1] Archita Agarwal, Maurice Herlihy, Seny Kamara, and Tarik Moataz. Encrypted databases for differential pri- vacy. PoPETs, 2019(3):170–190, July 2019.
[2] Rakesh Agrawal, Jerry Kiernan, Ramakrishnan Srikant, and Yirong Xu. Order preserving encryption for nu- meric data. In Proceedings of the 2004 ACM SIGMOD international conference on Management of data, pages 563–574, 2004.
[3] Panagiotis Antonopoulos, Arvind Arasu, Kunal D Singh, Ken Eguro, Nitish Gupta, Rajat Jain, Raghav Kaushik, Hanuma Kodavalla, Donald Kossmann, Nikolas Ogg, et al. Azure sql database always encrypted. In Proceed- ings of the 2020 ACM SIGMOD International Confer- ence on Management of Data, pages 1511–1525, 2020.
[4] Alexandre Anzala-Yamajako, Olivier Bernard, Matthieu Giraud, and Pascal Lafourcade. No such thing as a small leak: Leakage-abuse attacks against symmetric searchable encryption. In International Conference on E-Business and Telecommunications, pages 253–277. Springer, 2019.
[5] Assaf Ben-David, Noam Nisan, and Benny Pinkas. Fair- playMP: a system for secure multi-party computation. In Peng Ning, Paul F. Syverson, and Somesh Jha, editors, ACM CCS 2008, pages 257–266. ACM Press, October 2008.
[6] Vincent Bindschaedler, Paul Grubbs, David Cash, Thomas Ristenpart, and Vitaly Shmatikov. The tao of inference in privacy-protected databases. Cryptol- ogy ePrint Archive, Report 2017/1078, 2017. https: //eprint.iacr.org/2017/1078.
[7] Laura Blackstone, Seny Kamara, and Tarik Moataz. Re- visiting leakage abuse attacks. In NDSS 2020. The Internet Society, February 2020.
[8] Dan Boneh, Giovanni Di Crescenzo, Rafail Ostrovsky, and Giuseppe Persiano. Public key encryption with key- word search. In Christian Cachin and Jan Camenisch, ed- itors, EUROCRYPT 2004, volume 3027 of LNCS, pages 506–522. Springer, Heidelberg, May 2004.
[9] Raphael Bost. Σoφoς: Forward secure searchable en- cryption. In Edgar R. Weippl, Stefan Katzenbeisser, Christopher Kruegel, Andrew C. Myers, and Shai Halevi, editors, ACM CCS 2016, pages 1143–1154. ACM Press, October 2016.
[10] Raphael Bost and Pierre-Alain Fouque. Thwarting leak- age abuse attacks against searchable encryption – A formal approach and applications to database padding. Cryptology ePrint Archive, Report 2017/1060, 2017. https://eprint.iacr.org/2017/1060.
[11] David Cash, Paul Grubbs, Jason Perry, and Thomas Ris- tenpart. Leakage-abuse attacks against searchable en- cryption. In Indrajit Ray, Ninghui Li, and Christopher Kruegel, editors, ACM CCS 2015, pages 668–679. ACM Press, October 2015.
[12] David Cash, Joseph Jaeger, Stanislaw Jarecki, Charan- jit S. Jutla, Hugo Krawczyk, Marcel-Catalin Rosu, and Michael Steiner. Dynamic searchable encryption in very-large databases: Data structures and implementa- tion. In NDSS 2014. The Internet Society, February 2014.
[13] David Cash, Ruth Ng, and Adam Rivkin. Improved structured encryption for SQL databases via hybrid in- dexing. In Kazue Sako and Nils Ole Tippenhauer, edi- tors, ACNS 21, Part II, volume 12727 of LNCS, pages 480–510. Springer, Heidelberg, June 2021.
[14] Javad Ghareh Chamani, Dimitrios Papadopoulos, Char- alampos Papamanthou, and Rasool Jalili. New con- structions for forward and backward private symmet- ric searchable encryption. In David Lie, Mohammad Mannan, Michael Backes, and XiaoFeng Wang, editors, ACM CCS 2018, pages 1038–1055. ACM Press, October 2018.
[15] Yan-Cheng Chang and Michael Mitzenmacher. Privacy preserving keyword searches on remote encrypted data. In John Ioannidis, Angelos Keromytis, and Moti Yung, editors, ACNS 05, volume 3531 of LNCS, pages 442– 455. Springer, Heidelberg, June 2005.
[16] Zhao Chang, Dong Xie, Sheng Wang, and Feifei Li. Towards practical oblivious join. In Proceedings of the 2022 International Conference on Management of Data, pages 803–817, 2022.
[17] Melissa Chase and Seny Kamara. Structured encryption and controlled disclosure. In Masayuki Abe, editor, ASIACRYPT 2010, volume 6477 of LNCS, pages 577– 594. Springer, Heidelberg, December 2010.
[18] Reza Curtmola, Juan A. Garay, Seny Kamara, and Rafail Ostrovsky. Searchable symmetric encryption: improved definitions and efficient constructions. In Ari Juels, Re- becca N. Wright, and Sabrina De Capitani di Vimercati, editors, ACM CCS 2006, pages 79–88. ACM Press, Oc- tober / November 2006.
[19] Ioannis Demertzis, Dimitrios Papadopoulos, Charalam- pos Papamanthou, and Saurabh Shintre. SEAL: Attack mitigation for encrypted databases via adjustable leak- age. In Srdjan Capkun and Franziska Roesner, editors, USENIX Association 33rd USENIX Security Symposium    7425 USENIX Security 2020, pages 2433–2450. USENIX As- sociation, August 2020.
[20] Francesca Falzon, Evangelia Anna Markatou, Akshima, David Cash, Adam Rivkin, Jesse Stern, and Roberto Tamassia. Full database reconstruction in two dimen- sions. In Jay Ligatti, Xinming Ou, Jonathan Katz, and Giovanni Vigna, editors, ACM CCS 2020, pages 443– 460. ACM Press, November 2020.
[21] Craig Gentry. Fully homomorphic encryption using ideal lattices. In Michael Mitzenmacher, editor, 41st ACM STOC, pages 169–178. ACM Press, May / June 2009.
[22] Matthieu Giraud, Alexandre Anzala-Yamajako, Olivier Bernard, and Pascal Lafourcade. Practical passive leakage-abuse attacks against symmetric searchable en- cryption. Cryptology ePrint Archive, Report 2017/046, 2017. https://eprint.iacr.org/2017/046.
[23] Eu-Jin Goh. Secure indexes. Cryptology ePrint Archive, Report 2003/216, 2003. https://eprint.iacr.org/ 2003/216.
[24] Oded Goldreich. Towards a theory of software protec- tion and simulation by oblivious RAMs. In Alfred Aho, editor, 19th ACM STOC, pages 182–194. ACM Press, May 1987.
[25] Paul Grubbs, Marie-Sarah Lacharité, Brice Minaud, and Kenneth G. Paterson. Pump up the volume: Practical database reconstruction from volume leakage on range queries. In David Lie, Mohammad Mannan, Michael Backes, and XiaoFeng Wang, editors, ACM CCS 2018, pages 315–331. ACM Press, October 2018.
[26] Paul Grubbs, Kevin Sekniqi, Vincent Bindschaedler, Muhammad Naveed, and Thomas Ristenpart. Leakage- abuse attacks against order-revealing encryption. In 2017 IEEE Symposium on Security and Privacy, pages 655–672. IEEE Computer Society Press, May 2017.
[27] Zichen Gui, Kenneth G Paterson, and Tianxin Tang. Se- curity analysis of mongodb queryable encryption. In 32nd USENIX Security Symposium (USENIX Security 23), pages 7445–7462, 2023.
[28] Florian Hahn, Nicolas Loza, and Florian Kerschbaum. Joins over encrypted data with fine granular security. In 2019 IEEE 35th International Conference on Data Engineering (ICDE), pages 674–685. IEEE, 2019.
[29] Mohammad Saiful Islam, Mehmet Kuzu, and Murat Kantarcioglu. Access pattern disclosure on search- able encryption: Ramification, attack and mitigation. In NDSS 2012. The Internet Society, February 2012.
[30] Charanjit Jutla and Sikhar Patranabis. Efficient search- able symmetric encryption for join queries. In Advances in Cryptology–ASIACRYPT 2022: 28th International Conference on the Theory and Application of Cryptol- ogy and Information Security, Taipei, Taiwan, Decem- ber 5–9, 2022, Proceedings, Part III, pages 304–333. Springer, 2023.
[31] Seny Kamara, Abdelkarim Kati, Tarik Moataz, Thomas Schneider, Amos Treiber, and Michael Yonli. Sok: Cryptanalysis of encrypted search with leaker–a frame- work for leakage attack evaluation on real-world data. In 2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P), pages 90–108. IEEE, 2022.
[32] Seny Kamara and Tarik Moataz. SQL on structurally- encrypted databases. In Thomas Peyrin and Steven Galbraith, editors, ASIACRYPT 2018, Part I, volume 11272 of LNCS, pages 149–180. Springer, Heidelberg, December 2018.
[33] Seny Kamara and Tarik Moataz. Computationally volume-hiding structured encryption. In Yuval Ishai and Vincent Rijmen, editors, EUROCRYPT 2019, Part II, volume 11477 of LNCS, pages 183–213. Springer, Hei- delberg, May 2019.
[34] Georgios Kellaris, George Kollios, Kobbi Nissim, and Adam O’Neill. Generic attacks on secure outsourced databases. In Edgar R. Weippl, Stefan Katzenbeisser, Christopher Kruegel, Andrew C. Myers, and Shai Halevi, editors, ACM CCS 2016, pages 1329–1340. ACM Press, October 2016.
[35] Harold W Kuhn. The hungarian method for the as- signment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955.
[36] Marie-Sarah Lacharité and Kenneth G. Paterson. A note on the optimality of frequency analysis vs. ℓp- optimization. Cryptology ePrint Archive, Report 2015/1158, 2015. https://eprint.iacr.org/2015/ 1158.
[37] Muhammad Naveed, Seny Kamara, and Charles V. Wright. Inference attacks on property-preserving en- crypted databases. In Indrajit Ray, Ninghui Li, and Christopher Kruegel, editors, ACM CCS 2015, pages 644–655. ACM Press, October 2015.
[38] Jianting Ning, Xinyi Huang, Geong Sen Poh, Jiaming Yuan, Yingjiu Li, Jian Weng, and Robert H. Deng. LEAP: Leakage-abuse attack on efficiently deployable, efficiently searchable encryption with partially known dataset. In Giovanni Vigna and Elaine Shi, editors, ACM CCS 2021, pages 2307–2320. ACM Press, November 2021. 7426    33rd USENIX Security Symposium USENIX Association
[39] Simon Oya and Florian Kerschbaum. IHOP: Improved statistical query recovery against searchable symmetric encryption through quadratic optimization. In Kevin R. B. Butler and Kurt Thomas, editors, USENIX Security 2022, pages 2407–2424. USENIX Association, August 2022.
[40] Sarvar Patel, Giuseppe Persiano, Kevin Yeo, and Moti Yung. Mitigating leakage in secure cloud-hosted data structures: Volume-hiding for multi-maps via hash- ing. In Lorenzo Cavallaro, Johannes Kinder, XiaoFeng Wang, and Jonathan Katz, editors, ACM CCS 2019, pages 79–93. ACM Press, November 2019.
[41] Raluca Ada Popa, Catherine M. S. Redfield, Nickolai Zeldovich, and Hari Balakrishnan. Cryptdb: A practical encrypted relational dbms. In In Proceedings of the 23rd ACM Symposium on Operating Systems Principles (SOSP), Cascais, Portugal, October 2011. ACM.
[42] David Pouliot and Charles V. Wright. The shadow nemesis: Inference attacks on efficiently deployable, efficiently searchable encryption. In Edgar R. Weippl, Stefan Katzenbeisser, Christopher Kruegel, Andrew C. Myers, and Shai Halevi, editors, ACM CCS 2016, pages 1341–1352. ACM Press, October 2016.
[43] Dawn Xiaodong Song, David Wagner, and Adrian Perrig. Practical techniques for searches on encrypted data. In 2000 IEEE Symposium on Security and Privacy, pages 44–55. IEEE Computer Society Press, May 2000.
[44] Cédric Van Rompay, Refik Molva, and Melek Önen. A leakage-abuse attack against multi-user searchable en- cryption. Cryptology ePrint Archive, Report 2017/400, 2017. https://eprint.iacr.org/2017/400.
[45] Lei Xu, Huayi Duan, Anxin Zhou, Xingliang Yuan, and Cong Wang. Interpreting and mitigating leakage-abuse attacks in searchable symmetric encryption. IEEE Trans- actions on Information Forensics and Security, 16:5310– 5325, 2021.
[46] Lei Xu, Leqian Zheng, Chengzhi Xu, Xingliang Yuan, and Cong Wang. Leakage-abuse attacks against forward and backward private searchable symmetric encryption. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security, pages 3003– 3017, 2023.
[47] Xianglong Zhang, Wei Wang, Peng Xu, Laurence T. Yang, and Kaitai Liang. High recovery with fewer injections: Practical binary volumetric injection at- tacks against dynamic searchable encryption. In 32nd USENIX Security Symposium (USENIX Security 23), pages 5953–5970, Anaheim, CA, August 2023. USENIX Association. Alg Lp(⃗c,ρ) Parse (c1,...,cn,0) ←⃗c ; N ← n ∑ i=1 ci f ←$ argmin f n ∑ i=1 |ci −N ·ρ(f(i))|p Return f Figure 10: The ℓp-norm optimization leakage-abuse attack, originally presented in [37].
[48] Yupeng Zhang, Jonathan Katz, and Charalampos Pa- pamanthou. All your queries are belong to us: The power of file-injection attacks on searchable encryption. In Thorsten Holz and Stefan Savage, editors, USENIX Security 2016, pages 707–720. USENIX Association, August 2016.
[49] Zheguang Zhao, Seny Kamara, Tarik Moataz, and Stan Zdonik. Encrypted databases: From theory to systems. In CIDR, 2021. A Column Equality Theory This section contains theorems and proofs omitted from the main text for brevity. We recall an attack from prior work in Figure
5. Let ε > 0, V be an n element set, m < n be an integer,⃗c = (c1,...,cm,u) ∈Zm+1 (with u ≥1) and ρ ∈ Dist(V) with ρ(v) ≥ε for all v ∈V. Then, SelAttackε(⃗c,ρ) outputs a plaintext mapping g : [m] →V such that Pr[⃗c|f = g,ρ] ≥(max f Pr[⃗c|f = f,ρ])−O(u(n−m)ε), USENIX Association 33rd USENIX Security Symposium    7427 Alg POAAε(R,ρ1,ρ2,u1,u2) If u1 = 0 return (/0,R) If u2 = 0 return (R, /0) {v1,...,vr} ←R T1 ←∑i∈[r] ρ1(vi) ; T2 ←∑i∈[r] ρ2(vi) Define rndε(x,y) = (εT1 ·⌈x εT1 ⌋,εT2 ·⌈y εT2 ⌋) T[rndε(ρ1(v1),0)] ←({v1},1) T[rndε(0,ρ2(v1))] ←(/0,1) For i = 2,...,r: For (x,y) ∈T.keys() (S,c) ←T[(x,y)] If c = i−1 then T[rndε(x+ρ1(vi),y)] = (S∪{vi},i) T[rndε(x,y+ρ2(vi))] = (S,i) m ←0 ; S′ ←/0 For (x,y) ∈T.keys() (S,c) ←T[(x,y)] p ←(∑v∈S ρ1(v))u1(∑v∈R\S ρ2(v))u2 If c = r and p > m then m ←p ; S′ ←S Return (S′,R\S′) Figure 11: Pseudocode for POAAε. when ε > 0. We defer the proof of Theorem 5 to the full version. B Partition Optimization In this section, we discuss our new Partitioning Optimization Approximation Algorithm (POAA). As written, POAAε uses time an space O(|R|/ε2) in a word-RAM model. The same functionality can be performed using only O(|R|/ε) time and space. The idea is that we do not need to keep track of both dimensions of the sums. Instead, we can just keep track of the largest y available at that point for a given x sum, which is the version used in our experiments. We further observe that the algorithm could be further opti- mized to use only O(|R|+ 1 ε) space at the cost of some time by only tracking the possible sums and recursively recon- structing the sets after the best sum is found. We leave this code out of the paper for brevity and because we didn’t need the space improvement in our experiments. C Hardness of Optimal Inference In this section, we use the optimality definition from Sec- tion 5 which requires an attack to return a triple (f,U1,U2) which maximizes Pr[⃗c1,⃗c2|f = f,U1 = U1,U2 = U2,ρ1,ρ2]. For concreteness in the proof, we explicitly state the constant implied in Section 5, K⃗c1,⃗c2 =  N1 c1,...,cm,u1  N2 d1,...,dm,u2  , Crime Taxi Rideshare Crashes 2018 268,820 20,732,089 14,735,872 118,950 2019 261,297 16,477,366 22,783,672 117,763 2020 212,185 3,889,033 53,561 92,092 2021 208,775 3,948,046 11,150 108,764 2022 238,758 6,382,426 21,467,407 108,398 Figure 12: The number of rows for each table by year. the product of two multinomial coefficients, with N1 = u1 + ∑i ci and N2 = u2 +∑i di. We go on to define the DICI problem below, which is strictly easier than finding the maximizing triple (f,U1,U2). Name: Decision Incomplete Cross Inference (DICI) Given: Two integers with m < n, a number t ∈[0,1],⃗c1 ∈ [n]m+1 and ⃗c2 ∈[n]m+1 and distributions ρ1 and ρ2 over [n] and. 7 Question: Does there exist a triple (f,U1,U2) such that Pr[⃗c1,⃗c2|f = f,U1 = U1,U2 = U2,ρ1,ρ2] ≥t? Theorem
6. Decision Incomplete Cross Inference (DICI) is NP-hard. We defer the proof of Theorem 6 to the full version. D Experimental Data and Results In our experiments, we use data made public by the city of Chicago.8 In particular, we using datasets of crimes,9 taxi rides,10 rideshare services,11 and car crashes12 for years be- tween 2019 and 2022. Information about the number of rows can be found in Figure
12. The lack of data for the 2020 and 2021 years likely negatively impacted our experiments, but we were still able to attack these anomalous years. 7Formally, this problem only takes in t and distributions which can be described using poly(n) bits, rather than all real numbers. 8https://data.cityofchicago.org/ 9https://data.cityofchicago.org/Public-Safety/ Crimes-2001-to-Present/ijzp-q8t2 10https://data.cityofchicago.org/Transportation/ Taxi-Trips/wrvz-psew 11https://data.cityofchicago.org/Transportation/ Transportation-Network-Providers-Trips-2018-2022-/ m6dm-c72p 12https://data.cityofchicago.org/Transportation/ Traffic-Crashes-Crashes/85ca-t3if 7428    33rd USENIX Security Symposium USENIX Association
Formal verification of the PQXDH Post-Quantum key agreement protocol for end-to-end secure messaging.
[1] Classic mceliece. conservative code-based cryptogra- phy: design rationale. online, 2022. https://classi c.mceliece.org/mceliece-rationale-20221023. pdf.
[2] Module-lattice-based key-encapsulation mechanism standard. Technical report, Gaithersburg, MD, 2023.
[3] Joël Alwen, Sandro Coretti, and Yevgeniy Dodis. The double ratchet: security notions, proofs, and modular- ization for the signal protocol. In Annual International Conference on the Theory and Applications of Crypto- graphic Techniques, pages 129–158. Springer, 2019.
[4] David Baelde, Stéphanie Delaune, Adrien Koutsos, Charlie Jacomme, and Solène Moreau. An interactive prover for protocol verification in the computational model. In 42nd IEEE Symposium on Security and Pri- vacy (S&P’21),, pages 537–554, Los Alamitos, CA, May 2021. IEEE Computer Society Press.
[5] Manuel Barbosa, Gilles Barthe, Xiong Fan, Benjamin Grégoire, Shih-Han Hung, Jonathan Katz, Pierre-Yves Strub, Xiaodi Wu, and Li Zhou. Easypqc: Verifying post- quantum cryptography. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2564–2586, 2021.
[6] Manuel Barbosa, Deirdre Connolly, João Diogo Duarte, Aaron Kaiser, Peter Schwabe, Karoline Varner, and Bas Westerbaan. X-wing: The hybrid kem you’ve been looking for. Cryptology ePrint Archive, February 2024. https://eprint.iacr.org/archive/2024/039/1 707692113.pdf.
[7] Gilles Barthe, Benjamin Grégoire, Sylvain Heraud, and Santiago Zanella Béguelin. Computer-aided security proofs for the working cryptographer. In Phillip Rog- away, editor, Advances in Cryptology – CRYPTO 2011, volume 6841 of Lecture Notes in Computer Science, pages 71–90, Berlin, Heidelberg, August 2011. Springer. 482    33rd USENIX Security Symposium USENIX Association
[8] David Basin, Jannik Dreier, Lucca Hirschi, Saša Radomirovic, Ralf Sasse, and Vincent Stettler. A for- mal analysis of 5g authentication. In Proceedings of the 2018 ACM SIGSAC conference on computer and communications security, pages 1383–1396, 2018.
[9] David Basin, Ralf Sasse, and Jorge Toro-Pozo. The emv standard: Break, fix, verify. In 2021 IEEE Symposium on Security and Privacy (SP), pages 1766–1781. IEEE, 2021.
[10] Karthikeyan Bhargavan, Abhishek Bichhawat, Quoc Huy Do, Pedram Hosseyni, Ralf Küsters, Guido Schmitz, and Tim Würtele. Dy*: A modular symbolic verification framework for executable cryptographic protocol code. In 2021 IEEE European Symposium on Security and Privacy (EuroS&P), pages 523–542. IEEE, 2021.
[11] Karthikeyan Bhargavan, Bruno Blanchet, and Nadim Kobeissi. Verified models and reference implemen- tations for the TLS 1.3 standard candidate. In IEEE Symposium on Security and Privacy (S&P’17), pages 483–503, Los Alamitos, CA, May 2017. IEEE Computer Society Press.
[12] Karthikeyan Bhargavan, Charlie Jacomme, Franziskus Kiefer, and Rolfe Schmidt. Cryptoverif and proverif models, 2024. https://github.com/Inria-Prose cco/pqxdh-analysis/tree/2e676a009471f370d bbfad3ac7ab5d7d9518ab57.
[13] Alexander Bienstock, Jaiden Fairoze, Sanjam Garg, Pratyay Mukherjee, and Srinivasan Raghuraman. A more complete analysis of the signal double ratchet algo- rithm. In Annual International Cryptology Conference, pages 784–813. Springer, 2022.
[14] Bruno Blanchet. Modeling and verifying security pro- tocols with the applied pi calculus and proverif. Foun- dations and Trends® in Privacy and Security, 1(1-2):1– 135, 2016.
[15] Bruno Blanchet and Charlie Jacomme. Post-quantum sound CryptoVerif and verification of hybrid TLS and SSH key-exchanges. In Proceedings of the 37th IEEE Computer Security Foundations Symposium (CSF’24). IEEE Computer Society Press, 2024.
[16] Joppe Bos, Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyubashevsky, John M Schanck, Peter Schwabe, Gregor Seiler, and Damien Stehlé. Crystals-kyber: a cca-secure module-lattice-based kem. In 2018 IEEE Eu- ropean Symposium on Security and Privacy (EuroS&P), pages 353–367. IEEE, 2018.
[17] Joppe W. Bos, Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyubashevsky, John M. Schanck, Peter Schwabe, Gregor Seiler, and Damien Stehlé. CRYSTALS - Ky- ber: A CCA-Secure Module-Lattice-Based KEM. In EuroS&P, pages 353–367. IEEE, 2018.
[18] Jacqueline Brendel, Cas Cremers, Dennis Jackson, and Mang Zhao. The provable security of ed25519: theory and practice. In 2021 IEEE Symposium on Security and Privacy (SP), pages 1659–1676. IEEE, 2021.
[19] Jacqueline Brendel, Rune Fiedler, Felix Günther, Chris- tian Janson, and Douglas Stebila. Post-quantum asyn- chronous deniable key exchange and the signal hand- shake. In Goichiro Hanaoka, Junji Shikata, and Yohei Watanabe, editors, Public-Key Cryptography - PKC 2022 - 25th IACR International Conference on Prac- tice and Theory of Public-Key Cryptography, Virtual Event, March 8-11, 2022, Proceedings, Part II, volume 13178 of Lecture Notes in Computer Science, pages 3–
34. Springer, 2022.
[20] Jacqueline Brendel, Marc Fischlin, Felix Günther, Chris- tian Janson, and Douglas Stebila. Towards post-quantum security for signal’s X3DH handshake. In Orr Dunkel- man, Michael J. Jacobson Jr., and Colin O’Flynn, editors, Selected Areas in Cryptography - SAC 2020 - 27th In- ternational Conference, Halifax, NS, Canada (Virtual Event), October 21-23, 2020, Revised Selected Papers, volume 12804 of Lecture Notes in Computer Science, pages 404–430. Springer, 2020.
[21] Katriel Cohn-Gordon, Cas Cremers, Benjamin Dowling, Luke Garratt, and Douglas Stebila. A formal security analysis of the signal messaging protocol. Journal of Cryptology, 33:1914–1983, 2020.
[22] Cas Cremers, Alexander Dax, and Niklas Medinger. Keeping up with the kems: Stronger security notions for kems. Cryptology ePrint Archive, 2023.
[23] Cas Cremers, Caroline Fontaine, and Charlie Jacomme. A logic and an interactive prover for the computational post-quantum security of protocols. In 2022 IEEE Sym- posium on Security and Privacy (SP), pages 125–141. IEEE, 2022.
[24] Cas Cremers, Charlie Jacomme, and Aurora Naska. For- mal analysis of session-handling in secure messaging: Lifting security from sessions to conversations. In Usenix Security, 2023.
[25] Keitaro Hashimoto, Shuichi Katsumata, Kris Kwiatkowski, and Thomas Prest. An efficient and generic construction for signal’s handshake (X3DH): post-quantum, state leakage secure, and deniable. J. Cryptol., 35(3):17, 2022. USENIX Association 33rd USENIX Security Symposium    483
[26] Charlie Jacomme, Elise Klein, Steve Kremer, and Maïwenn Racouchot. A comprehensive, formal and automated analysis of the edhoc protocol. In USENIX Security’23-32nd USENIX Security Symposium, 2023.
[27] Nadim Kobeissi, Karthikeyan Bhargavan, and Bruno Blanchet. Automated verification for secure messag- ing protocols and their implementations: A symbolic and computational approach. In 2017 IEEE European symposium on security and privacy (EuroS&P), pages 435–450. IEEE, 2017.
[28] Ehren Kret and Rolfe Schmidt. The pqxdh key agree- ment protocol - diff between rev 1 and 2, September 2023. https://github.com/Inria-Prosecco/pq xdh-analysis/blob/main/revision2/pqxdh-dif f-rev-1-to-2.pdf.
[29] Ehren Kret and Rolfe Schmidt. The pqxdh key agree- ment protocol - revision 1, September 2023. Archive: https://github.com/Inria-Prosecco/pqxdh-a nalysis/blob/main/revision1/pqxdh-rev1.pdf.
[30] Ehren Kret and Rolfe Schmidt. The pqxdh key agree- ment protocol - revision 2, September 2023. Archive: https://github.com/Inria-Prosecco/pqxdh-a nalysis/blob/main/revision2/pqxdh-rev2.pdf.
[31] A. Langley, M. Hamburg, and S. Turner. Elliptic curves for security. RFC 7748, RFC Editor, January 2016.
[32] Moxie Marlinspike and Trevor Perrin. The X3DH Key Agreement Protocol, 2016.
[33] Trevor Perrin and Moxie Marlinspike. The Double Ratchet Algorithm, 2016.
[34] Andreea-Ina Radu, Tom Chothia, Christopher JP New- ton, Ioana Boureanu, and Liqun Chen. Practical emv relay protection. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1737–1756. IEEE, 2022.
[35] Phillip Rogaway. Authenticated-encryption with associated-data. In Proceedings of the 9th ACM Confer- ence on Computer and Communications Security, pages 98–107, 2002.
[36] P.W. Shor. Algorithms for quantum computation: dis- crete logarithms and factoring. In Proceedings 35th Annual Symposium on Foundations of Computer Sci- ence, pages 124–134, 1994.
[37] Erik Thormarker. On using the same key pair for ed25519 and an x25519 based kem. Cryptology ePrint Archive, 2021.
[38] Dominique Unruh. Quantum relational hoare logic. Proceedings of the ACM on Programming Languages, 3(POPL):1–31, 2019.
[39] Keita Xagawa. Anonymity of nist pqc round 3 kems. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, pages 551– 581, 2022. A Formal Symbolic security Theorems We proved in PROVERIF a set of three queries, modeling:
3. the exhaustive case disjunction under which there is authentication. In PROVERIF, the final correct and complete query we were able to prove for the secrecy of the responder key is: query A,B:client, spk:point, pqpk:kempub, sk:symkey, i,j:time; event(AlexOK(A,B,spk,pqpk,ts))@i =⇒not(attacker(sk)) | (CompromisedIK(B)@j & (j<i | (event(CompromiseSPK(B,spk)) & (event(CompromisePQPK(B,pqpk)) | event(BrokenKEM)) ) ) ) | (event(BrokenDH())@j & (j < i | event(CompromisePQPK(B,pqpk)) | event(BrokenKEM) ) ) This can be translated as a security theorem detailing the possible cases. Theorem 7 (Symbolic Responder Secrecy). The key SKA computed by the responder Alex is secret, unless:
4. DH was broken only after the key exchange, and either KEMs are fully broken or the PQSPKB (similar to case 2) . All those cases appear normal, and it is in all the possible compromise cases that still maintain security that we find the classical security notions to be implied. 484    33rd USENIX Security Symposium USENIX Association Remark that using an OPK does not change anything on the responder side, as they are not authenticated. But of course, compromising the OPK makes it so that the honest responder will never receive and answer the message. We can also prove some form of authentication and data agreement: Theorem 8 (Symbolic authentication). Whenever an initiator Blake accepts (resp. with or without an OPK), then, there ex- ists a responder Alex that also accepted (resp. with or without the same OPK) with the same SPKB and PQSPKB, unless:
7. DH was broken after the exchange, and KEMs are broken (similar to 5) In contrast, the OPK now plays a role and increases the security, and also need to be compromised in many cases. Summing up the three theorems, we do have the higher level security properties mentioned in Theorem 1:
2. forward secrecy: implied by Theorems 7 and 9, where we can see that compromising the identity key of any party after the completion of a key exchange is not one of the insecure case, and is thus not enough to break the security.
4. session independence: implied by Theorems 7 and 9, where we can see that one must compromise precisely ephemerals secrets of the target session to break it, and thus that leaking the ephemeral keys of other sessions does not impact security.
5. resistance to “harvest now decrypt later”: all three theo- rems give us that just breaking DH after completion is not enough, and that additional compromises are always needed. B Full protocol description USENIX Association 33rd USENIX Security Symposium    485 Long term keys: IKsk B ,IKpk A BLAKE SERVER Long term keys: IKpk B ,IKsk A ALEX Medium term keys: SPKsk B ,SPKpk B $←−DH.Keygen PQSPKsk B ,PQSPKpk B $←−KEM.Keygen Short term keys: OPKsk B ,OPKpk B $←−DH.Keygen PQSPK′sk B ,PQSPK′pk B $←−KEM.Keygen OPKpk B ,SPKpk B ,sign(encodeEC(SPKpk B ),IKsk B ) PQSPKpk B ,sign(encodeKEM(PQSPKpk B ),IKsk B ) PQSPK′pk B ,sign(encodeKEM(PQSPK′pk B ),IKsk B ) PQSPK′pk B ,sign(encodeKEM(PQSPK′pk B ),IKsk B ) (?OPKpk B ),SPKpk B ,sigEC, PQSPKpk B ,sigKEM Verify signatures EKsk A ,EKpk A $←−DH.Keygen CT,SS $←−KEM.encaps(PQSPKpk B ) DH1−3 = (SPKpk B )IKsk A ∥(IKpk B )EKsk A ∥(SPKpk B )EKsk A SKB = kdf(DH1−3(?∥(OPKpk B )EKsk A )∥SS) AD = IKpk A ∥IKpk B EKpk A ,id(SPKB),(?id(OPKB)), id(PQSPKB),CT,enc(”hello”,0,AD,SKB) Fetch secret keys from ids SS = KEM.decaps(CT,PQSPKsk B ) DH1−3 = (IKpk A )SPKsk B ∥(EKpk A )IKsk B ∥(EKpk A )SPKsk B SKA = kdf(DH1−3(?∥(EKpk A )OPKsk B )∥SS) Check if AD = IKpk A ∥IKpk B Decrypt and check aead Delete used short term keys Figure 4: The PQXDH protocol, revision 1. It is exactly the X3DH protocol, with additional KEM computations, highlighted with a light gray background. Question marks denote optional elements. 486    33rd USENIX Security Symposium USENIX Association
Notus: Dynamic Proofs of Liabilities from Zero-knowledge RSA Accumulators.
[1] “Bankruptcy of ftx,” https://en.wikipedia.org/wiki/Bankruptcy_of_FT X/, accessed: 2023-04-19.
[2] N. Bari´c and B. Pfitzmann, “Collision-free accumulators and fail-stop signature schemes without trees,” in International conference on the theory and applications of cryptographic techniques, 1997.
[3] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev, “Scalable, trans- parent, and post-quantum secure computational integrity,” Cryptology ePrint Archive, 2018.
[4] J. Benaloh and M. De Mare, “One-way accumulators: A decentralized alternative to digital signatures,” in EUROCRYPT, 1993.
[5] “Binance exchange,” https://www.binance.com/.
[6] “Binance proof-of-reserves,” https://www.binance.com/en/proof-of-r eserves/.
[7] “Binance proof-of-reserves code,” https://github.com/binance/zkmerkl e-proof-of-solvency/.
[8] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer, “From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again,” in Innovations in Theoretical Computer Science, 2012.
[9] D. Boneh, B. Bünz, and B. Fisch, “Batching techniques for accumula- tors with applications to iops and stateless blockchains,” in CRYPTO, 2019.
[10] D. Boneh and M. Franklin, “Efficient generation of shared rsa keys,” in CRYPTO, 1997.
[11] G. Botrel, T. Piellard, Y. E. Housni, I. Kubjas, and A. Tabaie, “Consensys/gnark: v0.8.0,” Feb. 2023. [Online]. Available: https: //doi.org/10.5281/zenodo.5819104
[12] J. Buchmann and H. C. Williams, “A key-exchange system based on imaginary quadratic fields,” Journal of Cryptology, 1988.
[13] B. Bünz, J. Bootle, D. Boneh, A. Poelstra, P. Wuille, and G. Maxwell, “Bulletproofs: Short proofs for confidential transactions and more,” in IEEE symposium on security and privacy (SP), 2018.
[14] J. Burkhardt, I. Damgård, T. Frederiksen, S. Ghosh, and C. Orlandi, “Improved distributed rsa key generation using the miller-rabin test,” in Proceedings of the ACM CCS, 2023.
[15] V. Buterin, “Having a safe cex: proof of solvency and beyond,” https: //vitalik.ca/general/2022/11/19/proof_of_solvency.html, accessed: 2023-05-10.
[16] M. Campanelli, D. Fiore, S. Han, J. Kim, D. Kolonelos, and H. Oh, “Succinct zero-knowledge batch proofs for set accumulators,” in Pro- ceedings of the ACM CCS, 2022.
[17] M. Campanelli, D. Fiore, and A. Querol, “Legosnark: Modular design and composition of succinct zero-knowledge proofs,” in Proceedings of the ACM CCS, 2019.
[18] M. Campanelli, M. Hall-Andersen, and S. H. Kamp, “Curve trees: Prac- tical and transparent {Zero-Knowledge} accumulators,” in USENIX Security Symposium, 2023.
[19] D. Catalano and D. Fiore, “Vector commitments and their applications,” in PKC, 2013.
[20] D. Catalano, D. Fiore, and M. Messina, “Zero-knowledge sets with short proofs,” in EUROCRYPT, 2008.
[21] E. Cecchetti, F. Zhang, Y. Ji, A. E. Kosba, A. Juels, and E. Shi, “Solidus: Confidential distributed ledger transactions via PVORM,” in Proceed- ings of the ACM CCS, 2017.
[22] K. Chalkias, P. Chatzigiannis, and Y. Ji, “Broken proofs of solvency in blockchain custodial wallets and exchanges,” IACR Cryptol. ePrint Arch., p. 43, 2022.
[23] K. Chalkias, K. Lewi, P. Mohassel, and V. Nikolaenko, “Practical pri- vacy preserving proofs of solvency,” Amsterdam ZKProof Community Event, 2019.
[24] ——, “Distributed auditing proofs of liabilities,” Cryptology ePrint Archive, 2020. 1466    33rd USENIX Security Symposium USENIX Association
[25] M. Chase, A. Deshpande, E. Ghosh, and H. Malvai, “Seemless: Secure end-to-end encrypted messaging with less trust,” in Proceedings of the ACM CCS, 2019.
[26] M. Chase, A. Healy, A. Lysyanskaya, T. Malkin, and L. Reyzin, “Mer- curial commitments with applications to zero-knowledge sets.” in EU- ROCRYPT, 2005.
[27] P. Chatzigiannis, F. Baldimtsi, and K. Chalkias, “Sok: auditability and accountability in distributed payment systems,” in ACNS, 2021.
[28] “Coinbase exchange,” https://www.coinbase.com/.
[29] G. Couteau, T. Peters, and D. Pointcheval, “Removing the strong RSA assumption from arguments over the integers,” in EUROCRYPT, 2017.
[30] G. G. Dagher, B. Bünz, J. Bonneau, J. Clark, and D. Boneh, “Provi- sions: Privacy-preserving proofs of solvency for bitcoin exchanges,” in Proceedings of the ACM CCS, 2015.
[31] I. Damgård and E. Fujisaki, “A statistically-hiding integer commitment scheme based on groups with hidden order,” in ASIACRYPT, 2002.
[32] F. Falzon, K. Elkhiyaoui, Y. Manevich, and A. D. Caro, “Short privacy- preserving proofs of liabilities,” in Proceedings of the ACM CCS, 2023.
[33] R. Gennaro, S. Halevi, and T. Rabin, “Secure hash-and-sign signatures without the random oracle,” in EUROCRYPT, 1999.
[34] E. Ghosh, O. Ohrimenko, D. Papadopoulos, R. Tamassia, and N. Trian- dopoulos, “Zero-knowledge accumulators and set algebra,” in ASI- ACRYPT 2016, 2016.
[35] O. Goldreich and R. Ostrovsky, “Software protection and simulation on oblivious rams,” Journal of the ACM (JACM), vol. 43, no. 3, , 1996.
[36] S. Gorbunov, L. Reyzin, H. Wee, and Z. Zhang, “Pointproofs: Aggre- gating proofs for multiple vector commitments,” in Proceedings of the ACM CCS, 2020.
[37] L. Grassi, D. Khovratovich, C. Rechberger, A. Roy, and M. Schofnegger, “Poseidon: A new hash function for zero-knowledge proof systems,” in USENIX Security Symposium, 2021.
[38] J. Groth, “On the size of pairing-based non-interactive arguments,” in EUROCRYPT, 2016.
[39] K. Hu, Z. Zhang, and K. Guo, “Breaking the binding: Attacks on the merkle approach to prove liabilities and its applications,” Computers & Security, 2019.
[40] Y. Hu, K. Hooshmand, H. Kalidhindi, S. J. Yang, and R. A. Popa, “Merkle2: A low-latency transparency log system,” in 2021 IEEE Sym- posium on Security and Privacy (SP). IEEE, 2021.
[41] Y. Ji and K. Chalkias, “Generalized proof of liabilities,” in Proceedings of the ACM CCS, 2021.
[42] A. Kate, G. M. Zaverucha, and I. Goldberg, “Constant-size commit- ments to polynomials and their applications,” in ASIACRYPT, 2010.
[43] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Ham- burg, M. Lipp, S. Mangard, T. Prescher et al., “Spectre attacks: Exploit- ing speculative execution,” Communications of the ACM, 2020.
[44] B. Laurie, A. Langley, and E. Kasper, “Rfc 6962: Certificate trans- parency,” 2013.
[45] J. Li, N. Li, and R. Xue, “Universal accumulators with efficient non- membership proofs,” in ACNS, 2007.
[46] H. Lipmaa, “On diophantine complexity and statistical zero-knowledge arguments,” in ASIACRYPT, 2003.
[47] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg, “Meltdown,” arXiv preprint arXiv:1801.01207, 2018.
[48] A. Luthra, J. Cavanaugh, H. R. Olcese, R. M. Hirsch, and X. Fu, “Ze- roaudit,” in Annual Computer Security Applications Conference, 2020,
[49] C. McIvor, M. McLoone, and J. V. McCanny, “Modified mont- gomery modular multiplication and rsa exponentiation techniques,” IEE Proceedings-Computers and Digital Techniques, vol. 151, no. 6, , 2004.
[50] R. McMillan, “The inside story of mt. gox, bitcoin’s $460 million disaster,” https://www.wired.com/2014/03/bitcoin-exchange/, accessed: 2023-01-02.
[51] M. S. Melara, A. Blankstein, J. Bonneau, E. W. Felten, and M. J. Freed- man, “Coniks: Bringing key transparency to end users,” in USENIX Security Symposium, 2015.
[53] A. Ozdemir, R. Wahby, B. Whitehat, and D. Boneh, “Scaling verifiable computation using efficient set accumulators,” in USENIX Security Symposium, 2020.
[54] T. P. Pedersen, “Non-interactive and information-theoretic secure veri- fiable secret sharing,” in CRYPTO, 1992.
[55] Y. Peng, M. Du, F. Li, R. Cheng, and D. Song, “Falcondb: Blockchain- based collaborative database,” in Proceedings of the 2020 ACM SIG- MOD international conference on management of data, 2020.
[56] D. Reijsbergen, A. Maw, Z. Yang, T. T. A. Dinh, and J. Zhou, “TAP: transparent and privacy-preserving data services,” in USENIX Security Symposium, 2023.
[57] A. M. Rozario and M. A. Vasarhelyi, “Auditing with smart contracts.” International Journal of Digital Accounting Research, vol. 18, 2018.
[58] S. Srinivasan, I. Karantaidou, F. Baldimtsi, and C. Papamanthou, “Batching, aggregation, and zero-knowledge proofs in bilinear accumu- lators,” in Proceedings of the 2022 ACM CCS, 2022.
[59] A. Tomescu, V. Bhupatiraju, D. Papadopoulos, C. Papamanthou, N. Triandopoulos, and S. Devadas, “Transparency logs via append-only authenticated dictionaries,” in Proceedings of the ACM CCS, 2019.
[60] I. A. Tomescu Nicolescu, “How to keep a secret and share a public key (using polynomial commitments),” Ph.D. dissertation, Massachusetts Institute of Technology, 2020.
[61] N. Tyagi, B. Fisch, A. Zitek, J. Bonneau, and S. Tessaro, “VeRSA: Verifiable registries with efficient client audits from rsa authenticated dictionaries,” in Proceedings of the ACM CCS, 2022.
[62] B. Wesolowski, “Efficient verifiable delay functions,” in EUROCRYPT, 2019.
[63] E. G. Weyl, P. Ohlhaver, and V. Buterin, “Decentralized society: Finding web3’s soul,” Available at SSRN 4105763, 2022.
[64] H. Wu, W. Zheng, A. Chiesa, R. A. Popa, and I. Stoica, “DIZK: A distributed zero knowledge proof system,” in USENIX Security Sympo- sium, 2018.
[65] J. Xin, A. Haghighi, X. Tian, and D. Papadopoulos, “Notus: Dynamic proofs of liabilities from zero-knowledge RSA accumulators,” Cryptology ePrint Archive, Paper 2024/395, 2024. [Online]. Available: https://eprint.iacr.org/2024/395
[66] C. Yue, T. T. A. Dinh, Z. Xie, M. Zhang, G. Chen, B. C. Ooi, and X. Xiao, “Glassdb: An efficient verifiable ledger database system through transparency,” Proceedings of the VLDB Endowment, 2023.
[67] A. Zapico, V. Buterin, D. Khovratovich, M. Maller, A. Nitulescu, and M. Simkin, “Caulk: Lookup arguments in sublinear time,” in Proceed- ings of the ACM CCS, 2022.
[68] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou, “vSQL: Verifying Arbitrary SQL Queries over Dynamic Outsourced Databases,” in IEEE Symposium on Security and Privacy, SP, 2017.
[69] Y. Zhang, J. Katz, and C. Papamanthou, “An expressive (zero- knowledge) set accumulator,” in 2017 IEEE European Symposium on Security and Privacy, EuroS&P, 2017. USENIX Association 33rd USENIX Security Symposium    1467 A Extended Preliminaries A.1 Range proof Range proofs are zero-knowledge proofs where the prover convinces the verifier that the committed values are in specific ranges. For hidden order group-based commitments, range proofs are usually [29,46] composed by zero-knowledge ar- gument of positivity (ZKAoP): in order to prove x ∈[a,b], the prover proves x−a > 0 and b−x >
1. Given security parameter λ, a universal ac- cumulator is a tuple of four PPT algorithms (KeyGen, Acc, Witness, Verify): • (ek,vk) ←KeyGen(1λ). This algorithm takes as input the security parameter and outputs a public evaluation key ek that will be used to generate witnesses and a pub- lic verification key vk that will be used to verify witness. • C ←Acc(ek,X). This algorithm takes as input a set X ⊂Xλ where Xλ is the input domain for the elements to be accumulated and the evaluation key ek and outputs one accumulation of the set C ∈Gλ where Gλ is the output domain for Acc. • (b,wx) ←Witness(X,x,C,ek). This algorithm takes as input a set X ⊂Xλ, one element x ∈Xλ, the evaluation key ek and the accumulation of the set C. It outputs a boolean value b indicating whether the element is in the set and a witness wx for the answer. b = 1 indicates the element is in the set and this witness is a membership witness. Otherwise, b = 0 and this witness is a non- membership witness. • 0/1 ←Verify(C,x,wx,b,vk). This algorithm takes as input the accumulation valueC ∈Gλ, one element x ∈Xλ, the witness wx, a bit b and the public verification key vk. It outputs 1 if it accepts the proof and 0 otherwise. A.3 Division Intractable Hash Division Intractable (DI) hash is a special kind of hash function where it is hard to find any set of distinct preimages such that one hash result divides the product of the remaining hash results. It can be formally defined as follows. Definition
2. Division intractable. A function family H is called division intractable (DI) if given security parameter λ, finding H ∈H and distinct inputs X1,...,Xm,Y, m < poly(λ) such that Pr[H(Y)|H(X1)...H(Xm)] < negl(λ). Clearly, all Hash-to-prime hash functions are DI. However, most Hash-to-prime functions are time-consuming. Accord- ing to Lemma 6 in [33], a random oracle with λ2-bit output is also DI. Informally, random numbers with large bit-length tend to have large prime factors. A large prime factor makes the random number hard to divide from other random num- bers with different large prime factors. In particular, Ozdemir et al.
[53] conjectured that the den- sity of integers in [1,α] with small factors also holds for a large interval around α, more specifically, [α,α+α1/8]. Based on this conjecture, we can construct a DI-hash more efficiently in computation. Let ∆be a large integer with λ2-bit, and H(x) be a collision resistant and preimage-hard hash function with α1/8 bits output. H∆(x) = ∆+H(x), H∆(x) is also DI. B Correctness and Security Definitions of DPoL Definition 3 (DPoL Completeness). ∀ordered sequences of appends Si, for all users u ∈U and 1 ≤i ≤m epochs, Pr   (ek,vk) ←Setup(1λ), di ←Digest(ek,Li,auxi)+, ∀u ∈U,πmem ←LookupProof(ek,Li,u,auxi), πsum ←ProveSum(ek,Li,auxi), ∀i ∈[1,m],πi ←ProveConsistent(ek,Li,auxi) : ∀u ∈U,VerLookup(vk,di,H1,i u ,πmem) = 1, VerSum(vk,di,sum,πsum) = 1, ∀i ∈[1,m],VerConsistent(vk,i,di−1,di,πi) = 1   ≥1−negl(λ) Definition 4 (DPoL Undeniability). ∀adversaries A running in time poly(λ), for any user u ∈U and any epoch i ∈[1,m], Pr   (ek,vk) ←Setup(1λ), (di,sum,sum′,πsum,π′ sum,Li,L′ i, auxi,aux′ i) ←A(1λ,ek,vk) : (sum ̸= sum′ ∧VerSum(vk,di,sum,πsum) = 1 ∧VerSum(vk,di,sum′,π′ sum) = 1) ∨ (Li ̸= L′ i ∧di ←Digest(ek,Li,auxi)∧ di ←Digest(ek,L′ i,aux′ i))   ≤negl(λ) 1468    33rd USENIX Security Symposium USENIX Association Definition 5 (DPoL Update Soundness). ∀adversaries A running in time poly(λ), Pr   (ek,vk) ←Setup(1λ), (Li−1,Li,di−1,di,πi,auxi,auxi−1,sumi−1, sumi,πi−1 sum,πi sum) ←A(1λ,ek,vk) : di ←Digest(ek,Li,auxi), di−1 ←Digest(ek,Li−1,auxi−1), Li−1 ⊂Li, Si = Li \Li−1, VerConsistency(vk,i,di−1,di,πi) = 1, VerSum(vk,di−1,sumi−1,πi−1 sum) = 1, VerSum(vk,di,sumi,πi sum) = 1, (∃tx ∈Si : tx.upd ̸= i∨tx.lia < 0)∨ sumi −sumi−1 ̸= ∑ u∈Si (Hi u.lia−Hi−1 u .lia)   ≤negl(λ) Definition 6 (DPoL Sum Soundness). ∀adversaries A run- ning in time poly(λ), Pr   (ek,vk) ←Setup(1λ), (di,sumi,πi sum,H1,i u0 ,...,H1,i uj , πmem0,...,πmemj) ←A(1λ,ek,vk) : VerSum(vk,di,sumi,πi sum) = 1∧ ∀j,VerLookup(vk,di,H1,i u j ,πmemj) = 1∧ sumi < ∑ ∀u H1,i uj .lia∧∀H1,i u j .lia > 0   ≤negl(λ) Additional discussions for these definitions can be found in the extended version of our paper [65]. Definition 7 (DPoL Privacy). Let F1 be a function checking user u’s history for a given ledger Li, H1,i u ←F1(Li,u). Let F2 be a function checking the sum of liabilities for a given ledger Li, sum ←F2(Li). Let RealAdv(1λ), IdealAdv,Sim(1λ) be games between a challenger, an adversary A and a simu- lator Sim=(Sim1,Sim2), defined as follows: RealAdv(1λ): • Setup. The challenger runs (ek,vk) ←Setup(1λ) and for- wards (ek,vk) to A, A chooses S1 with |S1| ≤poly(λ) and sends to the challenger. The challenger runs d1 ← Digest(ek,L1 = S1,aux1) and sends d1 to A. • Query. For i = 1,...,ζ where ζ ≤poly(λ), the A outputs op = (lookup,u), op=sum or op = (update,Si+1). −If op = (lookup,u), the challenger runs πmem ← LookupProof(ek,Li,u,auxi) if user u has transaction his- tory in the ledger in epoch i and returns πmem to A. − If op = sum, the challenger runs πsum ← ProveSum(ek,Li,auxi), returns (sum,πsum) to A. − If op = (update,Si+1), the challenger runs Li+1 = Li SSi+1, di+1 ←Digest(ek,Li+1,auxi+1), πi+1 ← ProveConsistency(ek,Li+1,auxi+1) and returns (di+1,πi+1) to A. • Respond. A outputs a bit b = 0/1. IdealAdv,Sim(1λ): • Setup. The simulator Sim1 inputs (1λ) and forwards vk to A, A chooses S1 with |S1| ≤poly(λ). The simulator (without seeing S1) responds with d1 to A and maintains state StateS. • Query. For i = 1,...,ζ where ζ ≤poly(λ), A outputs op = (lookup,u), op=sum or op = (update,Si+1). −If op = (lookup,u), the simulator runs πmem ← Sim2(ek,StateS,F1(Li,u)) if F1(Li,u) outputs history H1,i u and returns πmem to A. −If op = sum, the simulator runs πsum ←Sim2(ek,StateS, F2(Li)) and returns (sum,πsum) to A. −If op = (update,Si+1), the simulator runs (di+1,πi+1) ← Sim2(ek,StateS,di) and returns (di+1,πi+1) to A. • Respond. A outputs a bit b = 0/1. A DPoL scheme is zero-knowledge if there exists a proba- bilistic polynomial time (PPT) simulator Sim=(Sim1,Sim2) such that for all Adv, |Pr[RealAdv(1λ) = 1]−Pr[IdealAdv,Sim(1λ) = 1]| ≤negl(λ). If the above probabilities are equivalent, the DPoL scheme is perfect zero-knowledge. If the inequality only holds for PPT Adv, the DPoL scheme is computational zero-knowledge. C Zero-knowledge RSA accumulator Let λ be the security parameter. We set Xλ = Z2λ2. Xλ is the input domain for the elements to be accumulated. Denote by X = {x1,...,xm} the set of m elements to be accumulated. HDI is a DI-hash family. We use QRN to denote the subgroup of Z∗ N of squares (quadratic residues modulo N). In order to let adaptive root assumption hold in Z∗ N, we usually eliminate elements with trivial roots, {1,−1}. We use G = QRN \{1,−1} to denote excluding the use of {1,−1} in challenges and proofs so that strong RSA assumption, adaptive root assumption hold in G. Denote K > max{maxord(G)2λ+2,2λ2} where maxord(G) is the upper bound for the group order and 2λ2 is the lower bound to make random numbers DI as discussed in
GoFetch: Breaking Constant-Time Cryptographic Implementations Using Data Memory-Dependent Prefetchers.
3. Breaking Constant-Time Cryptography. Undergirded by our chosen-input attack framework, in Sections 6 and 7 we develop end-to-end key-extraction attacks on constant- time implementations of classical cryptography (OpenSSL Diffie-Hellman Key Exchange and Go RSA decryption) and post-quantum cryptography (CRYSTALS-Kyber and CRYSTALS-Dilithium). 1.2 Disclosure We disclosed to Apple, OpenSSL, Go Crypto, and the CRYS- TALS team. Apple is investigating our PoC. OpenSSL re- ported that local side-channel attacks (i.e., ones where an attacker process runs on the same machine) fall outside of their threat model. The Go Crypto team considers this attack to be low severity. The CRYSTALS team agreed that pinning to the Icestorm cores without DMP could be the short-term solution and hardware fixes are needed in the long term. 2 Background Cache Architecture. Modern processors use a hierarchy of caches to reduce memory access latency. Typically, higher- level caches are smaller and faster to access, while lower-level caches are larger but slower to access. For example, the Apple processors we study in this paper have two cache levels, a core- private L1 and a shared L2. These caches are set-associative, meaning that they contain a fixed number of cache sets, each of which can fit a fixed number of cache lines. Cache lines are the basic unit for cache transactions. Multi-level caches have an inclusion policy that determines how the presence of a cache line in one level affects its presence in other levels. Most of our experiments were conducted on the Apple M1’s 4 Firestorm (performance) cores, which are the only ones to have a DMP. Each Firestorm core has a 128 KByte, 8 way set- associative L1 data cache with 64 Byte cache lines and these 4 Firestorm cores share a 12 MByte, 12 way set-associative L2 data cache with 128 Byte cache lines. The shared L2 cache is inclusive of the L1 caches, i.e. every cache line present in the L1 is also present in the L2 [94]. Cache Side-Channel Attacks. In a cache side-channel at- tack, an attacker infers a victim program’s secret by observing the side effects of the victim program’s secret-dependent ac- cesses to the processor cache. These attacks typically consist of three steps, during which the attacker (i) brings the cache into a known state, (ii) lets the victim execute, and (iii) checks the state of the cache to learn information about the victim’s execution during step (ii). Two techniques commonly used to mount cache side-channel attacks are Flush+Reload
[92] and Prime+Probe [64]. In Flush+Reload, an attacker that shares memory with a victim flushes individual shared cache lines and later reloads them to figure out if the victim accessed them. In Prime+Probe, the attacker builds an eviction set of addresses that map to the same cache set as the victim’s target cache line, primes the cache set with the eviction set, and later probes it to figure out whether the victim accessed the target line / displaced a line in the eviction set. Classical Prefetchers. Prefetchers are a hardware opti- mization used to hide memory access latency. Prefetchers live in the memory system, typically between the L1 and L2 or between the L2 and DRAM, and work by pre-loading data into the cache before it is requested by the core. In particular, given a program memory access pattern, classical prefetchers try to predict the next addresses the program will access based on its access pattern (an address trace) thus far. Classical Prefetcher Security Implications. Several prior works have analyzed the security implications of classical 1118    33rd USENIX Security Symposium USENIX Association prefetchers [17, 26, 27, 31, 76, 91, 98]. These works demon- strate that, through unintended interactions with prefetchers, victim programs can create cache state changes that can be measured by the attacker to leak information. Fortunately, leakage through these attacks is limited to the victim’s access pattern and can be mitigated through constant-time program- ming practices that ensure the program memory access pattern does not depend on secrets. Data Memory-Dependent Prefetchers (DMPs). DMPs are a class of prefetchers designed to prefetch irregular memory access patterns. In contrast to classical prefetchers, which only take the memory access pattern as an input, DMPs also take into account the contents of data memory directly to determine what to prefetch. The computer architecture literature and industry patents proposed several types of DMPs [7,8,16,24, 29,50,84,96,97], which differ in the irregular access patterns that they are designed to speed up (e.g., linked-list traversals, sparse matrix traversals). DMP Security Implications. Vicarte et al. were the first to perform an analysis of the security implications of DMPs [72]. In the worst case, they found that proposed (but not known to be implemented) indirect memory prefetchers could be used to build universal read gadgets that leak a program’s entire memory, similar to Spectre [52, 60]. More recently, Augury demonstrated that modern Apple processors employ a type of DMP referred to as an Array-of-Pointers (AoP) DMP [84]. We describe this DMP’s behavior in more detail in Section 4.1. 3 Threat Model and Setup In this paper we assume a typical microarchitectural attack scenario, where the victim and attacker have two different processes co-located on the same machine. Software. For our cryptographic attacks, we assume the attacker runs unprivileged code and is able to interact with the victim via nominal software interfaces, triggering it to perform private key operations. Next, we assume that the victim is constant-time software that does not exhibit any (known) microarchitectural side-channel leakage. Finally, we assume that the attacker and the victim do not share memory, but that the attacker can monitor any microarchitectural side channels available to it, e.g., cache latency. As we test unpriv- ileged code, we only consider memory addresses commonly allocated to userspace (EL0) programs by macOS. Hardware. Unless otherwise specified, we focus on Apple hardware. The M1-based experiments of Section 4 are run on a Mac Mini with an Apple M1 running macOS 13.5. For our investigation into the M2/M3 microarchitecture, we used a Mac Mini with an Apple M2 (running macOS 14.2.1) and a MacBook Pro with an Apple M3 (running macOS 14.2). Finally, when investigating Intel’s DMP implementation, we used an Intel Core i9-13900K (Raptor Lake) CPU, running Ubuntu 23.04 with kernel version 6.2.0. Prefetched by stream prefetcher Dereferenced by code Dereferenced by DMP dummy dummy dummy … This Work ptr[0] ptr[1] ptr[2] ptr[M-1] … This Work * * * * ptr[0] ptr[1] ptr[2] ptr[N-1] … Augury ptr[N] * * * * * ptr[M-1] * … ptr[M-1] … * dummy ptr[N] * ptr[0] * This Work ptr[1] ptr[7] … Loaded alongside (within same cache line) * * Figure 1: We compare memory access patterns and subse- quent prefetches. The first row represents the activation pat- tern reported by Augury [84]: a streaming dereference access pattern causes the DMP to dereference out-of-bounds pointers. In the second row, we show that architectural/program-level dereferences are unnecessary; we see DMP activations even when the training array contains non-pointer values. In the third row, we show that the DMP even dereferences the in- bounds pointers that are architecturally accessed (but, again, not dereferenced). Finally, the last row shows that a single access to a memory location results in all pointers stored in the incident cache line being dereferenced. 4 Microarchitectural Characterization 4.1 Revisiting DMP Data Access Patterns In this section, we investigate the access patterns required to activate the M1 DMP. We show that the M1 DMP deref- erences more pointers and with fewer program assumptions than was claimed by Augury [84]. Figure 1 summarizes the subsection’s findings. Augury. We begin by reviewing the M1 DMP activation pattern and methodology described in Augury. Augury’s code, summarized in Listing 1 (left), first allocates an array (aop) of length M and fills aop with pointers to memory addresses that correspond to unique L2 cache lines. Next, it evicts these cache lines from the L2 via cache thrashing (by loading an ar- ray eight times the size of the cache). The code then accesses (loads) and dereferences the first N elements of the aop, where N ≤M. We call aop[0], ..., aop[N-1] the in-bounds point- ers and aop[N], ..., aop[M-1] the out-of-bounds pointers. Augury inferred the DMP’s activity by adding code after the loop to time how long it would take to dereference pointers in the aop. We call these test accesses. The main finding was that the latency of test accesses for out-of-bounds pointers in some index range [N,N +δ) corresponded to L2 cache hits. This is noteworthy because the code itself never dereferenced pointers located after aop[N]. Augury attributed this behavior USENIX Association 33rd USENIX Security Symposium    1119 to a new form of prefetcher, with prefetch distance δ. uint64_t* aop[M]; // Fill aop with pointers // to unique addresses // or random values for (i=0; i<N; i++) { *aop[i%N]; } // Measure latency to // set of test addresses uint64_t* aop[M]; // Fill aop with pointers // to unique addresses // or random values for (i=0; i<N; i++) { aop[i%N]; } // Measure latency to // set of test addresses Listing 1: Left: The DMP activation code pattern studied by Augury [84]. Right: The DMP activation pattern studied in this work. For both, assume N ≤M. Both code patterns fill the aop before the loop begins and use a mod operation to inhibit speculative execution. Observing DMP Activations. We reproduce Augury’s ex- periments by setting N = 256 and M = 264, choosing a set of test pointers, and then either filling the out-of-bounds region with those pointers or random values. When the pointers are present, a test access (dereference) to one takes ∼250 cycles,1 as shown in Figure 2a. When the pointers are not present, the same test accesses take significantly longer. A cutoff of 300 cycles (red dash line) cleanly differentiates between the two cases and thus DMP activations. This corresponds to the L2 hit time and matches Augury’s findings, consistent with δ ≥8. Avoiding Architectural Pointer Dereferencing. To deter- mine if the architectural pointer dereferences are required to trigger DMP activations we use the code in Listing 1 (right), where the in-bounds region does not contain pointers nor does the aop traversal loop perform any pointer dereferences. Again, we either fill the out-of-bounds region with test point- ers or random values. See Figure 1 (second row). As seen in Figure 2b, when the out-of-bounds region con- tains pointers, test accesses are < 300 cycles despite no ar- chitectural dereferences occurring to the in-bounds pointers. From this, we deduce that architectural dereferences are not re- quired for the DMP to activate, i.e., that the DMP will prefetch out-of-bounds pointers without them. In-bounds DMP Dereferencing. We then further check if the in-bounds pointers are also dereferenced by the DMP as they are no longer architecturally dereferenced in Listing 1 (right). This is the memory access pattern outlined in Figure 1 (third row), where we iterate over an array containing valid pointers without performing any dereferences. Figure 2c shows that for N = 8, we can still consistently differentiate between the two cases. This indicates that if the aop contains data which can be interpreted as valid pointers, merely iterating over it is sufficient to activate the DMP. One Load, Single Pointer. Finally, we consider how general the memory access pattern can be by performing a single data 1We collect timing measurements by configuring and reading performance counters (PMC2-PMC7) for cycle counting via kperf. 256 257 258 259 260 261 262 263 Test Index 0 100 200 300 400 500 600 700 800 Access Latency (cycles) No Pointer Contain Pointer (a) Row 1: Traversing the AoP with dereferences; out-of-bounds pointers are prefetched 256 257 258 259 260 261 262 263 Test Index 0 100 200 300 400 500 600 700 800 Access Latency (cycles) No Pointer Contain Pointer (b) Row 2: Traversing the AoP without dereferences; out-of- bounds pointers are prefetched 0 1 2 3 4 5 6 7 Test Index 0 100 200 300 400 500 600 700 800 Access Latency (cycles) No Pointer Contain Pointer (c) Row 3: Traversing the AoP without dereferences; in-bounds pointers are prefetched 0 1 2 3 4 5 6 7 Test Index 0 100 200 300 400 500 600 700 800 Access Latency (cycles) No Pointer Contain Pointer (d) Row 4: One load to AoP; pointers within the incident cache line are prefetched Figure 2: Median, minimum, and maximum test access laten- cies (over 32 samples for each bar) using the access patterns of Figure
8. In all cases, we observe DMP activations/dereferences for all pointers in aop, indicating that even a single pointer can trigger the DMP. 4.2 DMP Activation Criteria Having established what memory access patterns activate the DMP, this section investigates where data must reside in the memory hierarchy to be DMP-searched for pointers. We show that the DMP dereferences pointers specifically on L1 cache fills and features two mechanisms to prevent redundant prefetches: a history filter and a do-not-scan hint. In this section, we make use of standard eviction sets, i.e., eviction sets for individual cache sets. We generate these eviction sets using standard techniques from prior work [85].3 History Filter. We start by rerunning the experiments from 2Replacing the load with the store instruction, we find that none of point- ers in the accessed cache line are dereferenced. 3This is in contrast with Augury, which, as we mentioned in Section 4.1, relied on cache thrashing to precondition the cache. 1120    33rd USENIX Security Symposium USENIX Association Section 4.1 using standard L2 eviction sets to evict both the aop array and the L2 cache lines that are pointed to by pointers in the aop array. We call these L2 lines the target lines. We observe that the DMP only reliably dereferences each pointer once, on the first access to its aop entry. That is, even if the previously prefetched target line is evicted from the cache, along with its aop entry, the DMP no longer activates when seeing that pointer in the future. This observation suggests that the decision to dereference a pointer is made based on not only the program’s access pattern but also some additional mechanism. An Apple patent suggests that this mechanism might be a history filter that “attempts to identify whether a given memory pointer candidate likely corresponds to a candidate that has been recently prefetched, in which case the given candidate may be discarded as a likely duplicate” [47]. The same patent suggests that this filter may be organized as a direct-mapped 128-entry or 256-entry structure. History Filter Reverse Engineering. To corroborate the history filter hypothesis, we design a new experiment where aop only contains a single pointer ptr. First, we access aop, causing the DMP to dereference ptr. We then evict aop and the target line for ptr from the cache using standard eviction sets. Next, we read S unique pointers stored in a different array, causing the DMP to inspect and dereference S additional pointers. Finally, we re-access aop and check if this second access causes the DMP to dereference ptr. We run the experiment 100 times for each value of S and report the success rate (i.e., the percentage of times that the DMP activated on the second aop access) in Figure 3. 1 2 4 8 16 32 64 128 256 Number of different ptrs 0 10 20 30 40 50 60 70 80 Success Rate (%) Figure 3: The percentage of experiments where the DMP re-activates when ptr is re-accessed (Success Rate, y-axis), as a function of the number of unique pointers accessed in between the first and second access to ptr (x-axis). Observe that Success Rate increases with the number of unique inter- mediate pointer accesses. We observe that the DMP only reliably re-activates on ptr when S ≥128. This behavior is likely due to the lim- ited capacity of the history filter. That is, accessing S unique pointers results in the record of ptr’s target getting evicted from the filter when S ≥128. We hypothesize that Augury’s methodology was not affected by the history filter because its aggressive cache thrashing technique (i.e., accessing an array eight times the size of the cache) had a side effect of also flushing the history filter. We further find that the history filter is a per-core structure and is reset if a core remains idle for an extended period of time. Specifically, the DMP reliably re-activates even when S = 0 if we (i) reschedule our experiment to a different core between the first and the second aop access or (ii) run the experiment on one core but leave the core idle for 100µs or more between the first and the second aop access. L1 and L2 Cache Fills. The above observations indicate that the DMP activates when an aop entry is accessed from DRAM and the record of its target is not present in the history filter. Next, we investigate at which stage of a DRAM fetch the DMP scans the data for pointers. Recall that the M1 has an L2 line size of 128 Bytes and an L1 line size of 64 Bytes. With each pointer containing 8 Bytes, L2 lines can thus be split into “lower” and “upper” halves, each of which is an independent L1 line that can store 64/8 = 8 pointers. When a program accesses either the lower or upper half, the accessed L1 line will be filled into both the L1 and L2 caches, while the other half will only be filled into the L2 cache.4 In order to differentiate between L1 and L2 fills, we populate a L2 line size-aligned aop with 16 unique pointers and run the experiment from Listing 1 (right) in Section 4.1 with N = 1 and M =
16. Before each repetition, we use cache thrashing (as in Section 4.1) to evict the aop and its target lines from both the cache and the history filter. Figure 4 (top) summarizes our findings, repeating each ex- periment 100 times and using the 300 cycle threshold from Section 4.1 for L2 cache hits. Here, we observe that when the program accesses aop[0], the DMP only dereferences aop[0], ···, aop[7]. We run 7 more variants of this experi- ment, varying the single aop[i] access from i = 1,··· ,7 and observe the same behavior for each choice of i. Next, we run 8 more variants of the same experiment, this time making a single access to aop[i] for i = 8,··· ,15. In this case, we ob- serve that aop[8], ···, aop[15] are all dereferenced for each choice of i, as shown in Figure 4 (bottom). We conclude that when filling an L2 cache line from DRAM, the DMP derefer- ences all pointers in the specific L1 line that is accessed, and not those in the other half of the L2 line. We run 8 more variants of the above experiment. For these, before making an access to aop[i] for i = 0,··· ,7, we first make an access to aop[8]. We then repeat this setup while ex- ploring the opposite case: before making an access to aop[i] for i = 8,··· ,15, we first make an access to aop[0]. As dis- cussed above, the first access brings aop[i] from DRAM to the L2 cache and aop[i] further moves to the L1 cache with the second access. We observe that the DMP reliably dereferences the contents of the L1 line containing aop[i]. This means that L2 to L1 fills can also activate the DMP. Do-not-scan Hint. The above experiments suggest that 4We empirically verify this by subsequently timing an access to the other half and observing that its access latency corresponds to the that of an L2 hit. USENIX Association 33rd USENIX Security Symposium    1121 0 50 100 Success Rate (%) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Position Offset 0 50 100 Success Rate (%) Figure 4: Which pointers in an L2 line are dereferenced when an access is made to data in that line? Top: the code accesses aop[0]. Bottom: the code accesses aop[8]. We conclude that the DMP dereferences pointers in the specific L1 line (either the upper or lower half of the L2 line) the code accessed. the DMP searches for pointers in L1 cache lines during L1 fills, regardless of whether the L1 line is fetched from DRAM or the L2. To corroborate this hypothesis, we design another variant of the single-pointer experiment from Section 4.1. The experiment starts by loading the aop into the L1 and subsequently using eviction sets to either (i) evict the aop from the L1 or (ii) evict the aop from both the L1 and L2. In both cases, the experiment also evicts the target line from the cache and accesses a separate set of 256 pointers to evict the record of the target line from the history filter. Finally, the experiment re-accesses aop and tests if this second aop access causes the DMP to re-dereference ptr. Interestingly, we observe that the DMP does not re- dereference ptr when the experiment re-accesses aop and aop was only evicted from the L1. However, when the aop is also evicted from the L2, the DMP re-dereferences it. This means that even if the previously prefetched target line is evicted from both the cache and the history filter, the DMP does not dereference that pointer again unless its aop entry is also evicted from both the L1 and L2. This behavior matches a mechanism also described in the previously referenced Ap- ple patent [47], where the L2 sets a “do-not-scan” hint on L1 cache fills to prevent a previously scanned L1 cache line from being redundantly re-scanned. Fortunately, in our ex- periments, evicting the aop from both the L1 and the L2 is sufficient to clear the “do-not-scan” hint on the aop. 4.3 Restrictions on Dereferenced Pointers In the previous section, we learned that the DMP activates on L1 fills and dereferences the pointers inside it if and only if those pointers’ targets are not in the history filter and the filled line is not marked with the "do-not-scan" hint. We now investigate what pointers can be dereferenced by the DMP. For this, we again use Listing 1 (right) with N = 1 and M = 1 and rely on cache thrashing to ensure that the aop is uncached. We then try testing different pointer values in the aop, and checking for DMP activations. 4GByte Prefetch Region. We begin by investigating if the DMP requires there to be a relationship between the ad- dress of the aop entry and the value of the aop entry (i.e., the pointer). We call the address of the aop entry the en- try’s/pointer’s position. To understand what the requirements are for one pointer to be dereferenced, we carry out a series of experiments that vary a pointer’s position and value. See one such experiment in Figure 5 which shows that the pointer’s position and value must be related for DMP activation to oc- cur. Overall, we discover that the DMP only dereferences a pointer if the aop entry and target line are in the same 4 GByte- aligned region (Figure 6). In other words, that the upper 32 bits of their addresses match. Apple’s patent
63. We observe that the DMP does not 1122    33rd USENIX Security Symposium USENIX Association * target aop … 4GByte Bound aop * Figure 6: Outline of the placement of the target line and the aop entry. Following the observation from Figure 5, if the aop entry and target line straddle a 4GByte boundary, the DMP won’t dereference the pointer. dereference the original pointer if a bit in the range [48,55] is flipped. However, if a bit in the range [56,63] is flipped, the original pointer gets dereferenced. We conclude that the DMP ignores the upper 8 bits of a pointer when dereferencing it, which matches the “Top-Byte-Ignore” in ARMv8. 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 Flip Bit Index 0 20 40 60 80 100 Success Rate (%) Figure 7: Activation success rate for a pointer when it is accessed by the program, after having one bit flipped between bit 48 to 63. Auxiliary next-line prefetch. Finally, we investigate the amount of data prefetched when the DMP dereferences a pointer. We test this by performing a test access to not only a pointer’s target line, but also to nearby lines. Apart from the target line, we also observe L2 hits to cache lines immediately next to the target line. We hypothesize that this is due to a next-line prefetcher being triggered alongside the DMP, which matches the adjacent-line prefetch behavior described in Apple’s patent [47]. 4.4 A Model for the DMP’s Behavior We now summarize the previous two subsections and make several new observations. Step 1: Observing Cache Line Data. The DMP scans the data in an L1 line when that line is filled to the L1, if the line is not marked with the “do-not-scan” hint (i.e., the line has not been scanned since it was brought into the cache; Section 4.2). The DMP performs the scan by checking each pointer size-aligned chunk (the first 64 bits, second 64 bits, etc.) in the cache line.5 Step 2: Address Check. Next, the DMP applies additional checks and filters to each chunk (candidate pointer) to see if it should be dereferenced. Bits [63:56] are ignored (Section 4.3). 5Pointers in aop should be 64-bit aligned, which is also discussed in [84]. Further, per Section 4.3, the cache line that stores the pointer (its position) must be in the same 4 GByte (log2 4 GByte = 32 bits)-aligned region as the cache line that the pointer points to (its target). In other words, the DMP checks whether bits [55:32] of the candidate pointer match the corresponding bits of the address of the target cache line. Finally, the DMP checks if the candidate pointer is present in the history filter (Section 4.2). If bits [55:32] match and the pointer is not in the history filter, the DMP attempts to prefetch two L2 lines. Specifically, it first prefetches the cache line targeted by the 64-bit chunk, ignoring the top byte value. Next, it triggers the CPU’s next line prefetcher and fetches the neighboring cache line also into the CPU’s L2 cache (Section 4.3). Both prefetched addresses are then inserted to the history filter. As part of the prefetching process, the DMP looks up the translation lookaside buffer (TLB) and triggers page table walks to obtain the physical address corresponding to each candidate pointer (which is a virtual address [33]). On a TLB miss, the DMP inserts the missing translations into the TLB.6 4.5 Other Microarchitectures We investigated the DMP behavior on other microarchitec- tures including the Apple M2/M3 and Intel’s 13th Generation (Raptor Lake) CPUs, and display results in Figures 8a and 8b. As the Apple M3 behaves similarly to the M2, we omit its figure. In these two figures, the x-axis refers to the four access patterns shown as the rows in Figure 1, while the y-axis is the access latency for test accesses. For simplicity, we only show latencies for test accesses to the first pointer in each pattern. The Intel i9-13900K (Raptor Lake) shows a distin- guishable timing difference only for the first access pattern from Figure 1, whereas the M2/M3 activates on all the pat- terns discussed previously. We conclude that while DMPs are present on Raptor Lake machines, they require different acti- vation patterns. Finally, we leave the systematic investigation and exploration of Intel’s DMPs to future work. Row 1 Row 2 Row 3 Row 4 0 100 200 300 400 500 600 700 800 Access Latency (cycles) No Pointer Contain Pointer (a) Apple M2 Row 1 Row 2 Row 3 Row 4 0 100 200 300 400 500 600 700 800 Access Latency (cycles) No Pointer Contain Pointer (b) Intel Raptor Lake Figure 8: We test four access patterns shown in Figure 1 on Apple M2 (left) and Intel 13th generation Raptor Lake (right). 6Prior work
[84] also observes that the M1 DMP fills TLB entries for pointers in the aop. USENIX Association 33rd USENIX Security Symposium    1123 5 Attacking Constant-Time Conditional Swap To mitigate microarchitectural side channels, cryptographic code follows the constant-time programming principle: A secret should not determine which instructions to execute, which memory to access, or be used as input for variable-time instructions [11,13,14,21–23,62]. We now show how the DMP can break cryptographic secu- rity even when code is written to follow the constant-time prin- ciple. To introduce ideas and attacker tools, this section show- cases a Proof-of-Concept (PoC) attack on a core constant-time cryptographic primitive
[54] called ct-swap which condi- tionally swaps the contents of two arrays a and b based on a secret bit secret. We start with ct-swap to simplify the presentation. Later sections will reuse the ideas and processes described here to break real cryptographic code. Constant Time Swap Overview. Listing 2 swaps the contents of array a and b based on the value of secret in a constant-time manner. The underlying swap opera- tion for each 64-bit entry is borrowed from OpenSSL.7 To achieve constant-time behavior, Line 4 in Listing 2 first extends secret to be a machine-sized word; i.e., 0x0000000000000000 or 0xFFFFFFFFFFFFFFFF based on the value of secret. Next, for each loop iteration, Line 6 of Listing 2 computes a masked delta between the contents of the current elements of a and b. Finally, Lines 7 and 8 actually conditionally swap the contents of the two elements, based on the value of secret. 1 void ct-swap(uint64_t secret, uint64_t *a, uint64_t *b, 2 size_t len) { 3 uint64_t delta; 4 uint64_t mask = ~(secret-1); 5 for (size_t i = 0; i < len; i++) { 6 delta = (a[i] ^ b[i]) & mask; 7 a[i] = a[i] ^ delta; 8 b[i] = b[i] ^ delta; 9 } 10 } Listing 2: Code snippet of constant-time swap. The contents of a and b is conditionally swapped based on secret. 5.1 Attack Overview and Challenges Emulating realistic attack scenarios, we assume that ct-swap runs in a victim process, separate from the attacker’s address space. We assume a simple but common protocol between victim and attacker, where the victim takes input from the attacker to populate the ct-swap’s a and b arrays and then executes ct-swap. The outcome of the swap is never directly revealed, nor is the value of secret. The attacker can learn page offsets (not randomized by ASLR) of array a and b by 7constant_time_cond_swap_64: https://github.com/openssl/ openssl/blob/1751185154ab1f1a796e0f39567fe51c8e24b78d/ include/internal/constant_time.h. investigating the victim’s program in advance. The attacker process’ goal is to extract the value of secret from the victim, using microarchitectural side channels and the DMP. Chosen-Input Attack. We now overview how the attacker uses the DMP to extract secret. At a high level, the attacker populates one of ct-swap’s arrays (a or b—let us assume it chooses b) with a pointer ptr of its choosing, and then arranges for the DMP to dereference the contents of the other array (a) during the conditional swap computation. Then, the attacker uses conventional cache side-channel analysis to observe whether ptr was dereferenced by the DMP due to ct-swap’s computation over a, which in turn reveals whether the swap occurred and therefore the value of secret. Overcoming DMP Activation Criteria. To correctly at- tribute the DMP’s activation to ptr being moved from b to a, the attacker must ensure that the DMP’s activation criteria are only satisfied when accessing a (and not b). Based on Section 4.2, one necessary prerequisite to activate the DMP on an aop load is to evict the aop from the L2 cache. Thus, we need a means to evict a8 (but not b). Overcoming Address Space Separation. Yet, since the attacker runs in a separate process from the victim and without any shared memory, we must replace the Flush+Reload in Section 4 with Prime+Probe. In particular, we must build an eviction set to detect whether ptr was dereferenced by the DMP inside the victim process. However, it is not clear how to build eviction sets for ptr’s target line (or a mentioned above),9 as we cannot time accesses to these since they are located inside the victim’s address space. 5.2 Compound Eviction Set Construction We now present a novel technique—compound eviction set generation—which solves the above problem by using ct-swap’s access to a as well as DMP dereferences to ptr to simultaneously build eviction sets for both elements. Establishing a Timing Source. To start, we need to distin- guish between L2 hits and misses. However, as the attacker is running without elevated privileges, it is unable to access nanosecond-accurate timers on Apple CPUs, instead being limited to the system’s 42 ns timer. Unfortunately, we empir- ically find that this timer is not sufficient to reliably mount Prime+Probe attacks. We sidestep this issue by using the multi-thread timer approach of [46, 69, 73]. Here, the main idea is to use a dedicated counting thread, which constantly in- crements a shared variable with the attacker process in a tight loop. By loading the value of the shared variable, the attacker 8Triggering the DMP also requires that a is refilled after it is evicted. We rely on the victim to perform this refill. For example, ct-swap reads a in a loop, which will cause each cache line making up a to be accessed (refilled) multiple times (len > 1). 9We assume that the base addresses of a and b have different page-offset bits, so that the eviction set for a would not evict b, which also holds for later attacks. 1124    33rd USENIX Security Symposium USENIX Association process is thus able to obtain high resolution timestamps, allowing us to distinguish L2 hits from misses. Generating Standard Eviction Sets. Next, we need to gen- erate a large number of standard L2 eviction sets, i.e., eviction sets targeted to individual L2 sets. The M1 has 8192 (213) L2 cache sets, indexed with 6 (upper) bits from the physical page frame and 7 (lower) bits from the page offset. We generate standard eviction sets for all these L2 sets by extending the technique used in Section 4.2 (detailed in
Single Pass Client-Preprocessing Private Information Retrieval.
[1] Code repository for SinglePass PIR. Available at: https://github.com/SinglePass712/Submission.
[2] Ishtiyaque Ahmad, Yuntian Yang, Divyakant Agrawal, Amr El Abbadi, and Trinabh Gupta. Addra: Metadata- private voice communication over fully untrusted infras- tructure. 2021.
[3] Sebastian Angel and Srinath Setty. Unobservable com- munication over fully untrusted infrastructure. In Pro- ceedings of the 12th USENIX conference on Operating Systems Design and Implementation, OSDI’16, pages 551–569, USA, November 2016. USENIX Association.
[4] Michael Backes, Aniket Kate, Matteo Maffei, and Kim Pecina. ObliviAd: Provably Secure and Practical Online Behavioral Advertising. In 2012 IEEE Symposium on Security and Privacy, pages 257–271, May 2012. ISSN: 2375-1207.
[5] Amos Beimel, Yuval Ishai, and Tal Malkin. Reduc- ing the Servers Computation in Private Information Retrieval: PIR with Preprocessing. In Mihir Bellare, editor, Advances in Cryptology — CRYPTO 2000, Lec- ture Notes in Computer Science, pages 55–73, Berlin, Heidelberg, 2000. Springer.
[6] Elette Boyle, Niv Gilboa, and Yuval Ishai. Function Secret Sharing. In Elisabeth Oswald and Marc Fischlin, editors, Advances in Cryptology - EUROCRYPT 2015, Lecture Notes in Computer Science, pages 337–367, Berlin, Heidelberg, 2015. Springer.
[7] Elette Boyle, Yuval Ishai, Rafael Pass, and Mary Woot- ters. Can We Access a Database Both Locally and Privately? pages 662–693, November 2017.
[8] Benny Chor, Niv Gilboa, and Moni Naor. Private Infor- mation Retrieval by Keywords, 1998. Report Number: 003. 5One caveat of the comparison is it is necessary for the updatable version of Checklist to support keyword queries in order to achieve the O(logN) amortized bandwidth. SinglePass is a pure PIR scheme that only supports index queries. However, using cuckoo hashing we can derive a keyword PIR scheme with a 2× overhead [33].
[9] Henry Corrigan-Gibbs and Dmitry Kogan. Private Infor- mation Retrieval with Sublinear Online Time. In Anne Canteaut and Yuval Ishai, editors, Advances in Cryptol- ogy – EUROCRYPT 2020, Lecture Notes in Computer Science, pages 44–75, Cham, 2020. Springer Interna- tional Publishing.
[10] Richard Durstenfeld. Algorithm 235: Random permuta- tion. Communications of the ACM, 7(7):420, July 1964.
[11] Ronald Aylmer Fisher and Frank Yates. Statistical tables for biological, agricultural and medical research, edited by R.A. Fisher and F. Yates. 6th ed. Edinburgh: Oliver and Boyd, 1963. Accepted: 2006-06-27T07:57:52Z.
[12] Niv Gilboa and Yuval Ishai. Distributed Point Functions and Their Applications. In Phong Q. Nguyen and Elis- abeth Oswald, editors, Advances in Cryptology – EU- ROCRYPT 2014, Lecture Notes in Computer Science, pages 640–658, Berlin, Heidelberg, 2014. Springer.
[13] Oded Goldreich, S. Goldwasser, and S. Micali. How to Construct Random Functions (Extended Abstract). In FOCS, 1984.
[14] Oded Goldreich and Rafail Ostrovsky. Software protec- tion and simulation on oblivious RAMs. Journal of the ACM, 43(3):431–473, May 1996.
[15] Trinabh Gupta, Natacha Crooks, Whitney Mulhern, Sri- nath Setty, Lorenzo Alvisi, and Michael Walfish. Scal- able and private media consumption with Popcorn. In Proceedings of the 13th Usenix Conference on Net- worked Systems Design and Implementation, NSDI’16, pages 91–107, USA, March 2016. USENIX Associa- tion.
[16] Syed Mahbub Hafiz and Ryan Henry. A Bit More Than a Bit Is More Than a Bit Better: Faster (essen- tially) optimal-rate many-server PIR. Proceedings on Privacy Enhancing Technologies, 2019(4):112–131, Oc- tober 2019.
[17] Laura Hetz, Thomas Schneider, and Christian Weinert. Scaling Mobile Private Contact Discovery to Billions of Users, 2023. Publication info: Published elsewhere. Minor revision. ESORICS 2023.
[18] Viet Tung Hoang, Ben Morris, and Phillip Rogaway. An Enciphering Scheme Based on a Card Shuffle. Tech- nical Report arXiv:1208.1176, arXiv, November 2014. arXiv:1208.1176
[19] Justin Holmgren, Ran Canetti, and Silas Richelson. To- wards Doubly Efficient Private Information Retrieval. Technical Report 568, 2017. USENIX Association 33rd USENIX Security Symposium    5977 512-byte word databases 1024-byte word databases 2048-byte word databases Figure 8: Comparison of benchmarking over preprocessing time, query time, bandwidth, client storage and update time over increasing updatable databases sizes (x-axis) for different element sizes (on a log scale). 5978    33rd USENIX Security Symposium USENIX Association Scheme Preprocessing Time (s) Query Time (ms) Query BW (KB) Client Size (MB) Update Time (ms) SinglePass 0.122 0.02ms 0.68KB 23.3MB 0.19ms Checklist 13.22s 0.95ms 1.48KB 23.6MB 3.78ms Table 2: Comparison for Updatable Database with 3,000,000 32-byte elements. The update time is for a batch of 500 updates.
[20] Donald E Knuth. The Art of Computer Programming, Volume II: Seminumerical Algorithms. Addison-Wesley, 1969.
[21] Dmitry Kogan and Henry Corrigan-Gibbs. Private Blocklist Lookups with Checklist. In 30th USENIX Security Symposium (USENIX Security 21), pages 875– 892. USENIX Association, 2021.
[22] Arthur Lazzaretti and Charalampos Papamanthou. Near- Optimal Private Information Retrieval with Preprocess- ing. In Guy Rothblum and Hoeteck Wee, editors, Theory of Cryptography, Lecture Notes in Computer Science, pages 406–435, Cham, 2023. Springer Nature Switzer- land.
[23] Arthur Lazzaretti and Charalampos Papamanthou. TreePIR: Sublinear-Time and Polylog-Bandwidth Pri- vate Information Retrieval from DDH. In Advances in Cryptology – CRYPTO 2023: 43rd Annual Interna- tional Cryptology Conference, CRYPTO 2023, Santa Barbara, CA, USA, August 20–24, 2023, Proceedings, Part II, pages 284–314, Berlin, Heidelberg, August 2023. Springer-Verlag.
[24] Wei-Kai Lin, Ethan Mook, and Daniel Wichs. Doubly Efficient Private Information Retrieval and Fully Ho- momorphic RAM Computation from Ring LWE, 2022. Report Number: 1703.
[25] Yiping Ma, Zhong Ke, Tal Rabin, and Sebastian Angel. Incremental Offline/Online PIR (extended version). In USENIX Security 2022, 2022.
[26] Rashed Mazumder, Atsuko Miyaji, and Chunhua Su. A simple construction of encryption for a tiny domain message. pages 1–6, March 2017.
[27] Samir Menon. SpiralWiki, 2022.
[28] Sarah Miracle and Scott Yilek. Cycle Slicer: An Algo- rithm for Building Permutations on Special Domains. pages 392–416, November 2017.
[29] Ben Morris and Phillip Rogaway. Sometimes-Recurse Shuffle. In Phong Q. Nguyen and Elisabeth Oswald, editors, Advances in Cryptology – EUROCRYPT 2014, Lecture Notes in Computer Science, pages 311–326, Berlin, Heidelberg, 2014. Springer.
[30] Muhammad Haris Mughees, Sun I, and Ling Ren. Sim- ple and Practical Amortized Sublinear Private Informa- tion Retrieval, 2023. Publication info: Preprint.
[31] Thomas Ristenpart and Scott Yilek. The Mix-and-Cut Shuffle: Small-Domain Encryption Secure against N Queries. In Ran Canetti and Juan A. Garay, editors, Ad- vances in Cryptology – CRYPTO 2013, Lecture Notes in Computer Science, pages 392–409, Berlin, Heidelberg, 2013. Springer.
[32] Emil Stefanov and Elaine Shi. FastPRP: Fast pseudo- random permutations for small domains. Cryptology ePrint Report 2012/254. Technical report, 2012.
[33] Kevin Yeo. Cuckoo Hashing in Cryptography: Opti- mal Parameters, Robustness and Applications. In Ad- vances in Cryptology – CRYPTO 2023: 43rd Annual International Cryptology Conference, CRYPTO 2023, Santa Barbara, CA, USA, August 20–24, 2023, Proceed- ings, Part IV, pages 197–230, Berlin, Heidelberg, August 2023. Springer-Verlag.
[34] Mingxun Zhou, Andrew Park, Elaine Shi, and Wenting Zheng. Piano: Extremely Simple, Single-Server PIR with Sublinear Server Computation, 2023. Publication info: Published elsewhere. Major revision. IEEE S&P 2024. A Proof of Main Theorem In this section, we prove Theorem 4.1 Proof. Complexities: For Hint, by Lemma 2.1, we can sam- ple the permutations needed in O(N) time, and then use ran- dom access to compute the hints in O(N ·w) time. Query to x = (i∗, j∗) has to find the index ind such that pi∗(ind) = j∗. Notice that given the expanded format of each permutation and its inverse, this can be done in O(1) time, by simply tak- ing p−1 i∗(j∗).6 After, we just have to index pi(ind) for i ∈[Q] which takes O(Q) time, and send that to the server (with a symmetric number of operations to generate the refresh hint). 6We can store the inverse along with the permutation with constant over- head. In practice, for some scenarios, it might be beneficial to not store the inverse in order to save space. In those cases, the client time would be O(Q+N/Q). This is the only place where the inverse is used for that static scheme. For the updatable scheme, we require the inverse to get O(1) update operations. USENIX Association 33rd USENIX Security Symposium    5979 Answer only reads the array of size Q and accesses each el- ement indexed by the array. Assuming random access costs constant time, this also runs in O(Q) time. Finally, Recon- struct does O(Q) operations to update the hint parities of the elements used (from the above complexities, only O(Q) el- ements are sent/received on each query. The client storage is the hint it receives from Hint (and whatever refresh op- erations done on it, which don’t increase its size) plus the expanded client keys (N indices of [N], therefore, N logN space). Alternatively, the client can store only the seed used for the permutations and expand them at query time, but by Lemma 2.1 this would then require Query to run in O(N) time. Correctness: Follows by construction (we reiterate correct- ness is modeled for honest servers only). Note that after a correct preprocessing, Server 0 sends back to the client (ck,h) = ({pi}i∈Q,{hj}j∈⌊N/Q⌋where each pi is a pseudorandom permutation of [1,⌊N/Q⌋] and each h j = L i∈Q DB[pi(j)]. Then, for a query to x = (i∗, j∗), first define ind to be the ele- ment of [N/Q] such that pi∗(ind) = j∗. If Server 1 responds to q1 honestly, then it is clear to see that the client’s output for the query is L i∈Q,i̸=i∗DBi[pi(ind)]  ⊕hind = DBi∗[pi∗(ind)] = DBi∗[j∗] = DB[x]. For a subsequent query, what is left to show is that for every following query, for every j ∈[N/Q], hj = L i∈[Q] DBi[pi(j)] after the swaps. Notice that for each swap between pi(k) and pi(v), we let hk = hk ⊕DBi[pi(k)] ⊕DBi[pi(v)] therefore ef- fectively removing the old element in this hint’s position from the xor and adding the new one (this happens symmetrically on hv). Then, at the beginning of the next query, each hint hj is still equal to L i∈[Q] DBi[pi(j)]. Then, by our argument for the first query, correctness holds as well (and holds for any T). Privacy: We consider the privacy of each server separately according to the games defined in Figure 2. Server 0: To show privacy for Server 0 for any λ ∈N and any N(λ),T(λ), for any PPT adversary A(λ), Pr h PrivGame0 A,λ,N,T →1 i ≤1/2+ neg(λ). Note that in PrivGame0, which models the view of Server 0, Server 0 has access to both the client keys, and then for each query t ∈T, it gets access to the corresponding q0 for that query, which we will denote here as qt 0. Notice that as long as each pi is bijection from [N/Q] to [N/Q], then each pi(ri) is uniform and independent of the query being made, since by definition each ri is uniform and independent of the query being made. Since for every step, the new swapped pi is still a bijection, then this holds for any timestep t. So each q0 is a set of elements in [N/Q] independent of the query being made. Then, since each step q0 is independent of the query being made, it follows that for any pair x0,x1, even conditioned on seeing the preprocessing, an adversary acting as Server 0 cannot distinguish between b = 0 and b = 1 on the PrivGame0 experiment. If we use pseudorandomness output by a PRG with security parameter λ rather than true randomness to sample each ri, we incure a negligible probability of distinguishing, directly from the PRG security definition. Finally, we get that, Pr h PrivGame0 A,λ,N,T →1 i ≤1/2+ neg(λ). Server 1: To show privacy for Server 1 for any λ ∈N and any N(λ),T(λ), for any PPT adversary A(λ), Pr h PrivGame1 A,λ,N,T →1 i ≤1/2+ neg(λ). Notice that here, the adversary acting as Server 1 does not get access to the preprocessing (since it is run by Server 0), but it does see q1 for every timestep t ∈T. Here, we use Theorem A.1. Note that Experiment 1 in Theorem A.1 is exactly equivalent to our PIR query at each timestep. Then, by Theorem A.1, we can replace each q1 shown to Server 1 by uniform random elements of [N/Q]. This implies that for any x0,x1 picked by the adversary as inputs from PrivGame1, the outputs at each timestep will be identically distributed and indistinguishable when using true randomness. Then, we can replace the randomness used by pseudorandomness sampled through a PRG with security parameter λ (which is what we do in our scheme), and it fol- lows by the PRG security that this would be computationally indisinguishable from before. Then, it follows that: Pr h PrivGame1 A,λ,N,T →1 i ≤1/2+ neg(λ). ■ A.1 Server 1 Indistinguishability Theorem A.1 (Query indistinguishability ). For any adaptive adversary A, Experiment 0 and Experiment 1, as defined in Figure 9, are perfectly indistinguishable. Proof. We prove this through a series of hybrid experiments. Note that at each step t, the adversary can pick inputs and then see the outputs for that step before deciding its inputs for the next step. We start from H0, in which at each step, rather than simply sampling uniformly as in Experiment 0, the experiment samples Q independent permutations of [N/Q] uniformly. and behaves by using the adversary inputs to index these permutations. Since they permutations are uniformly and independently sampled, these are indistinguishable. We expand on this below. 5980    33rd USENIX Security Symposium USENIX Association Experiment 0 Public Parameters: N,Q ∈N, assume Q|N. Experiment:
6. Output (vT−1 1 ,...,vT−1 Q ) where: • vT−1 i = PT−1 i (ind) if i ̸= iT−1. • vT−1 i $←[N/Q] if i = iT−1. . Notice that for the first T −1 steps of the experiment (itera- tions 0 through T −2), it runs exactly as H0, so up to that point they are indistinguishable. The only difference is how we sam- USENIX Association 33rd USENIX Security Symposium    5981 ple each PT−1 i . In Experiment H0, it is sampled uniformly at random, whereas in Experiment H1, it is sampled by taking each PT−2 i , swapping the only element shown of PT−2 i with a uniform random point and denoting this new permutation as PT−1 i . Notice that, by the indistinguishability of the Show and Shuffle experiment (Lemma 3.1), we can see that each the set of PT−1 i in both experiments is identically distributed, since this is exactly the experiment proven in Lemma 3.1. Then, it follows directly that Experiment H0 and Experiment H1 are indistinguishable. Now, define experiment Hk as follows, k ∈{1,...,T −1}: Experiment Hk Public Parameters: N,Q ∈N, assume Q|N. Experiment:
11. As seen in Section 5, we can decrease query bandwidth and query time by using more storage. 5982    33rd USENIX Security Symposium USENIX Association 512-byte word databases 1024-byte word databases 2048-byte word databases Figure 10: Comparison of benchmarking over preprocessing time, query time, bandwidth and client storageover increasingly sized static databases (x-axis) for different element sizes (on a log scale) when fixing query time. USENIX Association 33rd USENIX Security Symposium    5983 512-byte word databases 1024-byte word databases 2048-byte word databases Figure 11: Comparison of benchmarking over preprocessing time, query time, bandwidth, client storage and update time over increasing updatable databases sizes (x-axis) for different element sizes (on a log scale) for fixing query time. 5984    33rd USENIX Security Symposium USENIX Association
ElectionGuard: a Cryptographic Toolkit to Enable Verifiable Elections.
[38] by producing a key computed as a sum of individual keys generated by guardians that are shared using a verifiable secret sharing (VSS) protocol. The differences 8Ideally, each guardian will use its own software obtained from a source of its own choosing. with Pedersen’s protocol are that (i) ElectionGuard does not start with a round during which every guardian commits to Ki,0 ( ˆKi,0) and then opens it, (ii) ElectionGuard adds Schnorr proofs for the Ki,j ( ˆKi,j), and (iii) ElectionGuard relies on guardians checking authentic election records instead of sign- ing their key shares. The vast majority of proposed DKG protocols, includ- ing [12, 14, 28, 31, 33, 38] for instance, focus on the honest majority case, which offers robustness. The dishonest majority case has been considered in the context of threshold signa- tures [24,32,34], and ElectionGuard’s DKG may be closest to the one proposed by Komlo and Goldberg for FROST [32]. In the following theorem, we claim the IND-CPA security of ElGamal encryption based on keys produced with the Elec- tionGuard DKG—we refer to the combined scheme as Elec- tionGuard ElGamal. Theorem
1. ElectionGuard ElGamal encryption is IND-CPA secure under static corruption of up to k −1 guardians (1 ≤ k ≤n) if standard ElGamal encryption (performed with the standard single-party key generation) is IND-CPA secure with the same public parameters. The proof of this theorem follows the strategy from Braun et al. [12], adapted to the dishonest majority case. Proof. Let k and n be fixed and define C = {1,...,k−1} and H = {k,...,n}. Assume, w.l.o.g., that the guardians in the set {Gi}i∈C are corrupted, while the others are honest. We design an adversary B against standard ElGamal encryption that wins the IND-CPA game with a probability equal, up to a negligible difference, to the probability that an adversary A controlling the corrupted guardians breaks the IND-CPA security of the ElectionGuard ElGamal encryption. Given A, we design B as follows: when B receives the ElGamal public parameters (Z∗ p,q,g) and the public key K∗ from the standard ElGamal challenger, it forwards the pub- lic parameters to A. B honestly plays the role of all honest guardians, except for Gn. For emulating Gn, it simulates a share of the discrete logarithm of Kn,0 = K∗by picking Pn(i) as a random element of Zq for every i ∈C. It then derives {Kn,i}i∈C so that gPn(i) = ∏k−1 j=0(Kn,j)ij for every i ∈C, by Lagrange interpolation “in the exponent”. B also submits simulated Schnorr proofs for every Kn,i with i ∈{0}∪C. The view of A is distributed in a way that is identical to what it would be in a normal execution of the ElectionGuard ElGamal key generation. B then verifies the guardian records: it checks that all the expected Ki,j values appear in the records, that the share veri- fication succeeds for all the values submitted by A, and that the Schnorr proofs are valid. If any of this fails, B aborts and A loses. If the verification succeeds, B extracts the dis- crete logarithms of the Ki,0 keys for i ∈C by rewinding A appropriately—this can be performed efficiently since it is a single round of extraction. USENIX Association 33rd USENIX Security Symposium    5489 Eventually, when A asks for the encryption of a pair of messages (m0,m1), B forwards it to the ElGamal chal- lenger, who returns a ciphertext (c0,c1) = (gr,mb(K∗)r). B then submits to A the ciphertext (c0,c1(c0)∑n−1 i=1 si) = (gr, mb(∏n i=1 Ki,0)r) where each si is the discrete logarithm of Ki,0, which has either been extracted from the Schnorr proofs or has been selected by B. When A outputs a guess b′ on b, B forwards that guess to the ElGamal challenger. The probabil- ity that b = b′ is exactly the one that A makes a correct guess in the ElectionGuard ElGamal IND-CPA security game. The only possible discrepancy comes from the potential failure to extract a Schnorr proof, which can be made negligible. This protocol works for any quorum k. If a quorum k = n is chosen, the VSS phase of the protocol could be avoided and the DKG could be as simple as asking each guardian to publish its public key together with a Schnorr proof that it knows the corresponding private key, as is done in the Helios voting system for instance [1]. In such a case, each guardian only needs to check that the election public key is indeed the product of a list of public keys that includes its own. In particular, no communication between guardians is needed, which may simplify the key generation ceremony by removing guardian coordination requirements. ElectionGuard chooses to offer a single key generation protocol to keep its specification and election verification as simple and uniform as possible. 2.6 Ballot Preparation A typical ElectionGuard ballot consists of a sequence of ElGa- mal encryptions—usually of either 0 or 1, encoded in expo- nential form to support an additive homomorphism, together with ZK proofs that these encryptions are indeed encryptions of bits. There is one ciphertext per choice on the ballot, and, for most election types, it encrypts 1 if and only if the voter supports the corresponding choice.9 The encrypted tally is computed by multiplying together all ciphertexts correspond- ing to the same choice across all cast ballots. ElectionGuard also supports more general option selection limits and contest selection limits: the former allow a voter to assign a value in a given range to a specific option on the ballot (enabling systems like cumulative voting, range voting, and score voting), and the latter allow the number of options selected by a voter within a specific contest to lie in a specific range (enabling voters to select more than one option in a contest). Again, ElectionGuard largely follows Cramer et al. [20], but makes some important tweaks and additions. 9A blank vote in a contest would be represented by an encryption of 0 for every option. 2.6.1 The ballot nonce For each ballot B, a secret random nonce ξB is chosen in addi- tion to the public random selection encryption identifier idB. As discussed above, idB is used to derive the ballot identifier hash HI, which also incorporates the information related to the election public key and to the election manifest. This identifier hash is used, together with the secret ballot nonce ξB, to derive the randomness ξi,j used to encrypt the voter’s choice for option j of contest i on the ballot: ξi,j = Hq(HI;0x21,i, j,ξB). This approach is useful in several use cases. • Some ElectionGuard-enabled systems can take advan- tage of this nonce to efficiently challenge an encryption operation performed by an untrusted device. In such systems, the device is required to publish a ballot con- firmation code, essentially a hash of all the ciphertexts on that ballot (we will discuss this further below), be- fore the voter decides to cast the ballot. The voter may then choose to challenge the device, in which case the device only needs to provide the 32-byte ballot nonce ξB, which can then be used to re-derive, on a personal device, all the ξi,j values, recompute all the ciphertexts on the ballot, and verify that the ballot confirmation code is actually consistent with the voter’s choices. If a ballot is cast instead of being challenged, the ballot nonce is permanently erased. • Some systems may use an offline ballot marking device (BMD) to print a human readable ballot with the voter’s choices, and to compute and print the ballot confirma- tion code that the voter takes home. As the BMD is offline, there may be no way to transmit the full cipher- texts to the server that publishes the encrypted ballots for verification and in support of the tallying operations. When the paper ballots are anonymous (because they are dropped in a ballot box, for instance), a solution might be to print an encrypted version of ξB on the ballot so that, after scanning and decryption, an election server can recompute all ciphertexts on the ballot with the same randomness as the BMD, supporting the election verifi- cation steps. 2.6.2 Encryption The encryption of a selection σ made by a voter, using randomness ξ derived as explained above, is computed as (α,β) = (gξ,Kξ+σ). Each ElGamal ciphertext is accompa- nied by a proof that it really encrypts a selection σ ∈{0,1} (or, when allowed, in a specified larger domain), which is computed as a disjunctive version of the Chaum-Pedersen protocol [16,19], following a most common choice in voting 5490    33rd USENIX Security Symposium USENIX Association systems [1,4,18,20,40]. The proof is generated by first com- puting a commitment consisting of two ciphertexts (a0,b0) = (gu0,Ku0+σc0) and (a1,b1) = (gu1,Ku1+(σ−1)c1) for random choices of u0,u1,c0,c1 in Zq. Then, a global challenge is computed10 as c = Hq(HI;0x24,α,β,a0,b0,a1,b1) and the selection challenge is updated to cσ = c−c1−σ. Observe that cσ did not play any role in the computation of the commit- ment. Eventually, responses are computed as v0 = u0 −c0ξ and v1 = u1 −c1ξ. The proof consists of (c0,c1,v0,v1) and is verified by checking that (α,β) are elements of the expected subgroup of Zq, recomputing the commitment, recomputing c using H, and verifying that c is the sum of c0 and c1. The ElectionGuard encryption process differs from the tra- ditional encryption method where ciphertexts are computed as (gξ,gσKξ) [1, 4, 18, 20, 40]: this modification has no im- pact on security but reduces the cost of computing the ZK proof from 5 to 4 exponentiations, following an observation by Devillez et al. [22]. The recent literature offers numerous other options for computing these 0-1 encryption proofs, and these often lead to more compact and faster ways to compute proofs—several such methods are also described and com- pared by Devillez et al. [22]. ElectionGuard aims at keeping the programming of an election verifier as simple as possi- ble, and therefore keeps these disjunctive Chaum-Pedersen proofs. In terms of proof size, a proof only takes 1024 bits compared to ciphertexts of 8192 bits, so the relative bene- fits of smaller proofs appear to be marginal. Furthermore, as will be described in the implementation section, the com- putation process can also be made fast enough for practical deployments by relying on other simple techniques, including fixed-base exponentiation methods. 2.6.3 Encryption of more sophisticated ballots The encryption process just described can be used for tradi- tional election methods and approval voting, i.e., contests in which voters can select as many options as they like. Elec- tionGuard supports several other types of contests: • ElectionGuard includes range proofs, which are immedi- ate extensions of the disjunctive proof technique used to demonstrate that a ciphertext encrypts a 0 or a
1. These can be used to prove that a single selection ciphertext is within an arbitrary range [a,b], hence offering support to other types of voting methods, including cumulative voting and Borda count. These can also be used to prove that the product of the selection encryptions of a single contest is within a range, hence proving that a voter se- lected exactly or at most x options in that contest for instance. • ElectionGuard supports contest write-in data, where a voter can enter text in a write-in field instead of select- 10ElectionGuard often hashes more context inputs like contest and selection indices that are omitted here for simplicity. ing a listed option. Here, an extra counter is encrypted for the write-in, and the text itself is encrypted using the secondary ElGamal public key ˆK in the threshold version of Signed ElGamal mode [43], hence offering NM-CPA security just as the security mode used to en- crypt selections [10]. The counter is used to count the number of voters who used the write-in option and, when that number is low enough to guarantee that no write-in candidate could win (which is expected in most cases), the text of the write-ins is simply ignored and never de- crypted. Otherwise, these write-in ciphertexts may be decrypted, providing that they offer sufficient anonymity guarantees. 2.6.4 Confirmation Codes After all selections on a ballot have been encrypted, a con- firmation code is prepared and, in most common use cases, given to the voter. The code is a hash value computed from the sequence of ciphertexts that constitute the encrypted ballot as follows. First, for each contest on the ballot, a contest hash is computed. Specifically, if (αi,βi) is the ciphertext encrypting the i-th selection of the l-th contest (with m options) on the ballot, the contest hash is χl = H(HI;0x28,indc(Λl),α1,β1,α2,β2,...,αm,βm), where indc(Λl) is the unique contest index for the index with label Λl specified by the election manifest. Ciphertexts are hashed in the order specified by the election manifest. All contest hashes are then hashed in the order specified by the election manifest to obtain the confirmation code (assum- ing there are mB contests on the ballot) as HC = H(HI;0x29,χ1,χ2,...,χmB,BC). The last input BC is the chaining field byte array that deter- mines the ballot chaining mode and the additional input for ballot chaining. ElectionGuard offers the option to chain ballots together via dependencies of their confirmation codes. A simple chaining mode would include the confirmation code of the previous ballot that was encrypted on the same device into the compu- tation of the current confirmation code. The chaining field BC is a fixed-length byte array that consists of a chaining mode identifier and the previous confirmation code. This means, the j-th confirmation code computed on a device is H j = H(HI;0x29,χ1,χ2,...,χmB,BC,j), where BC,j = iC ∥H j−1 is the concatenation of the chaining mode identifier iC and the confirmation code H j−1 of the previous ballot computed on the same device. The first ballot encludes an initial hash value that is derived from device information. USENIX Association 33rd USENIX Security Symposium    5491 The goal of this chaining process is similar to that of the one proposed by Sandler and Wallach [41]: to make it eas- ier to detect a modification to any ballot. When ballots are chained, any change in a ciphertext that appears on a ballot would require adapting all subsequent elements of the chain in order to keep the chain consistent and valid. As a result, any voter who verifies a confirmation code linked to a ballot appearing in the original chain after the modified ciphertext was included, would detect the modification. This makes de- tection more likely than in the absence of chaining: without chaining, only the voter holding the confirmation code of the modified ballot is able to detect the modification. The ElectionGuard hashing process to compute confirma- tion codes does not include ZK proofs as inputs, which differs from other systems [1,18]. Including only the ciphertexts is sufficient to commit to the content of the votes and, in some applications, it is convenient to be able to delay the compu- tation of ballot validity proofs to a subsequent step in the election process. Regardless of the chaining mode, the most a typical voter would do is check an election record to ensure that the ex- pected confirmation code is present. The computations to con- firm that confirmation codes are correct are more commonly delegated to election verifiers who, as part of the process of verifying the integrity of an election record, will confirm that each confirmation code in the record is correctly computed. Of course, anyone – including voters – can verify any or all of the contents of an election record. A component of an election verifier can be a single ballot verifier which takes as its input all data used to generate a confirmation code (including, when appropriate, the chaining variable) and confirms the correct computation of a confirma- tion code. A single ballot verifier can be particularly useful when instant verification of challenges is offered to voters (for instance, at a poll site). In this scenario, a voter who chal- lenges a ballot would receive information that would allow an app (perhaps installed on a mobile device) to check that the confirmation code is consistent with the selection made by the voter. It is important to emphasize that since confirmation codes are derived entirely from encryptions of votes, their being given to voters and even their publication in properly de- ployed in-person applications does not in any way compro- mise voter privacy or enable coercion or vote-selling. 2.7 Tally 2.7.1 Update of the Election Record Once voting has concluded, all encrypted ballots consisting of encrypted selections and corresponding ZK proofs of ballot well-formedness are added to the election record, with a clear mark indicating whether each ballot is intended to be included in the tally or is challenged, in which case it is not included in the tally and needs to be individually decrypted. The election record is committed to by the election administrator, and made available for everyone to check, in particular to the guardians who can compare their views of these election records. Again, requiring the administrator to sign the records may help to identify a rogue administrator who would distribute different views of the records to different parties. 2.7.2 Homomorphic tally computation All ZK proofs of well-formedness are verified, the uniqueness of the selection encryption identifiers is verified, and the en- crypted ballots that are intended to be tallied are aggregated to obtain the encrypted tallies. These are computed via the ad- ditive homomorphism of the exponentially encoded ElGamal encryption, that is, they are the componentwise products of all selection encryptions that correspond to the same option across all encrypted ballots containing that contest. 2.7.3 Decryption When all encrypted tallies are available, at least k guardians reconvene together with the election administrator and jointly decrypt every tally for every selection in every contest of the election. Each available guardian Gi uses its private key share P(i) to compute a partial decryption Mi = AP(i) of each given tally ciphertext (A,B). The available partial decryp- tions are combined to obtain the value M = ∏i∈U(Mi)wi, where U ⊆{1,2,...,n} is the set of indices of the available guardians, and the wi for i ∈U are the corresponding La- grange coefficients used to reconstruct the shared secret. The value M is therefore the value that would have been obtained by decrypting with the secret key corresponding to the elec- tion public key K. This secret key remains implicit in all ElectionGuard computations and is never explicitly recon- structed. The value M allows decryption of the tally t via Kt = BM−1 through the computation of a small discrete logarithm that can be computed efficiently (for example using a precomputed ta- ble) because tally values are typically bounded by the number of votes cast, a relatively small number.11 2.7.4 Proof of correct decryption To enable verifiable decryption, the available guardians col- laborate to produce a Chaum-Pedersen proof of correct de- cryption with the secret key corresponding to K. This proof can be computed in a way that is reminiscent of threshold signatures. We suppose that a set U ⊆{1,...,n} of guardians is avail- able for performing the decryption of a ciphertext (A,B) and that |U| ≥k. Each guardian Gi, i ∈U starts by committing to 11In voting methods that allow a voter to place more than one vote on a candidate, the discrete logarithms may be slightly larger, but they are still easily computed. 5492    33rd USENIX Security Symposium USENIX Association the commitment of an individual Chaum-Pedersen proof, by selecting a random ui ←Zq, computing (ai,bi) = (gui,Aui), and sending di = H(HE;0x30,i,A,B,ai,bi,M,U). When Gi has received a dj value from every other guardian G j, j ∈U, it sends the pair (ai,bi). After receiving the (aj,bj) from the other guardians, it then checks that dj was computed correctly for all j ∈U and halts if any of these verification steps fail. This round of commit-reveal guarantees that cor- rupted guardians are unable to select their (ai,bi) pairs as a function of the pairs of the honest guardians, and that the product (a,b) = (∏i∈U ai,∏i∈U bi) is uniformly distributed as long as one of the guardians Gi, i ∈U is honest. After these verification steps, the proof challenge is com- puted as c = Hq(HE;0x31,A,B,a,b,M). Each guardian Gi (i ∈U) can then use the i-th Lagrange coefficient wi to com- pute an adjusted challenge ci = c·wi mod q and an individ- ual response vi = ui −ciP(i) mod q. The final response is computed as v = ∑i∈U vi mod q, and the decryption proof is the pair (c,v). Note that v = ∑i∈U ui −c∑i∈U wiP(i) = ∑i∈U ui −c·s mod q, but again, the secret election key s has not been explicitly reconstructed to compute this proof. If the proof is valid, that is, if v ∈Zq and if c can be correctly recomputed as above, using a = gvKc and b = AvMc, then it is published in the election record. It would have been more direct for each guardian to pub- lish an independent Chaum-Pedersen proof that it computed its partial decryption accurately. However, as ElectionGuard aims at making election verification as simple as possible, the present protocol, which is more complex for the guardians, offers the central benefit of making the role and identity of the participating guardians completely invisible to an election verifier. From the verifier perspective, the decryption proof is one single Chaum-Pedersen proof. It can be observed that this protocol is very similar to the Sparkle threshold signature protocol [21]. Its security analysis partly follows similar arguments. First, we can observe that the protocol is sound: since it produces valid Chaum-Pedersen proofs, it follows that it has the same special soundness prop- erty and that obtaining two executions with the same commit- ments but two different challenges and valid responses makes it possible to extract the unique value s such that K = gs and M = As. We can also show that honest guardians do not reveal any information by computing the Chaum-Pedersen proof as described above. We believe this approach of combining zero-knowledge proofs of partial decryptions into a single zero-knowledge proof of complete decryption to be novel. It is especially valuable under threshold conditions where some partial de- cryptions may not be available, and it completely removes one of the greatest challenges for verifiers, which is the handling of missing guardians and the associated Lagrange coefficients. This approach may have application outside of the domain of elections. Theorem
1. Cast-as-intended verifiability makes it possible for a voter to verify that the selections made by the voter have been properly recorded. USENIX Association 33rd USENIX Security Symposium    5493
1. The guardian software must verify that the cryptographic parameters that are used offer the expected security level. This avoids accepting primes that would be too small for instance.
2. Guardians must check the guardian record at the end of the key generation phase: they must be certain that the published view of the key generation process is consis- tent with their own. This prevents a rogue administrator from replacing a guardian’s key, or from subverting a guardian’s key by sending malicious messages during the key generation process. 12Cryptographic means cannot ensure that there are no cameras hidden behind voters recording their actions. 5494    33rd USENIX Security Symposium USENIX Association
3. Guardians must check that the ciphertexts they decrypt are those listed for decryption in the election record. This prevents a rogue administrator from asking for the de- cryption of individual cast ballots for instance. Guardians should also verify that ballots have been aggregated cor- rectly and that all ballots have a unique selection encryp- tion identifier and correct validity proofs. Though the latter task may be delegated to others, it must be verified before guardians engage in any decryption. 2.8.4 Verification software In order to perform all these verification steps, voters, guardians and observers should use software that offers as much independence as possible. For instance, if the goal is to detect a malicious election administrator, it makes no sense to blindly trust software provided by the election administrator to perform these verification steps. Public code and avail- ability of software from multiple sources are two important features for a meaningful use of ElectionGuard, and the Elec- tionGuard website13 offers links to six independent verifiers (as well as one independent port of the full ElectionGuard implementation). 2.9 Trust With the design described herein, privacy of ballots is de- pendent upon the cryptographic assumption that standard ElGamal encryption is IND-CPA secure as shown in Theo- rem 1 together with an assumption that the device on which the ElectionGuard application performing ballot encryption (such as an in-precinct ballot scanner) maintains ballot privacy. These assumptions need to be paired with necessary physi- cal assumptions about any particular use case. Cryptography cannot prevent strategically-placed cameras or key-loggers from learning the inputs of voters.14 A principal goal of Elec- tionGuard—as a technology that is intended to augment but not replace existing voting methods—is to add verifiability without materially weakening privacy. What ElectionGuard achieves is the ability for voters and observers to verify the accuracy of election results with min- imal trust—and critically with no trust at all in election ad- ministrators or any other specific entities (such as device man- ufacturers or software implementers). There is a very weak assumption on the collision resistance of the SHA-256 hash function (essentially that an adversarial agent should not be able to produce two distinct votes or ballots with the same hash). Beyond this, voters and observers may proxy their trust as they wish to one or more verifiers of their choosing or they may instead choose to write their own verifiers and confirm the integrity of the results entirely on their own. 13https://www.electionguard.vote 14It may be possible to use code voting to add a layer of indirection so that a voter’s inputs do not reveal the voter’s selections. Confidence in an election result requires confidence that the ballots being counted are genuine. A single, digitally- signed election record allows all voters to confirm that their votes are properly included. The discovery of two distinct signed election records immediately implicates the election administrator who published those records as maleficent. An interesting challenge in some applications is so-called eligibility verification—ensuring that all votes are cast by voters who are eligible to vote and do not vote more of- ten than allowed. In the U.S. and many other countries, the list of voters who cast ballots in any jurisdiction is a mat- ter of public record. Eligibility is thereby achieved entirely through publicly-verifiable processes that are entirely outside the scope of ElectionGuard, and the only intersection is for in- terested parties to confirm that the number of ballots cast does not exceed the number of voters listed. There is an expecta- tion that interested parties will scrutinize this list for fictitious voters and for voters who are listed as voting but who did not do so. When voting is in-person, observers can simply count the number of voters present. But these measures are beyond the scope of ElectionGuard. When the list of voters is not public, it is very difficult for observers to verify that insiders did not add additional ballots to the count and inflate counts of the number of voters. 3 Preferred Uses The primary intended use of ElectionGuard is for in-person poll-site voting. But there are many possible designs that are compatible with a wide variety of equipment. Additionally, many elections offer different modes of voting. For exam- ple, hand-marked paper ballots for in-person voters together with machine-marked ballots for voters with disabilities that prevent them from marking physical ballots, together with mailed ballots for voters who are not able to vote in person. To be effective, ElectionGuard must enable all of these and other modes of voting in a single election. There are even ap- plications in which voters are not present and ballot contents are encrypted administratively. In all applications, an election using ElectionGuard begins with a key-generation ceremony in which an election admin- istrator works with guardians to form election keys. Later, usually at the conclusion, the administrator will again work with guardians to produce verifiable tallies. What happens in between, however, can vary widely. 3.1 Precinct Ballot Scanners An ideal use of ElectionGuard is on precinct-based ballot scanners. An in-person voter can mark a ballot—either by hand or by using a ballot-marking device—and then feed the ballot into a scanner which may read the contents of the ballot, display the contents as it interpreted them, and print a confirmation code for the voter. USENIX Association 33rd USENIX Security Symposium    5495 Once in possession of the paper confirmation code, the voter can choose to either accept the scanner’s interpretation of the ballot contents and cast the ballot or instead challenge the ballot. A challenged ballot is marked as cancelled and the confirmation code is opened15 by the scanner.16 A voter who challenges a ballot can then restart the voting process by marking a fresh ballot. Both cast and challenged ballots will be part of the election record. 3.2 Electronic Ballot Markers ElectionGuard could instead be hosted by ballot marking de- vices. In one flow, a voter could make selections directly on an electronic (usually touch-screen) device which would then print a confirmation code and allow a voter to either cast the ballot or challenge the ballot and restart. In another flow, a ballot marking device which can neither store ballot encryptions nor transmit them within a LAN could use the ballots themselves to convey encryptions by printing an encoding of the encryption directly onto a paper ballot.17 3.3 Vote by Mail Pre-encrypted ElectionGuard ballots could be mailed to voters using the STROBE paradigm [3]. These paper ballots would have short codes printed beside each possible selection and voters could record short codes associated with their selections and check later to ensure that they appear correctly in the election record. Unreturned ballots could serve as challenge ballots and would be opened to show that their short codes and associated confirmation codes are correct. 3.4 Internet Voting Although not recommended for public elections18, Elec- tionGuard could be used for Internet voting in a manner very similar to Helios [1]. Voters would make their selections on- line, receive confirmation codes, and then choose to either cast or open their ballots. The Helios model allows voters to prepare as many ballots as they wish—with only the last cast ballot counting. 3.5 Risk-Limiting Audits ElectionGuard can also be used to protect voter privacy in risk-limiting audits (RLAs). 15This is accomplished by providing a verifiable decryption to demonstrate that the confirmation code is consistent with the voter’s selections. 16It is also possible for challenged confirmation codes to be opened as part of the subsequent tally decryption ceremony. 17To save space, a symmetric encryption of a nonce could be recorded onto a paper ballot to allow a full encryption to be regenerated later. 18For a discussion of Internet voting, see the U.S. National Academies report at https://nap.nationalacademies.org/catalog/25120 The most efficient post-election RLAs are ballot- comparison audits which operate as follows. The contents of each ballot are published together with ballot identifiers that match identifiers on corresponding paper ballots. Ballots are randomly selected from the published record and matched against the stored paper ballots to show that the stored ballots are consistent with announced tallies. A major problem with ballot-comparison audits is that publication of ballot contents can compromise voter privacy. Voters can be coerced or sell their votes by completing a less important part of their ballots according to unusual pre- determined patterns that are likely to be unique within a voting precinct. This allows each ballot—including the remaining selections—to be associated with specific voters. Following the VAULT paradigm of [9], ElectionGuard can be used to post encrypted versions of all ballots cast and to prove that these encrypted ballots are consistent with an- nounced tallies. Randomly-selected ballots are decrypted and matched with corresponding paper ballots. These decryptions do not compromise voter privacy since coerced voters can simply claim that their assigned patterns did not appear be- cause they were not among those that happened to be selected for audit. In this application, ballots are encrypted administratively, and confirmation codes are not needed. 3.6 Other Uses The above examples are just a sample of the wide variety of ways in which ElectionGuard can be used. The flexibility of ElectionGuard is novel and is one of its primary benefits. It is important to note, however, that merely using the Elec- tionGuard tools does not ensure that an election’s results will be publicly verifiable. There have, for example, been instances where users have sought to require voters to announce in ad- vance when they intended to challenge a ballot or to even eliminate the challenge process entirely. For at least the near future, it is important to include experts in the process of deciding how ElectionGuard will be used in any new deployments. 4 Implementations Since its original specification in 2019 [6], there have been several implementations of ElectionGuard that have been used in various applications and pilot elections. Early implemen- tations by various contributors included a Python reference implementation of the full ElectionGuard 1.0 specification, an encryption engine in C++ with C# bindings, implemen- tations in Haskell, Java, and TypeScript. More recently, we have implemented ElectionGuard 2.0 in Kotlin and Rust. This section discusses some of the lessons learned from building these implementations. 5496    33rd USENIX Security Symposium USENIX Association 4.1 Performance Unsurprisingly, the modular exponentiation at the heart of most ElectionGuard operations imposes the highest computa- tional cost among all computations and is the limiting factor in any performance analysis. Using fast libraries for modular arithmetic is crucial to achieve good performance so that la- tency due to ballot encryption and ZK proof generation does not impact usability in the voting place. For code running on the Java virtual machine (including Kotlin), or on Android, Java’s BigInteger class is the obvi- ous choice. For Python, it is straightforward to use GnuMP, which has hand-tuned assembly routines. Inside a browser, modern JavaScript engines have a native bigint type which is also very performant. The Kotlin code when targeting “na- tive” code rather than the JVM, uses Microsoft’s HACL* [11]—a performant C implementation of a wide variety of cryptographic primitives which have been formally verified for correctness. Fixed-base modular exponentiation. Most exponentia- tions in ElectionGuard have a fixed base, either the generator g or the election public key K. It is well-known [36, §14.6.3] that using pre-computed tables of certain powers of these bases makes encryption and proving operations substantially faster, as shown in the election context by Devillez et al. [22]. To compute gx, one parses x in groups of k bits, e.g., for 8-bit groups, gx = gx0−7g(x8−15)≪8g(x16−23)≪16 ···. If x has ℓbits, a precomputed table with all values g2ki·j for 0 ≤i < ⌈ℓ/k⌉, 0 ≤j < 2k, turns the computation of gx into a series of table lookups and multiplications. Using larger k leads to larger tables (O(2k) memory usage), but reduces the number of mul- tiplications. In the original Python implementation, 8-bit tables yielded a 5.1x performance improvement for encryption. 13-bit tables yielded a 7.4x improvement. 16-bit tables yielded an 8.6x improvement. (Measurements taken on a 2013 MacPro with a 3.5GHz Intel Xeon.) Verification operations do make some use of the generator g, but otherwise have variable bases, so we only see improvements of 1.6x-1.7x. It is standard practice to use Montgomery multiplica- tion
[37] for implementing modular multiplication of large integers. In particular, entries in pre-computed tables should be directly provided in Montgomery form to avoid the costly conversion. HACL* provides the necessary primitives, giving a 2.5x performance improvement. Using base-K encoded ElGamal encryption. As men- tioned above in §2.6.2, using the public election key K as the base to encode voter selections for ElGamal encryption saves one exponentiation when encrypting the selection and generating the ZK proof of well-formedness. In our imple- mentations, we observed a 13% speedup as expected. Compact Chaum-Pedersen proofs. To keep memory re- quirements for the ZK proofs low, it is important to use the compact representation for proofs consisting of challenge and response values instead of including the commitments as well. Commitments have a large size of 512 bytes (4096-bit values), but they do not need to be stored as they can be recomputed from the challenge and response values, which only are 32 bytes in size each. Side-channel attacks. Side-channel attacks on crypto- graphic operations are generally less of a threat for voting devices than with other applications. A poll site presents many more direct opportunities for an attacker to obtain a voter’s selections. Nevertheless, implementations should be made side-channel resistant whenever practical. 4.2 Latency Voter-perceived latency certainly needs to be considered, par- ticularly if the voting device has a slow CPU. Luckily, beyond the optimizations discussed above, there are a variety of other options to hide this latency. For example, we also enable a precomputation approach since most of the computation for encrypting selections and generating the ZK proofs is inde- pendent of the voter’s selections. 4.3 Compatibility Every implementation of the ElectionGuard specification should be compatible with other implementations. The design specification only specifies the cryptographic operations in detail. In particular early on, the lack of a concrete implemen- tation specification meant that implementation specifics were developed dynamically while several implementation efforts were underway. This naturally lead to challenges for agreeing on the specifics of data serialization into the JSON format. For example, the Python implementation initially used a base-64 encoding of cryptographic values into JSON strings, which was problematic for the C++ implementation. This lead to a less efficient hexadecimal encoding. Later on, the Kotlin implementation supported Google’s Protocol Buffers, for an efficient binary representation, while the Rust code supported MongoDB’s BSON (a binary variant of JSON). The initial under-specification of how inputs to the cryp- tographic hash function should be serialized in the original version 1.0 specification has created unnecessary complica- tions for achieving compatible implementations. 4.4 Scalability The original definition of ElectionGuard specified a singular JSON election record. This was a problem for the Voting- Works implementation of VAULT [5], which was meant to read the tabular output of a plain paper ballot scanner and USENIX Association 33rd USENIX Security Symposium    5497 produce a public bulletin board with as many as a million encrypted ballots. Getting the necessary throughput required running on about 1000 CPU cores. Fundamentally, ElectionGuard encryption is a CPU-bound operation. It is easy to express the encryption of a million bal- lots in any sort of data-parallel (e.g., MapReduce) paradigm, and as such, it is straightforward to scale the encryption throughput across multiple cores or multiple machines. The challenges come afterward. Before we had all the optimiza- tions described above, each encrypted ballot was roughly 1MB of JSON data, so a million ballots required a terabyte of storage. On a cloud storage system like AWS S3, scalable read or write performance can only be achieved if your data is spread across multiple separate subdirectories, due to the way these systems do sharding. We ultimately settled on a design using one file per ballot, and building a Merkle tree into the directory structure, so any individual ballot can be verified without needing to read the full terabyte of data. This is what was used in the Inyo County pilot (see Section 6.2). It will be necessary to allow for bulk storage and for effi- cient verification operations (e.g., voters, given receipts with the hashes of their ciphertext and knowledge of the root hash of the entire election, should be able to verify their ballots’ correct representation in the election record without needing to read and process a terabyte of data). 5 In-Person Voting While ElectionGuard has proven to be very flexible and usable in a wide variety of voting scenarios (e.g., in-person, mail- in, and Internet), the primary intent is for it to be used for in-person poll-site voting. Even within the in-person setting, ElectionGuard can be used in many different ways: with hand-marked and/or machine-marked ballots, on ballot scanners, on ballot printers, or on ballot-marking devices. We describe in detail here a preferred scenario which matches the use of ElectionGuard in some of the deployments listed in section 6. In an ideal setting, the ElectionGuard ballot encryption soft- ware can be housed on a ballot scanner located in a voting precinct. The use of precinct-based scanners has become com- mon in the U.S. because of their reliability and flexibility (they can generally read either hand-marked or machine-marked ballots or a combination). Both the Idaho and Maryland de- ployments described in section 6 used the Hart Intercivic Verity ballot scanner which included both a display and a thermal printer. Upon completing a paper ballot—either by hand or using a ballot-marking device—a voter feeds the paper ballot into the ballot scanner. After reading the contents of the ballot, the scanner displays its interpretation of the ballot contents and also calls the embedded ElectionGuard application with these same ballot contents. The ElectionGuard application encrypts these contents and returns a confirmation code which is printed for the voter. (N.b., the confirmation code is derived from the encryption of the voter selections and in no way reveals the selections themselves.) The voter collects the paper confirmation code and reviews the selections displayed on the screen. The voter may either indicate approval of the ballot— in which case the paper ballot is mechanically dropped into a bin beneath the scanner—or cancel the ballot—which causes the paper ballot to be returned to the voter. If the ballot is cancelled, the voter may make changes directly on the paper ballot or visit a poll-worker to obtain a fresh blank ballot or authorization to start again on a ballot-marking device. Confirmation codes from cancelled ballots will be opened and serve to ensure correctness of the system as in [2]. The contents of cancelled ballots will be published in the election record together with additional data to enable verifiers to confirm that they match the given confirmation codes. It is also possible for voters to use personal apps from sources of their choosing together with supplemental data provided when a ballot is cancelled to instantly confirm that the confirmation code matches the voter’s selections.19 6 Deployments and Other Use Cases One of the principal benefits of the ElectionGuard toolkit model is its flexibility. This is shown by the variety of use cases seen in the deployments described in this section. 6.1 Wisconsin The first use of ElectionGuard in a public election occurred in February of 2020 in the town of Fulton, Wisconsin. In Fulton, Microsoft partnered with VotingWorks20 to deploy a system with five ballot-marking devices, a single ballot printer that was controlled by a laptop which also hosted the ElectionGuard vote encryption tools, and a ballot scanner. Voters made their selections using one of the touchscreen ballot-marking devices and each voter’s selections were writ- ten onto a smart card. Upon completing the selection process, a voter would take the smartcard to the printing station which would process the selections, call the ElectionGuard software, and print an ordinary ballot with the voter’s selections and, on a separate yellow sheet, an ElectionGuard confirmation code. The voter would then have the option of either scanning the printed ballot or taking it to a poll worker to challenge the ballot and restart the voting process. In either case, the yellow sheets containing confirmation codes could be retained by the voters. In Fulton, 398 voters cast ballots, and 4 ballots were chal- lenged. After the ElectionGuard tallies were computed and released, a hand count of the paper ballots was initiated to confirm the results. The hand counted tally differed by 1 vote 19This instant verification feature was not available in recent deployments in Idaho and Maryland. 20https://www.voting.works/ 5498    33rd USENIX Security Symposium USENIX Association from the ElectionGuard tally. But after a hand recount, it was discovered that one of the paper ballots had been put in the wrong pile, and once this was corrected, the results matched perfectly. 6.2 California The next use of ElectionGuard in a public election was in November of 2020 in Inyo County, California [5]. But, unlike in Wisconsin, it was not part of the voting but instead part of the auditing process. California requires post-election audits of paper ballots to confirm that they are consistent with any machine counts that may have been done. The best modern audits, ballot-comparison Risk-Limiting Audits (RLAs) [35], typically begin by publishing the contents of every ballot and then perform random sampling to show that the published contents match the paper ballots. The concern about ballot-comparison audits is that publi- cation of ballot contents—even without any indication of the voters who cast each ballot—can compromise voter privacy.21 The work in
[9] shows how the tools used to achieve E2E- verifiability can also be used to conduct a ballot-comparison RLA without revealing raw ballot contents. In Inyo County, California, ballot contents were encrypted by VotingWorks using ElectionGuard, and these encryptions were published instead of raw ballot contents. An election record was published to show that these encrypted ballots matched the announced tallies, and any ballot selected for au- diting was decrypted and matched against the corresponding paper ballot.22 6.3 U.S. Congress Shortly after the November 2020 U.S. general election, the respective political parties in the U.S. Senate and House of Representatives met to elect their leadership. At that time, the COVID-19 pandemic was a great concern, and discus- sions began between the U.S. House Democratic caucus and Microsoft about enabling leadership elections to be held re- motely. While Congressional votes are public, the internal caucus elections are held by secret ballot, and ElectionGuard therefore provided a possible solution. Internet voting poses many challenges, and although E2E- verifiability can mitigate many of these challenges, it does not offer a solution that is suitable for public elections
[27] – 21On a ballot with many contests and questions (as is typical in California), a voter can be instructed to make a very specific set of selections which is likely to be unique amongst all ballots cast within a precinct or jurisdiction. If the contents of each ballot are published, a coercer or vote-buyer can inspect the list of published ballot contents to ensure that a ballot matching the specific instructions is present. 22It is important to note that the small number of ballots that were de- crypted and revealed do not enable coercion since a coerced voter can simply assert that the instructed ballot contents did not appear amongst the set of pub- lished raw votes because that ballot was, evidently, not amongst the audited ballots. it does nothing to protect the voting servers from large scale attacks for instance. Microsoft did a careful analysis of this scenario and concluded that for various reasons—including the small number of voters, the opportunity for direct voter education, the secondary channel available to each voter to confirm vote receipt, and, most importantly, the centrally man- aged mobile phones held by each voter—that this was an ap- propriate use of the ElectionGuard technology and partnered with Markup23 to build a customized solution for the U.S. House Democratic caucus.24 House members downloaded a custom application onto their managed mobile devices which they used to make their selections of candidates for offices such as Speaker, Majority Leader, and Whip. Upon making their selections, each House member received a confirmation code and could choose to either cast the ballot or challenge it to verify that it reflected the selections that were made. After each round of voting, the lists of candidates were shortened and a new vote was conducted until a single winner was determined for each lead- ership position. The record of each round of voting was made available internally to House members and their staffs to en- able verification. 6.4 Idaho Starting in 2021, Microsoft partnered with election vendor Hart InterCivic25 to integrate ElectionGuard into their vot- ing equipment. The first public use of the Hart equipment with ElectionGuard took place in Preston, Idaho in the gen- eral election of November of 2022. Although the design was unchanged, numerous efficiency improvements were made to accommodate the Hart requirements, and new capabilities were added to meet their particular needs. MITRE Corpora- tion26 built its own independent verifier of the election record and took it to Preston to perform an immediate verification of the election record. Voters had the choice to use ballot marking devices (which print paper ballots marked according to voter selections) or to fill out paper ballots by hand. Voters then had the option to insert their paper ballots into a traditional ballot scanner or a ballot scanner enhanced with ElectionGuard which provided a confirmation code for each vote on thermal paper. In either case, voters had an opportunity to review the scanners’ inter- pretations of the selections on their ballots and could choose at that time to challenge their ballots and have the paper ballot returned. Voters could take challenged ballots to a poll worker and restart the voting process. In all, 111 voters in Preston chose to cast their votes on the ballot scanner enhanced with ElectionGuard. 23https://www.markuplabs.com/ 24This tool was also offered to the House Republican caucus and both Senate caucuses. 25https://www.hartintercivic.com/ 26https://www.mitre.org/ USENIX Association 33rd USENIX Security Symposium    5499 6.5 Utah Utah statute has allowed some voters to return ballots elec- tronically since 2006. In the November 2023 general election, Enhanced Voting27 used ElectionGuard to add integrity to this process in a Congressional special election and several local elections. Ballots that were electronically transmitted were also encrypted and tallied with ElectionGuard to verify that the tally had not been altered. 514 ballots across the state were processed with ElectionGuard. 6.6 Maryland In November of 2023, ElectionGuard was used for munici- pal elections in College Park Maryland. Hart conducted this election with similar equipment to that used in Preston, Idaho. Although by this time, most, but not all, of the ElectionGuard version 2 features had been implemented. MITRE corporation revised their independent verifier to match the new features of this version and again ran their verifier immediately after the election. All 1468 voters in this election had their votes encrypted with ElectionGuard. 6.7 Neuilly-sur-Seine Since late 2021, ElectionGuard has been used by Electis28 for civic voting in the Paris suburb of Neuilly-sur-Seine.29 This is a blockchain-based voting system of a kind explicitly recom- mended against by sources like the U.S. National Academies report.30 However, ElectionGuard is open-source and may be used by anyone without payment or permission, and its use here demonstrates its broad applicability. 6.8 Concordium Concordium31 is a blockchain company based in Switzerland and Denmark. Its June 2024 internal elections32 used its own Rust implementation of ElectionGuard. Here, the fact that an independent company did its own implementation demon- strates both the applicability and appeal of the ElectionGuard design. 27https://www.enhancedvoting.com/ 28https://electis.com 29https://xtz.news/adoption/the-neuilly-sur-seine-municipal-youth- council-elections-have-been-completed-using-the-tezos-based-voting- application-electis/ 30https://nap.nationalacademies.org/catalog/25120/securing-the-vote- protecting-american-democracy 31https://www.concordium.com/ 32https://medium.com/@concordium/concordiums-on-chain-voting- protocol-40d4aaafa880 6.9 Lessons User surveys were conduced at the end of several Elec- tionGuard deployments.33 These deployments happened in very different contexts, and were often accompanied by other important changes in the elections, like the introduction of electronic voting. As a result, it is hard to draw strong lessons, and more surveys in similar settings are needed. At this stage, surveys showed that voters and poll workers expressed a strong increase in confidence in the accuracy of the election results when using ElectionGuard. In the eyes of technical experts observing the deployments, the key man- agement by the guardians appears to be a central aspect that should motivate further research: the current deployments had guardians essentially blindly follow instructions provided by the election organizers, using software and hardware pro- vided by these same organizers. Better ways of achieving independence in practice are needed. 7 Conclusions As can be seen from the wide variety of scenarios described above, ElectionGuard has proven to be a very versatile design. When used in its primary application, ElectionGuard gives voters the ability to confirm on their own that their votes have been accurately counted—whether cast in-person, by mail, or online—without having to trust anyone or anything out of their control. ElectionGuard can also be used to protect voter privacy in post-election risk-limiting audits. ElectionGuard also introduces new cryptographic ap- proaches of independent interest that make ElectionGuard a flexible, efficient, and easy to use toolkit with numerous applications.
K-Waay: Fast and Deniable Post-Quantum X3DH without Ring Signatures.
[1] Shweta Agrawal, Damien Stehlé, and Anshu Yadav. Round-optimal lattice-based threshold signatures, re- visited. In ICALP, volume 229 of LIPIcs, pages 8:1– 8:20. Schloss Dagstuhl - Leibniz-Zentrum für Infor- matik, 2022.
[2] Jacob Alperin-Sheriff and Chris Peikert. Circular and KDM security for identity-based encryption. In Public Key Cryptography, volume 7293 of Lecture Notes in Computer Science, pages 334–352. Springer, 2012.
[3] Joël Alwen, Bruno Blanchet, Eduard Hauck, Eike Kiltz, Benjamin Lipp, and Doreen Riepel. Analysing the hpke standard. In EUROCRYPT 2021, pages 87–116. Springer, 2021.
[4] Joël Alwen, Sandro Coretti, and Yevgeniy Dodis. The double ratchet: Security notions, proofs, and modular- ization for the signal protocol. In EUROCRYPT, pages 129–158. Springer, 2019.
[5] Christoph Bader, Dennis Hofheinz, Tibor Jager, Eike Kiltz, and Yong Li. Tightly-secure authenticated key exchange. In Yevgeniy Dodis and Jesper Buus USENIX Association 33rd USENIX Security Symposium    447 Nielsen, editors, Theory of Cryptography - 12th The- ory of Cryptography Conference, TCC 2015, Warsaw, Poland, March 23-25, 2015, Proceedings, Part I, vol- ume 9014 of Lecture Notes in Computer Science, pages 629–658. Springer, 2015.
[6] Mihir Bellare. New proofs for nmac and hmac: Security without collision-resistance. In CRYPTO 2006, pages 602–619. Springer, 2006.
[7] Mihir Bellare and Phillip Rogaway. Random oracles are practical: A paradigm for designing efficient protocols. In CCS, pages 62–73. ACM, 1993.
[8] Daniel J Bernstein. Curve25519: new diffie-hellman speed records. In International Workshop on Public Key Cryptography, pages 207–228. Springer, 2006.
[9] Ward Beullens, Shuichi Katsumata, and Federico Pin- tore. Calamari and falafl: Logarithmic (linkable) ring signatures from isogenies and lattices. In ASIACRYPT (2), volume 12492 of Lecture Notes in Computer Sci- ence, pages 464–492. Springer, 2020.
[10] Alexander Bienstock, Jaiden Fairoze, Sanjam Garg, Pratyay Mukherjee, and Srinivasan Raghuraman. A more complete analysis of the signal double ratchet al- gorithm. In Yevgeniy Dodis and Thomas Shrimpton, editors, CRYPTO 2022, volume 13507 of Lecture Notes in Computer Science, pages 784–813. Springer, 2022.
[11] Dan Boneh, Özgür Dagdelen, Marc Fischlin, Anja Lehmann, Christian Schaffner, and Mark Zhandry. Ran- dom oracles in a quantum world. In ASIACRYPT, vol- ume 7073 of Lecture Notes in Computer Science, pages 41–69. Springer, 2011.
[12] Joppe W. Bos, Craig Costello, Léo Ducas, Ilya Mironov, Michael Naehrig, Valeria Nikolaenko, Ananth Raghu- nathan, and Douglas Stebila. Frodo: Take off the ring! practical, quantum-secure key exchange from LWE. In CCS, pages 1006–1018. ACM, 2016.
[13] Joppe W. Bos, Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyubashevsky, John M. Schanck, Peter Schwabe, Gregor Seiler, and Damien Stehlé. CRYSTALS - ky- ber: A cca-secure module-lattice-based KEM. In 2018 IEEE European Symposium on Security and Privacy, EuroS&P, pages 353–367, 2018.
[14] Katharina Boudgoust, Corentin Jeudy, Adeline Roux- Langlois, and Weiqiang Wen. On the hardness of module-lwe with binary secret. In CT-RSA, volume 12704 of Lecture Notes in Computer Science, pages 503– 526. Springer, 2021.
[15] Zvika Brakerski, Adeline Langlois, Chris Peikert, Oded Regev, and Damien Stehlé. Classical hardness of learn- ing with errors. CoRR, abs/1306.0281, 2013.
[16] Jacqueline Brendel, Rune Fiedler, Felix Günther, Chris- tian Janson, and Douglas Stebila. Post-quantum asyn- chronous deniable key exchange and the signal hand- shake. In Goichiro Hanaoka, Junji Shikata, and Yohei Watanabe, editors, Public-Key Cryptography - PKC 2022 - 25th IACR International Conference on Prac- tice and Theory of Public-Key Cryptography, Virtual Event, March 8-11, 2022, Proceedings, Part II, volume 13178 of Lecture Notes in Computer Science, pages 3–
34. Springer, 2022.
[17] Jacqueline Brendel, Marc Fischlin, Felix Günther, Chris- tian Janson, and Douglas Stebila. Towards post-quantum security for signal’s X3DH handshake. In SAC, volume 12804 of Lecture Notes in Computer Science, pages 404– 430. Springer, 2020.
[18] Ran Canetti, Palak Jain, Marika Swanberg, and Mayank Varia. Universally composable end-to-end secure mes- saging. In Yevgeniy Dodis and Thomas Shrimpton, editors, CRYPTO 2022, volume 13508 of Lecture Notes in Computer Science, pages 3–33. Springer, 2022.
[19] Ran Canetti and Hugo Krawczyk. Security analysis of ike’s signature-based key-exchange protocol. In CRYPTO 2002, pages 143–161. Springer, 2002.
[20] Wouter Castryck and Thomas Decru. An efficient key recovery attack on sidh. In Annual International Confer- ence on the Theory and Applications of Cryptographic Techniques, pages 423–447. Springer, 2023.
[21] Wouter Castryck, Tanja Lange, Chloe Martindale, Lorenz Panny, and Joost Renes. CSIDH: an efficient post-quantum commutative group action. In Thomas Peyrin and Steven D. Galbraith, editors, ASIACRYPT 2018, volume 11274 of Lecture Notes in Computer Sci- ence, pages 395–427. Springer, 2018.
[22] Katriel Cohn-Gordon, Cas Cremers, Benjamin Dowling, Luke Garratt, and Douglas Stebila. A formal security analysis of the signal messaging protocol. J. Cryptol., 33(4):1914–1983, 2020.
[23] Katriel Cohn-Gordon, Cas Cremers, Kristian Gjøsteen, Håkon Jacobsen, and Tibor Jager. Highly efficient key exchange protocols with optimal tightness. In CRYPTO 2019, pages 767–797. Springer, 2019.
[24] Daniel Collins, Simone Colombo, and Loïs Huguenin- Dumittan. Real world deniability in messaging. Cryp- tology ePrint Archive, 2023.
[25] Daniel Collins, Loïs Huguenin-Dumittan, Ngoc Khanh Nguyen, Nicolas Rolin, and Serge Vaudenay. K-waay: Fast and deniable post-quantum x3dh without ring sig- natures. Cryptology ePrint Archive, 2023. 448    33rd USENIX Security Symposium USENIX Association
[26] Cas Cremers and Michele Feltz. One-round strongly secure key exchange with perfect forward secrecy and deniability. Cryptology ePrint Archive, Paper 2011/300, 2011.
[27] Cas Cremers and Mang Zhao. Secure messaging with strong compromise resilience, temporal privacy, and im- mediate decryption. In IEEE S&P, 2024.
[28] Dana Dachman-Soled, Léo Ducas, Huijing Gong, and Mélissa Rossi. LWE with side information: Attacks and concrete security estimation. In CRYPTO (2), volume 12171 of Lecture Notes in Computer Science, pages 329– 358. Springer, 2020.
[29] Dana Dachman-Soled, Huijing Gong, Tom Hanson, and Hunter Kippen. Revisiting security estimation for lwe with hints from a geometric perspective. In Helena Handschuh and Anna Lysyanskaya, editors, CRYPTO 2023, pages 748–781, Cham, 2023. Springer Nature Switzerland.
[30] Whitfield Diffie and Martin E. Hellman. New directions in cryptography. IEEE Trans. Inf. Theory, 22(6):644– 654, 1976.
[31] Samuel Dobson and Steven D. Galbraith. Post-quantum signal key agreement from SIDH. In Jung Hee Cheon and Thomas Johansson, editors, Post-Quantum Cryptog- raphy - 13th International Workshop, PQCrypto 2022, Virtual Event, September 28-30, 2022, Proceedings, vol- ume 13512 of Lecture Notes in Computer Science, pages 422–450. Springer, 2022.
[32] Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyuba- shevsky, Peter Schwabe, Gregor Seiler, and Damien Stehlé. Crystals-dilithium: A lattice-based digital sig- nature scheme. IACR Trans. Cryptogr. Hardw. Embed. Syst., 2018(1):238–268, 2018.
[33] Cynthia Dwork, Moni Naor, and Amit Sahai. Concur- rent zero-knowledge. Journal of the ACM (JACM), 51(6):851–898, 2004.
[34] Muhammed F. Esgin, Ron Steinfeld, and Raymond K. Zhao. Matrict+: More efficient post-quantum private blockchain payments. In IEEE Symposium on Security and Privacy, pages 1281–1298. IEEE, 2022.
[35] BSI German Federal Office for Information Security. Bsi tr-01102-1, 2023. https://www.bsi.bund.de/ SharedDocs/Downloads/EN/BSI/Publications/ TechGuidelines/TG02102/BSI-TR-02102-1.html.
[36] Lachlan J Gunn, Ricardo Vieitez Parra, and N Asokan. Circumventing cryptographic deniability with remote attestation. Proceedings on Privacy Enhancing Tech- nologies, 3:350–369, 2019.
[37] Keitaro Hashimoto, Shuichi Katsumata, Kris Kwiatkowski, and Thomas Prest. An efficient and generic construction for signal’s handshake (X3DH): post-quantum, state leakage secure, and deni- able. In Juan A. Garay, editor, Public-Key Cryptography - PKC 2021 - 24th IACR International Conference on Practice and Theory of Public Key Cryptography, Virtual Event, May 10-13, 2021, Proceedings, Part II, volume 12711 of Lecture Notes in Computer Science, pages 410–440. Springer, 2021.
[38] Keitaro Hashimoto, Shuichi Katsumata, Kris Kwiatkowski, and Thomas Prest. An efficient and generic construction for signal’s handshake (X3DH): post-quantum, state leakage secure, and deniable. J. Cryptol., 35(3):17, 2022.
[39] Loïs Huguenin-Dumittan and Serge Vaudenay. On ind- qcca security in the rom and its applications: Cpa se- curity is sufficient for tls 1.3. In EUROCRYPT 2022, pages 613–642. Springer, 2022.
[40] Eike Kiltz, Jiaxin Pan, Doreen Riepel, and Magnus Ringerud. Multi-user cdh problems and the concrete security of naxos and hmqv. In Cryptographers’ Track at the RSA Conference, pages 645–671. Springer, 2023.
[41] Duhyeong Kim, Dongwon Lee, Jinyeong Seo, and Yong- soo Song. Toward practical lattice-based proof of knowl- edge from hint-mlwe. In CRYPTO (5), volume 14085 of Lecture Notes in Computer Science, pages 549–580. Springer, 2023.
[42] Brian LaMacchia, Kristin Lauter, and Anton Mitya- gin. Stronger security of authenticated key exchange. In Provable Security: First International Conference, ProvSec 2007, Wollongong, Australia, November 1-2, 2007. Proceedings 1, pages 1–16. Springer, 2007.
[43] Adeline Langlois and Damien Stehlé. Worst-case to average-case reductions for module lattices. Des. Codes Cryptogr., 75(3):565–599, 2015.
[44] Xingye Lu, Man Ho Au, and Zhenfei Zhang. Raptor: A practical lattice-based (linkable) ring signature. In ACNS, volume 11464 of Lecture Notes in Computer Science, pages 110–130. Springer, 2019.
[45] Xingye Lu, Man Ho Au, and Zhenfei Zhang. Raptor: a practical lattice-based (linkable) ring signature. In Ap- plied Cryptography and Network Security: 17th Interna- tional Conference, ACNS 2019, Bogota, Colombia, June 5–7, 2019, Proceedings 17, pages 110–130. Springer, 2019.
[46] Joshua Lund. Technology preview: Sealed sender for sig- nal. https://signal.org/blog/sealed-sender/, 2018. Last visited on 13-09-2023. USENIX Association 33rd USENIX Security Symposium    449
[47] Vadim Lyubashevsky. Fiat-shamir with aborts: Applica- tions to lattice and factoring-based signatures. In ASI- ACRYPT, volume 5912 of Lecture Notes in Computer Science, pages 598–616. Springer, 2009.
[48] Vadim Lyubashevsky and Ngoc Khanh Nguyen. BLOOM: bimodal lattice one-out-of-many proofs and applications. In ASIACRYPT (4), volume 13794 of Lec- ture Notes in Computer Science, pages 95–125. Springer, 2022.
[49] Vadim Lyubashevsky, Chris Peikert, and Oded Regev. On ideal lattices and learning with errors over rings. In EUROCRYPT, volume 6110 of Lecture Notes in Com- puter Science, pages 1–23. Springer, 2010.
[50] Moxie Marlinspike and Trevor Perrin. The x3dh key agreement protocol. Open Whisper Systems, 283, 2016.
[51] Jose Maria Bermudo Mera, Angshuman Karmakar, Tilen Marc, and Azam Soleimanian. Efficient lattice- based inner-product functional encryption. In Public Key Cryptography (2), volume 13178 of Lecture Notes in Computer Science, pages 163–193. Springer, 2022.
[52] Daniele Micciancio and Petros Mol. Pseudorandom knapsacks and the sample complexity of LWE search- to-decision reductions. In CRYPTO, volume 6841 of Lecture Notes in Computer Science, pages 465–484. Springer, 2011.
[53] Chris Peikert. Lattice cryptography for the internet. In PQCrypto, volume 8772 of Lecture Notes in Computer Science, pages 197–219. Springer, 2014.
[54] Trevor Perrin and Moxie Marlinspike. The double ratchet algorithm. GitHub wiki, 2016.
[55] Mario Di Raimondo, Rosario Gennaro, and Hugo Krawczyk. Deniable authentication and key exchange. In Ari Juels, Rebecca N. Wright, and Sabrina De Capi- tani di Vimercati, editors, Proceedings of the 13th ACM Conference on Computer and Communications Security, CCS 2006, Alexandria, VA, USA, October 30 - Novem- ber 3, 2006, pages 400–409. ACM, 2006.
[56] Oded Regev. On lattices, learning with errors, random linear codes, and cryptography. In STOC, pages 84–93. ACM, 2005.
[57] Peter Schwabe, Douglas Stebila, and Thom Wiggers. Post-quantum TLS without handshake signatures. In Jay Ligatti, Xinming Ou, Jonathan Katz, and Giovanni Vigna, editors, CCS ’20: 2020 ACM SIGSAC Confer- ence on Computer and Communications Security, Vir- tual Event, USA, November 9-13, 2020, pages 1461– 1480. ACM, 2020.
[58] Peter W. Shor. Polynominal time algorithms for dis- crete logarithms and factoring on a quantum computer. In Leonard M. Adleman and Ming-Deh A. Huang, ed- itors, Algorithmic Number Theory, First International Symposium, ANTS-I, Ithaca, NY, USA, May 6-9, 1994, Proceedings, volume 877 of Lecture Notes in Computer Science, page 289. Springer, 1994.
[59] Damien Stehlé, Ron Steinfeld, Keisuke Tanaka, and Keita Xagawa. Efficient public key encryption based on ideal lattices. In ASIACRYPT, volume 5912 of Lecture Notes in Computer Science, pages 617–635. Springer, 2009.
[60] Nik Unger and Ian Goldberg. Deniable key exchanges for secure messaging. In Indrajit Ray, Ninghui Li, and Christopher Kruegel, editors, Proceedings of the 22nd ACM SIGSAC Conference on Computer and Commu- nications Security, Denver, CO, USA, October 12-16, 2015, pages 1211–1223. ACM, 2015.
[61] Nik Unger and Ian Goldberg. Improved strongly deni- able authenticated key exchanges for secure messaging. Proc. Priv. Enhancing Technol., 2018(1):21–66, 2018.
[62] US National Security Agency. Announcing the com- mercial national security algorithm suite 2.0. https: //media.defense.gov/2022/Sep/07/2003071834/ -1/-1/0/CSA_CNSA_2.0_ALGORITHMS_.PDF.
[63] Nihal Vatandas, Rosario Gennaro, Bertrand Ithurburn, and Hugo Krawczyk. On the cryptographic deniabil- ity of the signal protocol. In Mauro Conti, Jianying Zhou, Emiliano Casalicchio, and Angelo Spognardi, ed- itors, ACNS 2020, volume 12147 of Lecture Notes in Computer Science, pages 188–209. Springer, 2020.
[64] Tsz Hon Yuen, Muhammed F Esgin, Joseph K Liu, Man Ho Au, and Zhimin Ding. Dualring: generic con- struction of ring signatures with efficient instantiations. In CRYPTO 2021, pages 251–281. Springer, 2021. 450    33rd USENIX Security Symposium USENIX Association
Closed-Form Bounds for DP-SGD against Record-level Inference.
[1] Martín Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In 23rd ACM SIGSAC Conference on Computer and Communications Security, CCS 2016, pages 308–318. ACM, 2016. doi: 10.1145/2976749.2978318.
[2] Borja Balle and Yu-Xiang Wang. Improving the gaus- sian mechanism for differential privacy: Analytical cal- ibration and optimal denoising. In International Con- ference on Machine Learning, pages 394–403. PMLR, 2018.
[3] Wenxuan Bao, Luke A Bauer, and Vincent Bind- schaedler. On the importance of architecture and fea- ture selection in differentially private machine learning. arXiv preprint arXiv:2205.06720, 2022.
[4] SS Barsov and Vladimir V Ul’yanov. Estimates of the proximity of Gaussian measures. Sov. Math., Dokl, 34: 462–466, 1987.
[5] Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and Florian Tramer. Membership infer- ence attacks from ﬁrst principles. In 2022 IEEE Sympo- sium on Security and Privacy (SP), pages 1897–1914. IEEE, 2022.
[6] K. Chatzikokolakis, G. Cherubin, C. Palamidessi, and C. Troncoso. Bayes security: A not so average metric. In 2023 2023 IEEE 36th Computer Security Founda- tions Symposium (CSF) (CSF), pages 159–177. IEEE Computer Society, jul 2023. doi: 10.1109/CSF57540. 2023.00011.
[7] Giovanni Cherubin. Bayes, not naïve: Security bounds on website ﬁngerprinting defenses. Proceedings on Privacy Enhancing Technologies, 2017.
[8] Giovanni Cherubin. Black-box security: measuring black-box information leakage via machine learning. PhD thesis, Royal Holloway, University of London, 2019.
[9] Giovanni Cherubin, Konstantinos Chatzikokolakis, and Catuscia Palamidessi. F-BLEAU: fast black-box leak- age estimation. In 2019 IEEE Symposium on Security and Privacy (SP), pages 835–852. IEEE, 2019.
[10] R Dennis Cook and Sanford Weisberg. Characteriza- tions of an empirical inﬂuence function for detecting inﬂuential cases in regression. Technometrics, 22(4): 495–508, 1980.
[11] Thomas M Cover. Elements of information theory. John Wiley & Sons, 1999.
[12] Luc Devroye, Abbas Mehrabian, and Tommy Reddad. The total variation distance between high-dimensional Gaussians with the same mean. arXiv preprint arXiv:1810.08693 [math.ST], 2018. doi: 10.48550/ ARXIV.1810.08693.
[13] Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy, 2019. URL https://arxiv.org/ abs/1905.02383.
[14] Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Connect the dots: Tighter discrete approximations of privacy loss distributions, 2022. URL https://arxiv.org/abs/2207.04380.
[15] Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Connect the dots: Tighter discrete approximations of privacy loss distributions. arXiv preprint arXiv:2207.04380, 2022.
[16] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attacks that exploit conﬁdence infor- mation and basic countermeasures. In ACM SIGSAC Conference on Computer and Communications Security (CCS), pages 1322–1333. ACM, 2015. doi: 10.1145/ 2810103.2813677.
[17] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Nu- merical composition of differential privacy. Advances in Neural Information Processing Systems, 34:11631– 11642, 2021.
[18] Frank R Hampel. The inﬂuence curve and its role in robust estimation. Journal of the american statistical association, 69(346):383–393, 1974.
[19] John R Hershey and Peder A Olsen. Approximating the kullback leibler divergence between gaussian mixture models. In 2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP’07, volume 4, pages IV–317. IEEE, 2007.
[20] Thomas Humphries, Simon Oya, Lindsey Tulloch, Matthew Rafuse, Ian Goldberg, Urs Hengartner, and Florian Kerschbaum. Investigating membership in- ference attacks under data dependencies. CoRR, abs/2010.12112v3, 2021.
[21] Mahdi Imanparast, Seyed Naser Hashemi, and Ali Mo- hades. Efﬁcient approximation algorithms for point-set diameter in higher dimensions. Journal of Algorithms and Computation, 51(2):47–61, 2019.
[22] Daniel Kifer and Ashwin Machanavajjhala. No free lunch in data privacy. In Proceedings of the 2011 ACM SIGMOD International Conference on Management of data, pages 193–204, 2011. 4832    33rd USENIX Security Symposium USENIX Association
[23] Pang Wei Koh and Percy Liang. Understanding black- box predictions via inﬂuence functions. In Interna- tional conference on machine learning, pages 1885– 1894. PMLR, 2017.
[24] Antti Koskela and Antti Honkela. Computing differen- tial privacy guarantees for heterogeneous compositions using fft, 2021. URL https://arxiv.org/abs/2102. 12412.
[25] Antti Koskela, Joonas Jälkö, Lukas Prediger, and Antti Honkela. Tight differential privacy for discrete-valued mechanisms and for the subsampled gaussian mecha- nism using fft. 2020. doi: 10.48550/ARXIV.2006.07134. URL https://arxiv.org/abs/2006.07134.
[26] Ninghui Li, Wahbeh Qardaji, Dong Su, Yi Wu, and Wein- ing Yang. Membership privacy: A unifying framework for privacy deﬁnitions. In 2013 ACM SIGSAC Confer- ence on Computer and Communications Security, CCS, page 889–900. ACM, 2013. doi: 10.1145/2508859. 2516686.
[27] Saeed Mahloujifar, Alexandre Sablayrolles, Graham Cormode, and Somesh Jha. Optimal membership in- ference bounds for adaptive composition of sampled gaussian mechanisms. arXiv preprint arXiv:2204.06106, 2022.
[28] Ilya Mironov, Kunal Talwar, and Li Zhang. R\’enyi differential privacy of the sampled gaussian mechanism. arXiv preprint arXiv:1908.10530, 2019.
[29] Reza Shokri, Marco Stronati, Congzheng Song, and Vi- taly Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE Symposium on Security and Privacy, S&P, pages 3–18. IEEE, 2017. doi: 10.1109/SP.2017.41.
[30] Geoffrey Smith. On the foundations of quantitative in- formation ﬂow. In International Conference on Founda- tions of Software Science and Computational Structures, pages 288–302. Springer, 2009.
[31] David Sommer, Sebastian Meiser, and Esfandiar Mo- hammadi. Privacy loss classes: The central limit theo- rem in differential privacy. Cryptology ePrint Archive, 2018.
[32] Yu-Xiang Wang, Borja Balle, and Shiva Prasad Ka- siviswanathan. Subsampled rényi differential privacy and analytical moments accountant. In The 22nd In- ternational Conference on Artiﬁcial Intelligence and Statistics, pages 1226–1235. PMLR, 2019.
[33] Andrew Chi-Chih Yao. On constructing minimum span- ning trees in k-dimensional spaces and related problems. SIAM Journal on Computing, 11(4):721–736, 1982.
[34] Samuel Yeom, Irene Giacomelli, Alan Menaged, Matt Fredrikson, and Somesh Jha. Overﬁtting, robustness, and malicious algorithms: A study of potential causes of privacy risk in machine learning. Journal of Computer Security, 28(1):35–70, 2020. doi: 10.3233/JCS-191362.
[35] Ashkan Yousefpour, Igor Shilov, Alexandre Sablay- rolles, Davide Testuggine, Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode, and Ilya Mironov. Opacus: User-friendly differential privacy library in PyTorch. arXiv preprint arXiv:2109.12298, 2021.
[36] Santiago Zanella-Béguelin, Lukas Wutschitz, Shruti Tople, Ahmed Salem, Victor Rühle, Andrew Paverd, Mo- hammad Naseri, and Boris Köpf. Bayesian estimation of differential privacy. arXiv preprint arXiv:2206.05199, 2022.
[37] Wanrong Zhang, Olga Ohrimenko, and Rachel Cum- mings. Attribute privacy: Framework and mechanisms. In Proceedings of the 2022 ACM Conference on Fair- ness, Accountability, and Transparency, pages 757–766, 2022. A Proofs Proposition
[11] and Eq. 13 in [19]): DKL(fM , fN (pµ,σ2C2)) ≤ ∑ b∈{0,1}T πbDKL(fN (µb,σ2C2), fN (pµ,σ2C2)), where the KL divergence between two d-variate Gaussians, respectively centered in µ0 and µ1, is: DKL(fN (µ0,σ2 0), fN (µ1,σ2 1)) =1 2 (µ0 −µ1)⊺Σ−1 1 (µ0 −µ1) +tr(Σ−1 1 Σ0)−ln |Σ0| |Σ1| −T  ; USENIX Association 33rd USENIX Security Symposium    4833 Observe that, for Σ0 = Σ1 = σ2IT, we have tr(Σ−1 1 Σ0) − ln |Σ0| |Σ1| −T =
0. From the above, we obtain: DKL(fM ,fN (pµ,σ2C2)) ≤ ∑ b∈{0,1}T πb 2σ2C2 T ∑ i=1 µ2 i (bi −p)2 ! ≤ ∑ b∈{0,1}T πb 2σ2C2 T ∑ i=1 T max j=1 µ2 j(bi −p)2 ! = ∑ b∈{0,1}T πb 2σ2 T ∑ i=1 b2 i + p2T −2p T ∑ i=1 bi ! = ∑ b∈{0,1}T πb 2σ2 p2T +(1−2p) T ∑ i=1 bi ! = 1 2σ2  p2T ∑ b∈{0,1}T πb +(1−2p) ∑ b∈{0,1}T πb|b|   = 1 2σ2 pT −p2T  We used the fact that b2 i = bi. For a ﬁxed T, the goodness of this approximation depends on the choices of σ and of the sampling rate p. In our main result, T is the number of DP-SGD steps. The result matches expectations: if one wants to run DP-SGD for longer and retain strong security, one either needs to increase the noise multiplier or reduce the sampling rate. In Figure 2, we compare the approximation error between the two distributions for a varying ratio between noise and sampling rate parameters. We observe that Proposition 4 holds when the ratio is small. In particular, for realistic regimes with p/σ < 10−3, we observe a negligible approximation error (< 10−4). In Section 4, we observe that these values for the parameters are not only practical; they are recommended to achieve stronger levels of security against MIA threats. Theorem
6. Assume that f is a bijection, and let ∆f be de- ﬁned as in Equation (3). The Bayes security of DP-SGD with respect to the record-level property inference threat described in Section 3 is: β∗(PO|S) ≥1−erf  p ∆f 2 √ 2σC  −O √pT σ  . Proof. By Corollary 2, the relation between Bayes security and the total variation Proposition 3, and Theorem 1: β∗(PO|S) ≥β∗(PG|S) ≥1− max s0,s1∈dom(S)tv(PG|S=s0,PG|S=s1) We now determine the total variation term. Observe the following basic consequence of the triangle inequality. Let νa and ξa be two distributions parameterized by a ∈{0,1}. Then: tv(ν0,ν1) ≤tv(ξ0,ξ1)+tv(ν0,ξ0)+tv(ν1,ξ1). We use this to replace the Gaussians mixture PG|S with a Gaus- sian, replacing the two pairwise distances tv(ν0,ξ0),tv(ν1,ξ1) with an error term as deﬁned in Proposition 4. For any two s0,s1 ∈dom(S), we have: tv(PG|S=s0,PG|S=s1) =tv( ∑ b∈{0,1}T cbPG|B=b,S=s0, ∑ b∈{0,1}T cbPG|B=b,S=s1) ≤tv(N (p¯g(f −1(s0)),σ2C2),N (p¯g(f −1(s1)),σ2C2)) +O √pT σ  =erf  p∥¯g(f −1(s0))−¯g(f −1(s1))∥F 2 √ 2σC  +O √pT σ  In the ﬁrst step, we used the above consequence of the triangle inequality. In the second step, we used the fact that PG|B=b,S is a Gaussian distribution and applied Corollary 5. Proposition
0. If the mechanism is β∗-secure then for every attacker: TPR ≤1+FPR−β∗ if π ≤1/2 TPR ≤ π 1−π (1+FPR−β∗) otherwise. We have equality for a uniform prior, π = 1/2. Proof. Chatzikokolakis et al.
[6] show that Bayes security is the minimum of the ratio between the probability that the attacker guesses incorrectly having access to the mechanism, Pr[Attacker(π,M (S)) ̸= S], and the probability that the at- tacker guesses incorrectly without access to the mechanism, Pr[Attacker(π) ̸= S]; that is: β∗≤Pr[Attacker(π,M (S)) ̸= S] Pr[Attacker(π) ̸= S] ∀π ∈(0,1). We rewrite the above in terms of TPR and FPR. Say the mechanism is run k times, each time for a secret S sampled according to the prior distribution π. Let FP and TP be the 4834    33rd USENIX Security Symposium USENIX Association count of false positives and false negatives across these k trials. Then: Pr[Attacker(π,M (S)) ̸= S] = FP+FN k Pr[Attacker(π) ̸= S] = min(P,N) k By combining the above, we have: β∗≤Pr[Attacker(π,M (S)) ̸= S] Pr[Attacker(π) ̸= S] = k min(P,N) FP+FN k  = P min(P,N)(FPR+(1−TPR)) where P = πk and N = (1 −π)k are the number of positive and negative samples, respectively. The proof is concluded by considering separately the cases P ≤N and P > N. Before discussing the proofs for Corollary 7 and Corol- lary 10, we deﬁne the Frobenius norm. Deﬁnition
7. The Bayes security of DP-SGD against record- level MIA (Game 2) is: β∗≥1−erf p √ T √ 2σ ! −O √pT σ  . Proof. Observe that in the MIA threat model (Game 2) f(z∗ s) = s is a bijection. Then: ∆f = max z∗ 0,z∗ 1∈D∥¯g(z∗ 0)−¯g(z∗ 1)∥F = max z∗ 0,z∗ 1∈D s T ∑ t=1 ∥¯gt(z∗ 0)−¯gt(z∗ 1)∥2 ≤2C √ T . Applying Theorem 6 concludes the proof. Corollary
10. The Bayes security of DP-SGD against AI is: β∗(PO|S) ≥1−erf  p ∥R∥ 2 √ 2σC  −O √pT σ  , where R = (R1,...,RT) with Rt = max z∗∈Lt max s0,s1∈A ∥¯gt((ϕ(z∗),s0))−¯gt((ϕ(z∗),s1))∥, where Lt is the batch sampled at step t. Proof. Observe that f is a bijection: as per Game 3, for every z∗, there is exactly one value s ∈A such that f(z∗) = s. We bound ∆f as deﬁned in Equation (3): ∆f ≤ max s0,s1∈A,z∗∈D∥¯g(ϕ(z∗) | s0)−¯g(ϕ(z∗) | s1)∥F = max s0,s1∈A,z∗∈D s T ∑ t=1 ∥¯gt(ϕ(z∗) | s0)−¯gt(ϕ(z∗) | s1)∥2 ≤ T ∑ t=1 max s0,s1∈A,z∗∈D∥¯gt(ϕ(z∗) | s0)−¯gt(ϕ(z∗) | s1)∥ We then apply Theorem
10. Results for p = 0.001 (Figure 4) are reported again, for comparison. We observe that our observations hold for these parameters: the approximation error is small when σ ≥1; in general, a larger sampling rate p may further increase this error, but not signiﬁcatively. We also note that the PLD accountant failed to provide a bound for p = 0.0001 and σ = 0.5. Further, we observe that for the same sample rate, the approximation increases for a larger σ. We attribute this to numerical errors in the PLD accountant. USENIX Association 33rd USENIX Security Symposium    4835 Figure 10: Approximation error of the PLD accountant for different sample rates p and noise multipliers σ. 4836    33rd USENIX Security Symposium USENIX Association
Mempool Privacy via Batched Threshold Encryption: Attacks and Defenses.
[1] Guillermo Angeris, Alex Evans, and Tarun Chitra. A note on bundle profit maximization. Stanford University, 2021.
[2] arkworks contributors. arkworks zksnark ecosystem. https://arkworks.rs, 2022.
[3] Judit Bar-Ilan and Donald Beaver. Non-cryptographic fault-tolerant computing in constant number of rounds of interaction. In Piotr Rudnicki, editor, 8th ACM PODC, pages 201–209. ACM, August 1989.
[4] Carsten Baum, Bernardo David, and Tore Kasper Fred- eriksen. P2DEX: privacy-preserving decentralized cryp- tocurrency exchange. In Kazue Sako and Nils Ole Tip- penhauer, editors, Applied Cryptography and Network Security - 19th International Conference, 2021.
[5] Joseph Bebel and Dev Ojha. Ferveo: Threshold decryp- tion for mempool privacy in BFT networks. Cryptol- ogy ePrint Archive, Report 2022/898, 2022. https: //eprint.iacr.org/2022/898.
[6] Zuzana Beerliová-Trubíniová and Martin Hirt. Perfectly- secure MPC with linear communication complexity. In Ran Canetti, editor, TCC 2008, volume 4948 of LNCS, pages 213–230. Springer, Heidelberg, March 2008.
[7] Mihir Bellare, Anand Desai, David Pointcheval, and Phillip Rogaway. Relations among notions of security for public-key encryption schemes. In Hugo Krawczyk, editor, CRYPTO’98, volume 1462 of LNCS, pages 26–
45. Springer, Heidelberg, August 1998.
[8] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable, transparent, and post- quantum secure computational integrity. Cryptology ePrint Archive, Report 2018/046, 2018. https:// eprint.iacr.org/2018/046.
[9] Daniel J. Bernstein. Curve25519: New Diffie-Hellman speed records. In Moti Yung, Yevgeniy Dodis, Aggelos Kiayias, and Tal Malkin, editors, PKC 2006, volume 3958 of LNCS, pages 207–228. Springer, Heidelberg, April 2006.
[10] Dan Boneh, Joseph Bonneau, Benedikt Bünz, and Ben Fisch. Verifiable delay functions. In Hovav Shacham and Alexandra Boldyreva, editors, CRYPTO 2018, Part I, volume 10991 of LNCS, pages 757–788. Springer, Hei- delberg, August 2018.
[11] Dan Boneh and Matthew K. Franklin. Identity-based encryption from the Weil pairing. In Joe Kilian, editor, CRYPTO 2001, volume 2139 of LNCS, pages 213–229. Springer, Heidelberg, August 2001.
[12] Dan Boneh, Kevin Lewi, Hart William Montgomery, and Ananth Raghunathan. Key homomorphic PRFs and their applications. In Ran Canetti and Juan A. Garay, editors, CRYPTO 2013, Part I, volume 8042 of LNCS, pages 410–428. Springer, Heidelberg, August 2013.
[13] Ran Canetti and Shafi Goldwasser. An efficient thresh- old public key cryptosystem secure against adaptive chosen ciphertext attack. In Jacques Stern, editor, EU- ROCRYPT’99, volume 1592 of LNCS, pages 90–106. Springer, Heidelberg, May 1999.
[14] Agostino Capponi, Ruizhe Jia, and Ye Wang. The evo- lution of blockchain: from lit to dark. arXiv preprint, 2022.
[15] Koji Chida, Daniel Genkin, Koki Hamada, Dai Ikarashi, Ryo Kikuchi, Yehuda Lindell, and Ariel Nof. Fast large- scale honest-majority MPC for malicious adversaries. In Hovav Shacham and Alexandra Boldyreva, editors, CRYPTO 2018, Part III, volume 10993 of LNCS, pages 34–64. Springer, Heidelberg, August 2018.
[16] Arka Rai Choudhuri, Sanjam Garg, Julien Piet, and Guru-Vamsi Policharla. Mempool privacy via batched threshold encryption: Attacks and defenses. Cryptol- ogy ePrint Archive, Paper 2024/669, 2024. https: //eprint.iacr.org/2024/669.
[17] Michele Ciampi, Muhammad Ishaq, Malik Magdon- Ismail, Rafail Ostrovsky, and Vassilis Zikas. Fairmm: A fast and frontrunning-resistant crypto market-maker. IACR Cryptology ePrint Archive, 2021.
[18] Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li, Xueyuan Zhao, Iddo Bentov, Lorenz Breidenbach, and Ari Juels. Flash boys 2.0: Frontrunning in decentral- ized exchanges, miner extractable value, and consensus instability. In 2020 IEEE Symposium on Security and Privacy, pages 910–927. IEEE Computer Society Press, May 2020. 3526    33rd USENIX Security Symposium USENIX Association
[19] Ivan Damgård and Jesper Buus Nielsen. Scalable and unconditionally secure multiparty computation. In Al- fred Menezes, editor, CRYPTO 2007, volume 4622 of LNCS, pages 572–590. Springer, Heidelberg, August 2007.
[20] Isaac David, Liyi Zhou, Kaihua Qin, Dawn Song, Lorenzo Cavallaro, and Arthur Gervais. Do you still need a manual smart contract audit?, 2023.
[21] Alfredo De Santis, Yvo Desmedt, Yair Frankel, and Moti Yung. How to share a function securely. In 26th ACM STOC, pages 522–533. ACM Press, May 1994.
[22] Christian Decker and Roger Wattenhofer. Information propagation in the bitcoin network. In IEEE P2P 2013 Proceedings, pages 1–10, 2013.
[23] Yvo Desmedt and Yair Frankel. Threshold cryptosys- tems. In Gilles Brassard, editor, CRYPTO’89, volume 435 of LNCS, pages 307–315. Springer, Heidelberg, Au- gust 1990.
[24] Nico Döttling, Lucjan Hanzlik, Bernardo Magri, and Stella Wohnig. McFly: Verifiable encryption to the fu- ture made practical. Cryptology ePrint Archive, Report 2022/433, 2022. https://eprint.iacr.org/2022/ 433.
[25] Taher ElGamal. On computing logarithms over finite fields. In Hugh C. Williams, editor, CRYPTO’85, vol- ume 218 of LNCS, pages 396–402. Springer, Heidelberg, August 1986.
[26] Shayan Eskandari, Seyedehmahsa Moosavi, and Jeremy Clark. Sok: Transparent dishonesty: front-running at- tacks on blockchain. In International Conference on Financial Cryptography and Data Security, 2019.
[27] Dankrad Feist and Dmitry Khovratovich. Fast amor- tized KZG proofs. Cryptology ePrint Archive, Report 2023/033, 2023. https://eprint.iacr.org/2023/ 033.
[28] Yair Frankel. A practical protocol for large group ori- ented networks. In Jean-Jacques Quisquater and Joos Vandewalle, editors, EUROCRYPT’89, volume 434 of LNCS, pages 56–61. Springer, Heidelberg, April 1990.
[29] Georg Fuchsbauer, Antoine Plouviez, and Yannick Seurin. Blind schnorr signatures and signed ElGamal en- cryption in the algebraic group model. In Anne Canteaut and Yuval Ishai, editors, EUROCRYPT 2020, Part II, vol- ume 12106 of LNCS, pages 63–95. Springer, Heidelberg, May 2020.
[30] Sanjam Garg, Craig Gentry, Amit Sahai, and Brent Wa- ters. Witness encryption and its applications. In Dan Boneh, Tim Roughgarden, and Joan Feigenbaum, edi- tors, 45th ACM STOC, pages 467–476. ACM Press, June 2013.
[31] Craig Gentry, Shai Halevi, and Vadim Lyubashevsky. Practical non-interactive publicly verifiable secret shar- ing with thousands of parties. In Orr Dunkelman and Ste- fan Dziembowski, editors, EUROCRYPT 2022, Part I, volume 13275 of LNCS, pages 458–487. Springer, Hei- delberg, May / June 2022.
[32] Arthur Gervais, Ghassan O Karame, Karl Wüst, Vasileios Glykantzis, Hubert Ritzdorf, and Srdjan Cap- kun. On the security and performance of proof of work blockchains. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, 2016.
[33] Vipul Goyal, Abhiram Kothapalli, Elisaweta Masserova, Bryan Parno, and Yifan Song. Storing and retrieving secrets on a blockchain. In Goichiro Hanaoka, Junji Shikata, and Yohei Watanabe, editors, PKC 2022, Part I, volume 13177 of LNCS, pages 252–282. Springer, Hei- delberg, March 2022.
[34] Vipul Goyal, Yifan Song, and Chenzhi Zhu. Guaranteed output delivery comes free in honest majority MPC. In Daniele Micciancio and Thomas Ristenpart, editors, CRYPTO 2020, Part II, volume 12171 of LNCS, pages 618–646. Springer, Heidelberg, August 2020.
[35] Jens Groth. Non-interactive distributed key generation and key resharing. Cryptology ePrint Archive, Report 2021/339, 2021. https://eprint.iacr.org/2021/ 339.
[36] Lioba Heimbach and Roger Wattenhofer. Eliminating sandwich attacks with the help of game theory. arXiv preprint, 2022.
[37] Aljosha Judmayer, Nicholas Stifter, Philipp Schindler, and Edgar R. Weippl. Estimating (miner) extractable value is hard, let’s go shopping! IACR Cryptology ePrint Archive, 2021.
[38] Aniket Kate, Easwar Vivek Mangipudi, Pratyay Mukher- jee, Hamza Saleem, and Sri Aravinda Krishnan Thya- garajan. Non-interactive vss using class groups and application to dkg. Cryptology ePrint Archive, Paper 2023/451, 2023. https://eprint.iacr.org/2023/ 451.
[39] Aniket Kate, Gregory M. Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials and their ap- plications. In Masayuki Abe, editor, ASIACRYPT 2010, volume 6477 of LNCS, pages 177–194. Springer, Hei- delberg, December 2010. USENIX Association 33rd USENIX Security Symposium    3527
[40] Alireza Kavousi, Duc V. Le, Philipp Jovanovic, and George Danezis. Blindperm: Efficient mev mitigation with an encrypted mempool and permutation. Cryp- tology ePrint Archive, Paper 2023/1061, 2023. https: //eprint.iacr.org/2023/1061.
[41] Mahimna Kelkar, Soubhik Deb, Sishan Long, Ari Juels, and Sreeram Kannan. Themis: Fast, strong order- fairness in byzantine consensus. IACR Cryptology ePrint Archive, 2021.
[42] Mahimna Kelkar, Fan Zhang, Steven Goldfeder, and Ari Juels. Order-fairness for byzantine consensus. In International Cryptology Conference, 2020.
[43] Klaus Kursawe. Wendy, the good little fairness wid- get: Achieving order fairness for blockchains. In Pro- ceedings of the 2nd ACM Conference on Advances in Financial Technologies, 2020.
[44] Tom CW Lin. The new market manipulation. Emory LJ, 66:1253, 2016.
[45] Varun Madathil, Sri Aravinda Krishnan Thyagarajan, Dimitrios Vasilopoulos, Lloyd Fournier, Giulio Mala- volta, and Pedro Moreno-Sanchez. Cryptographic oracle-based conditional payments. In NDSS. The Inter- net Society, 2023.
[46] Dahlia Malkhi and Pawel Szalachowski. Maximal ex- tractable value (mev) protection on a dag, 2022.
[47] Conor McMenamin, Vanesa Daza, and Matthias Fitzi. Fairtradex: A decentralised exchange preventing value extraction. arXiv preprint, 2022.
[48] Julien Piet, Jaiden Fairoze, and Nicholas Weaver. Ex- tracting godl
[sic] from the salt mines: Ethereum miners extracting value, 2022.
[49] Julien Piet, Vivek Nair, and Sanjay Subramanian. Mevade: An mev-resistant blockchain design. In 2023 IEEE International Conference on Blockchain and Cryp- tocurrency (ICBC), pages 1–9. IEEE, 2023.
[50] Julien Piet, Vivek Nair, and Sanjay Subramanian. Mevade: An mev-resistant blockchain design. In IEEE International Conference on Blockchain and Cryptocur- rency (ICBC), 2023.
[51] Kaihua Qin, Liyi Zhou, and Arthur Gervais. Quantifying blockchain extractable value: How dark is the forest? arXiv preprint, 2021.
[52] Dan Robinson. Ethereum is a dark for- est. https://www.paradigm.xyz/2020/08/ ethereum-is-a-dark-forest, 2020. Accessed: 2022-02-16.
[53] Antoine Rondelet and Quintus Kilbourn. Threshold encrypted mempools: Limitations and considerations, 2023.
[54] samczsun. Escaping the dark forest. https: //samczsun.com/escaping-the-dark-forest/, 2020. Accessed: 2022-02-16.
[55] Claus-Peter Schnorr. Efficient signature generation by smart cards. Journal of Cryptology, 4(3):161–174, Jan- uary 1991.
[56] Berry Schoenmakers. A simple publicly verifiable secret sharing scheme and its application to electronic. In Michael J. Wiener, editor, CRYPTO’99, volume 1666 of LNCS, pages 148–164. Springer, Heidelberg, August 1999.
[57] Victor Shoup and Rosario Gennaro. Securing threshold cryptosystems against chosen ciphertext attack. Journal of Cryptology, 15(2):75–96, March 2002.
[58] Shutter Network contributors. The shutter network. https://shutter.network, 2021.
2. https://blog.shutter. network/announcing-rolling-shutter/, 2022.
[60] Christof Ferreira Torres, Ramiro Camino, et al. Frontrun- ner jones and the raiders of the dark forest: An empirical study of frontrunning on the ethereum blockchain. In 30th USENIX Security Symposium, 2021.
[61] Ye Wang, Yan Chen, Shuiguang Deng, and Roger Wat- tenhofer. Cyclic arbitrage in decentralized exchange markets. Available at SSRN 3834535, 2021.
[62] Lloyd R Welch and Elwyn R Berlekamp. Error correc- tion for algebraic block codes, December 30 1986. US Patent 4,633,470.
[63] Liyi Zhou, Kaihua Qin, Antoine Cully, Benjamin Livshits, and Arthur Gervais. On the just-in-time discov- ery of profit-generating transactions in defi protocols. In 2021 IEEE Symposium on Security and Privacy (SP), 2021.
[64] Liyi Zhou, Kaihua Qin, and Arthur Gervais. A2mm: Mitigating frontrunning, transaction reordering and con- sensus instability in decentralized exchanges. arXiv preprint, 2021.
[65] Liyi Zhou, Kaihua Qin, Christof Ferreira Torres, Duc V Le, and Arthur Gervais. High-frequency trading on decentralized on-chain exchanges. In 2021 IEEE Sym- posium on Security and Privacy (SP), 2021. 3528    33rd USENIX Security Symposium USENIX Association A Security Proof Due to space constraints, we defer the security proof to the full version of the paper [16]. Below, we introduce the q-SBDHT assumption (Definition 4) and the main theorem (Theorem 5). We prove security with guaranteed output delivery against a fully malicious adversary corrupting up to t < n/3 members of the committee and any number of users creating cipher- texts. We note that it is also possible to upgrade the protocol to t = n/2 using standard techniques of publishing commit- ments to secret keys of parties and proving that partial de- cryptions were computed correctly. For instance, one could use the KZG commitment scheme itself and prove that the computation was carried out using a zkSNARK such as the Halo2/STARK
6. We note that the n/3 threshold arises from the fact that adversarial committee members may send incorrect shares during the batch decryption procedure. One can also allow the adversary to corrupt < n/2 parties and prove that the protocol emulates the ideal functionality with abort. To achieve guaranteed output delivery in this setting we can use standard techniques (at the cost of concrete efficiency) of attaching proofs that all parties carried out their local com- putation correctly, thereby allowing us to successfully recover secrets from threshold secret sharing, even if n/2−1 corrupt parties behave maliciously and provide incorrect shares. In order to verify proofs of correct local computation, the state- ments need to be ‘public’. Proving correct computation over private shares is often done by broadcasting private shares to the committee by encrypting to the committee member in question, but as this is not relevant to our contribution, we ignore such details from this work and refer the reader to relevant multiparty computation works for more details. USENIX Association 33rd USENIX Security Symposium    3529
Leakage-Abuse Attacks Against Structured Encryption for SQL.
{'crypto': 13, 'security': 25, 'news': 1, 'policy_gov': 0, 'technical_doc': 0, 'other': 13, 'source_code': 0, 'vendor_doc': 0, 'industry_blog': 0}


Formal verification of the PQXDH Post-Quantum key agreement protocol for end-to-end secure messaging.
{'crypto': 14, 'security': 13, 'news': 0, 'policy_gov': 1, 'technical_doc': 1, 'other': 13, 'source_code': 4, 'vendor_doc': 0, 'industry_blog': 0}


Notus: Dynamic Proofs of Liabilities from Zero-knowledge RSA Accumulators.
{'crypto': 18, 'security': 29, 'news': 0, 'policy_gov': 1, 'technical_doc': 1, 'other': 21, 'source_code': 1, 'vendor_doc': 0, 'industry_blog': 0}


GoFetch: Breaking Constant-Time Cryptographic Implementations Using Data Memory-Dependent Prefetchers.
{'crypto': 1, 'security': 5, 'news': 0, 'policy_gov': 1, 'technical_doc': 0, 'other': 0, 'source_code': 0, 'vendor_doc': 0, 'industry_blog': 0}


Single Pass Client-Preprocessing Private Information Retrieval.
{'crypto': 10, 'security': 9, 'news': 0, 'policy_gov': 1, 'technical_doc': 0, 'other': 12, 'source_code': 4, 'vendor_doc': 0, 'industry_blog': 0}


ElectionGuard: a Cryptographic Toolkit to Enable Verifiable Elections.
{'crypto': 1, 'security': 7, 'news': 1, 'policy_gov': 1, 'technical_doc': 0, 'other': 0, 'source_code': 0, 'vendor_doc': 0, 'industry_blog': 0}


K-Waay: Fast and Deniable Post-Quantum X3DH without Ring Signatures.
{'crypto': 39, 'security': 11, 'news': 0, 'policy_gov': 1, 'technical_doc': 0, 'other': 14, 'source_code': 0, 'vendor_doc': 0, 'industry_blog': 0}


Closed-Form Bounds for DP-SGD against Record-level Inference.
{'crypto': 10, 'security': 9, 'news': 0, 'policy_gov': 1, 'technical_doc': 0, 'other': 25, 'source_code': 0, 'vendor_doc': 0, 'industry_blog': 0}


Mempool Privacy via Batched Threshold Encryption: Attacks and Defenses.
{'crypto': 36, 'security': 6, 'news': 0, 'policy_gov': 2, 'technical_doc': 0, 'other': 23, 'source_code': 0, 'vendor_doc': 0, 'industry_blog': 1}


nathanielclizbe@MacBookAir citation-analysis % 
